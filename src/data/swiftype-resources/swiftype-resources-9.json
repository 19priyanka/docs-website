{
  "/docs/browser/new-relic-browser/troubleshooting/app-server-requests-greatly-outnumber-browser-pageview-transactions": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.93292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.64916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-01T23:27:10Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.71362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.93286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.649635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Troubleshooting session trace collection",
        "Problem",
        "Solution"
      ],
      "title": "Troubleshooting session trace collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "3b15d44fe2d49e081cbf39fb86da752f0726b6c8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshooting-session-trace-collection/",
      "published_at": "2021-10-01T23:30:14Z",
      "updated_at": "2021-07-22T02:20:45Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You're not seeing session traces for your browser application. Solution If your application is instrumented with APM and other features associated with the Pro browser agent are working, follow these steps: Check if you are using multiple names for your application. Session traces are written only to the primary application. If you are using multiple names, check your APM application names to verify that the app is listed first. If the application is not listed first, look for session traces in the application name listed first instead. Other reasons that you may not see session trace data include: The end users are not using browsers that support the Resource Timing API. The end users cannot post data to the /resources endpoint on bam.nr-data.net.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.024086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshooting</em> session trace collection",
        "sections": "<em>Troubleshooting</em> session trace collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem You&#x27;re not seeing session traces for your <em>browser</em> application. Solution If your application is instrumented with APM and other features associated with the Pro <em>browser</em> agent are working, follow these steps: Check if you are using multiple names for your application. Session traces"
      },
      "id": "603e902c28ccbca1adeba793"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/browser-javascript-injection-causes-problems-page": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.93286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.649635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-01T23:27:10Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.714066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/get-browser-side-troubleshooting-details-har-file": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.9328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.64963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-01T23:27:10Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.714066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/not-seeing-specific-page-or-endpoint-names-browser-data": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.9328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.64963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-01T23:27:10Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.714066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/third-party-js-errors-missing-stack-traces": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.93274,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.64963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-01T23:27:10Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.714066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.93274,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.64963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-01T23:27:10Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.714066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/troubleshooting-session-trace-collection": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.93268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.64963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-01T23:27:10Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.714066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/view-detailed-error-logs-browser": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-01T23:08:02Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.93268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-01T12:31:02Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.64963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-01T23:27:10Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.714066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring": [
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-10-01T23:03:42Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.37326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "New Relic <em>browser</em> <em>monitoring</em> has a <em>single</em>-<em>page</em> application (SPA) <em>monitoring</em> feature that provides deeper visibility and actionable insights into real user interactions with <em>single</em>-<em>page</em> apps, and for any <em>app</em> that uses AJAX requests. In addition to <em>monitoring</em> route changes automatically, our SPA API"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-10-01T23:03:42Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.47203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-01T23:04:33Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.31592,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-10-01T23:02:40Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.01671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-10-01T23:03:42Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.47203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-01T23:04:33Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.31592,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-10-01T23:02:40Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.01671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-10-01T23:03:42Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.37326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "New Relic <em>browser</em> <em>monitoring</em> has a <em>single</em>-<em>page</em> application (SPA) <em>monitoring</em> feature that provides deeper visibility and actionable insights into real user interactions with <em>single</em>-<em>page</em> apps, and for any <em>app</em> that uses AJAX requests. In addition to <em>monitoring</em> route changes automatically, our SPA API"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-01T23:04:33Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.31592,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-10-01T23:02:40Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.65968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-10-01T23:03:42Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.32785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " your <em>app</em>&#x27;s <em>page</em> loads and route changes, and be able to solve bottlenecks and <em>troubleshoot</em> errors. For more about how New Relic handles SPA data, see Understand SPA data collection. <em>Browser</em> SPA features Here is a summary of SPA <em>monitoring</em> features: <em>Single</em>-<em>page</em> <em>app</em> <em>monitoring</em> Take advantage"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-10-01T23:03:42Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.97673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection": [
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-10-01T23:06:15Z",
      "updated_at": "2021-07-09T10:04:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by browser interaction name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line shows when the window load event is fired. This corresponds to the traditional page load timing measured by the browser agent without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.45099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-10-01T23:04:32Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.08281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-01T23:04:33Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.39117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api": [
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-10-01T23:06:15Z",
      "updated_at": "2021-07-09T10:04:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by browser interaction name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line shows when the window load event is fired. This corresponds to the traditional page load timing measured by the browser agent without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.45099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-10-01T23:04:32Z",
      "updated_at": "2021-07-09T08:08:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, browser initiates monitoring but then discards them. If these interactions do lead to a route change, browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.43242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-01T23:04:33Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.39116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui": [
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-10-01T23:04:32Z",
      "updated_at": "2021-07-09T08:08:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, browser initiates monitoring but then discards them. If these interactions do lead to a route change, browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.43242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-10-01T23:04:32Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.08281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-01T23:04:33Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.39116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.70248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.70236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.69725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.70248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.70236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.69725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.70242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.7023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.69719,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-01T08:28:37Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-executable-file-json-specifications": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.8636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.8636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-01T08:28:37Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1866,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.8635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format": [
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.8635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-01T08:28:37Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.18655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.87042,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.86343,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes": [
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-01T08:28:37Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.12927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.38437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.38426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data": [
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-01T08:28:37Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.12921,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-01T08:28:39Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.38432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-01T12:33:16Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.3842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    }
  ],
  "/docs/distributed-tracing/concepts/distributed-tracing-planning-guide": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-10-01T10:17:14Z",
      "updated_at": "2021-07-22T05:57:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us or, if you're using Infinite Tracing, you'd probably send us all your trace data and use our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans is made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.22125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.2117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and <em>get</em> <em>started</em> quickly, go to <em>Start</em> reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (Infinite <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-10-01T10:16:08Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.02583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick <em>start</em>. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    }
  ],
  "/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works": [
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.2117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and <em>get</em> <em>started</em> quickly, go to <em>Start</em> reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (Infinite <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-10-01T10:15:09Z",
      "updated_at": "2021-07-09T04:30:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.68497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " is enabled, with a link to the associated transaction. With <em>distributed</em> <em>tracing</em> enabled, it will display the service&#x27;s URL. If you wanted to <em>get</em> more detail about <em>trace</em> activity, you would go to the <em>Distributed</em> <em>tracing</em> UI page and examine that <em>trace</em>. Cross-application <em>tracing</em> will be disabled"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-10-01T10:16:08Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.02583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick <em>start</em>. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    }
  ],
  "/docs/distributed-tracing/concepts/introduction-distributed-tracing": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-10-01T10:17:14Z",
      "updated_at": "2021-07-22T05:57:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us or, if you're using Infinite Tracing, you'd probably send us all your trace data and use our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans is made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.22124,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.2117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and <em>get</em> <em>started</em> quickly, go to <em>Start</em> reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (Infinite <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-10-01T10:15:09Z",
      "updated_at": "2021-07-09T04:30:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.68497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " is enabled, with a link to the associated transaction. With <em>distributed</em> <em>tracing</em> enabled, it will display the service&#x27;s URL. If you wanted to <em>get</em> more detail about <em>trace</em> activity, you would go to the <em>Distributed</em> <em>tracing</em> UI page and examine that <em>trace</em>. Cross-application <em>tracing</em> will be disabled"
      },
      "id": "6072a60564441f3a629d8535"
    }
  ],
  "/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.84106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up Infinite <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:16:08Z",
      "updated_at": "2021-04-11T07:33:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.6436,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-01T10:24:48Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.8351,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you <em>enable</em> <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer troubleshooting errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:16:08Z",
      "updated_at": "2021-04-15T22:20:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Istio, Kamon, OpenCensus, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.93259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you install a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:16:08Z",
      "updated_at": "2021-04-11T07:33:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.6436,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-01T10:24:48Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.83508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you <em>enable</em> <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer troubleshooting errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up Infinite <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:16:08Z",
      "updated_at": "2021-04-15T22:20:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Istio, Kamon, OpenCensus, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.93259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you install a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-01T10:24:48Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.83508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you <em>enable</em> <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer troubleshooting errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/distributed-tracing/enable-configure/quick-start": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 745.3085,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Quick</em> <em>start</em> for standard <em>distributed</em> <em>tracing</em> (recommended):",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of <em>distributed</em> <em>tracing</em>: <em>Quick</em> <em>start</em> for standard <em>distributed</em> <em>tracing</em> (recommended): A fast way to get started Infinite <em>Tracing</em>: An advanced alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "87eeada741d7f22204b37e7d6a906b9546ab8d4a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-10-06T21:51:43Z",
      "updated_at": "2021-10-06T21:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.561516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has <em>distributed</em> <em>tracing</em> enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-10-01T10:21:46Z",
      "updated_at": "2021-08-26T14:11:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry, OpenCensus, others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.55484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up Infinite <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> data to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/index": [
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "87eeada741d7f22204b37e7d6a906b9546ab8d4a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-10-06T21:51:43Z",
      "updated_at": "2021-10-06T21:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 893.3727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has <em>distributed</em> <em>tracing</em> enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-10-01T10:16:08Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> data, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect data as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "image": "https://docs.newrelic.com/static/f487e8c287d614c494f56bd35fd38bb5/c1b63/arrow-step-diagram-trans.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/quick-start/",
      "sections": [
        "Distributed tracing quick start"
      ],
      "published_at": "2021-10-01T10:17:15Z",
      "title": "Distributed tracing quick start",
      "updated_at": "2021-09-14T05:45:31Z",
      "type": "docs",
      "external_id": "f9f4aa287602eee82a0eb7d15775d033ada26d63",
      "document_type": "page",
      "popularity": 1,
      "body": "To set up distributed tracing, you'll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you'll need this information in the next step). If you have an environment diagram like the following, you could use it to create a list of services handling requests: Instrument services: Instrument each service you identify so it can send your trace data. Some tools, such as APM agents, instrument services automatically, while other tools require you to insert some code in the services. Click the icon below for instrumentation steps: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Browser monitoring Mobile monitoring AWS Lambda Functions Istio Kamon OpenTelemetry X-Ray Zipkin format: custom integration New Relic format: custom integration View traces: After you instrument the services, generate some traffic in your application, and then go to the New Relic UI to see your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em> quick start",
        "sections": "<em>Distributed</em> <em>tracing</em> quick start",
        "body": "To set up <em>distributed</em> <em>tracing</em>, you&#x27;ll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you&#x27;ll need this information in the next step). If you have an environment diagram like"
      },
      "id": "6072a60564441f2f6f9d8541"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-proxy-support": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.99738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.54451,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-07-27T05:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.67526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-random-trace-filter": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.99738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.54451,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-07-27T05:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.67526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-span-attribute-trace-filter": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.99734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.5445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-07-27T05:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.67526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-trace-observer-monitoring": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.9973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.5445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-07-27T05:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.67525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.9973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.5445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-01T10:22:41Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.59703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/set-trace-observer": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.99728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.54448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-07-27T05:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.67525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/other-requirements/infinite-tracing-configuring-ssl-java-7-8": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.99728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.54448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-07-27T05:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.67525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/trace-api/introduction-trace-api": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Data limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-10-01T10:23:56Z",
      "updated_at": "2021-08-27T14:05:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via HTTPS POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires a license key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Data limits Distributed tracing rate limits are set per account and data type. For details about data limits, see New Relic data usage limits and policies. When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.44656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "). Infinite <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Report traces via the Trace API (New Relic format)",
        "Get started",
        "Send sample trace payload (non-Infinite Tracing)",
        "Tip",
        "Trace API payload (New Relic format)",
        "The Span object in the spans array",
        "The common object (optional)",
        "Highly recommended attributes",
        "Reserved attributes",
        "Other attributes",
        "Explore more about distributed tracing:"
      ],
      "title": "Report traces via the Trace API (New Relic format)",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "7b6be23c78b9a06ebf71671cc69590b4ac4b3311",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api/",
      "published_at": "2021-10-01T10:22:41Z",
      "updated_at": "2021-08-26T14:10:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send traces in our general format, aka new-relic format. (To send Zipkin-format data, see Zipkin.) Get started Using our Trace API is as simple as: Sending trace data in the expected format (in this case, our new-relic format). Sending that data to the appropriate endpoint. Before using the Trace API, you should decide whether you want to use Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, follow one of these paths: Want to use Infinite Tracing? Follow the Set up a trace observer instructions. That walks you through creating a trace observer and sending a sample payload to the trace observer endpoint. Don't want Infinite Tracing? See how to send a sample payload (below). Send sample trace payload (non-Infinite Tracing) The following explains how to send a standard (non-Infinite Tracing) payload to the Trace API using our newrelic format. Get a license key for the account you want to report data to. Insert that key into the following JSON and then send the JSON to our endpoint. Note: if you have a EU New Relic account, use the EU endpoint instead. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $YOUR_LICENSE_KEY' \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"service.name\": \"Test Service A\", \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"name\": \"/home\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"error.message\": \"Invalid credentials\", \"service.name\": \"Test Service A\", \"host\": \"host456.example.com\", \"duration.ms\": 2.97, \"name\": \"/auth\", \"parent.id\": \"ABC\" } } ] } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Tip If you're sending more than one POST, change the trace.id to a unique value. Sending the same payload or span id multiple times for the same trace.id may result in fragmented traces in the UI. If your test returned HTTP/1.1 202 Accepted, go to our UI to see a query of your test data using the span attribute service.name = Test Service A. Tip Traces may take up to one minute to be processed by both the trace observer and the Trace API. Trace API payload (New Relic format) The Trace API JSON payload is an array of objects, with each object representing a single trace. Each of these objects requires a spans key and may also include a common key. spans (required) contains an array of objects, with each object representing a span. common (optional) shares information across multiple spans. The Span object in the spans array field type description required default id string Unique identifier for this span. yes N/A trace.id string Unique identifier shared by all spans within a single trace. yes N/A timestamp long Span start time in milliseconds since the Unix epoch. no Current time in UTC timezone attributes object Any set of key: value pairs that add more details about a span. duration.ms, name, and parent.id are strongly recommended to add. no N/A Requests without the required keys above will be rejected, and an NrIntegrationError will be generated. The common object (optional) field type description required default attributes object Any set of key: value pairs that add common details about spans in the payload. If a span contains an attribute that has been set in common, the key in the span attributes object will take precedence. duration.ms, name, and parent.id are strongly recommended to add. no N/A Highly recommended attributes While not required, these attributes should be included for the best experience with your data in the attributes object for each span. attribute default description duration.ms float none Duration of this span in milliseconds. name string none The name of this span. parent.id string none The id of the caller of this span. Value is null if this is the root span. Traces without a root span will not be displayed. service.name string none The name of the entity that created this span. Reserved attributes These attributes are currently reserved for internal New Relic usage. While they are not explicitly blocked, we recommend not using them. attribute default description entity.name string service.name This is derived from the service.name attribute. entity.type string service The entity type is assumed to be a service. entity.guid string None The entity.guid is a derived value that uniquely identifies the entity in New Relic's backend. Other attributes You can add any arbitrary attributes you want in the attributes object in either common or each span object, with the exception of the restricted attributes. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Requirements and guidelines for trace JSON using the newrelic format: Each JSON payload is an array of objects. Each object should contain a required spans key. Each object can contain an optional common key. Use this if you want to share information across multiple spans in a object. Any keys on a span have precedence over the same key in the common block. The value for a spans key is a list of span objects. Certain attributes are required, and must be included either in the optional common block, or in each span. Recommended and custom attributes can be optionally included in a list of key-value pairs under a key named attributes, in the optional common block and/or in each span. In the following example POST, there are two spans, both of which have the trace.id 12345 and the custom attribute host: host123.example.com. The first span has no parent.id, so that is the root of the trace; the second span's parent.id points to the ID of the first. [ { \"common\": { \"attributes\": { \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"12345\", \"id\": \"abc\", \"timestamp\": 1603336834823, \"attributes\": { \"user.email\": \"bob@newr.com\", \"service.name\": \"my-service\", \"duration.ms\": 750, \"name\": \"my-span\" } }, { \"trace.id\": \"12345\", \"id\": \"def\", \"timestamp\": 1603336834899, \"attributes\": { \"parent.id\": \"abc\", \"service.name\": \"second-service\", \"duration.ms\": 750, \"name\": \"second-span\" } } ] } ] Copy To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about distributed tracing: Learn where Trace API data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience. For example, you can have spans show up as datastore spans or display errors. Learn about general data limits, required metadata, and response validation. If you don't see your trace data, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.71791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>traces</em> via the <em>Trace</em> <em>API</em> (New Relic format)",
        "sections": "Explore more about <em>distributed</em> <em>tracing</em>:",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about <em>distributed</em> <em>tracing</em>: Learn where <em>Trace</em> <em>API</em> data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience"
      },
      "id": "6071cfc8196a6790e864a7a4"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-10-01T10:21:46Z",
      "updated_at": "2021-08-26T14:09:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Data limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-10-01T10:23:56Z",
      "updated_at": "2021-08-27T14:05:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via HTTPS POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires a license key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Data limits Distributed tracing rate limits are set per account and data type. For details about data limits, see New Relic data usage limits and policies. When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.44656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "). Infinite <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-10-01T10:21:46Z",
      "updated_at": "2021-08-26T14:09:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.71692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. Want to try out the <em>Trace</em> <em>API</em>? Make sure you&#x27;ve created a free New"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Data limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-10-01T10:23:56Z",
      "updated_at": "2021-08-27T14:05:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via HTTPS POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires a license key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Data limits Distributed tracing rate limits are set per account and data type. For details about data limits, see New Relic data usage limits and policies. When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.44656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "). Infinite <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Report traces via the Trace API (New Relic format)",
        "Get started",
        "Send sample trace payload (non-Infinite Tracing)",
        "Tip",
        "Trace API payload (New Relic format)",
        "The Span object in the spans array",
        "The common object (optional)",
        "Highly recommended attributes",
        "Reserved attributes",
        "Other attributes",
        "Explore more about distributed tracing:"
      ],
      "title": "Report traces via the Trace API (New Relic format)",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "7b6be23c78b9a06ebf71671cc69590b4ac4b3311",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api/",
      "published_at": "2021-10-01T10:22:41Z",
      "updated_at": "2021-08-26T14:10:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send traces in our general format, aka new-relic format. (To send Zipkin-format data, see Zipkin.) Get started Using our Trace API is as simple as: Sending trace data in the expected format (in this case, our new-relic format). Sending that data to the appropriate endpoint. Before using the Trace API, you should decide whether you want to use Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, follow one of these paths: Want to use Infinite Tracing? Follow the Set up a trace observer instructions. That walks you through creating a trace observer and sending a sample payload to the trace observer endpoint. Don't want Infinite Tracing? See how to send a sample payload (below). Send sample trace payload (non-Infinite Tracing) The following explains how to send a standard (non-Infinite Tracing) payload to the Trace API using our newrelic format. Get a license key for the account you want to report data to. Insert that key into the following JSON and then send the JSON to our endpoint. Note: if you have a EU New Relic account, use the EU endpoint instead. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $YOUR_LICENSE_KEY' \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"service.name\": \"Test Service A\", \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"name\": \"/home\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"error.message\": \"Invalid credentials\", \"service.name\": \"Test Service A\", \"host\": \"host456.example.com\", \"duration.ms\": 2.97, \"name\": \"/auth\", \"parent.id\": \"ABC\" } } ] } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Tip If you're sending more than one POST, change the trace.id to a unique value. Sending the same payload or span id multiple times for the same trace.id may result in fragmented traces in the UI. If your test returned HTTP/1.1 202 Accepted, go to our UI to see a query of your test data using the span attribute service.name = Test Service A. Tip Traces may take up to one minute to be processed by both the trace observer and the Trace API. Trace API payload (New Relic format) The Trace API JSON payload is an array of objects, with each object representing a single trace. Each of these objects requires a spans key and may also include a common key. spans (required) contains an array of objects, with each object representing a span. common (optional) shares information across multiple spans. The Span object in the spans array field type description required default id string Unique identifier for this span. yes N/A trace.id string Unique identifier shared by all spans within a single trace. yes N/A timestamp long Span start time in milliseconds since the Unix epoch. no Current time in UTC timezone attributes object Any set of key: value pairs that add more details about a span. duration.ms, name, and parent.id are strongly recommended to add. no N/A Requests without the required keys above will be rejected, and an NrIntegrationError will be generated. The common object (optional) field type description required default attributes object Any set of key: value pairs that add common details about spans in the payload. If a span contains an attribute that has been set in common, the key in the span attributes object will take precedence. duration.ms, name, and parent.id are strongly recommended to add. no N/A Highly recommended attributes While not required, these attributes should be included for the best experience with your data in the attributes object for each span. attribute default description duration.ms float none Duration of this span in milliseconds. name string none The name of this span. parent.id string none The id of the caller of this span. Value is null if this is the root span. Traces without a root span will not be displayed. service.name string none The name of the entity that created this span. Reserved attributes These attributes are currently reserved for internal New Relic usage. While they are not explicitly blocked, we recommend not using them. attribute default description entity.name string service.name This is derived from the service.name attribute. entity.type string service The entity type is assumed to be a service. entity.guid string None The entity.guid is a derived value that uniquely identifies the entity in New Relic's backend. Other attributes You can add any arbitrary attributes you want in the attributes object in either common or each span object, with the exception of the restricted attributes. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Requirements and guidelines for trace JSON using the newrelic format: Each JSON payload is an array of objects. Each object should contain a required spans key. Each object can contain an optional common key. Use this if you want to share information across multiple spans in a object. Any keys on a span have precedence over the same key in the common block. The value for a spans key is a list of span objects. Certain attributes are required, and must be included either in the optional common block, or in each span. Recommended and custom attributes can be optionally included in a list of key-value pairs under a key named attributes, in the optional common block and/or in each span. In the following example POST, there are two spans, both of which have the trace.id 12345 and the custom attribute host: host123.example.com. The first span has no parent.id, so that is the root of the trace; the second span's parent.id points to the ID of the first. [ { \"common\": { \"attributes\": { \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"12345\", \"id\": \"abc\", \"timestamp\": 1603336834823, \"attributes\": { \"user.email\": \"bob@newr.com\", \"service.name\": \"my-service\", \"duration.ms\": 750, \"name\": \"my-span\" } }, { \"trace.id\": \"12345\", \"id\": \"def\", \"timestamp\": 1603336834899, \"attributes\": { \"parent.id\": \"abc\", \"service.name\": \"second-service\", \"duration.ms\": 750, \"name\": \"second-span\" } } ] } ] Copy To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about distributed tracing: Learn where Trace API data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience. For example, you can have spans show up as datastore spans or display errors. Learn about general data limits, required metadata, and response validation. If you don't see your trace data, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>traces</em> via the <em>Trace</em> <em>API</em> (New Relic format)",
        "sections": "Explore more about <em>distributed</em> <em>tracing</em>:",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about <em>distributed</em> <em>tracing</em>: Learn where <em>Trace</em> <em>API</em> data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience"
      },
      "id": "6071cfc8196a6790e864a7a4"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.71692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. Want to try out the <em>Trace</em> <em>API</em>? Make sure you&#x27;ve created a free New"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Data limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-10-01T10:23:56Z",
      "updated_at": "2021-08-27T14:05:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via HTTPS POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires a license key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Data limits Distributed tracing rate limits are set per account and data type. For details about data limits, see New Relic data usage limits and policies. When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.44655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "). Infinite <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Report traces via the Trace API (New Relic format)",
        "Get started",
        "Send sample trace payload (non-Infinite Tracing)",
        "Tip",
        "Trace API payload (New Relic format)",
        "The Span object in the spans array",
        "The common object (optional)",
        "Highly recommended attributes",
        "Reserved attributes",
        "Other attributes",
        "Explore more about distributed tracing:"
      ],
      "title": "Report traces via the Trace API (New Relic format)",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "7b6be23c78b9a06ebf71671cc69590b4ac4b3311",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api/",
      "published_at": "2021-10-01T10:22:41Z",
      "updated_at": "2021-08-26T14:10:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send traces in our general format, aka new-relic format. (To send Zipkin-format data, see Zipkin.) Get started Using our Trace API is as simple as: Sending trace data in the expected format (in this case, our new-relic format). Sending that data to the appropriate endpoint. Before using the Trace API, you should decide whether you want to use Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, follow one of these paths: Want to use Infinite Tracing? Follow the Set up a trace observer instructions. That walks you through creating a trace observer and sending a sample payload to the trace observer endpoint. Don't want Infinite Tracing? See how to send a sample payload (below). Send sample trace payload (non-Infinite Tracing) The following explains how to send a standard (non-Infinite Tracing) payload to the Trace API using our newrelic format. Get a license key for the account you want to report data to. Insert that key into the following JSON and then send the JSON to our endpoint. Note: if you have a EU New Relic account, use the EU endpoint instead. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $YOUR_LICENSE_KEY' \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"service.name\": \"Test Service A\", \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"name\": \"/home\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"error.message\": \"Invalid credentials\", \"service.name\": \"Test Service A\", \"host\": \"host456.example.com\", \"duration.ms\": 2.97, \"name\": \"/auth\", \"parent.id\": \"ABC\" } } ] } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Tip If you're sending more than one POST, change the trace.id to a unique value. Sending the same payload or span id multiple times for the same trace.id may result in fragmented traces in the UI. If your test returned HTTP/1.1 202 Accepted, go to our UI to see a query of your test data using the span attribute service.name = Test Service A. Tip Traces may take up to one minute to be processed by both the trace observer and the Trace API. Trace API payload (New Relic format) The Trace API JSON payload is an array of objects, with each object representing a single trace. Each of these objects requires a spans key and may also include a common key. spans (required) contains an array of objects, with each object representing a span. common (optional) shares information across multiple spans. The Span object in the spans array field type description required default id string Unique identifier for this span. yes N/A trace.id string Unique identifier shared by all spans within a single trace. yes N/A timestamp long Span start time in milliseconds since the Unix epoch. no Current time in UTC timezone attributes object Any set of key: value pairs that add more details about a span. duration.ms, name, and parent.id are strongly recommended to add. no N/A Requests without the required keys above will be rejected, and an NrIntegrationError will be generated. The common object (optional) field type description required default attributes object Any set of key: value pairs that add common details about spans in the payload. If a span contains an attribute that has been set in common, the key in the span attributes object will take precedence. duration.ms, name, and parent.id are strongly recommended to add. no N/A Highly recommended attributes While not required, these attributes should be included for the best experience with your data in the attributes object for each span. attribute default description duration.ms float none Duration of this span in milliseconds. name string none The name of this span. parent.id string none The id of the caller of this span. Value is null if this is the root span. Traces without a root span will not be displayed. service.name string none The name of the entity that created this span. Reserved attributes These attributes are currently reserved for internal New Relic usage. While they are not explicitly blocked, we recommend not using them. attribute default description entity.name string service.name This is derived from the service.name attribute. entity.type string service The entity type is assumed to be a service. entity.guid string None The entity.guid is a derived value that uniquely identifies the entity in New Relic's backend. Other attributes You can add any arbitrary attributes you want in the attributes object in either common or each span object, with the exception of the restricted attributes. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Requirements and guidelines for trace JSON using the newrelic format: Each JSON payload is an array of objects. Each object should contain a required spans key. Each object can contain an optional common key. Use this if you want to share information across multiple spans in a object. Any keys on a span have precedence over the same key in the common block. The value for a spans key is a list of span objects. Certain attributes are required, and must be included either in the optional common block, or in each span. Recommended and custom attributes can be optionally included in a list of key-value pairs under a key named attributes, in the optional common block and/or in each span. In the following example POST, there are two spans, both of which have the trace.id 12345 and the custom attribute host: host123.example.com. The first span has no parent.id, so that is the root of the trace; the second span's parent.id points to the ID of the first. [ { \"common\": { \"attributes\": { \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"12345\", \"id\": \"abc\", \"timestamp\": 1603336834823, \"attributes\": { \"user.email\": \"bob@newr.com\", \"service.name\": \"my-service\", \"duration.ms\": 750, \"name\": \"my-span\" } }, { \"trace.id\": \"12345\", \"id\": \"def\", \"timestamp\": 1603336834899, \"attributes\": { \"parent.id\": \"abc\", \"service.name\": \"second-service\", \"duration.ms\": 750, \"name\": \"second-span\" } } ] } ] Copy To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about distributed tracing: Learn where Trace API data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience. For example, you can have spans show up as datastore spans or display errors. Learn about general data limits, required metadata, and response validation. If you don't see your trace data, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>traces</em> via the <em>Trace</em> <em>API</em> (New Relic format)",
        "sections": "Explore more about <em>distributed</em> <em>tracing</em>:",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about <em>distributed</em> <em>tracing</em>: Learn where <em>Trace</em> <em>API</em> data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience"
      },
      "id": "6071cfc8196a6790e864a7a4"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-10-01T10:21:46Z",
      "updated_at": "2021-08-26T14:09:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.71739,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits": [
    {
      "sections": [
        "Report traces via the Trace API (New Relic format)",
        "Get started",
        "Send sample trace payload (non-Infinite Tracing)",
        "Tip",
        "Trace API payload (New Relic format)",
        "The Span object in the spans array",
        "The common object (optional)",
        "Highly recommended attributes",
        "Reserved attributes",
        "Other attributes",
        "Explore more about distributed tracing:"
      ],
      "title": "Report traces via the Trace API (New Relic format)",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "7b6be23c78b9a06ebf71671cc69590b4ac4b3311",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api/",
      "published_at": "2021-10-01T10:22:41Z",
      "updated_at": "2021-08-26T14:10:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send traces in our general format, aka new-relic format. (To send Zipkin-format data, see Zipkin.) Get started Using our Trace API is as simple as: Sending trace data in the expected format (in this case, our new-relic format). Sending that data to the appropriate endpoint. Before using the Trace API, you should decide whether you want to use Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, follow one of these paths: Want to use Infinite Tracing? Follow the Set up a trace observer instructions. That walks you through creating a trace observer and sending a sample payload to the trace observer endpoint. Don't want Infinite Tracing? See how to send a sample payload (below). Send sample trace payload (non-Infinite Tracing) The following explains how to send a standard (non-Infinite Tracing) payload to the Trace API using our newrelic format. Get a license key for the account you want to report data to. Insert that key into the following JSON and then send the JSON to our endpoint. Note: if you have a EU New Relic account, use the EU endpoint instead. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $YOUR_LICENSE_KEY' \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"service.name\": \"Test Service A\", \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"name\": \"/home\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"error.message\": \"Invalid credentials\", \"service.name\": \"Test Service A\", \"host\": \"host456.example.com\", \"duration.ms\": 2.97, \"name\": \"/auth\", \"parent.id\": \"ABC\" } } ] } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Tip If you're sending more than one POST, change the trace.id to a unique value. Sending the same payload or span id multiple times for the same trace.id may result in fragmented traces in the UI. If your test returned HTTP/1.1 202 Accepted, go to our UI to see a query of your test data using the span attribute service.name = Test Service A. Tip Traces may take up to one minute to be processed by both the trace observer and the Trace API. Trace API payload (New Relic format) The Trace API JSON payload is an array of objects, with each object representing a single trace. Each of these objects requires a spans key and may also include a common key. spans (required) contains an array of objects, with each object representing a span. common (optional) shares information across multiple spans. The Span object in the spans array field type description required default id string Unique identifier for this span. yes N/A trace.id string Unique identifier shared by all spans within a single trace. yes N/A timestamp long Span start time in milliseconds since the Unix epoch. no Current time in UTC timezone attributes object Any set of key: value pairs that add more details about a span. duration.ms, name, and parent.id are strongly recommended to add. no N/A Requests without the required keys above will be rejected, and an NrIntegrationError will be generated. The common object (optional) field type description required default attributes object Any set of key: value pairs that add common details about spans in the payload. If a span contains an attribute that has been set in common, the key in the span attributes object will take precedence. duration.ms, name, and parent.id are strongly recommended to add. no N/A Highly recommended attributes While not required, these attributes should be included for the best experience with your data in the attributes object for each span. attribute default description duration.ms float none Duration of this span in milliseconds. name string none The name of this span. parent.id string none The id of the caller of this span. Value is null if this is the root span. Traces without a root span will not be displayed. service.name string none The name of the entity that created this span. Reserved attributes These attributes are currently reserved for internal New Relic usage. While they are not explicitly blocked, we recommend not using them. attribute default description entity.name string service.name This is derived from the service.name attribute. entity.type string service The entity type is assumed to be a service. entity.guid string None The entity.guid is a derived value that uniquely identifies the entity in New Relic's backend. Other attributes You can add any arbitrary attributes you want in the attributes object in either common or each span object, with the exception of the restricted attributes. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Requirements and guidelines for trace JSON using the newrelic format: Each JSON payload is an array of objects. Each object should contain a required spans key. Each object can contain an optional common key. Use this if you want to share information across multiple spans in a object. Any keys on a span have precedence over the same key in the common block. The value for a spans key is a list of span objects. Certain attributes are required, and must be included either in the optional common block, or in each span. Recommended and custom attributes can be optionally included in a list of key-value pairs under a key named attributes, in the optional common block and/or in each span. In the following example POST, there are two spans, both of which have the trace.id 12345 and the custom attribute host: host123.example.com. The first span has no parent.id, so that is the root of the trace; the second span's parent.id points to the ID of the first. [ { \"common\": { \"attributes\": { \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"12345\", \"id\": \"abc\", \"timestamp\": 1603336834823, \"attributes\": { \"user.email\": \"bob@newr.com\", \"service.name\": \"my-service\", \"duration.ms\": 750, \"name\": \"my-span\" } }, { \"trace.id\": \"12345\", \"id\": \"def\", \"timestamp\": 1603336834899, \"attributes\": { \"parent.id\": \"abc\", \"service.name\": \"second-service\", \"duration.ms\": 750, \"name\": \"second-span\" } } ] } ] Copy To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about distributed tracing: Learn where Trace API data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience. For example, you can have spans show up as datastore spans or display errors. Learn about general data limits, required metadata, and response validation. If you don't see your trace data, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>traces</em> via the <em>Trace</em> <em>API</em> (New Relic format)",
        "sections": "Explore more about <em>distributed</em> <em>tracing</em>:",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about <em>distributed</em> <em>tracing</em>: Learn where <em>Trace</em> <em>API</em> data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience"
      },
      "id": "6071cfc8196a6790e864a7a4"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-10-01T10:21:46Z",
      "updated_at": "2021-08-26T14:09:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.71739,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.71692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. Want to try out the <em>Trace</em> <em>API</em>? Make sure you&#x27;ve created a free New"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-01T10:24:48Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.05597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you enable <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer <em>troubleshooting</em> errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Missing trace data",
        "Problem",
        "Solution",
        "Important",
        "Problems with enabling or instrumenting",
        "Missing spans due to service not having distributed tracing enabled",
        "Missing apps/services may require manual instrumentation",
        "Problems with spans",
        "Infinite Tracing: missing spans",
        "Missing span not getting exported",
        "Missing spans due to sampling process",
        "Missing spans due to span limits maxed out",
        "Missing spans due to spans being sent late",
        "Problems with trace details",
        "Middleware doesn't recognize proprietary New Relic header",
        "An intermediary is missing or isn't passing trace context",
        "Tip",
        "Stitching together spans from mixed sources",
        "Trace details are obfuscated",
        "Trace list information and trace details don't match",
        "Long traces with short backend times",
        "Problems with browser applications",
        "Missing spans and transactions after enabling for a browser application",
        "Not seeing browser app end-user spans",
        "Browser spans are not connected to other spans",
        "Other problems",
        "Search by entity.name not finding associated app names",
        "Supporting OpenTelemetry"
      ],
      "title": "Missing trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "2997172d74563c4fa31d5a9fc05c562d62c1c790",
      "image": "https://docs.newrelic.com/static/ef51359ad9a7999f7fdaf812fab535bc/d7542/missing-exporter.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/missing-trace-data/",
      "published_at": "2021-10-01T13:12:05Z",
      "updated_at": "2021-07-08T22:10:20Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have enabled distributed tracing but data you expected to see does not appear in New Relic's distributed tracing UI. Solution Important Before performing troubleshooting, we recommend reading How distributed tracing works. Here are some causes and solutions when you have problems finding expected data in the distributed tracing UI: Problems with enabling or instrumenting Missing spans due to service not having distributed tracing enabled In order for distributed tracing to report details for all nodes in a trace, each application must be monitored by a New Relic agent that has had distributed tracing enabled. If an application's New Relic account has not had distributed tracing enabled, it will have these issues: Its distributed tracing UI page won't have data. It won't report data to other accounts' distributed traces. Missing apps/services may require manual instrumentation When you enable distributed tracing for applications and services that New Relic automatically instruments, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some services or applications are missing from traces, or that there are some internal spans you expect to see that are missing. If that's the case, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the New Relic agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the New Relic agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application. Problems with spans Infinite Tracing: missing spans If your APM agent can’t write data fast enough to the trace observer, queue_size is an additional APM agent configuration to limit the number of spans the agent will hold. See the following examples for your agent: .NET configuration method Example Configuration file <configuration . . . > <infiniteTracing> <trace_observer> <span_events queue_size=\"100000\" /> </trace_observer> </infiniteTracing> </configuration> Copy Environment variable NEW_RELIC_INFINITE_TRACING_SPAN_EVENTS_QUEUE_SIZE=100000 Copy Python configuration method Example Configuration file infinite_tracing.span_queue_size = 100000 Environment Variable NEW_RELIC_INFINITE_TRACING_SPAN_QUEUE_SIZE = 100000 Missing span not getting exported Sometimes header propagation is successful, but the span information isn't getting sent to New Relic. For example, if OpenTelemetry is not instrumented with a New Relic exporter, the span details never make it to New Relic. In this diagram, notice that the header propagation is successful, but no exporter is set up in Service 2 to send the span to New Relic: The following diagram also shows successful header propagation, but it includes an exporter in Service 2 that sends the span details to New Relic (see Trace API): Missing spans due to sampling process Standard distributed tracing for APM uses adaptive sampling. This means that a percentage of calls to a service will be reported as part of a distributed trace. Specific calls to your service might not have been selected to be sampled. Missing spans due to span limits maxed out There are limits on the number of spans that can be collected and displayed. If an application generates a very large number of spans for a single call, it might exceed the APM agent's span-collection limit for that harvest cycle. This could result in missing spans and significantly limit the number of traces the agent can completely sample and report. We currently only show 10,000 spans at a time. Missing spans due to spans being sent late Spans must be sent within the last twenty minutes to be captured in a trace index. If you send any spans older than twenty minutes but newer than a day, the span data will still be written. However, it won't be rolled into the trace index, which controls the trace list in the distributed tracing UI. If a span has a timestamp older than a day, it will be dropped. This often occurs when there is clock skew (timing differences) between systems or long running background jobs. Problems with trace details Middleware doesn't recognize proprietary New Relic header If your transactions are only sending the proprietary New Relic header, some middleware might not recognize the format and then drop the information as shown in this diagram: One solution is to upgrade your New Relic agent to a version that supports W3C trace context. In the diagram below, the W3C-compliant New Relic agent passes the prior header along with two standardized headers: An intermediary is missing or isn't passing trace context Some potential problems with proxies and other intermediaries: Incomplete trace. Some intermediaries won't automatically propagate the distributed tracing header. In that case, you must configure that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in trace. If the intermediary is New Relic-monitored, ensure that it propagates the newrelic header that is generated or updated by the New Relic agent running on that intermediary. This may manifest when an intermediary was previously visible in traces, but disappeared after distributed tracing was enabled for an upstream entity (for example, a browser-monitored application). Tip If some entities report trace data to another tracing system, you can use the trace ID from the New Relic UI to search other tracing systems for missing spans. Stitching together spans from mixed sources If each agent in a chain supports W3C Trace Context, then we can stitch the spans together into a complete trace. If part of the chain is from an agent, such as Zipkin, which doesn't support W3C Trace Context, then spans coming from that agent may not be included in the trace. Trace details are obfuscated If a trace contains data from applications monitored by multiple New Relic accounts, and your user permissions don't allow you to access those accounts, some of the span and service details will be obfuscated in the UI. For example, you may see a series of asterisks ( * * * * * ) instead of the service name in your distributed tracing list if you don't have access to the account linked with the service. Trace list information and trace details don't match The trace list is generated by trace indexes, which are captured in a twenty minute window from when the first spans are received. Usually, this is due to late spans. Long traces with short backend times If you're seeing unusually short backend times for long traces, this is likely an issue with the timestamps being sent. For example, the root span might be reposting microseconds as milliseconds. This can also happen if the root span is a browser application. When using an external client like a web browser, you may experience clock skew (timing differences) more often. Problems with browser applications Missing spans and transactions after enabling for a browser application Older versions of some APM agents are incompatible with distributed tracing for browser applications. If the browser application makes an AJAX request to an APM application running an incompatible agent, then the APM agent may not record transaction and span data for that request. If distributed tracing is enabled for a browser application and you are not seeing transaction or span data for downstream APM requests, review the browser data in distributed tracing requirements, and confirm that all applications are running supported versions of the APM agent. Not seeing browser app end-user spans If traces seem to be missing end-user spans, be sure you've read and understand the browser distributed tracing requirements and enable procedures. On the AJAX UI page, there are links to the distributed tracing UI regardless of whether there are end-user spans present in that trace. For details about what data generates spans, see Requirements. Browser spans are not connected to other spans Older versions of some APM agents are incompatible with distributed tracing for browser applications. If APM spans are missing consistently from traces that include browser applications, please refer to the browser data in distributed tracing requirements and confirm that all applications are running supported versions of the APM agent. For other causes of orphaned browser spans, see Browser span reporting. Other problems Search by entity.name not finding associated app names Potential cause: For applications that have multiple app names, the entity.name attribute will be associated only with the primary app name. To search by other app names, search using the appName attribute. Supporting OpenTelemetry Questions about integrating with OpenTelemetry should be taken to the Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.23822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>trace</em> data",
        "sections": "Missing spans due to service not having <em>distributed</em> <em>tracing</em> enabled",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem You have enabled <em>distributed</em> <em>tracing</em> but data you expected to see does not appear in New Relic&#x27;s <em>distributed</em> <em>tracing</em> UI. Solution Important Before performing <em>troubleshooting</em>, we recommend reading How <em>distributed</em> <em>tracing</em> works. Here are some causes and solutions when you have problems"
      },
      "id": "6072a76764441f109b9d857b"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.02193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a tool that emits <em>tracing</em> data but that requires a backend for <em>trace</em> storage. You want to report <em>distributed</em> <em>tracing</em> data to New Relic without the use of our installed solutions. You use Zipkin and want to see that <em>trace</em> data in New Relic without changing your instrumentation. Want to <em>understand</em> how"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/missing-trace-data": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-01T10:24:48Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.05597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you enable <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer <em>troubleshooting</em> errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-01T10:22:41Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.30768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infinite <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "Infinite <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled Infinite <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-Infinite <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling Infinite <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-01T10:20:33Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.02193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a tool that emits <em>tracing</em> data but that requires a backend for <em>trace</em> storage. You want to report <em>distributed</em> <em>tracing</em> data to New Relic without the use of our installed solutions. You use Zipkin and want to see that <em>trace</em> data in New Relic without changing your instrumentation. Want to <em>understand</em> how"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/ui-data/query-distributed-trace-data": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-01T10:24:48Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.68103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-10-01T10:24:49Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.49754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.93558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the <em>UI</em>: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> <em>UI</em> Query <em>distributed</em> <em>trace</em> <em>data</em> Set up Infinite <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    }
  ],
  "/docs/distributed-tracing/ui-data/span-attributes": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-01T10:24:48Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.68103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-10-01T10:23:56Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.24835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.93558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the <em>UI</em>: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> <em>UI</em> Query <em>distributed</em> <em>trace</em> <em>data</em> Set up Infinite <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    }
  ],
  "/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui": [
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-10-01T10:24:49Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.49754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-10-01T10:23:56Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.24835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-01T10:19:31Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.93556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the <em>UI</em>: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> <em>UI</em> Query <em>distributed</em> <em>trace</em> <em>data</em> Set up Infinite <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    }
  ],
  "/docs/full-stack-observability/index": [
    {
      "sections": [
        "New Relic quickstarts overview",
        "Preview feature",
        "Why it matters",
        "What are quickstarts",
        "Some technical detail"
      ],
      "title": "New Relic quickstarts overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Quickstarts",
        "Instant Observability"
      ],
      "external_id": "e12df6102b9361f953bdab2f4b49baa5756f7048",
      "image": "https://docs.newrelic.com/static/ec52d123f2853cc7fc4d3fab9f9f3be7/c1b63/quickstart-home.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview/",
      "published_at": "2021-10-06T23:40:45Z",
      "updated_at": "2021-10-06T22:17:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor your tech stack without the burden of manual set up. New Relic I/O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O Preview feature Everyone has access to New Relic I/O for now. After the preview, only full users will be able to access the dashboards installed from a quickstart. Why it matters With our I/O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to get started with monitoring your technology stack; that includes instrumentation, integrations, dashboards, and alerts, all ready to install with a click. What are quickstarts Quickstarts are bundles of dashboards, alerts, and instrumentation that are ready to install with a single click, specific to each technology we support. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of instrumentations, dashboards, and alerts. New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edit to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1340.8524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "Monitor your tech <em>stack</em> without the burden of manual set up. New Relic I&#x2F;O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by <em>observability</em> experts around the world, vetted by New Relic, and ready for you"
      },
      "id": "6157008964441f500d099617"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-09-30T19:22:49Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 978.2255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " great ways to report to senior executive teams or customers. Take a look at the <em>full</em> list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications &gt; (selected app) &gt; Reports. Select the report you&#x27;d like to see. If you want to save or export a report to share"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-10-01T08:29:57Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 798.4243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "Get started with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "<em>Full</em>-<em>Stack</em> <em>Observability</em> is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running"
      },
      "id": "603e891528ccbce6d9eba765"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations": [
    {
      "sections": [
        "New Relic quickstarts overview",
        "Preview feature",
        "Why it matters",
        "What are quickstarts",
        "Some technical detail"
      ],
      "title": "New Relic quickstarts overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Quickstarts",
        "Instant Observability"
      ],
      "external_id": "e12df6102b9361f953bdab2f4b49baa5756f7048",
      "image": "https://docs.newrelic.com/static/ec52d123f2853cc7fc4d3fab9f9f3be7/c1b63/quickstart-home.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview/",
      "published_at": "2021-10-06T23:40:45Z",
      "updated_at": "2021-10-06T22:17:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor your tech stack without the burden of manual set up. New Relic I/O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O Preview feature Everyone has access to New Relic I/O for now. After the preview, only full users will be able to access the dashboards installed from a quickstart. Why it matters With our I/O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to get started with monitoring your technology stack; that includes instrumentation, integrations, dashboards, and alerts, all ready to install with a click. What are quickstarts Quickstarts are bundles of dashboards, alerts, and instrumentation that are ready to install with a single click, specific to each technology we support. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of instrumentations, dashboards, and alerts. New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edit to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.33734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " the preview, only <em>full</em> users will be able to access the dashboards installed from a quickstart. Why it matters With our I&#x2F;O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to <em>get</em> <em>started</em> with monitoring your technology <em>stack</em>; that includes instrumentation"
      },
      "id": "6157008964441f500d099617"
    },
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-10-01T08:29:57Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.81044,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " allows you to <em>start</em> your <em>observability</em> journey from any element of your <em>stack</em>. For example, you can <em>get</em> to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the <em>full</em> <em>stack</em> of your software, see"
      },
      "id": "603e891528ccbce6d9eba765"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-09-30T19:22:49Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.8787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": ". How to do it Go to one.newrelic.com &gt; More &gt; Service maps. To <em>get</em> <em>started</em>, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/instrument-core-services-applications/cloud-services-integrations": [
    {
      "sections": [
        "New Relic quickstarts overview",
        "Preview feature",
        "Why it matters",
        "What are quickstarts",
        "Some technical detail"
      ],
      "title": "New Relic quickstarts overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Quickstarts",
        "Instant Observability"
      ],
      "external_id": "e12df6102b9361f953bdab2f4b49baa5756f7048",
      "image": "https://docs.newrelic.com/static/ec52d123f2853cc7fc4d3fab9f9f3be7/c1b63/quickstart-home.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview/",
      "published_at": "2021-10-06T23:40:45Z",
      "updated_at": "2021-10-06T22:17:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor your tech stack without the burden of manual set up. New Relic I/O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O Preview feature Everyone has access to New Relic I/O for now. After the preview, only full users will be able to access the dashboards installed from a quickstart. Why it matters With our I/O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to get started with monitoring your technology stack; that includes instrumentation, integrations, dashboards, and alerts, all ready to install with a click. What are quickstarts Quickstarts are bundles of dashboards, alerts, and instrumentation that are ready to install with a single click, specific to each technology we support. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of instrumentations, dashboards, and alerts. New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edit to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.09438,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "Monitor your tech <em>stack</em> without the burden of manual set up. New Relic I&#x2F;O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by <em>observability</em> experts around the world, vetted by New Relic, and ready for you"
      },
      "id": "6157008964441f500d099617"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-10-01T23:31:22Z",
      "updated_at": "2021-07-27T09:41:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.45685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " of <em>applications</em>, frameworks, <em>services</em>, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain"
      },
      "id": "603e817f28ccbc4857eba798"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-09-30T19:22:49Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.87311,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Add tags to your <em>applications</em>",
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " a high-level overview of all your <em>applications</em> and <em>services</em>, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as &quot;My Application&quot; or &quot;PHP Application,&quot; if you don&#x27;t specify one in your New Relic configuration"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability": [
    {
      "sections": [
        "New Relic quickstarts overview",
        "Preview feature",
        "Why it matters",
        "What are quickstarts",
        "Some technical detail"
      ],
      "title": "New Relic quickstarts overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Quickstarts",
        "Instant Observability"
      ],
      "external_id": "e12df6102b9361f953bdab2f4b49baa5756f7048",
      "image": "https://docs.newrelic.com/static/ec52d123f2853cc7fc4d3fab9f9f3be7/c1b63/quickstart-home.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview/",
      "published_at": "2021-10-06T23:40:45Z",
      "updated_at": "2021-10-06T22:17:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor your tech stack without the burden of manual set up. New Relic I/O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O Preview feature Everyone has access to New Relic I/O for now. After the preview, only full users will be able to access the dashboards installed from a quickstart. Why it matters With our I/O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to get started with monitoring your technology stack; that includes instrumentation, integrations, dashboards, and alerts, all ready to install with a click. What are quickstarts Quickstarts are bundles of dashboards, alerts, and instrumentation that are ready to install with a single click, specific to each technology we support. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of instrumentations, dashboards, and alerts. New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edit to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 395.7303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " the preview, only <em>full</em> users will be able to access the dashboards installed from a quickstart. Why it matters With our I&#x2F;O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to <em>get</em> <em>started</em> with monitoring your technology <em>stack</em>; that includes instrumentation"
      },
      "id": "6157008964441f500d099617"
    },
    {
      "sections": [
        "New Relic guided install overview",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-10-06T23:38:25Z",
      "updated_at": "2021-08-20T13:37:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.2579,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em> <em>started</em>? Click the Guided install button. If your"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-09-30T19:22:49Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.83768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": ". How to do it Go to one.newrelic.com &gt; More &gt; Service maps. To <em>get</em> <em>started</em>, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview": [
    {
      "sections": [
        "New Relic quickstarts overview",
        "Preview feature",
        "Why it matters",
        "What are quickstarts",
        "Some technical detail"
      ],
      "title": "New Relic quickstarts overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Quickstarts",
        "Instant Observability"
      ],
      "external_id": "e12df6102b9361f953bdab2f4b49baa5756f7048",
      "image": "https://docs.newrelic.com/static/ec52d123f2853cc7fc4d3fab9f9f3be7/c1b63/quickstart-home.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview/",
      "published_at": "2021-10-06T23:40:45Z",
      "updated_at": "2021-10-06T22:17:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor your tech stack without the burden of manual set up. New Relic I/O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O Preview feature Everyone has access to New Relic I/O for now. After the preview, only full users will be able to access the dashboards installed from a quickstart. Why it matters With our I/O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to get started with monitoring your technology stack; that includes instrumentation, integrations, dashboards, and alerts, all ready to install with a click. What are quickstarts Quickstarts are bundles of dashboards, alerts, and instrumentation that are ready to install with a single click, specific to each technology we support. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of instrumentations, dashboards, and alerts. New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edit to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 395.72992,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " the preview, only <em>full</em> users will be able to access the dashboards installed from a quickstart. Why it matters With our I&#x2F;O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to <em>get</em> <em>started</em> with monitoring your technology <em>stack</em>; that includes instrumentation"
      },
      "id": "6157008964441f500d099617"
    },
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-10-01T08:29:57Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.64209,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " allows you to <em>start</em> your <em>observability</em> journey from any element of your <em>stack</em>. For example, you can <em>get</em> to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and <em>observe</em> the <em>full</em> <em>stack</em> of your software, see"
      },
      "id": "603e891528ccbce6d9eba765"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-09-30T19:22:49Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.83762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": ". How to do it Go to one.newrelic.com &gt; More &gt; Service maps. To <em>get</em> <em>started</em>, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview": [
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-10-01T08:29:57Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.62674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " allows you to <em>start</em> your <em>observability</em> journey from any element of your <em>stack</em>. For example, you can <em>get</em> to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and <em>observe</em> the <em>full</em> <em>stack</em> of your software, see"
      },
      "id": "603e891528ccbce6d9eba765"
    },
    {
      "sections": [
        "New Relic guided install overview",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-10-06T23:38:25Z",
      "updated_at": "2021-08-20T13:37:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.1972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em> <em>started</em>? Click the Guided install button. If your"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-09-30T19:22:49Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.87857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": ". How to do it Go to one.newrelic.com &gt; More &gt; Service maps. To <em>get</em> <em>started</em>, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/gateway-api-import-data-other-observability-platforms": [
    {
      "sections": [
        "Python: Configure logs in context",
        "Set up your Python app",
        "Python StreamHandler example",
        "What's next?"
      ],
      "title": "Python: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Python"
      ],
      "external_id": "a51497a54dbdd8c6ee16e8cf097a090347166d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-python/",
      "published_at": "2021-10-06T21:52:55Z",
      "updated_at": "2021-10-06T21:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Python agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Python app To enable logs in context for APM apps monitored by Python: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Python agent version, and enable distributed tracing. Use Python agent version 5.4.0 or higher for logs in context. Configure logs in context for your log handler. Python StreamHandler example Enabling logs in Python is as simple as instantiating a log formatter and adding it to your log handler. This example uses a StreamHandler which by default writes logs to sys.stderr, but any handler can be used. For more information about configuring log handlers, see the Python.org documentation. # Import the logging module and the New Relic log formatter import logging from newrelic.agent import NewRelicContextFormatter # Instantiate a new log handler handler = logging.StreamHandler() # Instantiate the log formatter and add it to the log handler formatter = NewRelicContextFormatter() handler.setFormatter(formatter) # Get the root logger and add the handler to it root_logger = logging.getLogger() root_logger.addHandler(handler) Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.0184,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " a StreamHandler which by default writes logs to sys.stderr, but any handler can be used. For more information about configuring log handlers, see the Python.org documentation. # <em>Import</em> the logging module and the New Relic log formatter <em>import</em> logging <em>from</em> newrelic.agent <em>import</em> NewRelicContextFormatter"
      },
      "id": "612d463564441f2c8042434e"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.26648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect your Algorithmia <em>data</em> to New Relic",
        "body": " or any <em>other</em> change in state that you want to describe. You can also send any type of <em>data</em> to Incident Intelligence straight <em>from</em> your own systems or applications. The REST <em>API</em> supports secure token-based authentication and accepts JSON content as input. For more information on authentication"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/chart-group/",
      "sections": [
        "ChartGroup",
        "Usage",
        "Examples",
        "Props"
      ],
      "published_at": "2021-10-06T13:39:59Z",
      "title": "ChartGroup",
      "updated_at": "2021-09-30T18:19:07Z",
      "type": "developer",
      "external_id": "4d1a985ff83a6bb1f2986828a2232e60f432ec98",
      "document_type": "page",
      "popularity": 1,
      "body": "Usage import { ChartGroup } from 'nr1' Copy Examples Props childrenrequirednode Arbitrary content. All charts inside ChartGroup communicate between each other.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 83.92398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Usage <em>import</em> { ChartGroup } <em>from</em> &#x27;nr1&#x27; Copy Examples Props childrenrequirednode Arbitrary content. All charts inside ChartGroup communicate between each <em>other</em>."
      },
      "id": "6091f82628ccbcbadaa268e6"
    }
  ],
  "/docs/infrastructure/index": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-01T12:35:22Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 49.57269,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; condition",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; condition",
        "tags": "<em>Infrastructure</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.2654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>infrastructure</em> monitoring agent for Linux",
        "sections": "Install the <em>infrastructure</em> monitoring agent for Linux",
        "tags": "<em>Infrastructure</em>",
        "body": "Our <em>infrastructure</em> monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-09-27T15:12:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.21 Red Hat Enterprise Linux (RHEL) Version 6 or higher Oracle Linux Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.257244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> agent",
        "sections": "Requirements for the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em>",
        "body": "Before installing our <em>infrastructure</em> agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The <em>infrastructure</em> agent supports these processor architectures"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    }
  ],
  "/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition": [
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-09-30T23:08:13Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.8123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-09-30T23:08:14Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.86559,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-09-30T23:07:11Z",
      "updated_at": "2021-07-27T13:58:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances on one host This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.86206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances"
      },
      "id": "603eb49128ccbca939eba74a"
    }
  ],
  "/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/verify-your-alerts-after-activating-remote-monitoring": [
    {
      "sections": [
        "Node.js: Configure logs in context",
        "Set up your Node.js app",
        "Node.js configuration with Winston",
        "What's next?"
      ],
      "title": "Node.js: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Node.js"
      ],
      "external_id": "25a42c104600852e6c71dc7747b2e1a3c4439dcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-nodejs/",
      "published_at": "2021-10-06T21:51:43Z",
      "updated_at": "2021-10-06T21:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Node.js agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Node.js app To enable logs in context for APM apps monitored by Node.js: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Node.js agent version, and enable distributed tracing. Use Node.js agent version 6.2.0 or higher for logs in context. Install the Winston logging framework version 3.0.0 or higher to enrich your log data. Configure logs in context for Node.js using the Winston extension. Node.js configuration with Winston To install the Winston log enricher, enter the following command into your terminal or command line interface: npm install @newrelic/winston-enricher Copy In your application code, update your logging configuration to add the newrelicFormatter: // index.js require('newrelic') const newrelicFormatter = require('@newrelic/winston-enricher') Copy The New Relic formatter can be used individually or combined with other formatters as the final format. format: winston.format.combine( winston.format.label({label: 'test'}), newrelicFormatter() ) Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.41891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Set up <em>your</em> Node.js app",
        "body": ". Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both <em>your</em> application and <em>your</em> platform performance data by forwarding <em>your</em> logs with our infrastructure <em>monitoring</em> agent. Review <em>your</em> infrastructure logs in the UI. Set up <em>alerts</em>. Query <em>your</em> data and create dashboards."
      },
      "id": "612b7a7ee7b9d2d42bb6f24b"
    },
    {
      "sections": [
        "Python: Configure logs in context",
        "Set up your Python app",
        "Python StreamHandler example",
        "What's next?"
      ],
      "title": "Python: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Python"
      ],
      "external_id": "a51497a54dbdd8c6ee16e8cf097a090347166d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-python/",
      "published_at": "2021-10-06T21:52:55Z",
      "updated_at": "2021-10-06T21:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Python agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Python app To enable logs in context for APM apps monitored by Python: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Python agent version, and enable distributed tracing. Use Python agent version 5.4.0 or higher for logs in context. Configure logs in context for your log handler. Python StreamHandler example Enabling logs in Python is as simple as instantiating a log formatter and adding it to your log handler. This example uses a StreamHandler which by default writes logs to sys.stderr, but any handler can be used. For more information about configuring log handlers, see the Python.org documentation. # Import the logging module and the New Relic log formatter import logging from newrelic.agent import NewRelicContextFormatter # Instantiate a new log handler handler = logging.StreamHandler() # Instantiate the log formatter and add it to the log handler formatter = NewRelicContextFormatter() handler.setFormatter(formatter) # Get the root logger and add the handler to it root_logger = logging.getLogger() root_logger.addHandler(handler) Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.3281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Set up <em>your</em> Python app",
        "body": " with our Logs UI. See <em>your</em> logs in context of <em>your</em> app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both <em>your</em> application and <em>your</em> platform performance data by forwarding <em>your</em> logs with our infrastructure <em>monitoring</em> agent. Review <em>your</em> infrastructure logs in the UI. Set up <em>alerts</em>. Query <em>your</em> data and create dashboards."
      },
      "id": "612d463564441f2c8042434e"
    },
    {
      "sections": [
        "Remote monitoring in on-host integrations",
        "Important",
        "Effects of activating remote_monitoring",
        "Alert verification",
        "New entity attributes",
        "Changes in recorded metrics",
        "Unrecorded attributes",
        "Updated hostname"
      ],
      "title": "Remote monitoring in on-host integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "Understand and use data"
      ],
      "external_id": "1cfea4c65b855ce9ac5078d2a36ba11b63a6101b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/understand-use-data/remote-monitoring-host-integrations/",
      "published_at": "2021-10-01T21:38:50Z",
      "updated_at": "2021-03-16T06:05:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "From a New Relic perspective, entity is a broad concept. An entity is anything New Relic can identify that has data you can monitor. Integrations can be configured to create their own entity, called a remote entity, by setting the remote_monitoring option to true. If set to false, an integration will be considered a local entity, and the data related to it will be attached to the host entity that the agent creates. Remote monitoring requires infrastructure agent version 1.2.25 or higher. For the Apache, Cassandra, MySQL, NGINX, and Redis integrations, remote monitoring (and multi-tenancy) is enabled by activating the configuration parameter remote_monitoring. Important If your Apache, Cassandra, MySQL, NGINX, or Redis service is located in the same host as the agent, when you activate remote monitoring the resulting entity will be considered as remote, regardless of its actual location. This may affect alerts, alter attributes, and have other effects, as explained here. Effects of activating remote_monitoring By enabling remote_monitoring, the integration becomes a different entity which is no longer attached to the infrastructure agent. As a result, the following items may be affected: Alert verification Enabling remote monitoring can affect your configured alerts in case they are using any of the values that are affected by this new feature. We strongly recommend checking your existing alerts to make sure they keep on working as expected. New entity attributes These attributes are modified in the resulting entity: Display name: New entity unique key (instead of using the display name) Entity GUID: New entity GUID Entity ID: New entity ID Entity key: New entity unique key (instead of using the display name) External key: Using integration entity name (instead of using the agent display) Changes in recorded metrics When remote monitoring is enabled, we will add the hostname and port values to all metrics. If the nricluster name or nriservice are defined in the integration configuration file, they will also be decorated. Unrecorded attributes Since the integration is now an independent entity which is not attached to the agent, the following agent attributes are not collected: agentName agentVersion coreCount criticalViolationCount fullHostname instanceType kernelVersion linuxDistribution entityType operatingSystem processorCount systemMemoryBytes warningViolationCount Your custom attributes Updated hostname For the ApacheSample, RedisSample, CassandraSample, and NginxSample integration metrics, we will use the integration configuration hostname instead of the short hostname from the agent. When the integration hostname is a loopback address, the agent will replace it in order to guarantee uniqueness.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.2287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Remote</em> <em>monitoring</em> in on-host integrations",
        "sections": "<em>Remote</em> <em>monitoring</em> in on-host integrations",
        "body": " be affected: <em>Alert</em> verification Enabling <em>remote</em> <em>monitoring</em> can affect <em>your</em> configured <em>alerts</em> in case they are using any of the values that are affected by this new feature. We strongly recommend checking <em>your</em> existing <em>alerts</em> to make sure they keep on working as expected. New entity attributes"
      },
      "id": "603ec000e7b9d216732a07ef"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring": [
    {
      "sections": [
        "Compatibility and requirements for the Node.js agent",
        "Node.js version support",
        "Tip",
        "Support for new Node.js releases",
        "End of support for Node.js releases reaching EOL",
        "Node.js 12 errors",
        "Supported Node.js frameworks",
        "Operating systems",
        "Datastores",
        "Instance details",
        "Messages queues",
        "Hosting services",
        "Process managers",
        "Security requirements",
        "Connect the agent to other New Relic features"
      ],
      "title": "Compatibility and requirements for the Node.js agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Nodejs agent",
        "Getting started"
      ],
      "external_id": "dd144d7ffce53c47f9dd6d872f61905157023f6f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/nodejs-agent/getting-started/compatibility-requirements-nodejs-agent/",
      "published_at": "2021-09-30T19:31:47Z",
      "updated_at": "2021-09-30T19:31:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Node.js agent is publicly available on the Node Package Manager (npm) repository as well as on GitHub. Before you install the Node.js agent, make sure your application meets the following system requirements. If you haven't already, create a New Relic account. It's free, forever. Node.js version support Tip For best performance, use the latest active long term support (LTS) version of Node.js. Support for new Node.js releases We will support the latest even versions of Node.js releases by the beginning of the following active long term support schedule. The version support policy does not replace the general agent and plugin end-of-life (EOL) policy. The following are proposed time ranges. The actual release date may vary. Node.js version Active long term support (LTS) start date Initial release date of Node.js agent with support 18 October 2022 April-October 2022 16 October 2021 July 26, 2021 with Node.js agent v8.0.0 End of support for Node.js releases reaching EOL When support for a new long term support agent version is made available, support for the Node.js agent version that reaches end-of-life during the same time period will simultaneously drop. The following are proposed time ranges. The actual release date may vary. Node.js version End of life (EOL) date Initial release date of Node.js agent dropping support 12 April 2022 April-October 2022 10 April 2021 As of July 26, 2021, we have discontinued support for Node.js 10 with v8 of the Node.js agent. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Node.js 12 errors For Node.js 12, the following change affects the Node.js agent: Errors resulting in unhandled rejections are not scoped to the transaction that was active when the rejected promise was created. This is because the promise responsible for triggering the init async hook is no longer passed through on the promise wrap instance. This breaks the linkage that associates a given promise rejection with the transaction it was scheduled in. Supported Node.js frameworks Express 4.6.0 or higher Restify Connect Hapi Koa 2.0.0 or higher (external module loaded with the agent) If you are using a supported framework with default routers, the Node.js agent can read these frameworks' route names as-is. However, if you want more specific names than are provided by your framework, you may want to use one or more of the tools New Relic provides with the Node.js transaction naming API. Operating systems Linux SmartOS macOS 10.7 and higher Windows Server 2008 and higher Datastores The Node.js agent monitors the performance of Node.js application calls to these datastores: Cassandra Memcached MongoDB MySQL (via mysql and mysql2 packages) Redis Postgres (including the native and pure JavaScript packages) Instance details We collect instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your agent version. New Relic's Node.js agent version 1.31.0 or higher supports the following: Database npm module name Minimum module version Minimum agent version PostgreSQL pg 4.0.0 1.31.0 Redis redis 2.0.0 1.31.0 MongoDB mongodb 2.1.0 1.32.0 MySQL mysql 2.4.1 1.32.0 Memcached memcached 1.0.0 1.33.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Messages queues Message queue instrumentation is only available with the New Relic Node.js agent v2 or higher. Currently supported message queue instrumentation: amqplib For other message queue libraries, use custom instrumentation. Hosting services Google App Engine (GAE) flexible environment AWS EC2 Microsoft Azure Heroku Process managers In general, process managers that handle starting, stopping, and restarting of Node.js (like Forever) should be compatible with the Node.js agent. If you are using PM2, the minimum supported version of PM2 is 2.0. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Connect the agent to other New Relic features The Node.js agent integrates with other features to give you full-stack observability: Product Integration Browser monitoring The Node.js agent can add the benefits of browser monitoring when you enable auto-instrumentation. After enabling browser monitoring injection, simply follow our guide to installing browser monitoring with the Node.js agent. Once you've completed these steps, you can view your browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see browser monitoring and the Node.js agent. Infrastructure monitoring When you install the infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. New Relic dashboards The Node.js agent sends default events and attributes for NRQL queries. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from synthetic monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.635735,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Getting</em> <em>started</em>",
        "body": ". <em>Infrastructure</em> <em>monitoring</em> When you install the <em>infrastructure</em> and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your <em>infrastructure</em> hosts by APM app in the <em>Infrastructure</em> UI. For more information, see APM data"
      },
      "id": "6043d8dae7b9d2d4415799df"
    },
    {
      "sections": [
        "Install the infrastructure agent",
        "Quick start: Use our guided install",
        "Important",
        "Install the infrastructure monitoring agent",
        "Linux",
        "Windows Server and 10",
        "Other installation scenarios",
        "One agent, many capabilities",
        "Check the source code",
        "What's next"
      ],
      "title": "Install the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "ccb11bfd79824202d189a3e743771cfc81e77710",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent/",
      "published_at": "2021-09-30T23:02:39Z",
      "updated_at": "2021-09-02T09:05:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure monitoring agent is a lightweight executable file that collects data about your hosts. It also forwards data from infrastructure integrations to New Relic, as well as log data for log analytics. The infrastructure monitoring agent can currently run on many Linux distributions, Windows, and macOS. There are multiple ways to install and deploy the agent, depending on your setup and needs. This document describes how the infrastructure monitoring agent works and how to install it. Quick start: Use our guided install The quickest way to get started with our infrastructure monitoring agent is through our guided install. Our guided install not only installs the infrastructure agent, but also discovers the applications and log sources running in your environment. It recommends which ones you should instrument. Ready to get started? Click one of these button to try it out. Guided install EU Guided install The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your infrastructure. For more information on where you can run the agent, check the compatibility and requirements page. Important If you install the agent using the New Relic One UI, the Infrastructure status API is enabled by default. Install the infrastructure monitoring agent Linux If you don't have a New Relic account yet, the guided install doesn't work, or prefer to follow the procedure manually, see our tutorial. Windows Server and 10 If you don't have a New Relic account yet, the guided install doesn't work, or prefer to follow the procedure manually using our MSI installer, see our tutorial. Other installation scenarios The infrastructure monitoring agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Infrastructre can also be deployed in macOS. One agent, many capabilities Our infrastructure monitoring agent collects performance and health data about the system resources and processes of the host where it's enabled (on-premises or virtualized). At the same time, it acts as a forwarder for two types of data: core services metrics, which are collected by on-host integrations, and logs. If you want to collect data about core services running on your host, you need to install the infrastructure monitoring agent first, and then install or enable on-host integrations. Our infrastructure monitoring agent and its integrations collect data from the system and core services. It can also forward logs to New Relic. Backend application metrics (APM) are collected by separate language agents. Notice how each integration and forwarder feed different data types in the New Relic database (NRDB). Check the source code The infrastructure monitoring agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README. What's next After you've installed the infrastructure monitoring agent: Learn how to configure the agent or edit the config template. Install on-host integrations (for example, for Apache or MySQL). Enable log forwarding using the infrastructure agent. Learn how to manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.16659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>infrastructure</em> agent",
        "sections": "Install the <em>infrastructure</em> <em>monitoring</em> agent",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " distributions, Windows, and macOS. There are multiple ways to install and deploy the agent, depending on your setup and needs. This document describes how the <em>infrastructure</em> <em>monitoring</em> agent works and how to install it. Quick <em>start</em>: Use our guided install The quickest way to <em>get</em> <em>started</em> with our"
      },
      "id": "603e79bd64441f99814e8888"
    },
    {
      "sections": [
        "Connect Google Cloud Platform services to New Relic",
        "Requirements",
        "Authorization options",
        "Service account (recommended)",
        "User account",
        "Connect GCP to New Relic infrastructure monitoring",
        "Tip",
        "Explore app data in New Relic",
        "Link multiple Google projects",
        "Unlink your GCP integrations"
      ],
      "title": "Connect Google Cloud Platform services to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "05934d2b03ec1ac5fa43298b21a06dc2e0f8c3b9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/get-started/connect-google-cloud-platform-services-new-relic/",
      "published_at": "2021-10-07T00:06:31Z",
      "updated_at": "2021-09-27T15:50:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Google Cloud Platform (GCP) data with New Relic GCP integrations, connect your Google project to New Relic infrastructure monitoring. If you don't have one already, create a New Relic account. It's free, forever. Requirements These are the requirements for the authorization: GCP integration requirements Comments Monitoring In the GCP project API & Services Library settings, you must enable Google Stackdriver Monitoring API. Authorization For service account authorization (recommended): A user with Project IAM Admin role is needed to add the service account ID as a member in your GCP project. In the GCP project IAM & admin, the service account must have the Project Viewer role and the Service Usage Consumer role or, alternatively, a custom role. For user account authorization: The New Relic user that will integrate the GCP project must have a Google account and must be able to view the GCP project that New Relic will monitor. In the GCP project IAM & admin, the user must have the Project Viewer role. Please note that this authorization method will not allow New Relic to collect labels and other inventory attributes that can be useful for narrowing down your NRQL queries, dashboards and alerts. You can migrate the authorization method from user account to service account from the Manage services link in New Relic's user interface. Project name As part of the online setup process, you must identify Project name of the projects you want to monitor with New Relic. The UI workflow automatically lists active projects you can select. Permissions (only for user account authorization) New Relic requires a specific set of read-only permissions exclusively; this means that, for certain integrations, only partial inventory data will be available. Keep in mind that New Relic doesn't inherit your Google account's permissions and therefore is not authorized to perform any changes in the project. For more information about the API permissions that New Relic uses, see the Google documentation about scopes. Authorization options Integrating your GCP project with New Relic requires you to authorize New Relic to fetch monitoring data from your GCP project. You can choose between two authorization methods: Service accounts or User accounts. Service account (recommended) The service account authorization is recommended. If you authorize New Relic to fetch data through a service account, we will call your GCP project APIs using a service account ID and its associated public/private key pair. New Relic manages a specific Google service account for your New Relic account; you do not need to create it or manage the associated private key. Just add the service account ID as a member with viewing permissions in your project. If your organization uses a domain restriction constraint, you will have to update the policy to allow the New Relic domain, C02x1gp26. This authorization method is recommended, especially if your GCP project is managed by a team. It also guarantees that New Relic will collect labels and inventory attributes whenever possible. User account If you authorize New Relic to fetch data through a user account, New Relic will access your GCP project monitoring data on behalf of a particular Google user. The authorization process is achieved through an OAuth workflow, which redirects you from the New Relic UI to a Google authorization interface. However, since the authorization is linked to a particular Google user, this method is not recommended for GCP projects that are managed by large teams. Connect GCP to New Relic infrastructure monitoring To connect your Google account to New Relic with user account authorization: Go to one.newrelic.com > Infrastructure > GCP. At the top of Infrastructure's Google Cloud Services integrations page, select Add a GCP account. Choose Authorization Method: Select either Authorize a Service Account or Authorize a User Account, and follow the instructions in the UI to authorize New Relic. Add projects: Select the projects that you want New Relic to receive data from. Select services: From the list of available services for your GCP account, select the individual services you want New Relic to receive data from, or select all of the services. Tip These services will be enabled for all of the projects that you selected in the previous step. Once the setup process is finished, you can fine-tune the services that you want monitored for each project individually. To complete the setup process, select Finish. If you see API authentication errors, follow the troubleshooting procedures. Explore app data in New Relic After you authorize New Relic to integrate one or more of your Google project's services, New Relic starts monitoring your GCP data at regular polling intervals. After a few minutes, data will appear in the New Relic UI. To find and use your data, including links to dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP. Link multiple Google projects For your convenience, the setup process allows you to select more than one project at a time. After the first setup, if you need to monitor additional GCP projects with New Relic, you can repeat the procedure to connect your GCP services as many times as you need. Unlink your GCP integrations You can disable any of your GCP integrations any time and still keep your Google project connected to New Relic. If you want to... Do this Disable a GCP service monitoring To disconnect individual GCP services but keep the integration with New Relic for other GCP services in your Google account: Go to one.newrelic.com > Infrastructure > GCP and select Manage services. From your GCP account page, make changes to the checkbox options for available services and select Save changes. Unlink your project monitoring To uninstall all of your GCP services completely from New Relic Integrations, unlink your Google account: Go to one.newrelic.com > Infrastructure > GCP and select Manage services. From your GCP account page, select Unlink account and select Save changes. Clean your GCP Projects after unlinking New Relic To clean your GCP project after unlinking, follow these steps if you were using a service account: Open the GCP IAM Console. Select the project you want to unlink from New Relic and click Open. Select the service account that is used by New Relic. Click the Remove icon. Or follow these steps if you were using a user account: Open your Google user account settings. Open the Apps with access to your account section. Choose New Relic application. Choose Remove Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.99141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect GCP to New Relic <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "To <em>start</em> receiving Google Cloud Platform (GCP) data with New Relic GCP integrations, connect your Google project to New Relic <em>infrastructure</em> <em>monitoring</em>. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Requirements These are the requirements for the authorization: GCP"
      },
      "id": "603e8309196a67fc4fa83da7"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/infrastructure-security/infrastructure-security": [
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "7f77d1e4599c8f7b9b2a44bc817f328f11410651",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.06316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "API <em>and</em> other options",
        "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from <em>infrastructure</em> <em>monitoring</em> in New Relic One. See"
      },
      "id": "603ea62e196a6749f8a83dc9"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.83031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> troubleshooting",
        "body": ". Generate some traffic for your app. Wait a few minutes, and then check for APM data in <em>infrastructure</em> <em>monitoring</em>. Make sure the hostnames are the same in APM and <em>Infrastructure</em>. If the hostnames are different in APM and <em>infrastructure</em> <em>monitoring</em>, New Relic cannot integrate the data. One common cause"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-01T12:59:41Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.77149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> troubleshooting",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.20956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-09-30T23:10:12Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.57222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-09-30T23:11:19Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.65799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure": [
    {
      "sections": [
        "The agent is not starting and there are no logs",
        "Problem",
        "Solution",
        "Check requiretty",
        "Important",
        "Review log permissions"
      ],
      "title": "The agent is not starting and there are no logs",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "fefb6cf577c3c825a6908eba8e378de3ceca4cd7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs/",
      "published_at": "2021-09-30T23:10:12Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The infrastructure agent is not starting, and logs are not created. Solution Here are some troubleshooting options for non-root users if the infrastructure agent is not starting and there are no logs: Check requiretty To see if requiretty is causing logging issues: In /var/log/messages or /var/log/syslog, look for the message sudo: sorry, you must have a tty to run sudo . Important When using old Linux versions, sometimes the nri-agent user fails to execute a service because it does not have any TTY attached. If you find this message, edit your /etc/sudoers file with the visudo command and comment or remove the following line: Defaults requiretty Save and exit the file. Restart the newrelic-infra service. Review log permissions Check the agent's permission to open log_file. It's possible that the log file you are using was created when the agent was running as root, and now the nri-agent user does not have permissions to write it. To solve this, try one of these options: Change the owner of the log file. Change the log_file entry in the /etc/newrelic-infra.yml configuration file. Our installation scripts create the /var/log/newrelic-infra/ folder for that purpose, so we recommend the following value: log_file: /var/log/newrelic-infra/newrelic-infra.log Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.48494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The agent is not starting and there are no <em>logs</em>",
        "sections": "The agent is not starting and there are no <em>logs</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The <em>infrastructure</em> agent is not starting, and <em>logs</em> are not created. Solution Here are some <em>troubleshooting</em> options for non-root users if the <em>infrastructure</em> agent is not starting and there are no <em>logs</em>: Check requiretty To see if requiretty is causing logging issues: In &#x2F;var&#x2F;<em>log</em>&#x2F;messages"
      },
      "id": "603eba9e28ccbc5f64eba786"
    },
    {
      "sections": [
        "Infrastructure agent logging behavior",
        "Logging severity levels",
        "Important",
        "Log formatting",
        "Log rotation",
        "Logrotate config file sample",
        "Tip",
        "Smart verbose mode",
        "Logging before Infrastructure agent v1.4.9",
        "Integration log management",
        "Integration STDERR expected format"
      ],
      "title": "Infrastructure agent logging behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "0dc6570e893e47c4d5b5c4232283432926c6476a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior/",
      "published_at": "2021-09-30T23:01:43Z",
      "updated_at": "2021-03-16T07:31:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure agent gathers its own data as well as integrations's logs and consolidates them in a single source. By default, logs appear in standard-output and are added to a log file. To disable logs in standard output, see the agent's config options. Logging severity levels Infrastructure uses a subset of the standard Syslog severity levels: ERROR: Error conditions met WARN: Warning conditions met INFO: Informational messages DEBUG: Contains debug-level messages (useful when troubleshooting) Important DEBUG level is only shown when the verbose mode is enabled. Log formatting For infrastructure agent v1.4.9 or higher, log messages are inlined with context values. This offers better grouping and filtering; for example: containerized agent found in container containerID: VALUE Copy By default, Infrastructure logs are formatted as text: In foreground mode, log output is colored, without a timestamp: DEBUG Sending deltas divided in blocks component=PatchSender mentityKey=ohaimaci mnumberOfBlocks=1 Copy In background mode, logs are timestamped output, used when running as a service or dumping logs to a file: time=\"2019-07-12T09:54:15+02:00\" level=info msg=\"Agent service manager shutdown completed successfully.\" component=AgentService service=newrelic-infra Copy Alternatively, logs can be formatted as a JSON file: {\"context\":{},\"level\":\"info\",\"msg\":\"upstart_interval_sec: 0\",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} {\"context\":{},\"level\":\"info\",\"msg\":\"plugin_dir: \",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} Copy To change the log format, see the agent configuration settings. Log rotation The infrastructure agent does not provide any native log rotation or compression mechanism. Instead, we encourage you to use consolidated log rotation tools, such as the Linux logrotate tool, which is usually installed by default in most Linux distributions. Logrotate can be configured as an entry in /etc/logrotate.conf, or as a file in the /etc/logrotate.d directory. Logrotate config file sample A sample logrotate config file looks like this: /var/log/newrelic-infra/newrelic-infra.log { copytruncate compress daily dateext maxage 7 } Copy Where: /var/log/newrelic-infra/newrelic-infra.log: The Infrastructure agent log file. It must match the log_file configuration parameter in the /etc/newrelic-infra.yml file. copytruncate: Indicates that the log file is truncated but not deleted when it is rotated. This configuration option is mandatory, otherwise the log file will be deleted and won’t be recreated. compress: Compresses (usually in Gzip format) the rotated log files. daily: The agent rotates logs daily. dateext: Appends a date (by default, in the format YYYYMMDD) to the rotated log file (e.g. newrelic-infra.log-20190708.gz) maxage 7: Makes logrotate remove rotated files after 7 days. Tip For a complete description of the logrotate configuration options, see the Linux Logrotate documentation. Since logrotate is usually executed automatically as a cron job, verify that there is a logrotate entry in cron (for example, /etc/cron.daily/logrotate) similar to: #!/bin/sh /usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.conf EXITVALUE=$? if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\" fi exit 0 Copy Smart verbose mode For infrastructure agent versions 1.9.0 or higher, you can enable smart verbose mode for logs. Smart verbose mode prevents debug messages being logged until an error message is logged. Once an error has been logged, the cached debug messages are logged, but only the most recent number of configured debug messages. For example, if you have a configured limit of 10, after an error is logged, only the 10 most recent debug messages are logged, and older logs are discarded. For more information on how to enable smart verbose mode and the debug message limit, see Infrastructure configuration settings. Logging before Infrastructure agent v1.4.9 Here is a comparison of functionality for Infrastructure agent versions before and after v1.4.9: Agent v1.4.9 and higher Before v1.4.9 Foreground mode logged. The agent couldn't log some entries in foreground mode because the logging service wasn't able to write data until the agent was completely configured. Logs in text and JSON formats. Logs in text only. Logs displayed as inline text. Logs displayed as static literals in a single, decontextualized line. Integration log management Integrations write JSON payloads into STDOUT and plain-text (JSON structured in the future) logs into STDERR. The infrastructure agent handles integration STDERR lines and forward this output into the agent one, usually the service log. Agent handles each STDERR line as follows: when agent runs in verbose mode: it just forwards the full STDERR line as a DEBUG agent log entry placing integration line contexts within the ` msg ` field. otherwise: it parses the line against the expected format (see below) and only logs as agent ERROR level, entries produced by integrations with ` fatal ` or ` error ` severity levels. In this case fields are extracted and forwarded in structured manner (therefore if JSON output is enabled for the agent fields become queryable. Integration STDERR expected format A line is expected to be a list of key-value pairs separated by an equal character. Keys can contain any character, whereas values can have three different formats: string: < quote>any character including escaped quotes \\ \" < quote> map: & { any character} word: any character except spaces Internally agent used this regex to extract the fields: ([^\\s]*?)=(\".*?[^\\\\]\"|&{.*?}|[^\\s]*) Copy For instance, this line: time=\"2015-03-26T01:27:38-04:00\" level=error msg=\"Foo bar baz\" foo=bar Copy Will generate a structured agent log line with these fields: - \"time\": \"2015-03-26T01:27:38-04:00\" - \"level\": \"error\" - \"msg\": \"Foo bar baz\" - \"foo\": \"bar\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.48326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "sections": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "New Relic&#x27;s <em>infrastructure</em> agent gathers its own data as well as integrations&#x27;s <em>logs</em> and consolidates them in a single source. By default, <em>logs</em> appear in standard-output and are added to a <em>log</em> file. To disable <em>logs</em> in standard output, see the agent&#x27;s config options. Logging severity levels"
      },
      "id": "603eb3a228ccbc6badeba7a5"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.62558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior": [
    {
      "sections": [
        "The agent is not starting and there are no logs",
        "Problem",
        "Solution",
        "Check requiretty",
        "Important",
        "Review log permissions"
      ],
      "title": "The agent is not starting and there are no logs",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "fefb6cf577c3c825a6908eba8e378de3ceca4cd7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs/",
      "published_at": "2021-09-30T23:10:12Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The infrastructure agent is not starting, and logs are not created. Solution Here are some troubleshooting options for non-root users if the infrastructure agent is not starting and there are no logs: Check requiretty To see if requiretty is causing logging issues: In /var/log/messages or /var/log/syslog, look for the message sudo: sorry, you must have a tty to run sudo . Important When using old Linux versions, sometimes the nri-agent user fails to execute a service because it does not have any TTY attached. If you find this message, edit your /etc/sudoers file with the visudo command and comment or remove the following line: Defaults requiretty Save and exit the file. Restart the newrelic-infra service. Review log permissions Check the agent's permission to open log_file. It's possible that the log file you are using was created when the agent was running as root, and now the nri-agent user does not have permissions to write it. To solve this, try one of these options: Change the owner of the log file. Change the log_file entry in the /etc/newrelic-infra.yml configuration file. Our installation scripts create the /var/log/newrelic-infra/ folder for that purpose, so we recommend the following value: log_file: /var/log/newrelic-infra/newrelic-infra.log Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.48494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The agent is not starting and there are no <em>logs</em>",
        "sections": "The agent is not starting and there are no <em>logs</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The <em>infrastructure</em> agent is not starting, and <em>logs</em> are not created. Solution Here are some <em>troubleshooting</em> options for non-root users if the <em>infrastructure</em> agent is not starting and there are no <em>logs</em>: Check requiretty To see if requiretty is causing logging issues: In &#x2F;var&#x2F;<em>log</em>&#x2F;messages"
      },
      "id": "603eba9e28ccbc5f64eba786"
    },
    {
      "sections": [
        "Generate logs for troubleshooting the infrastructure agent",
        "Problem",
        "Important",
        "Solution",
        "Smart verbose mode",
        "Forward the agent logs to New Relic Logs",
        "Notes for specific systems",
        "Containerized agent on CoreOS"
      ],
      "title": "Generate logs for troubleshooting the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "a0c2ca22e3fca2b3add8c94d211adffce686661c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure/",
      "published_at": "2021-10-01T08:29:57Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting your infrastructure agent, generate verbose logs for a few minutes to find and investigate errors. This can be useful for your own troubleshooting or when working with New Relic Support. Important Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. If you have New Relic infrastructure agent 1.4.0 or higher, you can automate this process by using the newrelic-infra-ctl command. For more information, see the troubleshooting binary documentation. Solution Generating verbose log files requires editing your configuration file. For a sample config file that includes all applicable settings, see the example template. To generate detailed logs: Step Procedures Edit your newrelic-infra.yml file: Enable verbose logging: verbose: 1. (If you use a containerized infrastructure agent on CoreOS, see system-specific notes.) Set log_file to a convenient log file location. Restart the agent so the agent notices the new settings. Let your host run at normal load for about three minutes to generate sufficient logging data. Return your settings to default: Disable verbose logging by setting verbose: 0 in newrelic-infra.yml. Optional: Disable logging to a custom file by removing the log_file line from newrelic-infra.yml. Restart the agent so the agent notices the new settings. Examine the log file for errors. If you need to send your log file to New Relic Support: Include the line in your log file that contains the agent version: New Relic infrastructure agent version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your newrelic-infra.yml. Smart verbose mode Sometimes errors don't occur until after quite some time has passed. This makes debugging difficult, because typically verbose logs are only enabled for a short period time; otherwise there will be many debug logs. For example, if an error occurs one hour after the infrastructure agent has started, getting debug logs around the time of the error can be tricky or impractical. As of infrastructure agent v1.9.0 or higher, you can use smart verbose mode for logs. Smart verbose mode only logs the most recent debug messages after an error has been logged. This allows you to leave smart verbose mode running until an error occurs, without logging lots of irrelevant debug messages, and only logging the most recent debug messages. (The number of messages is determined by your configuration.) For more information on smart verbose mode, see the Infrastructure agent logging behavior docs, and use the Infrastructure configuration settings documentation for details on how to enable smart verbose mode. Forward the agent logs to New Relic Logs The Infrastructure agent can be configured to send its own logs to New Relic Logs. This can be useful for troubleshooting issues with log forwarding, the Infrastructure agent, or when contacting support. For details on how to enable log forwarding for the Infrastructure agent, see Troubleshoot log forwarding. Notes for specific systems These are some additional notes and requirements for specific systems, used to supplement the general logging instructions: Containerized agent on CoreOS If you are using a containerized infrastructure agent on CoreOS: Choose one of these options to change the log level to verbose: Recommended: Set the environment variable NRIA_VERBOSE to 1. Running this on the command line would look like: -e NRIA_VERBOSE=1 Copy OR Edit the config file to set verbose: 1. (Editing the config file in a container is not recommended, because it requires rebuilding the image twice: once to add verbose logging and once to remove it.) Use journalctl to collect the logs: journalctl -u newrelic-infra > newrelic-infra.log Copy Set the verbose logging level back to 0 after collecting logs for a few minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.48178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "sections": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " verbose mode. Forward the agent <em>logs</em> to New Relic <em>Logs</em> The <em>Infrastructure</em> agent can be configured to send its own <em>logs</em> to New Relic <em>Logs</em>. This can be useful for <em>troubleshooting</em> issues with <em>log</em> forwarding, the <em>Infrastructure</em> agent, or when contacting support. For details on how to enable <em>log</em> forwarding"
      },
      "id": "603e910028ccbc6304eba76d"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.62556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-09-30T23:09:10Z",
      "updated_at": "2021-09-08T16:49:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.8064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-09-30T23:07:10Z",
      "updated_at": "2021-08-27T07:06:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes unless you use guided install. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.27896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-09-30T23:09:10Z",
      "updated_at": "2021-03-11T11:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > E * *vents. The Events * * page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.26782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    }
  ],
  "/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-09-30T23:09:10Z",
      "updated_at": "2021-09-08T16:49:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.8064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-10-01T12:35:21Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.26935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-09-30T23:09:10Z",
      "updated_at": "2021-03-11T11:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > E * *vents. The Events * * page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.26782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk": [
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-10-01T08:31:10Z",
      "updated_at": "2021-07-27T09:36:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.67896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    },
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-09-30T23:02:39Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.93616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-10-01T00:08:22Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.71097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet": [
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-10-01T08:31:10Z",
      "updated_at": "2021-07-27T09:36:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.67896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-09-30T23:02:38Z",
      "updated_at": "2021-07-02T00:51:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.31665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-10-01T00:08:22Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.71097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible": [
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-09-30T23:02:38Z",
      "updated_at": "2021-07-02T00:51:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.31665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    },
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-09-30T23:02:39Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.93616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-10-01T00:08:22Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.71097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef": [
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-10-01T08:31:10Z",
      "updated_at": "2021-07-27T09:36:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.67896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-09-30T23:02:38Z",
      "updated_at": "2021-07-02T00:51:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.31665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    },
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-09-30T23:02:39Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.93616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/config-file-template-newrelic-infrayml": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-20T19:24:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user:access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.5537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> has a large set of <em>configuration</em> settings to fine-tune its behavior. Here we: List all the <em>configuration</em> options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.62973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can <em>install</em> the <em>agent</em> manually. Before installing <em>infrastructure</em>, be sure to: Review the requirements. Have a valid New Relic license key. To <em>install</em> <em>infrastructure</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-09-27T15:12:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.21 Red Hat Enterprise Linux (RHEL) Version 6 or higher Oracle Linux Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.32,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-20T19:24:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user:access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.5537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> has a large set of <em>configuration</em> settings to fine-tune its behavior. Here we: List all the <em>configuration</em> options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.62973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can <em>install</em> the <em>agent</em> manually. Before installing <em>infrastructure</em>, be sure to: Review the requirements. Have a valid New Relic license key. To <em>install</em> <em>infrastructure</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-09-27T15:12:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.21 Red Hat Enterprise Linux (RHEL) Version 6 or higher Oracle Linux Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.32,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.62964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can <em>install</em> the <em>agent</em> manually. Before installing <em>infrastructure</em>, be sure to: Review the requirements. Have a valid New Relic license key. To <em>install</em> <em>infrastructure</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-09-27T15:12:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.21 Red Hat Enterprise Linux (RHEL) Version 6 or higher Oracle Linux Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.31995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for macOS",
        "Tip",
        "Install for macOS (Beta)",
        "Limitations (Beta)",
        "Step-by-step instructions",
        "Homebrew install",
        "What's next?",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for macOS",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "macOS installation"
      ],
      "external_id": "755028024e9e2757dd8441cccb2adb1fd3aefdac",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/macos-installation/install-infrastructure-monitoring-agent-macos/",
      "published_at": "2021-09-30T23:01:42Z",
      "updated_at": "2021-09-14T20:38:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for macOS (Beta), you can monitor key performance metrics on macOS hosts. The agent can run on your own hardware or in cloud systems such as Amazon EC2. The infrastructure monitoring agent is compatible with all generally available, Apple supported macOS versions. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install for macOS (Beta) Before installation, be sure to review the requirements. Then, to install the infrastructure monitoring agent for macOS, you can use our Guided Install, or follow the instructions in this document to complete a basic installation. Limitations (Beta) The following capabilities of the infrastructure agent are not yet available on macOS: Process Monitoring. Log forwarder. On-host integrations (including built-in integrations such as Docker and Flex). Automated deployment via Configuration Management tools (Chef, Ansible, Puppet). Step-by-step instructions To install the infrastructure monitoring agent, follow the step-by-step instructions: Homebrew install Review the agent requirements and supported operating systems. Make sure Homebrew is installed in the system. You can check if Homebrew is installed with: which brew Copy If it's not installed, you can install it with this command (or check Homebrew up-to-date instructions): /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Copy Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /usr/local/etc/newrelic-infra/newrelic-infra.yml Copy Then, open the terminal and run the following command: brew install newrelic/tap/newrelic-infra-agent -q Copy Start the infrastructure agent service: brew services start newrelic-infra-agent Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.51279,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for macOS",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for macOS",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " on macOS: Process Monitoring. Log forwarder. On-host integrations (including built-in integrations such as Docker and Flex). Automated deployment via <em>Configuration</em> Management tools (Chef, Ansible, Puppet). Step-by-step instructions To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em>, follow the step-by-step"
      },
      "id": "611fe66a28ccbc920ff9abfa"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-09-27T15:12:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.21 Red Hat Enterprise Linux (RHEL) Version 6 or higher Oracle Linux Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 327.1822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.69069,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (No credit card required). Quick <em>start</em> The quickest way to <em>get</em> <em>started</em> with our <em>infrastructure</em> monitoring <em>agent</em> is through our guided <em>install</em>. Tip Try our guided <em>install</em> for yourself. (If you&#x27;re hosted in the EU, use our EU guided <em>install</em>.) Step-by-step instructions If guided <em>install</em> doesn&#x27;t work, you"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-20T19:24:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user:access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.23143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " = &#x27;production&#x27; Copy enable_process_metrics Important Requires <em>infrastructure</em> <em>agent</em> version 1.12.0 or higher. Accounts created before July 20, 2020 and&#x2F;or <em>infrastructure</em> agents installed using the new Guided <em>Install</em> have this variable enabled by default. Enables the sending of process metrics to New"
      },
      "id": "603ea542196a67a38aa83dd8"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent": [
    {
      "sections": [
        "Install the infrastructure agent",
        "Quick start: Use our guided install",
        "Important",
        "Install the infrastructure monitoring agent",
        "Linux",
        "Windows Server and 10",
        "Other installation scenarios",
        "One agent, many capabilities",
        "Check the source code",
        "What's next"
      ],
      "title": "Install the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "ccb11bfd79824202d189a3e743771cfc81e77710",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent/",
      "published_at": "2021-09-30T23:02:39Z",
      "updated_at": "2021-09-02T09:05:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure monitoring agent is a lightweight executable file that collects data about your hosts. It also forwards data from infrastructure integrations to New Relic, as well as log data for log analytics. The infrastructure monitoring agent can currently run on many Linux distributions, Windows, and macOS. There are multiple ways to install and deploy the agent, depending on your setup and needs. This document describes how the infrastructure monitoring agent works and how to install it. Quick start: Use our guided install The quickest way to get started with our infrastructure monitoring agent is through our guided install. Our guided install not only installs the infrastructure agent, but also discovers the applications and log sources running in your environment. It recommends which ones you should instrument. Ready to get started? Click one of these button to try it out. Guided install EU Guided install The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your infrastructure. For more information on where you can run the agent, check the compatibility and requirements page. Important If you install the agent using the New Relic One UI, the Infrastructure status API is enabled by default. Install the infrastructure monitoring agent Linux If you don't have a New Relic account yet, the guided install doesn't work, or prefer to follow the procedure manually, see our tutorial. Windows Server and 10 If you don't have a New Relic account yet, the guided install doesn't work, or prefer to follow the procedure manually using our MSI installer, see our tutorial. Other installation scenarios The infrastructure monitoring agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Infrastructre can also be deployed in macOS. One agent, many capabilities Our infrastructure monitoring agent collects performance and health data about the system resources and processes of the host where it's enabled (on-premises or virtualized). At the same time, it acts as a forwarder for two types of data: core services metrics, which are collected by on-host integrations, and logs. If you want to collect data about core services running on your host, you need to install the infrastructure monitoring agent first, and then install or enable on-host integrations. Our infrastructure monitoring agent and its integrations collect data from the system and core services. It can also forward logs to New Relic. Backend application metrics (APM) are collected by separate language agents. Notice how each integration and forwarder feed different data types in the New Relic database (NRDB). Check the source code The infrastructure monitoring agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README. What's next After you've installed the infrastructure monitoring agent: Learn how to configure the agent or edit the config template. Install on-host integrations (for example, for Apache or MySQL). Enable log forwarding using the infrastructure agent. Learn how to manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.00983,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " distributions, Windows, and macOS. There are multiple ways to <em>install</em> and deploy the <em>agent</em>, depending on your setup and needs. This document describes how the <em>infrastructure</em> monitoring <em>agent</em> works and how to <em>install</em> it. Quick <em>start</em>: Use our guided <em>install</em> The quickest way to <em>get</em> <em>started</em> with our"
      },
      "id": "603e79bd64441f99814e8888"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.69061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (No credit card required). Quick <em>start</em> The quickest way to <em>get</em> <em>started</em> with our <em>infrastructure</em> monitoring <em>agent</em> is through our guided <em>install</em>. Tip Try our guided <em>install</em> for yourself. (If you&#x27;re hosted in the EU, use our EU guided <em>install</em>.) Step-by-step instructions If guided <em>install</em> doesn&#x27;t work, you"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-20T19:24:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user:access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.23138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " = &#x27;production&#x27; Copy enable_process_metrics Important Requires <em>infrastructure</em> <em>agent</em> version 1.12.0 or higher. Accounts created before July 20, 2020 and&#x2F;or <em>infrastructure</em> agents installed using the new Guided <em>Install</em> have this variable enabled by default. Enables the sending of process metrics to New"
      },
      "id": "603ea542196a67a38aa83dd8"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/azure-extensions-infrastructure": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 386.7779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-01T23:34:44Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.64258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    },
    {
      "sections": [
        "Docker instrumentation for infrastructure monitoring",
        "Requirements",
        "Enable Docker container monitoring",
        "View your Docker data",
        "Docker attributes",
        "Set alert conditions"
      ],
      "title": "Docker instrumentation for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "7d6febf75c3e6b5a67fdda3226d31132cfc81b43",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/",
      "published_at": "2021-10-01T12:56:42Z",
      "updated_at": "2021-07-27T11:56:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure agent automatically monitors your Docker containers. With Docker monitoring you can: Group containers by tags, attributes, and other metadata. Search for containers relevant to your monitoring scenario. Link to related entities that may be affected by issues with the container. Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic's infrastructure agent: Infrastructure agent 1.8.32 or higher running on Linux If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable Docker container monitoring If you meet the requirements and have installed the correct infrastructure monitoring agent, there are no additional steps to enable Docker monitoring. If Docker is running, data will automatically be reported. You can also use a Docker image containing the infrastructure monitoring agent. For more information, see Docker container for infrastructure monitoring. View your Docker data To view your Docker data in the New Relic UI, use either of these options: Go to one.newrelic.com > Infrastructure > Hosts > Containers. OR Go to one.newrelic.com > Infrastructure > Third-party services, and select Docker-related links. For more information, see Query your data. Docker attributes Docker attributes (metrics and metadata) are attached to the ContainerSample event. Here's an example of a query to find out how many containers are associated with each Docker image: SELECT uniqueCount(containerId) FROM ContainerSample FACET imageName SINCE 1 HOUR AGO TIMESERIES Copy To see all ContainerSample attributes, use our data dictionary. Attributes include: General metadata (like containerId, name, and image) CPU metrics (like cpuUsedCores, cpuPercent, and cpuThrottleTimeMs) Memory metrics (like memoryUsageBytes, memoryCacheBytes, and memoryResidentSizeBytes) Network metrics (like networkRxBytes, networkRxDropped, and networkTxBytes) Docker metrics are also attached to the ProcessSample event. The reported data does not include information related to the container orchestrator (for example, ECS or Kubernetes). To monitor those, you can add the orchestrator's cluster and task names as labels. Set alert conditions To create Docker-related alert conditions, use either of these options: Go to one.newrelic.com > Alerts & AI. OR Go to one.newrelic.com > Infrastructure > Settings > Alerts. Create a new alert condition. For the condition type, select Container metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.7383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "sections": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic&#x27;s <em>infrastructure</em> <em>agent</em>: <em>Infrastructure</em> <em>agent</em> 1.8.32 or higher running on <em>Linux</em> If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable"
      },
      "id": "603e9f3ee7b9d2d57c2a0818"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 386.7779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Docker instrumentation for infrastructure monitoring",
        "Requirements",
        "Enable Docker container monitoring",
        "View your Docker data",
        "Docker attributes",
        "Set alert conditions"
      ],
      "title": "Docker instrumentation for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "7d6febf75c3e6b5a67fdda3226d31132cfc81b43",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/",
      "published_at": "2021-10-01T12:56:42Z",
      "updated_at": "2021-07-27T11:56:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure agent automatically monitors your Docker containers. With Docker monitoring you can: Group containers by tags, attributes, and other metadata. Search for containers relevant to your monitoring scenario. Link to related entities that may be affected by issues with the container. Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic's infrastructure agent: Infrastructure agent 1.8.32 or higher running on Linux If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable Docker container monitoring If you meet the requirements and have installed the correct infrastructure monitoring agent, there are no additional steps to enable Docker monitoring. If Docker is running, data will automatically be reported. You can also use a Docker image containing the infrastructure monitoring agent. For more information, see Docker container for infrastructure monitoring. View your Docker data To view your Docker data in the New Relic UI, use either of these options: Go to one.newrelic.com > Infrastructure > Hosts > Containers. OR Go to one.newrelic.com > Infrastructure > Third-party services, and select Docker-related links. For more information, see Query your data. Docker attributes Docker attributes (metrics and metadata) are attached to the ContainerSample event. Here's an example of a query to find out how many containers are associated with each Docker image: SELECT uniqueCount(containerId) FROM ContainerSample FACET imageName SINCE 1 HOUR AGO TIMESERIES Copy To see all ContainerSample attributes, use our data dictionary. Attributes include: General metadata (like containerId, name, and image) CPU metrics (like cpuUsedCores, cpuPercent, and cpuThrottleTimeMs) Memory metrics (like memoryUsageBytes, memoryCacheBytes, and memoryResidentSizeBytes) Network metrics (like networkRxBytes, networkRxDropped, and networkTxBytes) Docker metrics are also attached to the ProcessSample event. The reported data does not include information related to the container orchestrator (for example, ECS or Kubernetes). To monitor those, you can add the orchestrator's cluster and task names as labels. Set alert conditions To create Docker-related alert conditions, use either of these options: Go to one.newrelic.com > Alerts & AI. OR Go to one.newrelic.com > Infrastructure > Settings > Alerts. Create a new alert condition. For the condition type, select Container metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.7383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "sections": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic&#x27;s <em>infrastructure</em> <em>agent</em>: <em>Infrastructure</em> <em>agent</em> 1.8.32 or higher running on <em>Linux</em> If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable"
      },
      "id": "603e9f3ee7b9d2d57c2a0818"
    },
    {
      "sections": [
        "Tarball assisted install of the infrastructure agent for Linux",
        "Important",
        "Install the agent",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Tarball assisted install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "fd6735d0ef7034ddb5435a01658e07dca45efd57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux/",
      "published_at": "2021-10-01T23:34:45Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Linux, you can make the changes you need to the installation script and configuration file we provide so you can adapt it to your environment. Important Assisted install only works for the Systemd, Upstart, and SysV service managers. If you use any other service manager, proceed with the manual install. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Update your license key in config_defaults.sh. Optional: Update any other environment parameters in the configuration file. Execute installer.sh with admin rights. The script automatically identifies your service manager. If it fails, it will prompt you to manually update it. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Configure your installation The configuration file config_defaults.sh serves as a source of reference for all the configuration options. It contains the following environment parameters: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: /var/db/newrelic-infra/ Copy NRIA_BIN_DIR Required at installation. The path to the agent binary folder. Default: /usr/local/bin Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: /etc/newrelic-infra/yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The infrastructure agent license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: /var/run/newrelic-infra/newrelic-infra.log Copy NRIA_MODE Required at installation. The privilege level for the agent. Possible values are ROOT, PRIVILEGED or UNPRIVILEGED. For more info see our documentation on agent running modes. Default: ROOT Copy NRIA_PID_FILE Required at agent startup. The location where the agent will place its PID file. Default: /var/run/newrelic-infra/newrelic-infra.pid Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: /etc/newrelic-infra/integrations.d/ Copy NRIA_USER Required at installation time only when the running mode is set to either PRIVILEGED or UNPRIVILEGED. The user that will run the agent binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.32,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>, you can make the changes you need to the <em>installation</em> script and configuration file we provide so you can adapt it to your environment. Important Assisted <em>install</em> only works for the Systemd, Upstart, and SysV service managers. If you"
      },
      "id": "603ea54064441f6bb64e8859"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 386.77777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-01T23:34:44Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.64258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    },
    {
      "sections": [
        "Tarball assisted install of the infrastructure agent for Linux",
        "Important",
        "Install the agent",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Tarball assisted install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "fd6735d0ef7034ddb5435a01658e07dca45efd57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux/",
      "published_at": "2021-10-01T23:34:45Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Linux, you can make the changes you need to the installation script and configuration file we provide so you can adapt it to your environment. Important Assisted install only works for the Systemd, Upstart, and SysV service managers. If you use any other service manager, proceed with the manual install. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Update your license key in config_defaults.sh. Optional: Update any other environment parameters in the configuration file. Execute installer.sh with admin rights. The script automatically identifies your service manager. If it fails, it will prompt you to manually update it. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Configure your installation The configuration file config_defaults.sh serves as a source of reference for all the configuration options. It contains the following environment parameters: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: /var/db/newrelic-infra/ Copy NRIA_BIN_DIR Required at installation. The path to the agent binary folder. Default: /usr/local/bin Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: /etc/newrelic-infra/yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The infrastructure agent license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: /var/run/newrelic-infra/newrelic-infra.log Copy NRIA_MODE Required at installation. The privilege level for the agent. Possible values are ROOT, PRIVILEGED or UNPRIVILEGED. For more info see our documentation on agent running modes. Default: ROOT Copy NRIA_PID_FILE Required at agent startup. The location where the agent will place its PID file. Default: /var/run/newrelic-infra/newrelic-infra.pid Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: /etc/newrelic-infra/integrations.d/ Copy NRIA_USER Required at installation time only when the running mode is set to either PRIVILEGED or UNPRIVILEGED. The user that will run the agent binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.32,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>, you can make the changes you need to the <em>installation</em> script and configuration file we provide so you can adapt it to your environment. Important Assisted <em>install</em> only works for the Systemd, Upstart, and SysV service managers. If you"
      },
      "id": "603ea54064441f6bb64e8859"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux": [
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-01T23:34:44Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.64258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    },
    {
      "sections": [
        "Docker instrumentation for infrastructure monitoring",
        "Requirements",
        "Enable Docker container monitoring",
        "View your Docker data",
        "Docker attributes",
        "Set alert conditions"
      ],
      "title": "Docker instrumentation for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "7d6febf75c3e6b5a67fdda3226d31132cfc81b43",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/",
      "published_at": "2021-10-01T12:56:42Z",
      "updated_at": "2021-07-27T11:56:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure agent automatically monitors your Docker containers. With Docker monitoring you can: Group containers by tags, attributes, and other metadata. Search for containers relevant to your monitoring scenario. Link to related entities that may be affected by issues with the container. Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic's infrastructure agent: Infrastructure agent 1.8.32 or higher running on Linux If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable Docker container monitoring If you meet the requirements and have installed the correct infrastructure monitoring agent, there are no additional steps to enable Docker monitoring. If Docker is running, data will automatically be reported. You can also use a Docker image containing the infrastructure monitoring agent. For more information, see Docker container for infrastructure monitoring. View your Docker data To view your Docker data in the New Relic UI, use either of these options: Go to one.newrelic.com > Infrastructure > Hosts > Containers. OR Go to one.newrelic.com > Infrastructure > Third-party services, and select Docker-related links. For more information, see Query your data. Docker attributes Docker attributes (metrics and metadata) are attached to the ContainerSample event. Here's an example of a query to find out how many containers are associated with each Docker image: SELECT uniqueCount(containerId) FROM ContainerSample FACET imageName SINCE 1 HOUR AGO TIMESERIES Copy To see all ContainerSample attributes, use our data dictionary. Attributes include: General metadata (like containerId, name, and image) CPU metrics (like cpuUsedCores, cpuPercent, and cpuThrottleTimeMs) Memory metrics (like memoryUsageBytes, memoryCacheBytes, and memoryResidentSizeBytes) Network metrics (like networkRxBytes, networkRxDropped, and networkTxBytes) Docker metrics are also attached to the ProcessSample event. The reported data does not include information related to the container orchestrator (for example, ECS or Kubernetes). To monitor those, you can add the orchestrator's cluster and task names as labels. Set alert conditions To create Docker-related alert conditions, use either of these options: Go to one.newrelic.com > Alerts & AI. OR Go to one.newrelic.com > Infrastructure > Settings > Alerts. Create a new alert condition. For the condition type, select Container metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.7383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "sections": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic&#x27;s <em>infrastructure</em> <em>agent</em>: <em>Infrastructure</em> <em>agent</em> 1.8.32 or higher running on <em>Linux</em> If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable"
      },
      "id": "603e9f3ee7b9d2d57c2a0818"
    },
    {
      "sections": [
        "Tarball assisted install of the infrastructure agent for Linux",
        "Important",
        "Install the agent",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Tarball assisted install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "fd6735d0ef7034ddb5435a01658e07dca45efd57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux/",
      "published_at": "2021-10-01T23:34:45Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Linux, you can make the changes you need to the installation script and configuration file we provide so you can adapt it to your environment. Important Assisted install only works for the Systemd, Upstart, and SysV service managers. If you use any other service manager, proceed with the manual install. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Update your license key in config_defaults.sh. Optional: Update any other environment parameters in the configuration file. Execute installer.sh with admin rights. The script automatically identifies your service manager. If it fails, it will prompt you to manually update it. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Configure your installation The configuration file config_defaults.sh serves as a source of reference for all the configuration options. It contains the following environment parameters: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: /var/db/newrelic-infra/ Copy NRIA_BIN_DIR Required at installation. The path to the agent binary folder. Default: /usr/local/bin Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: /etc/newrelic-infra/yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The infrastructure agent license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: /var/run/newrelic-infra/newrelic-infra.log Copy NRIA_MODE Required at installation. The privilege level for the agent. Possible values are ROOT, PRIVILEGED or UNPRIVILEGED. For more info see our documentation on agent running modes. Default: ROOT Copy NRIA_PID_FILE Required at agent startup. The location where the agent will place its PID file. Default: /var/run/newrelic-infra/newrelic-infra.pid Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: /etc/newrelic-infra/integrations.d/ Copy NRIA_USER Required at installation time only when the running mode is set to either PRIVILEGED or UNPRIVILEGED. The user that will run the agent binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.32,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>, you can make the changes you need to the <em>installation</em> script and configuration file we provide so you can adapt it to your environment. Important Assisted <em>install</em> only works for the Systemd, Upstart, and SysV service managers. If you"
      },
      "id": "603ea54064441f6bb64e8859"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 386.77768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-01T23:34:44Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.64258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    },
    {
      "sections": [
        "Docker instrumentation for infrastructure monitoring",
        "Requirements",
        "Enable Docker container monitoring",
        "View your Docker data",
        "Docker attributes",
        "Set alert conditions"
      ],
      "title": "Docker instrumentation for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "7d6febf75c3e6b5a67fdda3226d31132cfc81b43",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/",
      "published_at": "2021-10-01T12:56:42Z",
      "updated_at": "2021-07-27T11:56:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure agent automatically monitors your Docker containers. With Docker monitoring you can: Group containers by tags, attributes, and other metadata. Search for containers relevant to your monitoring scenario. Link to related entities that may be affected by issues with the container. Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic's infrastructure agent: Infrastructure agent 1.8.32 or higher running on Linux If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable Docker container monitoring If you meet the requirements and have installed the correct infrastructure monitoring agent, there are no additional steps to enable Docker monitoring. If Docker is running, data will automatically be reported. You can also use a Docker image containing the infrastructure monitoring agent. For more information, see Docker container for infrastructure monitoring. View your Docker data To view your Docker data in the New Relic UI, use either of these options: Go to one.newrelic.com > Infrastructure > Hosts > Containers. OR Go to one.newrelic.com > Infrastructure > Third-party services, and select Docker-related links. For more information, see Query your data. Docker attributes Docker attributes (metrics and metadata) are attached to the ContainerSample event. Here's an example of a query to find out how many containers are associated with each Docker image: SELECT uniqueCount(containerId) FROM ContainerSample FACET imageName SINCE 1 HOUR AGO TIMESERIES Copy To see all ContainerSample attributes, use our data dictionary. Attributes include: General metadata (like containerId, name, and image) CPU metrics (like cpuUsedCores, cpuPercent, and cpuThrottleTimeMs) Memory metrics (like memoryUsageBytes, memoryCacheBytes, and memoryResidentSizeBytes) Network metrics (like networkRxBytes, networkRxDropped, and networkTxBytes) Docker metrics are also attached to the ProcessSample event. The reported data does not include information related to the container orchestrator (for example, ECS or Kubernetes). To monitor those, you can add the orchestrator's cluster and task names as labels. Set alert conditions To create Docker-related alert conditions, use either of these options: Go to one.newrelic.com > Alerts & AI. OR Go to one.newrelic.com > Infrastructure > Settings > Alerts. Create a new alert condition. For the condition type, select Container metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.7383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "sections": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic&#x27;s <em>infrastructure</em> <em>agent</em>: <em>Infrastructure</em> <em>agent</em> 1.8.32 or higher running on <em>Linux</em> If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable"
      },
      "id": "603e9f3ee7b9d2d57c2a0818"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 386.77768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-01T23:34:44Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.64258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    },
    {
      "sections": [
        "Docker instrumentation for infrastructure monitoring",
        "Requirements",
        "Enable Docker container monitoring",
        "View your Docker data",
        "Docker attributes",
        "Set alert conditions"
      ],
      "title": "Docker instrumentation for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "7d6febf75c3e6b5a67fdda3226d31132cfc81b43",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/",
      "published_at": "2021-10-01T12:56:42Z",
      "updated_at": "2021-07-27T11:56:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure agent automatically monitors your Docker containers. With Docker monitoring you can: Group containers by tags, attributes, and other metadata. Search for containers relevant to your monitoring scenario. Link to related entities that may be affected by issues with the container. Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic's infrastructure agent: Infrastructure agent 1.8.32 or higher running on Linux If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable Docker container monitoring If you meet the requirements and have installed the correct infrastructure monitoring agent, there are no additional steps to enable Docker monitoring. If Docker is running, data will automatically be reported. You can also use a Docker image containing the infrastructure monitoring agent. For more information, see Docker container for infrastructure monitoring. View your Docker data To view your Docker data in the New Relic UI, use either of these options: Go to one.newrelic.com > Infrastructure > Hosts > Containers. OR Go to one.newrelic.com > Infrastructure > Third-party services, and select Docker-related links. For more information, see Query your data. Docker attributes Docker attributes (metrics and metadata) are attached to the ContainerSample event. Here's an example of a query to find out how many containers are associated with each Docker image: SELECT uniqueCount(containerId) FROM ContainerSample FACET imageName SINCE 1 HOUR AGO TIMESERIES Copy To see all ContainerSample attributes, use our data dictionary. Attributes include: General metadata (like containerId, name, and image) CPU metrics (like cpuUsedCores, cpuPercent, and cpuThrottleTimeMs) Memory metrics (like memoryUsageBytes, memoryCacheBytes, and memoryResidentSizeBytes) Network metrics (like networkRxBytes, networkRxDropped, and networkTxBytes) Docker metrics are also attached to the ProcessSample event. The reported data does not include information related to the container orchestrator (for example, ECS or Kubernetes). To monitor those, you can add the orchestrator's cluster and task names as labels. Set alert conditions To create Docker-related alert conditions, use either of these options: Go to one.newrelic.com > Alerts & AI. OR Go to one.newrelic.com > Infrastructure > Settings > Alerts. Create a new alert condition. For the condition type, select Container metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.7383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "sections": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic&#x27;s <em>infrastructure</em> <em>agent</em>: <em>Infrastructure</em> <em>agent</em> 1.8.32 or higher running on <em>Linux</em> If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable"
      },
      "id": "603e9f3ee7b9d2d57c2a0818"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 386.7776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-01T23:34:44Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.64258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    },
    {
      "sections": [
        "Docker instrumentation for infrastructure monitoring",
        "Requirements",
        "Enable Docker container monitoring",
        "View your Docker data",
        "Docker attributes",
        "Set alert conditions"
      ],
      "title": "Docker instrumentation for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "7d6febf75c3e6b5a67fdda3226d31132cfc81b43",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/",
      "published_at": "2021-10-01T12:56:42Z",
      "updated_at": "2021-07-27T11:56:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure agent automatically monitors your Docker containers. With Docker monitoring you can: Group containers by tags, attributes, and other metadata. Search for containers relevant to your monitoring scenario. Link to related entities that may be affected by issues with the container. Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic's infrastructure agent: Infrastructure agent 1.8.32 or higher running on Linux If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable Docker container monitoring If you meet the requirements and have installed the correct infrastructure monitoring agent, there are no additional steps to enable Docker monitoring. If Docker is running, data will automatically be reported. You can also use a Docker image containing the infrastructure monitoring agent. For more information, see Docker container for infrastructure monitoring. View your Docker data To view your Docker data in the New Relic UI, use either of these options: Go to one.newrelic.com > Infrastructure > Hosts > Containers. OR Go to one.newrelic.com > Infrastructure > Third-party services, and select Docker-related links. For more information, see Query your data. Docker attributes Docker attributes (metrics and metadata) are attached to the ContainerSample event. Here's an example of a query to find out how many containers are associated with each Docker image: SELECT uniqueCount(containerId) FROM ContainerSample FACET imageName SINCE 1 HOUR AGO TIMESERIES Copy To see all ContainerSample attributes, use our data dictionary. Attributes include: General metadata (like containerId, name, and image) CPU metrics (like cpuUsedCores, cpuPercent, and cpuThrottleTimeMs) Memory metrics (like memoryUsageBytes, memoryCacheBytes, and memoryResidentSizeBytes) Network metrics (like networkRxBytes, networkRxDropped, and networkTxBytes) Docker metrics are also attached to the ProcessSample event. The reported data does not include information related to the container orchestrator (for example, ECS or Kubernetes). To monitor those, you can add the orchestrator's cluster and task names as labels. Set alert conditions To create Docker-related alert conditions, use either of these options: Go to one.newrelic.com > Alerts & AI. OR Go to one.newrelic.com > Infrastructure > Settings > Alerts. Create a new alert condition. For the condition type, select Container metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.7383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "sections": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic&#x27;s <em>infrastructure</em> <em>agent</em>: <em>Infrastructure</em> <em>agent</em> 1.8.32 or higher running on <em>Linux</em> If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable"
      },
      "id": "603e9f3ee7b9d2d57c2a0818"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/macos-installation/install-infrastructure-monitoring-agent-macos": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.2684,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " See Azure extensions for <em>infrastructure</em> monitoring. <em>Install</em> using tarball files For custom setup scenarios, you can <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default <em>installation</em> settings"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-09-27T15:12:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.21 Red Hat Enterprise Linux (RHEL) Version 6 or higher Oracle Linux Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.23018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " and requires Administrator privileges to run. <em>macOS</em>: The <em>agent</em> can be installed from any user account. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of your distribution. Network access In order"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-20T19:24:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user:access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.21768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size": [
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-08-20T21:39:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. macOS: Manually install agent versions through HomeBrew. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.25204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Start, stop, and restart the infrastructure agent",
        "Linux: Start, stop, restart, or check agent status",
        "Windows: Start, stop, restart, or check agent status",
        "Important",
        "Command prompt (cmd.exe)",
        "PowerShell",
        "macOS: Start, stop, restart, or check agent status",
        "Customize agent logs",
        "Determine your init system",
        "Configuration management tools"
      ],
      "title": "Start, stop, and restart the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "81bb8174fac415ee0ec94c51e123c32eba700d6e",
      "image": "https://docs.newrelic.com/static/19e41f9fd7395eb6f1c816aa87182bb9/103b3/otherlinux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/",
      "published_at": "2021-10-01T23:37:53Z",
      "updated_at": "2021-08-20T17:29:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent starts automatically after you run the installation script. However, there are situations where you may need to manually restart the agent (for example, after changing your agent configuration). Linux: Start, stop, restart, or check agent status For Linux, ensure you use the correct command for your init system. Select start, stop, restart, or status as appropriate: SystemD (Amazon Linux 2, SLES 12, CentOS 7 or higher, Debian 8 or higher, RHEL 7 or higher, Ubuntu 15.04 or higher): sudo systemctl <start|stop|restart|status> newrelic-infra Copy System V (Debian 7, SLES 11.4, RHEL 5): sudo /etc/init.d/newrelic-infra <start|stop|restart|status> Copy Upstart (Amazon Linux, RHEL 6, Ubuntu 14.04 or lower): sudo initctl <start|stop|restart|status> newrelic-infra Copy Windows: Start, stop, restart, or check agent status Important To start, stop, or restart the agent, you must run cmd.exe or PowerShell as Administrator. For Windows Server, you can use the Windows command prompt or PowerShell. Command prompt (cmd.exe) Start or stop the Windows agent: net <start|stop> newrelic-infra Copy Restart the Windows agent: net stop newrelic-infra ; net start newrelic-infra Copy Check the status of the Windows agent: sc query \"newrelic-infra\" | find \"STATE\" Copy PowerShell Start or stop the Windows agent: Stop-Service -Name \"newrelic-infra\" Start-Service -Name \"newrelic-infra\" Copy You can also use net start|stop newrelic-infra Restart the Windows agent: Restart-Service newrelic-infra Copy Check status of Windows agent: (Get-Service newrelic-infra).Status Copy macOS: Start, stop, restart, or check agent status Stop or start the agent: brew services stop newrelic-infra-agent brew services start newrelic-infra-agent Copy Restart the agent: brew services restart newrelic-infra-agent Copy Check status of the agent: brew services list Copy Customize agent logs The infrastructure agent logs to a default location which depends on your platform. You can customize this location with the log_file setting. You can also generate verbose logs for troubleshooting. Determine your init system For Windows Server, the commands in this document use the Windows command prompt. For Linux, the infrastructure agent selects an init system appropriate for your distribution: Distribution SystemD System V Upstart Amazon Linux Amazon Linux 2 CentOS 7 CentOS 8 Debian 7 (\"Wheezy\") Debian 8 (\"Jessie\") Debian 9 (\"Stretch\") RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To manage the infrastructure agent with your config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.0982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "sections": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&quot;) Debian 8 (&quot;Jessie&quot;) Debian 9 (&quot;Stretch&quot;) RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To <em>manage</em> the <em>infrastructure</em> <em>agent</em> with <em>your</em> config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration"
      },
      "id": "603ec355e7b9d294092a0818"
    },
    {
      "sections": [
        "Troubleshoot a running infrastructure agent",
        "Linux newrelic-infra-ctl",
        "Important",
        "Windows newrelic-infra-ctl"
      ],
      "title": "Troubleshoot a running infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "e1f206feb686f819c00db0619a8534609fe19c53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent/",
      "published_at": "2021-10-01T23:37:53Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can troubleshoot our infrastructure agent using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the agent: Enables verbose logs for a period of five minutes, then reverts the log level to its previous setting. Logs all the agent config options. Logs all the integrations config options. Executes a health check for every loaded integration. (A health check is an immediate execution of the integration with extra logs and output validation.) Linux newrelic-infra-ctl In Linux systems, the troubleshooting binary is /usr/bin/newrelic-infra-ctl, available in both the package manager or the tarball assisted install methods. Important When running on Linux, newrelic-infra-ctl must be executed by either the root user or the same user running the newrelic-infra process. The newrelic-infra-ctl binary can automatically detect the agent process running in the host. It can also detect whether the agent is running inside a container. To change the default settings of newrelic-infra-ctl: To change... Execute pid newrelic-infra-ctl -pid 14580 cid (when using a containerized version of the agent) newrelic-infra-ctl -cid 8fddbcbb101c docker-api-version newrelic-infra-ctl -docker-api-version 1.24 Windows newrelic-infra-ctl In Windows, using the MSI installer, the troubleshooting binary is C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra-ctl.exe. Important In Windows, the agent process is always automatically detected. It does not depend on the pid or the cid.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.38881,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "sections": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can troubleshoot our <em>infrastructure</em> <em>agent</em> using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the <em>agent</em>: Enables verbose logs for a period"
      },
      "id": "603eb3dee7b9d22a5f2f736b"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior": [
    {
      "sections": [
        "Start, stop, and restart the infrastructure agent",
        "Linux: Start, stop, restart, or check agent status",
        "Windows: Start, stop, restart, or check agent status",
        "Important",
        "Command prompt (cmd.exe)",
        "PowerShell",
        "macOS: Start, stop, restart, or check agent status",
        "Customize agent logs",
        "Determine your init system",
        "Configuration management tools"
      ],
      "title": "Start, stop, and restart the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "81bb8174fac415ee0ec94c51e123c32eba700d6e",
      "image": "https://docs.newrelic.com/static/19e41f9fd7395eb6f1c816aa87182bb9/103b3/otherlinux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/",
      "published_at": "2021-10-01T23:37:53Z",
      "updated_at": "2021-08-20T17:29:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent starts automatically after you run the installation script. However, there are situations where you may need to manually restart the agent (for example, after changing your agent configuration). Linux: Start, stop, restart, or check agent status For Linux, ensure you use the correct command for your init system. Select start, stop, restart, or status as appropriate: SystemD (Amazon Linux 2, SLES 12, CentOS 7 or higher, Debian 8 or higher, RHEL 7 or higher, Ubuntu 15.04 or higher): sudo systemctl <start|stop|restart|status> newrelic-infra Copy System V (Debian 7, SLES 11.4, RHEL 5): sudo /etc/init.d/newrelic-infra <start|stop|restart|status> Copy Upstart (Amazon Linux, RHEL 6, Ubuntu 14.04 or lower): sudo initctl <start|stop|restart|status> newrelic-infra Copy Windows: Start, stop, restart, or check agent status Important To start, stop, or restart the agent, you must run cmd.exe or PowerShell as Administrator. For Windows Server, you can use the Windows command prompt or PowerShell. Command prompt (cmd.exe) Start or stop the Windows agent: net <start|stop> newrelic-infra Copy Restart the Windows agent: net stop newrelic-infra ; net start newrelic-infra Copy Check the status of the Windows agent: sc query \"newrelic-infra\" | find \"STATE\" Copy PowerShell Start or stop the Windows agent: Stop-Service -Name \"newrelic-infra\" Start-Service -Name \"newrelic-infra\" Copy You can also use net start|stop newrelic-infra Restart the Windows agent: Restart-Service newrelic-infra Copy Check status of Windows agent: (Get-Service newrelic-infra).Status Copy macOS: Start, stop, restart, or check agent status Stop or start the agent: brew services stop newrelic-infra-agent brew services start newrelic-infra-agent Copy Restart the agent: brew services restart newrelic-infra-agent Copy Check status of the agent: brew services list Copy Customize agent logs The infrastructure agent logs to a default location which depends on your platform. You can customize this location with the log_file setting. You can also generate verbose logs for troubleshooting. Determine your init system For Windows Server, the commands in this document use the Windows command prompt. For Linux, the infrastructure agent selects an init system appropriate for your distribution: Distribution SystemD System V Upstart Amazon Linux Amazon Linux 2 CentOS 7 CentOS 8 Debian 7 (\"Wheezy\") Debian 8 (\"Jessie\") Debian 9 (\"Stretch\") RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To manage the infrastructure agent with your config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.0982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "sections": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&quot;) Debian 8 (&quot;Jessie&quot;) Debian 9 (&quot;Stretch&quot;) RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To <em>manage</em> the <em>infrastructure</em> <em>agent</em> with <em>your</em> config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration"
      },
      "id": "603ec355e7b9d294092a0818"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-09-30T23:04:57Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.3912,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    },
    {
      "sections": [
        "Troubleshoot a running infrastructure agent",
        "Linux newrelic-infra-ctl",
        "Important",
        "Windows newrelic-infra-ctl"
      ],
      "title": "Troubleshoot a running infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "e1f206feb686f819c00db0619a8534609fe19c53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent/",
      "published_at": "2021-10-01T23:37:53Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can troubleshoot our infrastructure agent using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the agent: Enables verbose logs for a period of five minutes, then reverts the log level to its previous setting. Logs all the agent config options. Logs all the integrations config options. Executes a health check for every loaded integration. (A health check is an immediate execution of the integration with extra logs and output validation.) Linux newrelic-infra-ctl In Linux systems, the troubleshooting binary is /usr/bin/newrelic-infra-ctl, available in both the package manager or the tarball assisted install methods. Important When running on Linux, newrelic-infra-ctl must be executed by either the root user or the same user running the newrelic-infra process. The newrelic-infra-ctl binary can automatically detect the agent process running in the host. It can also detect whether the agent is running inside a container. To change the default settings of newrelic-infra-ctl: To change... Execute pid newrelic-infra-ctl -pid 14580 cid (when using a containerized version of the agent) newrelic-infra-ctl -cid 8fddbcbb101c docker-api-version newrelic-infra-ctl -docker-api-version 1.24 Windows newrelic-infra-ctl In Windows, using the MSI installer, the troubleshooting binary is C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra-ctl.exe. Important In Windows, the agent process is always automatically detected. It does not depend on the pid or the cid.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.38881,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "sections": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can troubleshoot our <em>infrastructure</em> <em>agent</em> using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the <em>agent</em>: Enables verbose logs for a period"
      },
      "id": "603eb3dee7b9d22a5f2f736b"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead": [
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-08-20T21:39:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. macOS: Manually install agent versions through HomeBrew. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.25204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Start, stop, and restart the infrastructure agent",
        "Linux: Start, stop, restart, or check agent status",
        "Windows: Start, stop, restart, or check agent status",
        "Important",
        "Command prompt (cmd.exe)",
        "PowerShell",
        "macOS: Start, stop, restart, or check agent status",
        "Customize agent logs",
        "Determine your init system",
        "Configuration management tools"
      ],
      "title": "Start, stop, and restart the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "81bb8174fac415ee0ec94c51e123c32eba700d6e",
      "image": "https://docs.newrelic.com/static/19e41f9fd7395eb6f1c816aa87182bb9/103b3/otherlinux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/",
      "published_at": "2021-10-01T23:37:53Z",
      "updated_at": "2021-08-20T17:29:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent starts automatically after you run the installation script. However, there are situations where you may need to manually restart the agent (for example, after changing your agent configuration). Linux: Start, stop, restart, or check agent status For Linux, ensure you use the correct command for your init system. Select start, stop, restart, or status as appropriate: SystemD (Amazon Linux 2, SLES 12, CentOS 7 or higher, Debian 8 or higher, RHEL 7 or higher, Ubuntu 15.04 or higher): sudo systemctl <start|stop|restart|status> newrelic-infra Copy System V (Debian 7, SLES 11.4, RHEL 5): sudo /etc/init.d/newrelic-infra <start|stop|restart|status> Copy Upstart (Amazon Linux, RHEL 6, Ubuntu 14.04 or lower): sudo initctl <start|stop|restart|status> newrelic-infra Copy Windows: Start, stop, restart, or check agent status Important To start, stop, or restart the agent, you must run cmd.exe or PowerShell as Administrator. For Windows Server, you can use the Windows command prompt or PowerShell. Command prompt (cmd.exe) Start or stop the Windows agent: net <start|stop> newrelic-infra Copy Restart the Windows agent: net stop newrelic-infra ; net start newrelic-infra Copy Check the status of the Windows agent: sc query \"newrelic-infra\" | find \"STATE\" Copy PowerShell Start or stop the Windows agent: Stop-Service -Name \"newrelic-infra\" Start-Service -Name \"newrelic-infra\" Copy You can also use net start|stop newrelic-infra Restart the Windows agent: Restart-Service newrelic-infra Copy Check status of Windows agent: (Get-Service newrelic-infra).Status Copy macOS: Start, stop, restart, or check agent status Stop or start the agent: brew services stop newrelic-infra-agent brew services start newrelic-infra-agent Copy Restart the agent: brew services restart newrelic-infra-agent Copy Check status of the agent: brew services list Copy Customize agent logs The infrastructure agent logs to a default location which depends on your platform. You can customize this location with the log_file setting. You can also generate verbose logs for troubleshooting. Determine your init system For Windows Server, the commands in this document use the Windows command prompt. For Linux, the infrastructure agent selects an init system appropriate for your distribution: Distribution SystemD System V Upstart Amazon Linux Amazon Linux 2 CentOS 7 CentOS 8 Debian 7 (\"Wheezy\") Debian 8 (\"Jessie\") Debian 9 (\"Stretch\") RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To manage the infrastructure agent with your config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.0982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "sections": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&quot;) Debian 8 (&quot;Jessie&quot;) Debian 9 (&quot;Stretch&quot;) RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To <em>manage</em> the <em>infrastructure</em> <em>agent</em> with <em>your</em> config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration"
      },
      "id": "603ec355e7b9d294092a0818"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-09-30T23:04:57Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.3912,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-08-20T21:39:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. macOS: Manually install agent versions through HomeBrew. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.25204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-09-30T23:04:57Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.3912,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    },
    {
      "sections": [
        "Troubleshoot a running infrastructure agent",
        "Linux newrelic-infra-ctl",
        "Important",
        "Windows newrelic-infra-ctl"
      ],
      "title": "Troubleshoot a running infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "e1f206feb686f819c00db0619a8534609fe19c53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent/",
      "published_at": "2021-10-01T23:37:53Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can troubleshoot our infrastructure agent using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the agent: Enables verbose logs for a period of five minutes, then reverts the log level to its previous setting. Logs all the agent config options. Logs all the integrations config options. Executes a health check for every loaded integration. (A health check is an immediate execution of the integration with extra logs and output validation.) Linux newrelic-infra-ctl In Linux systems, the troubleshooting binary is /usr/bin/newrelic-infra-ctl, available in both the package manager or the tarball assisted install methods. Important When running on Linux, newrelic-infra-ctl must be executed by either the root user or the same user running the newrelic-infra process. The newrelic-infra-ctl binary can automatically detect the agent process running in the host. It can also detect whether the agent is running inside a container. To change the default settings of newrelic-infra-ctl: To change... Execute pid newrelic-infra-ctl -pid 14580 cid (when using a containerized version of the agent) newrelic-infra-ctl -cid 8fddbcbb101c docker-api-version newrelic-infra-ctl -docker-api-version 1.24 Windows newrelic-infra-ctl In Windows, using the MSI installer, the troubleshooting binary is C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra-ctl.exe. Important In Windows, the agent process is always automatically detected. It does not depend on the pid or the cid.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.38881,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "sections": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can troubleshoot our <em>infrastructure</em> <em>agent</em> using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the <em>agent</em>: Enables verbose logs for a period"
      },
      "id": "603eb3dee7b9d22a5f2f736b"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-09-30T23:04:56Z",
      "updated_at": "2021-08-20T21:39:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. macOS: Manually install agent versions through HomeBrew. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Start, stop, and restart the infrastructure agent",
        "Linux: Start, stop, restart, or check agent status",
        "Windows: Start, stop, restart, or check agent status",
        "Important",
        "Command prompt (cmd.exe)",
        "PowerShell",
        "macOS: Start, stop, restart, or check agent status",
        "Customize agent logs",
        "Determine your init system",
        "Configuration management tools"
      ],
      "title": "Start, stop, and restart the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "81bb8174fac415ee0ec94c51e123c32eba700d6e",
      "image": "https://docs.newrelic.com/static/19e41f9fd7395eb6f1c816aa87182bb9/103b3/otherlinux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/",
      "published_at": "2021-10-01T23:37:53Z",
      "updated_at": "2021-08-20T17:29:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent starts automatically after you run the installation script. However, there are situations where you may need to manually restart the agent (for example, after changing your agent configuration). Linux: Start, stop, restart, or check agent status For Linux, ensure you use the correct command for your init system. Select start, stop, restart, or status as appropriate: SystemD (Amazon Linux 2, SLES 12, CentOS 7 or higher, Debian 8 or higher, RHEL 7 or higher, Ubuntu 15.04 or higher): sudo systemctl <start|stop|restart|status> newrelic-infra Copy System V (Debian 7, SLES 11.4, RHEL 5): sudo /etc/init.d/newrelic-infra <start|stop|restart|status> Copy Upstart (Amazon Linux, RHEL 6, Ubuntu 14.04 or lower): sudo initctl <start|stop|restart|status> newrelic-infra Copy Windows: Start, stop, restart, or check agent status Important To start, stop, or restart the agent, you must run cmd.exe or PowerShell as Administrator. For Windows Server, you can use the Windows command prompt or PowerShell. Command prompt (cmd.exe) Start or stop the Windows agent: net <start|stop> newrelic-infra Copy Restart the Windows agent: net stop newrelic-infra ; net start newrelic-infra Copy Check the status of the Windows agent: sc query \"newrelic-infra\" | find \"STATE\" Copy PowerShell Start or stop the Windows agent: Stop-Service -Name \"newrelic-infra\" Start-Service -Name \"newrelic-infra\" Copy You can also use net start|stop newrelic-infra Restart the Windows agent: Restart-Service newrelic-infra Copy Check status of Windows agent: (Get-Service newrelic-infra).Status Copy macOS: Start, stop, restart, or check agent status Stop or start the agent: brew services stop newrelic-infra-agent brew services start newrelic-infra-agent Copy Restart the agent: brew services restart newrelic-infra-agent Copy Check status of the agent: brew services list Copy Customize agent logs The infrastructure agent logs to a default location which depends on your platform. You can customize this location with the log_file setting. You can also generate verbose logs for troubleshooting. Determine your init system For Windows Server, the commands in this document use the Windows command prompt. For Linux, the infrastructure agent selects an init system appropriate for your distribution: Distribution SystemD System V Upstart Amazon Linux Amazon Linux 2 CentOS 7 CentOS 8 Debian 7 (\"Wheezy\") Debian 8 (\"Jessie\") Debian 9 (\"Stretch\") RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To manage the infrastructure agent with your config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.09818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "sections": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&quot;) Debian 8 (&quot;Jessie&quot;) Debian 9 (&quot;Stretch&quot;) RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To <em>manage</em> the <em>infrastructure</em> <em>agent</em> with <em>your</em> config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration"
      },
      "id": "603ec355e7b9d294092a0818"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-09-30T23:04:57Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.3912,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent": [
    {
      "sections": [
        "Update the infrastructure agent",
        "Tip",
        "View the infrastructure agent version",
        "Update the agent for installs using the package manager",
        "Update using apt (Debian, Ubuntu)",
        "Update using yum (Amazon Linux, CentOS, RHEL)",
        "Update using Zypper (SLES)",
        "Update on Windows Server (32 bits)",
        "Update on Windows Server (64 bits)",
        "Update on macOS",
        "Update with config management tools",
        "Update the agent for assisted and manual tarball installs",
        "Important",
        "Update the containerized version of the agent",
        "Identify outdated agent versions from the UI"
      ],
      "title": "Update the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1ddaa00ceaf5936084d25f207f868d89fd0957f6",
      "image": "https://docs.newrelic.com/static/06b72c159cd2d6b502bb7cbab7a98e67/103b3/ebs.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent/",
      "published_at": "2021-10-01T12:57:52Z",
      "updated_at": "2021-08-20T17:30:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to update the infrastructure agent to the latest version for Linux and Windows servers. Tip To install the infrastructure agent for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To uninstall the infrastructure agent, see Uninstall the Infrastructure agent. View the infrastructure agent version The infrastructure agent does not update itself automatically. Check the infrastructure agent release notes to make sure you have the latest agent version. To view the current infrastructure agent version for a host, use any of these options: Go to one.newrelic.com > Infrastructure > Settings > Agents > Agent version. Go to one.newrelic.com > Infrastructure > Hosts > (select a host). Create a query for SystemSample. Update the agent for installs using the package manager If you used the default installation process, use your package manager to update the program and its dependencies to the latest version. Here are examples for some common systems: Update using apt ( Debian, Ubuntu) To manually update the infrastructure agent with apt-get: sudo apt-get update && sudo apt-get install --only-upgrade newrelic-infra -y Copy Update using yum ( Amazon Linux, CentOS, RHEL) To manually update the infrastructure agent with yum: sudo yum update newrelic-infra -y Copy After updating you may need to start the agent. Update using Zypper ( SLES) To manually update the infrastructure agent with Zypper: sudo zypper -n update newrelic-infra Copy After updating you may need to start the agent. Update on Windows Server (32 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy After updating you may need to start the agent. Update on Windows Server (64 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy After updating you may need to start the agent. Update on macOS To manually update the infrastructure agent on macOS, open the terminal and run the following commands: Stop the service (if already running): brew services stop newrelic-infra-agent Copy Uninstall the agent: brew update newrelic-infrastructure Copy Update with config management tools To update the infrastructure agent using your configuration management tool, see the documentation for your tool: Configure with Ansible Configure with Chef Configure with AWS Elastic Beanstalk Configure with Puppet Update the agent for assisted and manual tarball installs Important Since there are are no automated scripts, old files may remain when you update. Be sure to manually remove outdated files. To update the agent, download the file again and follow the installation procedure for Linux (assisted or manual) or Windows (assisted or manual). This will overwrite your old installation. Update the containerized version of the agent Use the latest label to ensure that our Docker image is automatically updated. Identify outdated agent versions from the UI You can use the Infrastructure monitoring UI to search for outdated agent versions: Go to one.newrelic.com > Infrastructure > Inventory * * * * . In the search bar, type newrelic-infra. Select a group's dropdown to see the agent versions for that group. To manually check the infrastructure agent versions, you can log onto a server and run newrelic-infra --version, or the applicable command for your package manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.43213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Update</em> <em>the</em> <em>agent</em> for <em>installs</em> using <em>the</em> package manager",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to <em>update</em> the <em>infrastructure</em> <em>agent</em> to the latest version for Linux and Windows servers. Tip To <em>install</em> the <em>infrastructure</em> <em>agent</em> for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To <em>uninstall</em> the <em>infrastructure</em> <em>agent</em>"
      },
      "id": "60440e8fe7b9d252a2579a19"
    },
    {
      "sections": [
        "Uninstall infrastructure integrations",
        "Cloud integrations",
        "AWS",
        "Azure",
        "Google Cloud Platform (GCP)",
        "On-host integrations",
        "Apache",
        "Cassandra",
        "Kubernetes",
        "MySQL",
        "NGINX",
        "Redis",
        "StatsD",
        "Moving away from the integrations package",
        "Uninstall package"
      ],
      "title": "Uninstall infrastructure integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1e9232193cbf71bdbe1a6c6d0374ed0d6b7e7b0f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations/",
      "published_at": "2021-10-01T12:57:52Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Uninstalling the infrastructure agent does not directly affect any of your infrastructure Integrations: if you uninstall the agent, your integrations will remain. Similarly, if you disable or uninstall your integrations, the infrastructure agent will remain. To uninstall any of your integrations, follow the procedure corresponding to the type of integration. Cloud integrations AWS You can disable infrastructure AWS integrations and still retain the connection between your AWS account and New Relic. We recommend not to disable your EC2 and EBS integrations because those add important metadata to your infrastructure data. If you want to... Do this Disable one or more AWS service integrations To disable services while keeping your AWS account linked to New Relic: From one.newrelic.com > Infrastructure, select AWS > Manage services. From your Edit AWS account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all AWS integrations To disconnect your AWS account completely from New Relic, you need to unlink your AWS account. This disables all New Relic integrations associated with that AWS account. Go to one.newrelic.com > Infrastructure > AWS > Manage services. From your Edit AWS account page, select Unlink this account. Save your changes. Sign in to AWS and select Services > IAM > Roles. Select the checkbox for the role you want to delete, then select Role Actions > Delete Role. Unlinking your AWS account will disable the trust relationship set up via your ARN. Azure If you want to... Do this Disable one or more Azure service integrations To disable services while keeping your Azure account linked to New Relic: Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all Azure integrations To disconnect your Azure account completely from New Relic, you need to unlink your Azure account. This requires being either the user who registered the app or an administrator. This procedure will disable all New Relic integrations associated with that Azure account. Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, select Unlink this account. Save your changes. Sign in to Azure and go into All Services > Identity > App registrations, or go to Azure Active Directory service and select App registrations. Find the registered app (the recommended name is NewRelic-Integrations). To see the full list of available apps, select the dropdown menu beside the search field and select All apps. Select the app and, on the panel that opens, select Delete. Google Cloud Platform (GCP) If you want to... Do this Disable one or more GCP service integrations To disable services while keeping your GCP account linked to New Relic: From one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all GCP integrations To disconnect your GCP account completely from New Relic, you need to unlink your GCP account. This disables all New Relic integrations associated with that GCP account. If you registered the GCP project using a User account, follow these steps. Go to one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, select Unlink this account. Save your changes. If you registered the GCP project using a Service account, follow these steps. If you are deleting a custom role, be aware that this role may be used for other purposes besides New Relic access. Sign in to New Relic and go to Infrastructure > Integrations > Google Cloud Platform. For a standard (non-custom) user role, select Manage Services for the account you want to remove. Copy the value of User and save it. OR For a custom user role, go to IAM > admin > Roles, search for the role, select it, and select DELETE. You are now finished and can skip the remaining steps. Standard (non-custom) user role: Sign in to Google Cloud and select the correct project in the Select a project box. From the navigation menu, select IAM & admin > IAM. Search for and select the user value you saved, then select REMOVE. On-host integrations If you used the integrations package, see the integrations package instructions. Here are some examples: Apache Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-apache yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-apache zypper (SLES) sudo zypper -n remove nri-apache Cassandra Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-cassandra yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-cassandra zypper (SLES) sudo zypper -n remove nri-cassandra Kubernetes Each cluster will have a single node where kubectl is running. To uninstall the Kubernetes integration, use the following command on each of these nodes: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy MySQL Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-mysql yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-mysql zypper (SLES) sudo zypper -n remove nri-mysql NGINX Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-nginx yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-nginx zypper (SLES) sudo zypper -n remove nri-nginx Redis Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-redis yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-redis zypper (SLES) sudo zypper -n remove nri-redis StatsD cd /path/to/statsd npm uninstall @newrelic/statsd-infra-backend From the StatsD config.js, remove the \"@newrelic/statsd-infra-backend\" entry from the list of backends. Restart StatsD. Moving away from the integrations package While it is still possible to use the integrations package, we recommend removing it completely and working with integrations on an individual basis. The last integration package contains the following versions of the integrations: Apache 1.1.2 Cassandra 2.0.3 MySQL 1.1.5 Nginx 1.0.2 Redis 1.0.1 If you remove the integrations package and want to continue using the related on-host integrations, you will need to install them one by one. To uninstall the package and re-install your integrations: Remove the integrations package by following these instructions. The config files from the old integrations will not be deleted, so you won’t have to configure them again. Uninstall package Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove newrelic-infra-integrations sudo apt-get autoremove yum (Amazon Linux, CentOS, or RHEL) sudo yum remove newrelic-infra-integrations sudo yum autoremove zypper (SLES) sudo zypper -n remove newrelic-infra-integrations --clean-deps Copy Install your integrations one by one following these instructions. To replicate the integrations package, you will need to install all the available integrations again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.10474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "sections": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Uninstalling the <em>infrastructure</em> <em>agent</em> does not directly affect any of your <em>infrastructure</em> Integrations: if you <em>uninstall</em> the <em>agent</em>, your integrations will remain. Similarly, if you disable or <em>uninstall</em> your integrations, the <em>infrastructure</em> <em>agent</em> will remain. To <em>uninstall</em> any of your integrations"
      },
      "id": "603ea831196a67fc6fa83db5"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.44409,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " to your environment, or to <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> on distributions that lack the newrelic-infra package in their repositories. Important Installing the <em>agent</em> using tarball files is officially supported only for the AWS Graviton 2 processor. <em>Update</em> the <em>agent</em> Follow standard"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations": [
    {
      "sections": [
        "Uninstall the infrastructure agent",
        "Uninstall the Linux infrastructure agent",
        "Uninstall with apt (Debian, Ubuntu)",
        "Uninstall with yum (Amazon Linux, CentOS, RHEL)",
        "Uninstall with Zypper (SLES)",
        "Important",
        "Uninstall the Windows infrastructure agent",
        "Tip",
        "Uninstall the macOS infrastructure agent",
        "Uninstall using config management tools",
        "Optional: Purge remaining files"
      ],
      "title": "Uninstall the infrastructure agent ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "d99fe6244698657f7f2e67bc6f6fcbfc9d8ffbf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent/",
      "published_at": "2021-10-01T12:56:42Z",
      "updated_at": "2021-08-26T14:37:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your hosts are added automatically when you install the infrastructure agent for your Linux or Windows operating system, or update the agent. Similarly, your hosts disappear automatically when you uninstall the agent. You do not need to manually add or remove your hosts. Uninstalling the agent does not directly affect any of your integrations. To uninstall an integration, see Uninstall integrations. Uninstall the Linux infrastructure agent If you used the default install procedure for your infrastructure agent for Linux environments, use your package management tools to uninstall it. You do not need to stop the service before running the uninstall command. Uninstall with apt ( Debian, Ubuntu) Execute the following command as root: sudo apt-get remove newrelic-infra Copy Uninstall with yum ( Amazon Linux, CentOS, RHEL) Execute the following command as root: sudo yum remove newrelic-infra Copy Uninstall with Zypper ( SLES) Execute the following command as root: sudo zypper -n remove newrelic-infra Copy If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the Windows infrastructure agent Tip Requires Administrator rights in your Windows admin group. If you used the default install procedure for the infrastructure agent for Windows environments, to uninstall: Stop the infrastructure agent. From the Windows Control Panel, use the Add/Remove Programs and Features tool to uninstall the infrastructure agent. From the Windows Program Files, manually delete the New Relic folder to delete all files associated with the infrastructure agent for Windows. If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the macOS infrastructure agent If you used the default install procedure for the infrastructure agent for macOS environments, to uninstall: Stop the infrastructure agent: brew services stop newrelic-infra-agent Copy From the terminal, run the uninstall command: brew uninstall newrelic-infra-agent Copy Uninstall using config management tools To uninstall the infrastructure agent if you used a configuration management tool: Config management tools Uninstall New Relic infrastructure agent Ansible Set the 'agent_state' parameter to 'absent' Chef Set the 'agent_action' node to uninstall AWS Elastic Beanstalk Remove newrelic.config from .ebextensions, then deploy. Puppet Set the 'ensure' parameter to 'absent' Optional: Purge remaining files If you use standard package management tools for your selected platform, the uninstall process typically leaves configuration and other miscellaneous files. If you need to completely purge any of the remaining files after uninstalling the New Relic infrastructure agent, follow standard procedures for your operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.11258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em> ",
        "sections": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Your hosts are added automatically when you <em>install</em> the <em>infrastructure</em> <em>agent</em> for your Linux or Windows operating system, or <em>update</em> the <em>agent</em>. Similarly, your hosts disappear automatically when you <em>uninstall</em> the <em>agent</em>. You do not need to manually add or remove your hosts. Uninstalling the <em>agent</em> does"
      },
      "id": "603ea0e964441f31114e885c"
    },
    {
      "sections": [
        "Update the infrastructure agent",
        "Tip",
        "View the infrastructure agent version",
        "Update the agent for installs using the package manager",
        "Update using apt (Debian, Ubuntu)",
        "Update using yum (Amazon Linux, CentOS, RHEL)",
        "Update using Zypper (SLES)",
        "Update on Windows Server (32 bits)",
        "Update on Windows Server (64 bits)",
        "Update on macOS",
        "Update with config management tools",
        "Update the agent for assisted and manual tarball installs",
        "Important",
        "Update the containerized version of the agent",
        "Identify outdated agent versions from the UI"
      ],
      "title": "Update the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1ddaa00ceaf5936084d25f207f868d89fd0957f6",
      "image": "https://docs.newrelic.com/static/06b72c159cd2d6b502bb7cbab7a98e67/103b3/ebs.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent/",
      "published_at": "2021-10-01T12:57:52Z",
      "updated_at": "2021-08-20T17:30:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to update the infrastructure agent to the latest version for Linux and Windows servers. Tip To install the infrastructure agent for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To uninstall the infrastructure agent, see Uninstall the Infrastructure agent. View the infrastructure agent version The infrastructure agent does not update itself automatically. Check the infrastructure agent release notes to make sure you have the latest agent version. To view the current infrastructure agent version for a host, use any of these options: Go to one.newrelic.com > Infrastructure > Settings > Agents > Agent version. Go to one.newrelic.com > Infrastructure > Hosts > (select a host). Create a query for SystemSample. Update the agent for installs using the package manager If you used the default installation process, use your package manager to update the program and its dependencies to the latest version. Here are examples for some common systems: Update using apt ( Debian, Ubuntu) To manually update the infrastructure agent with apt-get: sudo apt-get update && sudo apt-get install --only-upgrade newrelic-infra -y Copy Update using yum ( Amazon Linux, CentOS, RHEL) To manually update the infrastructure agent with yum: sudo yum update newrelic-infra -y Copy After updating you may need to start the agent. Update using Zypper ( SLES) To manually update the infrastructure agent with Zypper: sudo zypper -n update newrelic-infra Copy After updating you may need to start the agent. Update on Windows Server (32 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy After updating you may need to start the agent. Update on Windows Server (64 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy After updating you may need to start the agent. Update on macOS To manually update the infrastructure agent on macOS, open the terminal and run the following commands: Stop the service (if already running): brew services stop newrelic-infra-agent Copy Uninstall the agent: brew update newrelic-infrastructure Copy Update with config management tools To update the infrastructure agent using your configuration management tool, see the documentation for your tool: Configure with Ansible Configure with Chef Configure with AWS Elastic Beanstalk Configure with Puppet Update the agent for assisted and manual tarball installs Important Since there are are no automated scripts, old files may remain when you update. Be sure to manually remove outdated files. To update the agent, download the file again and follow the installation procedure for Linux (assisted or manual) or Windows (assisted or manual). This will overwrite your old installation. Update the containerized version of the agent Use the latest label to ensure that our Docker image is automatically updated. Identify outdated agent versions from the UI You can use the Infrastructure monitoring UI to search for outdated agent versions: Go to one.newrelic.com > Infrastructure > Inventory * * * * . In the search bar, type newrelic-infra. Select a group's dropdown to see the agent versions for that group. To manually check the infrastructure agent versions, you can log onto a server and run newrelic-infra --version, or the applicable command for your package manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.43213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Update</em> <em>the</em> <em>agent</em> for <em>installs</em> using <em>the</em> package manager",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to <em>update</em> the <em>infrastructure</em> <em>agent</em> to the latest version for Linux and Windows servers. Tip To <em>install</em> the <em>infrastructure</em> <em>agent</em> for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To <em>uninstall</em> the <em>infrastructure</em> <em>agent</em>"
      },
      "id": "60440e8fe7b9d252a2579a19"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.44403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " to your environment, or to <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> on distributions that lack the newrelic-infra package in their repositories. Important Installing the <em>agent</em> using tarball files is officially supported only for the AWS Graviton 2 processor. <em>Update</em> the <em>agent</em> Follow standard"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent": [
    {
      "sections": [
        "Uninstall the infrastructure agent",
        "Uninstall the Linux infrastructure agent",
        "Uninstall with apt (Debian, Ubuntu)",
        "Uninstall with yum (Amazon Linux, CentOS, RHEL)",
        "Uninstall with Zypper (SLES)",
        "Important",
        "Uninstall the Windows infrastructure agent",
        "Tip",
        "Uninstall the macOS infrastructure agent",
        "Uninstall using config management tools",
        "Optional: Purge remaining files"
      ],
      "title": "Uninstall the infrastructure agent ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "d99fe6244698657f7f2e67bc6f6fcbfc9d8ffbf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent/",
      "published_at": "2021-10-01T12:56:42Z",
      "updated_at": "2021-08-26T14:37:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your hosts are added automatically when you install the infrastructure agent for your Linux or Windows operating system, or update the agent. Similarly, your hosts disappear automatically when you uninstall the agent. You do not need to manually add or remove your hosts. Uninstalling the agent does not directly affect any of your integrations. To uninstall an integration, see Uninstall integrations. Uninstall the Linux infrastructure agent If you used the default install procedure for your infrastructure agent for Linux environments, use your package management tools to uninstall it. You do not need to stop the service before running the uninstall command. Uninstall with apt ( Debian, Ubuntu) Execute the following command as root: sudo apt-get remove newrelic-infra Copy Uninstall with yum ( Amazon Linux, CentOS, RHEL) Execute the following command as root: sudo yum remove newrelic-infra Copy Uninstall with Zypper ( SLES) Execute the following command as root: sudo zypper -n remove newrelic-infra Copy If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the Windows infrastructure agent Tip Requires Administrator rights in your Windows admin group. If you used the default install procedure for the infrastructure agent for Windows environments, to uninstall: Stop the infrastructure agent. From the Windows Control Panel, use the Add/Remove Programs and Features tool to uninstall the infrastructure agent. From the Windows Program Files, manually delete the New Relic folder to delete all files associated with the infrastructure agent for Windows. If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the macOS infrastructure agent If you used the default install procedure for the infrastructure agent for macOS environments, to uninstall: Stop the infrastructure agent: brew services stop newrelic-infra-agent Copy From the terminal, run the uninstall command: brew uninstall newrelic-infra-agent Copy Uninstall using config management tools To uninstall the infrastructure agent if you used a configuration management tool: Config management tools Uninstall New Relic infrastructure agent Ansible Set the 'agent_state' parameter to 'absent' Chef Set the 'agent_action' node to uninstall AWS Elastic Beanstalk Remove newrelic.config from .ebextensions, then deploy. Puppet Set the 'ensure' parameter to 'absent' Optional: Purge remaining files If you use standard package management tools for your selected platform, the uninstall process typically leaves configuration and other miscellaneous files. If you need to completely purge any of the remaining files after uninstalling the New Relic infrastructure agent, follow standard procedures for your operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.11258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em> ",
        "sections": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Your hosts are added automatically when you <em>install</em> the <em>infrastructure</em> <em>agent</em> for your Linux or Windows operating system, or <em>update</em> the <em>agent</em>. Similarly, your hosts disappear automatically when you <em>uninstall</em> the <em>agent</em>. You do not need to manually add or remove your hosts. Uninstalling the <em>agent</em> does"
      },
      "id": "603ea0e964441f31114e885c"
    },
    {
      "sections": [
        "Uninstall infrastructure integrations",
        "Cloud integrations",
        "AWS",
        "Azure",
        "Google Cloud Platform (GCP)",
        "On-host integrations",
        "Apache",
        "Cassandra",
        "Kubernetes",
        "MySQL",
        "NGINX",
        "Redis",
        "StatsD",
        "Moving away from the integrations package",
        "Uninstall package"
      ],
      "title": "Uninstall infrastructure integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1e9232193cbf71bdbe1a6c6d0374ed0d6b7e7b0f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations/",
      "published_at": "2021-10-01T12:57:52Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Uninstalling the infrastructure agent does not directly affect any of your infrastructure Integrations: if you uninstall the agent, your integrations will remain. Similarly, if you disable or uninstall your integrations, the infrastructure agent will remain. To uninstall any of your integrations, follow the procedure corresponding to the type of integration. Cloud integrations AWS You can disable infrastructure AWS integrations and still retain the connection between your AWS account and New Relic. We recommend not to disable your EC2 and EBS integrations because those add important metadata to your infrastructure data. If you want to... Do this Disable one or more AWS service integrations To disable services while keeping your AWS account linked to New Relic: From one.newrelic.com > Infrastructure, select AWS > Manage services. From your Edit AWS account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all AWS integrations To disconnect your AWS account completely from New Relic, you need to unlink your AWS account. This disables all New Relic integrations associated with that AWS account. Go to one.newrelic.com > Infrastructure > AWS > Manage services. From your Edit AWS account page, select Unlink this account. Save your changes. Sign in to AWS and select Services > IAM > Roles. Select the checkbox for the role you want to delete, then select Role Actions > Delete Role. Unlinking your AWS account will disable the trust relationship set up via your ARN. Azure If you want to... Do this Disable one or more Azure service integrations To disable services while keeping your Azure account linked to New Relic: Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all Azure integrations To disconnect your Azure account completely from New Relic, you need to unlink your Azure account. This requires being either the user who registered the app or an administrator. This procedure will disable all New Relic integrations associated with that Azure account. Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, select Unlink this account. Save your changes. Sign in to Azure and go into All Services > Identity > App registrations, or go to Azure Active Directory service and select App registrations. Find the registered app (the recommended name is NewRelic-Integrations). To see the full list of available apps, select the dropdown menu beside the search field and select All apps. Select the app and, on the panel that opens, select Delete. Google Cloud Platform (GCP) If you want to... Do this Disable one or more GCP service integrations To disable services while keeping your GCP account linked to New Relic: From one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all GCP integrations To disconnect your GCP account completely from New Relic, you need to unlink your GCP account. This disables all New Relic integrations associated with that GCP account. If you registered the GCP project using a User account, follow these steps. Go to one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, select Unlink this account. Save your changes. If you registered the GCP project using a Service account, follow these steps. If you are deleting a custom role, be aware that this role may be used for other purposes besides New Relic access. Sign in to New Relic and go to Infrastructure > Integrations > Google Cloud Platform. For a standard (non-custom) user role, select Manage Services for the account you want to remove. Copy the value of User and save it. OR For a custom user role, go to IAM > admin > Roles, search for the role, select it, and select DELETE. You are now finished and can skip the remaining steps. Standard (non-custom) user role: Sign in to Google Cloud and select the correct project in the Select a project box. From the navigation menu, select IAM & admin > IAM. Search for and select the user value you saved, then select REMOVE. On-host integrations If you used the integrations package, see the integrations package instructions. Here are some examples: Apache Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-apache yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-apache zypper (SLES) sudo zypper -n remove nri-apache Cassandra Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-cassandra yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-cassandra zypper (SLES) sudo zypper -n remove nri-cassandra Kubernetes Each cluster will have a single node where kubectl is running. To uninstall the Kubernetes integration, use the following command on each of these nodes: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy MySQL Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-mysql yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-mysql zypper (SLES) sudo zypper -n remove nri-mysql NGINX Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-nginx yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-nginx zypper (SLES) sudo zypper -n remove nri-nginx Redis Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-redis yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-redis zypper (SLES) sudo zypper -n remove nri-redis StatsD cd /path/to/statsd npm uninstall @newrelic/statsd-infra-backend From the StatsD config.js, remove the \"@newrelic/statsd-infra-backend\" entry from the list of backends. Restart StatsD. Moving away from the integrations package While it is still possible to use the integrations package, we recommend removing it completely and working with integrations on an individual basis. The last integration package contains the following versions of the integrations: Apache 1.1.2 Cassandra 2.0.3 MySQL 1.1.5 Nginx 1.0.2 Redis 1.0.1 If you remove the integrations package and want to continue using the related on-host integrations, you will need to install them one by one. To uninstall the package and re-install your integrations: Remove the integrations package by following these instructions. The config files from the old integrations will not be deleted, so you won’t have to configure them again. Uninstall package Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove newrelic-infra-integrations sudo apt-get autoremove yum (Amazon Linux, CentOS, or RHEL) sudo yum remove newrelic-infra-integrations sudo yum autoremove zypper (SLES) sudo zypper -n remove newrelic-infra-integrations --clean-deps Copy Install your integrations one by one following these instructions. To replicate the integrations package, you will need to install all the available integrations again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.10474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "sections": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Uninstalling the <em>infrastructure</em> <em>agent</em> does not directly affect any of your <em>infrastructure</em> Integrations: if you <em>uninstall</em> the <em>agent</em>, your integrations will remain. Similarly, if you disable or <em>uninstall</em> your integrations, the <em>infrastructure</em> <em>agent</em> will remain. To <em>uninstall</em> any of your integrations"
      },
      "id": "603ea831196a67fc6fa83db5"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.44397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " to your environment, or to <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> on distributions that lack the newrelic-infra package in their repositories. Important Installing the <em>agent</em> using tarball files is officially supported only for the AWS Graviton 2 processor. <em>Update</em> the <em>agent</em> Follow standard"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows": [
    {
      "sections": [
        "Zip assisted install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Zip assisted install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "fcadbeed626401863b6b16e5c52e9a472a5ac13e",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows/",
      "published_at": "2021-10-01T12:58:40Z",
      "updated_at": "2021-04-16T02:59:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Windows, you can make the changes you need to the installation script we provide so you can adapt it to your environment. Before installation, make sure to check the compatibility and requirements. Install the agent Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Once it's unpacked, access and edit the installation PowerShell script installer.ps1. Update your license key. Optional: Update any other parameters. Execute installer.ps1 with admin rights. Configure your installation Important Make sure any custom folder defined in the installation settings has permissions limitations properly defined. The infrastructure agent might execute any integration defined in the NRIA_PLUGIN_DIR directory with Administrator permissions. You can configure the following parameters during the assisted install for Windows: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: C:\\Program Files\\New Relic\\newrelic-infra Copy NRIA_APP_DATA_DIR This configures the data directory to store inventory and other agent files. Default: C:\\%ProgramData%\\New Relic\\newrelic-infra Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The New Relic license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy NRIA_OVERWRITE By default and for security reasons, Windows does not install a service if there's another service with the same name already installed. To bypass this check, make sure this setting NRIA_OVERWRITE is TRUE. Default: TRUE Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: C:\\Program Files\\NewRelic\\newrelic-infra\\inregrations.d Copy NRIA_SERVICE_NAME This provides the name for the Windows service. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.27591,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>, you can make the changes you need to the <em>installation</em> script we provide so you can adapt it to your environment. Before <em>installation</em>, make sure to check the compatibility and requirements. <em>Install</em> the <em>agent</em> Important As of version"
      },
      "id": "603ea7af196a67dab0a83d9d"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-01T12:58:40Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation, and place files and folders wherever you want on your filesystem. This method gives you full control of the installation: you are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The Infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, placed in the same folder with the agent, to configure the agent's behavior. You can create a new config file based on config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The Infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. Additionally, the agent uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your Infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic Infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.19072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for <em>Windows</em> allows you to tailor all aspects of the <em>installation</em>, and place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>: you are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.44397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " See Azure extensions for <em>infrastructure</em> monitoring. <em>Install</em> using tarball files For custom setup scenarios, you can <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default <em>installation</em> settings"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Windows",
        "Install for Windows Server and Windows 10 using our guided install",
        "Install using our step-by-step instructions",
        "PowerShell install",
        "32-bit Windows",
        "64-bit Windows",
        "Step-by-step install",
        "Important",
        "Scripted installation",
        "Install using zip files",
        "Caution",
        "What's next?",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "32766f16044664c9c7d66075801930ff53ca5c49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/",
      "published_at": "2021-10-01T12:58:40Z",
      "updated_at": "2021-08-26T18:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for Windows, you can monitor individual servers and also analyze how your service performs as a whole. The Windows agent can run on your own hardware or in cloud systems such as Amazon EC2 or Windows Azure, and supports Windows Server and Windows 10. You can also install with Chef. Before installation, be sure to review the requirements. If you haven't already, create a New Relic account. It's free, forever. Install for Windows Server and Windows 10 using our guided install To install the infrastructure monitoring agent for Windows, you can use our guided install. If you're in the EU, try our euro guided install. Install using our step-by-step instructions If guided install doesn't work, use our PowerShell script, or follow the step-by-step instructions: PowerShell install Review the agent requirements and supported operating systems. Open the PowerShell as administrator and run the following command: 32-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy 64-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy For a scripted installation, you can pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Step-by-step install Review the infrastructure monitoring agent requirements and supported operating systems. Download the latest .MSI installer image from: 32-bit Windows https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi​ Copy 64-bit Windows https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Copy Important Do not double-click the installer. This will not fully install the local agent and can result in permissions issues. In an admin account, run the install script using an absolute path. 32-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy 64-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy Scripted installation For a scripted installation, you can also pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Add your New Relic license key to the license_key attribute in newrelic-infra.yml, located in C:\\Program Files\\New Relic\\newrelic-infra\\. When finished, the contents of newrelic-infra.yml should resemble the following: license_key: YOUR_LICENSE_KEY Copy Start the newrelic-infra service. To start from the Windows command prompt, run: net start newrelic-infra Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. Install using zip files For custom setup scenarios, you can install the infrastructure monitoring agent using our zip files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment. Caution Installing the infrastructure monitoring agent using zip files is not supported. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.49756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". You can also <em>install</em> with Chef. Before <em>installation</em>, be sure to review the requirements. If you haven&#x27;t already, create a New Relic account. It&#x27;s free, forever. <em>Install</em> for <em>Windows</em> Server and <em>Windows</em> 10 using our guided <em>install</em> To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>, you can use"
      },
      "id": "6044672464441f9bb6378ed9"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-01T12:58:40Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation, and place files and folders wherever you want on your filesystem. This method gives you full control of the installation: you are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The Infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, placed in the same folder with the agent, to configure the agent's behavior. You can create a new config file based on config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The Infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. Additionally, the agent uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your Infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic Infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.19072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for <em>Windows</em> allows you to tailor all aspects of the <em>installation</em>, and place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>: you are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.44391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " See Azure extensions for <em>infrastructure</em> monitoring. <em>Install</em> using tarball files For custom setup scenarios, you can <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default <em>installation</em> settings"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Windows",
        "Install for Windows Server and Windows 10 using our guided install",
        "Install using our step-by-step instructions",
        "PowerShell install",
        "32-bit Windows",
        "64-bit Windows",
        "Step-by-step install",
        "Important",
        "Scripted installation",
        "Install using zip files",
        "Caution",
        "What's next?",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "32766f16044664c9c7d66075801930ff53ca5c49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/",
      "published_at": "2021-10-01T12:58:40Z",
      "updated_at": "2021-08-26T18:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for Windows, you can monitor individual servers and also analyze how your service performs as a whole. The Windows agent can run on your own hardware or in cloud systems such as Amazon EC2 or Windows Azure, and supports Windows Server and Windows 10. You can also install with Chef. Before installation, be sure to review the requirements. If you haven't already, create a New Relic account. It's free, forever. Install for Windows Server and Windows 10 using our guided install To install the infrastructure monitoring agent for Windows, you can use our guided install. If you're in the EU, try our euro guided install. Install using our step-by-step instructions If guided install doesn't work, use our PowerShell script, or follow the step-by-step instructions: PowerShell install Review the agent requirements and supported operating systems. Open the PowerShell as administrator and run the following command: 32-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy 64-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy For a scripted installation, you can pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Step-by-step install Review the infrastructure monitoring agent requirements and supported operating systems. Download the latest .MSI installer image from: 32-bit Windows https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi​ Copy 64-bit Windows https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Copy Important Do not double-click the installer. This will not fully install the local agent and can result in permissions issues. In an admin account, run the install script using an absolute path. 32-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy 64-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy Scripted installation For a scripted installation, you can also pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Add your New Relic license key to the license_key attribute in newrelic-infra.yml, located in C:\\Program Files\\New Relic\\newrelic-infra\\. When finished, the contents of newrelic-infra.yml should resemble the following: license_key: YOUR_LICENSE_KEY Copy Start the newrelic-infra service. To start from the Windows command prompt, run: net start newrelic-infra Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. Install using zip files For custom setup scenarios, you can install the infrastructure monitoring agent using our zip files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment. Caution Installing the infrastructure monitoring agent using zip files is not supported. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.49756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". You can also <em>install</em> with Chef. Before <em>installation</em>, be sure to review the requirements. If you haven&#x27;t already, create a New Relic account. It&#x27;s free, forever. <em>Install</em> for <em>Windows</em> Server and <em>Windows</em> 10 using our guided <em>install</em> To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>, you can use"
      },
      "id": "6044672464441f9bb6378ed9"
    },
    {
      "sections": [
        "Zip assisted install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Zip assisted install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "fcadbeed626401863b6b16e5c52e9a472a5ac13e",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows/",
      "published_at": "2021-10-01T12:58:40Z",
      "updated_at": "2021-04-16T02:59:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Windows, you can make the changes you need to the installation script we provide so you can adapt it to your environment. Before installation, make sure to check the compatibility and requirements. Install the agent Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Once it's unpacked, access and edit the installation PowerShell script installer.ps1. Update your license key. Optional: Update any other parameters. Execute installer.ps1 with admin rights. Configure your installation Important Make sure any custom folder defined in the installation settings has permissions limitations properly defined. The infrastructure agent might execute any integration defined in the NRIA_PLUGIN_DIR directory with Administrator permissions. You can configure the following parameters during the assisted install for Windows: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: C:\\Program Files\\New Relic\\newrelic-infra Copy NRIA_APP_DATA_DIR This configures the data directory to store inventory and other agent files. Default: C:\\%ProgramData%\\New Relic\\newrelic-infra Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The New Relic license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy NRIA_OVERWRITE By default and for security reasons, Windows does not install a service if there's another service with the same name already installed. To bypass this check, make sure this setting NRIA_OVERWRITE is TRUE. Default: TRUE Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: C:\\Program Files\\NewRelic\\newrelic-infra\\inregrations.d Copy NRIA_SERVICE_NAME This provides the name for the Windows service. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.27591,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>, you can make the changes you need to the <em>installation</em> script we provide so you can adapt it to your environment. Before <em>installation</em>, make sure to check the compatibility and requirements. <em>Install</em> the <em>agent</em> Important As of version"
      },
      "id": "603ea7af196a67dab0a83d9d"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-09-30T23:03:42Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.44391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " See Azure extensions for <em>infrastructure</em> monitoring. <em>Install</em> using tarball files For custom setup scenarios, you can <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default <em>installation</em> settings"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring": [
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-01T00:13:13Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.44193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-01T13:00:53Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.54836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-10-01T13:00:53Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.94734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data": [
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-01T00:13:13Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.44193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-10-01T13:00:53Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.94734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-10-01T12:59:44Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.94734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics": [
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-01T13:00:53Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.54836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-10-01T13:00:53Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.94734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-10-01T12:59:44Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.94734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ]
}