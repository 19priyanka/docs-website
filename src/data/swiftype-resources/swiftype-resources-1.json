{
  "/docs/accounts/accounts/account-maintenance/account-email-settings": [
    {
      "sections": [
        "Introduction to account settings",
        "Pricing, billing, and usage UI",
        "Manage users",
        "Add accounts",
        "Other account settings"
      ],
      "title": "Introduction to account settings",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "1dbac104fa7e60637c32a61a80b8b709f6fd84c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-10-19T03:52:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view and edit account-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the account dropdown. Keep reading for tips on how to find different kinds of account settings in the UI. Pricing, billing, and usage UI Note that user permissions may impact your access to some account settings. To find billing-related UI, go to one.newrelic.com and, in the upper right corner, click the account dropdown to access various account settings. Here's what you can find there: Manage your plan: Options for viewing and managing billing-related settings. Manage your data: Options for managing ingest of data, which can be a billing factor. Learn more about managing data. View your usage: View of your billing-related usage. Administration: Options related to billing, usage, and user management (this UI available only for users on our New Relic One user model). Account settings: Options related to subscription and usage, and user management (this UI available only to users on our original user model). Related topics: Pricing details: Original pricing plan | New Relic One pricing Manage data Manage users How you manage users depends on which user model you're on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the account dropdown, click Account settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you're on? See Determine user model. Add accounts Learn more about adding accounts. Other account settings See the account settings docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.20593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>account</em> <em>settings</em>",
        "sections": "Introduction to <em>account</em> <em>settings</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "To view and edit <em>account</em>-related and user-management-related <em>settings</em>, go to one.newrelic.com and in the top right corner, select the <em>account</em> dropdown. Keep reading for tips on how to find different kinds of <em>account</em> <em>settings</em> in the UI. Pricing, <em>billing</em>, and usage UI Note that user permissions may"
      },
      "id": "6043f38a196a679ae4960f5e"
    },
    {
      "sections": [
        "Set or change password",
        "Change your password",
        "Important",
        "Reset password"
      ],
      "title": "Set or change password",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "817d8d17dca7f361429109d8364eff931a1cb392",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-passwords-user-preferences/",
      "published_at": "2021-10-24T20:28:55Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains information on New Relic password requirements. Change your password New Relic account passwords don't expire. However, users can change their own password and other personal account information anytime. Your ability to change your password from the UI may depend on your user and organization level settings. To change your password from the UI: From one.newrelic.com, click the account dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length At least one letter (a-z, A-Z) At least one number (0-9), special character, or space Special characters allowed include ~ ` ! @ # $ % ^ & * ( ) _ - + = { [ } ] : ; \" ' < , > . ? / | \\. Spaces are also allowed. Important In addition to New Relic's requirements, follow your organization's guidelines for password length, use of upper or lower case letters, numbers, and special characters. Reset password If you forgot your own password or need to request a password reset, you can use New Relic's self-service options. Admins can't reset passwords for other users. If you need to reset someone else's password, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.5182,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Set</em> or change password",
        "sections": "<em>Set</em> or change password",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " and organization level <em>settings</em>. To change your password from the UI: From one.newrelic.com, click the <em>account</em> dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length"
      },
      "id": "603eb55a64441f9f8f4e889c"
    },
    {
      "sections": [
        "Change account or user name",
        "Change user name",
        "Change account name",
        "Important"
      ],
      "title": "Change account or user name",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "328b3ae3afa62555d246baee53ec49add7ad470c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-your-new-relic-account-name/",
      "published_at": "2021-10-24T20:28:56Z",
      "updated_at": "2021-08-26T14:42:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Change user name To change your user name: From the account dropdown, select User preferences. On the right side, click Full name. Change account name Only users on our original user model are able to change their New Relic account name. To do this: From the account dropdown, select Account settings. On the right side, edit the Name field. Important If you're on our New Relic One user model and want to change your account name, contact your account representative or support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.12033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change <em>account</em> or user name",
        "sections": "Change <em>account</em> or user name",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " <em>settings</em>. On the right side, edit the Name field. Important If you&#x27;re on our New Relic One user model and want to change your <em>account</em> name, contact your <em>account</em> representative or support."
      },
      "id": "6043ce92e7b9d215e55799e4"
    }
  ],
  "/docs/accounts/accounts/account-maintenance/change-passwords-user-preferences": [
    {
      "sections": [
        "Introduction to account settings",
        "Pricing, billing, and usage UI",
        "Manage users",
        "Add accounts",
        "Other account settings"
      ],
      "title": "Introduction to account settings",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "1dbac104fa7e60637c32a61a80b8b709f6fd84c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-10-19T03:52:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view and edit account-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the account dropdown. Keep reading for tips on how to find different kinds of account settings in the UI. Pricing, billing, and usage UI Note that user permissions may impact your access to some account settings. To find billing-related UI, go to one.newrelic.com and, in the upper right corner, click the account dropdown to access various account settings. Here's what you can find there: Manage your plan: Options for viewing and managing billing-related settings. Manage your data: Options for managing ingest of data, which can be a billing factor. Learn more about managing data. View your usage: View of your billing-related usage. Administration: Options related to billing, usage, and user management (this UI available only for users on our New Relic One user model). Account settings: Options related to subscription and usage, and user management (this UI available only to users on our original user model). Related topics: Pricing details: Original pricing plan | New Relic One pricing Manage data Manage users How you manage users depends on which user model you're on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the account dropdown, click Account settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you're on? See Determine user model. Add accounts Learn more about adding accounts. Other account settings See the account settings docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.20593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>account</em> <em>settings</em>",
        "sections": "Introduction to <em>account</em> <em>settings</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "To view and edit <em>account</em>-related and user-management-related <em>settings</em>, go to one.newrelic.com and in the top right corner, select the <em>account</em> dropdown. Keep reading for tips on how to find different kinds of <em>account</em> <em>settings</em> in the UI. Pricing, <em>billing</em>, and usage UI Note that user permissions may"
      },
      "id": "6043f38a196a679ae4960f5e"
    },
    {
      "sections": [
        "Change account or user name",
        "Change user name",
        "Change account name",
        "Important"
      ],
      "title": "Change account or user name",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "328b3ae3afa62555d246baee53ec49add7ad470c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-your-new-relic-account-name/",
      "published_at": "2021-10-24T20:28:56Z",
      "updated_at": "2021-08-26T14:42:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Change user name To change your user name: From the account dropdown, select User preferences. On the right side, click Full name. Change account name Only users on our original user model are able to change their New Relic account name. To do this: From the account dropdown, select Account settings. On the right side, edit the Name field. Important If you're on our New Relic One user model and want to change your account name, contact your account representative or support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.12033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change <em>account</em> or user name",
        "sections": "Change <em>account</em> or user name",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " <em>settings</em>. On the right side, edit the Name field. Important If you&#x27;re on our New Relic One user model and want to change your <em>account</em> name, contact your <em>account</em> representative or support."
      },
      "id": "6043ce92e7b9d215e55799e4"
    },
    {
      "sections": [
        "Default time zone setting",
        "Change your default time zone",
        "Exceptions"
      ],
      "title": "Default time zone setting",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "3a7abaee77b5d140836c96007766fa8eb9109b6b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/default-time-zone-setting/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-08-26T14:04:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your personal timezone setting controls most time-related settings in the New Relic UI, with a few exceptions, as explained in this document. If you change your timezone setting, this may take up to 24 hours to be reflected in the UI. Change your default time zone To change your default time zone for your New Relic account: Go to one.newrelic.com. Select the account dropdown, then select User preferences. Exceptions Users managed via automated user management (AUM) can't change their time zone in the UI. That must be configured in your identity provider. Some New Relic features do not rely on the User preferences time zone settings. The following use Coordinated Universal Time (UTC) and aren't affected by user preferences: Alerts REST API v2 There may be other features where the time zone doesn't rely on your default time zone settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.10881,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default time zone <em>setting</em>",
        "sections": "Default time zone <em>setting</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "Your personal timezone setting controls most time-related <em>settings</em> in the New Relic UI, with a few exceptions, as explained in this document. If you change your timezone setting, this may take up to 24 hours to be reflected in the UI. Change your default time zone To change your default time zone"
      },
      "id": "6043f38a28ccbc97e62c6090"
    }
  ],
  "/docs/accounts/accounts/account-maintenance/change-your-new-relic-account-name": [
    {
      "sections": [
        "Introduction to account settings",
        "Pricing, billing, and usage UI",
        "Manage users",
        "Add accounts",
        "Other account settings"
      ],
      "title": "Introduction to account settings",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "1dbac104fa7e60637c32a61a80b8b709f6fd84c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-10-19T03:52:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view and edit account-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the account dropdown. Keep reading for tips on how to find different kinds of account settings in the UI. Pricing, billing, and usage UI Note that user permissions may impact your access to some account settings. To find billing-related UI, go to one.newrelic.com and, in the upper right corner, click the account dropdown to access various account settings. Here's what you can find there: Manage your plan: Options for viewing and managing billing-related settings. Manage your data: Options for managing ingest of data, which can be a billing factor. Learn more about managing data. View your usage: View of your billing-related usage. Administration: Options related to billing, usage, and user management (this UI available only for users on our New Relic One user model). Account settings: Options related to subscription and usage, and user management (this UI available only to users on our original user model). Related topics: Pricing details: Original pricing plan | New Relic One pricing Manage data Manage users How you manage users depends on which user model you're on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the account dropdown, click Account settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you're on? See Determine user model. Add accounts Learn more about adding accounts. Other account settings See the account settings docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.2058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>account</em> <em>settings</em>",
        "sections": "Introduction to <em>account</em> <em>settings</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "To view and edit <em>account</em>-related and user-management-related <em>settings</em>, go to one.newrelic.com and in the top right corner, select the <em>account</em> dropdown. Keep reading for tips on how to find different kinds of <em>account</em> <em>settings</em> in the UI. Pricing, <em>billing</em>, and usage UI Note that user permissions may"
      },
      "id": "6043f38a196a679ae4960f5e"
    },
    {
      "sections": [
        "Set or change password",
        "Change your password",
        "Important",
        "Reset password"
      ],
      "title": "Set or change password",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "817d8d17dca7f361429109d8364eff931a1cb392",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-passwords-user-preferences/",
      "published_at": "2021-10-24T20:28:55Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains information on New Relic password requirements. Change your password New Relic account passwords don't expire. However, users can change their own password and other personal account information anytime. Your ability to change your password from the UI may depend on your user and organization level settings. To change your password from the UI: From one.newrelic.com, click the account dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length At least one letter (a-z, A-Z) At least one number (0-9), special character, or space Special characters allowed include ~ ` ! @ # $ % ^ & * ( ) _ - + = { [ } ] : ; \" ' < , > . ? / | \\. Spaces are also allowed. Important In addition to New Relic's requirements, follow your organization's guidelines for password length, use of upper or lower case letters, numbers, and special characters. Reset password If you forgot your own password or need to request a password reset, you can use New Relic's self-service options. Admins can't reset passwords for other users. If you need to reset someone else's password, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Set</em> or change password",
        "sections": "<em>Set</em> or change password",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " and organization level <em>settings</em>. To change your password from the UI: From one.newrelic.com, click the <em>account</em> dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length"
      },
      "id": "603eb55a64441f9f8f4e889c"
    },
    {
      "sections": [
        "Default time zone setting",
        "Change your default time zone",
        "Exceptions"
      ],
      "title": "Default time zone setting",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "3a7abaee77b5d140836c96007766fa8eb9109b6b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/default-time-zone-setting/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-08-26T14:04:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your personal timezone setting controls most time-related settings in the New Relic UI, with a few exceptions, as explained in this document. If you change your timezone setting, this may take up to 24 hours to be reflected in the UI. Change your default time zone To change your default time zone for your New Relic account: Go to one.newrelic.com. Select the account dropdown, then select User preferences. Exceptions Users managed via automated user management (AUM) can't change their time zone in the UI. That must be configured in your identity provider. Some New Relic features do not rely on the User preferences time zone settings. The following use Coordinated Universal Time (UTC) and aren't affected by user preferences: Alerts REST API v2 There may be other features where the time zone doesn't rely on your default time zone settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.1088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default time zone <em>setting</em>",
        "sections": "Default time zone <em>setting</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "Your personal timezone setting controls most time-related <em>settings</em> in the New Relic UI, with a few exceptions, as explained in this document. If you change your timezone setting, this may take up to 24 hours to be reflected in the UI. Change your default time zone To change your default time zone"
      },
      "id": "6043f38a28ccbc97e62c6090"
    }
  ],
  "/docs/accounts/accounts/account-maintenance/set-session-timeouts": [
    {
      "sections": [
        "Original product-based pricing and billing",
        "Important",
        "Overview of original pricing",
        "Annual vs monthly pricing plans",
        "APM and infrastructure: Compute-unit vs host-based pricing",
        "Compute unit pricing",
        "Host-based pricing",
        "Tip",
        "How is a \"host\" defined?",
        "Prorated billing",
        "Manage subscription and billing settings",
        "View summary information",
        "View or change current subscription",
        "View usage",
        "View or update billing information"
      ],
      "title": "Original product-based pricing and billing",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "92a9a2aaacf80af45767d6f8f15283c541b2bf08",
      "image": "https://docs.newrelic.com/static/a5a6fd548a3c62e03183f13e6be6688a/77a9e/Accounts_CU-calculation_0.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-pricing/product-based-pricing/",
      "published_at": "2021-10-24T19:44:57Z",
      "updated_at": "2021-09-14T14:48:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more on pricing and user-related changes, see Overview of changes. Overview of original pricing New Relic has two pricing plans: a newer one called New Relic One pricing, and our original pricing plan. Our original pricing plan was based on subscriptions to specific products, like APM, Mobile, and Infrastructure. If you are on this pricing plan, your users are likely on our original user model and use these original user docs. To understand more about the new pricing and user changes, see Overview of changes. For accounts on original pricing, this doc includes: Explanation of how our original pricing plan works How to manage subscription and billing settings Annual vs monthly pricing plans Here are the differences between billed-annually and billed-monthly plans: Pricing plans Details Annual (best price) New Relic charges your credit card each month for a year for a committed number of hosts or compute units. You can increase this amount at any time, and charges will adjust with the next monthly bill. Your account will automatically renew at the end of the year unless you change your subscription. Early termination, downgrade, or decrease in service: Unless your order form states otherwise, you will be charged at the level and quantity of service ordered until the end of the then-current term if you cancel or downgrade to a lower level of service or fewer hosts during your commitment year. Monthly (no commitment) New Relic charges your credit card each month for a specified number of hosts or compute units. The account Owner can change the credit card number. To edit billing settings, use the Billing UI. Adjustments to billing settings will take effect for the next billing period. Your account automatically renews each month unless you change your subscription. You can cancel service or downgrade to a lower level of service without penalty. APM and infrastructure: Compute-unit vs host-based pricing APM offers a choice between two pricing models: compute unit (CU) based pricing and host-based pricing. New Relic Infrastructure offers only CU-based pricing. This section shows how both options are calculated, and explains what \"host\" means in these pricing contexts: Compute unit pricing CU-based pricing is available for these New Relic products: APM (choice of either CU-based pricing or host-based pricing) Infrastructure: only CU-based pricing With CU-based pricing, your monthly price is determined by the size of the host (computing power and memory) running New Relic and the number of hours it connects to New Relic during the month. If a host is connected to New Relic at any time during an hour, that hour counts towards the CU calculation. Each host is counted separately for each New Relic account the host reports data to. For example, if you have a parent account with two children accounts, each running applications on the same host for 3,000 CUs in a given month, the usage for the parent account will be 6,000 CUs. For APM, CU-based pricing is the best choice if you have many cloud-based dynamic computing resources. For this reason, CU-based pricing is sometimes referred to as cloud pricing. CUs are calculated as follows: The maximum size of a given host (CPUs + GB RAM) is capped at 16. Examples: If a host has 2 CPU cores, 2GB RAM, and connects to New Relic for one hour (or less than one hour), it consumes 4 CUs. If a host has 2 CPU cores, 2GB RAM, and connects to New Relic for an entire month (750 hours used as standard month size), it consumes 3,000 CUs. You can purchase blocks of CUs to be consumed on a monthly basis. The total number of CUs purchased monthly is calculated by adding up the estimated CU consumption for all hosts for the month. There is no month-to-month rollover of unused CUs. Also, New Relic does not charge by JVMs, containers (such as Docker or Cloud Foundry), or application instances--it charges by the hosts running those containers or application instances. Price points vary, depending on the New Relic product and subscription level. You can view CU-based account usage from the New Relic UI. Host-based pricing Tip Pricing for your APM account can be either CU-based or host-based. New Relic Infrastructure uses only CU-based pricing. With host-based pricing, New Relic charges based on the number of equivalent hosts used in a month. One equivalent host is defined as: a host connected to New Relic for 750 hours (750 hours used as standard month size). If a host is connected to New Relic at any time during an hour, that hour counts towards the host calculation. These hours can be divided across multiple hosts. For example, you might have three hosts that are each connected to New Relic for 250 hours during one month: these hours would add up to equal one equivalent host. Each host is counted separately for each New Relic account the host reports data to. For example, if you have a parent account with two child accounts, each running applications on the same single host for 750 hours in a given month, the usage for the parent account will be 2 equivalent hosts. Once connected to New Relic, hosts are distinguished by their unique hostnames. A host is connected to New Relic when the language agent is active and is deployed on the host. New Relic does not charge by containers (such as Docker or Cloud Foundry), JVMs, or application instances; it charges by the hosts running those containers or application instances. New Relic APM gives you a choice between host-based pricing and CU-based pricing. Host-based pricing is ideal if you have mainly static environments, consisting of hosts you manage in your own data center. For specifics on pricing amounts, see the New Relic APM pricing page. How is a \"host\" defined? To understand how New Relic computes both host-based pricing and CU-based pricing, it's important to understand how the word host is used. A host can be one of the following: A physical machine is a hardware-based device with dedicated physical resources, including memory, processing, and storage. Each machine has its own OS which applications run on. A virtual machine (VM) is the software implementation of a physical machine that executes programs like a physical machine. One or more virtual machines can run on a physical machine. Each virtual machine has its own OS and allocated virtual machine resources such as RAM and CPU. A cloud instance is a type of virtual machine that is run in the public cloud. In this context, virtual machines and cloud instances are different from Java Virtual Machines (JVMs) and containers. For New Relic's pricing calculation purposes, a month is defined as 750 hours. Prorated billing If you upgrade your subscription partway through your billing period, you will be subject to a prorated charge for the higher level of service over the remainder of your billing period. This will be invoiced or charged to your credit card when the upgrade is submitted. You will be notified about this charge as part of the subscription change process. If you have questions, contact your New Relic account representative. If you need to report billing issues, contact New Relic's Billing Department. Manage subscription and billing settings Important Note that as of July 30 2020, we have a newer pricing plan. To learn more, see Overview of pricing. The account Owner can perform many subscription self-service functions directly from the user interface: From one.newrelic.com, select the account dropdown. Select your choice of self-service options. When making subscription changes, be sure to save any changes, agree to New Relic's Terms of Service and Supplemental Payment Terms as appropriate, and select Pay now. Optional: If you downgrade your subscription, complete New Relic's survey. Here is a summary of the available options from your account dropdown in the New Relic user interface: View summary information To view summary information about your subscription, go to the billing UI. View or change current subscription To adjust your subscription settings, use the Billing UI. If you need more help, contact your New Relic account representative, or contact New Relic's Billing Department. View usage To view your usage, use the usage UI. View or update billing information To view or update your New Relic account's billing information, see the billing UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.8522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "sections": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": ". For <em>accounts</em> on <em>original</em> <em>pricing</em>, this doc includes: Explanation of how our <em>original</em> <em>pricing</em> plan works How to manage subscription and <em>billing</em> settings Annual vs monthly <em>pricing</em> plans Here are the differences between billed-annually and billed-monthly plans: <em>Pricing</em> plans Details Annual (best <em>price</em>) New Relic"
      },
      "id": "6043f753e7b9d212085799da"
    },
    {
      "sections": [
        "Overview of changes to pricing and user model",
        "Overview of how pricing plan and user model relate",
        "Pricing plans explained",
        "Determine pricing plan",
        "Convert to new pricing",
        "User models explained",
        "Requirements for new user model",
        "Determine which user model you're on",
        "Feature impacts of user model",
        "Transition to new models"
      ],
      "title": "Overview of changes to pricing and user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "b19d61b5a0c65ca352e2ce0e260e2b53391b94fc",
      "image": "https://docs.newrelic.com/static/1461470cc1ef0be91120c84d76a7ccdd/c1b63/new-relic-one-pricing-plan-billing-ui.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-product-based-pricing/overview-changes-pricing-user-model/",
      "published_at": "2021-10-24T19:44:08Z",
      "updated_at": "2021-09-13T20:48:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In 2020, New Relic released both a newer pricing plan and a newer user model. Keep reading to learn about: How the pricing plan and the user model relate to each other Pricing plans explained User models explained How to switch to the new models Overview of how pricing plan and user model relate In 2020, we released both a new, improved pricing plan and a new, improved user model. These models represent the future. All new sign-ups are on these new models and eventually all organizations will be on these models. But currently, our customers from before July 2020 may have one of several combinations of these as they either switch to the new pricing or migrate their users to the new user model. This table shows how pricing and user model relate to each other: Pricing plan factors User model factors Original pricing If your organization was created before July 30 2020, you remain on our original pricing plan until you transition to New Relic One pricing. For original pricing accounts, you have users on the original user model unless you've migrated your users to the new model. Note that if you've added users via automated user management, they're on the new model. This means it's possible to have some users on both models. New Relic One pricing An organization is on the New Relic One pricing plan: If it was created on or after July 30 2020, or If it's an older organization but has switched to New Relic One pricing. If your organization was created on or after July 30 2020, your users are on the New Relic One user model. If you have an older organization, you have users on the original user model unless you've migrated your users to the new model. Pricing plans explained New Relic organizations are on one of two pricing plans: New Relic One pricing: Our new pricing plan is simpler. It bills on a) which edition you're on (Standard, Pro, or Enterprise), b) the GBs of data ingested, and c) how many billable full users you have. All organizations created on or after July 30 2020 are on this pricing plan, as are older organizations that have switched to this pricing. There are two versions of this pricing plan. Our original product-based pricing plan: this is based on subscriptions to specific products (for example, APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer pricing plan: in that case, their users remain on our original user model. Determine pricing plan To determine which pricing plan you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see billing information about data ingested and the number of billable users, you’re on the new pricing plan. If you're on New Relic One pricing, you'll see a billing UI like this. Convert to new pricing Some organizations are able to switch to new pricing. Learn more about switching your pricing plan. User models explained In this context, the term \"user model\" refers to the structure of a New Relic user record and how it interacts with the broader New Relic organization that it's in. Our two user models are: New Relic One user model: this newer, improved user model has these major differences from the original user model: All your accounts and users are contained under a top-level organization. This gives an organization stronger control over managing users and what they can access. One impact of this is that users who work with multiple New Relic organizations may have an email address associated with multiple logins. Users on this model have a different system for managing permissions and account access. Using access grants, you assign users access to specific roles on specific accounts. Original user model: some aspects of this older model that are different from our newer model: There wasn't as much organization-level control over users. For example, a New Relic user had the ability to access multiple accounts they'd been granted access to using a single login. Users on the original user model have a different user management system. To learn more about benefits of the new model, see our blog post about user model changes and an explanation of the new account structure. For impacts and limitations, see Feature impacts. Requirements for new user model Here's a synopsis of the factors governing what organizations use the new model: All New Relic organizations that signed up after July 30 2020 have users on this model, and also have the new pricing plan. Some older New Relic organizations have had their users migrated to the new model by New Relic or by using the user migration procedure. Note that switching to the new pricing plan is independent from migrating users. Partner accounts (resellers, managed service providers), and organizations using the partnership account structure, cannot yet migrate their users to the new model. Determine which user model you're on To determine what user model you're on, from the account dropdown select User preferences. If you see the UI below, you're on the New Relic One user model. If you see a different UI with more content displayed, you're on the original user model (see original user docs). To determine if you can manage users on the New Relic One user model, see Manage users. The user model is independent of your pricing plan. For how user model relates to pricing, see the Pricing and user model table. Feature impacts of user model The new user model offers many benefits. Here are some feature impacts of being on the New Relic One user model that may be not obvious to users accustomed to our previous user model: More separation of organizations/accounts: If you have an email address associated with multiple New Relic accounts, this may mean you need to log out and log back in. Learn more about account access. Adding accounts: Pro and Enterprise edition can have more than one account in their organization. Currently users in these organizations cannot, on their own, add accounts. They must get help from their New Relic account representative. To learn about adding users to accounts, see Manage users. Alerts-related impacts: Policy actions: For alert policies and conditions, some UI locations display the user that made the last modification. For users on the new model, it will display their user ID and not their user name. For example, a policy might read Last modified Sep 7, '20 4:26 pm by user 1234567 instead of by John Doe. If you have user management permissions, you can determine what user this is by going to the User management UI. Notifications: Users on the new model won’t show up as an option when choosing users to receive alert notifications. The result of this is that these users will not get New Relic mobile app push notifications. As a workaround, you can instead use their email address as the notification channel. You can't use the REST API to generate a list of users (only original model users). Instead you'd use the user management UI. Changing account name: These users cannot change the name of their organization after it has been created. Transition to new models Some New Relic organizations on the old models are able to transition to the new models. To learn more about this, see Transition to new models.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.18825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of changes to <em>pricing</em> <em>and</em> user model",
        "sections": "Overview of changes to <em>pricing</em> <em>and</em> user model",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": ". There are two versions of this <em>pricing</em> plan. Our <em>original</em> <em>product</em>-<em>based</em> <em>pricing</em> plan: this is <em>based</em> on subscriptions to specific products (for example, APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer <em>pricing</em> plan: in that case, their users remain"
      },
      "id": "603e97fa28ccbcb7c2eba754"
    },
    {
      "sections": [
        "Overview of data retention (original pricing plan)",
        "Important",
        "Limits on editing and deleting data",
        "Product and API data retention policies",
        "APM",
        "APM data retention policies",
        "Legacy APM data retention policies",
        "Browser",
        "Infrastructure",
        "Tip",
        "Infrastructure downsampling and data retention",
        "Integration compute unit event limits",
        "Insights",
        "Logs",
        "Logs in context data retention",
        "Mobile",
        "Mobile data retention policies",
        "Standard Mobile (legacy) data retention policies",
        "Plugins",
        "Plugins data retention",
        "Legacy Plugins data retention",
        "Synthetics",
        "Synthetics data retention policies",
        "Metric API",
        "Trace API",
        "Data components",
        "Event data: reported by most products",
        "Metric timeslice data: reported by APM, Browser, and Mobile",
        "Aggregate metric timeslice data: reported by APM, Browser, and Mobile",
        "Key metrics: reported by APM, Browser, and Mobile",
        "Trace data: reported by APM, Browser, and Mobile"
      ],
      "title": "Overview of data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "22d5ab9f4d623ead28ee7bb82c118d91804dee22",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-based-pricing/overview-data-retention-components/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-09-14T14:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on our New Relic One pricing plan, see Manage your data. Not sure which you're on? See Overview of pricing plans. If you're on the original product-based pricing plan, you retain your existing subscriptions and data retention values. You manage these existing retention settings from the Data management hub in New Relic One. To manage your retention settings, go to the Data management UI. You'll see your existing retention settings. Adjust retention values by clicking Edit retention. New Relic stores different types of data for different periods of time. The retention period for a type of data will vary depending on the product, the subscription level, and the feature. Limits on editing and deleting data Once telemetry data (events, metrics, logs, traces) is reported to New Relic and available for querying, that data cannot be edited or deleted. This is a purposeful design decision that optimizes New Relic's speed and performance. Data will expire after its data retention ends. If you sent unwanted data or sensitive data to New Relic that must be removed, contact your account representative at New Relic, or get support at support.newrelic.com. Product and API data retention policies Select a New Relic product to see details about its data retention: APM Specific retention policies apply to each APM subscription level, including Lite, Essentials, Pro, and Enterprise. This includes metric timeslice data, key metrics, trace data, and event data. In addition to retention limits, your data is subject to aggregation (averaging) after certain elapsed time periods. For more information, see the aggregate metric data description. APM data retention policies For accounts on our original product-based pricing, APM data retention policies depend on your APM product subscription level. Component Lite Essentials Pro Metric timeslice data 24 hours 3 days 90 days Key metrics none forever forever Distributed tracing and logs in context none none 8 days Other trace data * 1 day 3 days 7 days Event data * * 1 day 3 days 8 days * If you view a transaction trace in the New Relic UI, New Relic stores that trace data for up to one year. * * Learn about how to extend the retention of event data. Legacy APM data retention policies Component Standard Startup Small Business Enterprise Metric timeslice data 7 days 14 days 30 days 90 days Key metrics none none none forever Trace data 7 days 7 days 7 days 7 days Event data none 8 days 8 days 8 days Browser For accounts on our original product-based pricing, Browser data is stored depending on your subscription level: Component Lite Pro Metric data 24 hours 90 days Key metrics 24 hours forever Trace data 7 days 7 days Event data * 1 day 8 days SPA data Unavailable 8 days * Learn about how to extend the retention of event data. Infrastructure For accounts on our original product-based pricing, Infrastructure data retention policies depend on your Infrastructure subscription level and your New Relic Infrastructure compute units pricing model. Data retention rules apply the same whether that data is displayed in the UI or queried. Tip Infrastructure data retention is not governed by your Insights subscription. Infrastructure downsampling and data retention Types of data are stored depending on your subscription level: Component Essentials Pro Infrastructure data 3 months 13 months Host count Host count will stop reflecting a host whose agent is no longer reporting after three minutes. However, host data will be available, subject to other retention criteria. 3 minutes 3 minutes Inventory attributes removed Inventory attributes for a host are retained for 24 hours after the agent stops reporting. 24 hours 24 hours Integration data Not available with Essentials Limit of 2275 integration events per compute unit per month In addition, Infrastructure downsamples your data on the fly, as it's generated. All Infrastructure metric data types (including On-Host Integrations metrics) will display different granularity depending on the age of the data and the size of the time window. The following table illustrates when different downsampled buckets will be used, both in the Infrastructure UI and for queries: Bucket Size Used For Time Windows Covering... Data Retained For... Raw (5, 10 or 15 second) 0 to 59 minutes 7 days 1 minute 60 minutes to 6 hours 30 days 10 minutes 6 hours to 3 days Full account retention period 1 hour 3 days to 14 days Full account retention period 3 hours 14+ days Full account retention period Integration compute unit event limits The 2275 limit on integration events per compute unit per month is a limit on total Infrastructure integration events. It's not a limit of 2275 for each integration's events. Additional details and clarifications about this limit: This limit applies to all events from all integrations (cloud integrations and on-host integrations). The events are all handled the same. Default data received by the Infrastructure agent does not count against the 2275 event per compute unit limit. If you exceed your limit, we do not enforce this limit. If you exceed your limit, we'll review pricing options with you to ensure you get the most cost-effective pricing for your organization's integrations. Insights For accounts on our original product-based pricing, an Insights subscription extends your event data retention. An Insights Pro subscription allows you to customize the length of your event data retention. Logs For accounts on our original product-based pricing, log data can be retained for up to 30 days by New Relic. Shorter retention periods of 8 or 15 days are also available. Logs in context data retention New Relic Logs logs in context data retention policy is based on your current APM product subscription level. For more information, see APM data retention. Mobile For accounts on our original product-based pricing, Mobile data retention policies depend on your New Relic Mobile product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and event data. For information about your subscription-related data usage, see Mobile subscription usage. Mobile data retention policies Component Lite Enterprise Overview page data 24 hours 90 days Crash data and stack traces 24 hours 90 days HTTP requests (except errors) as metric data Unavailable 90 days HTTP request errors as metric data Unavailable 3 days Interaction traces Unavailable 90 days Custom events * Unavailable 1 day Mobile events * 1 day 8 days MobileBreadcrumb events * Unavailable 3 days MobileCrash events * 1 day 90 days MobileHandledException events * Unavailable 3 days MobileJSError events (React Native beta) * Unavailable 3 days MobileRequest events * Unavailable 3 days MobileRequestError events * Unavailable 3 days MobileSession events * 1 day 90 days * Learn how to extend retention of event data. Standard Mobile (legacy) data retention policies Unless otherwise noted, Insights event data is unavailable for Standard subscriptions. Component Standard Overview page data 7 days Crash data and stack traces 7 days HTTP requests (except errors) as metric data 7 days HTTP request errors as metric data 3 days Interaction traces Unavailable MobileCrash events 8 days MobileSession events 8 days Plugins The retention period for historical data depends on the product and subscription level. The following data retention periods exist for New Relic Plugins. Important Plugins is not supported with accounts that host data in the EU region data center. Plugins data retention Component Lite Essentials Pro Enterprise Metric data 24 hours 3 days 90 days 90 days Legacy Plugins data retention Component Standard Startup Small Business Metric data 7 days 14 days 30 days Synthetics For accounts on our original product-based pricing, Synthetics data retention policies depend on your Synthetics product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and Insights events. Tip Synthetics events do not count against an Insights Pro subscription. Your current subscription level appears in the right column of the Account summary page: Go to synthetics.newrelic.com > (account dropdown) > Account settings > Account > Summary. Synthetics data retention policies Component Lite Pro Synthetics monitor data 2 weeks 13 months Event data 2 weeks 13 months Also see the data retention details for APIs, including: Metric API All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Trace API See Trace API general requirements and limits. Data components For accounts on our original product-based pricing, the section below provides an explanation of some types of data components governed by the data retention rules of specific products: Event data: reported by most products See Event data retention for information on the event data type. Metric timeslice data: reported by APM, Browser, and Mobile Metric timeslice data is a specific type of data that is used for most metric charts and reports in APM, mobile, and browser. Important Note that metric timeslice data differs from other metric data types. All metric timeslice data is aggregated, but New Relic deals with fresh data and old data in different ways. Fresh data has specific policies applied to the data to keep granular views of performance as aggregate metrics. As data ages and becomes less useful in a granular state, we summarize that data and only keep key metrics. Aggregate metric timeslice data: reported by APM, Browser, and Mobile Aggregate metric timeslice data summarizes calls to specific methods in your application: how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on your subscription level. Subscription Level Aggregate retention Enterprise Aggregates (averages) to 1-hour periods after 8 days. After 90 days, the permanent metric data continues to be stored in 1-hour periods. This means you cannot obtain data granularity of less than 1 hour after 8 days, and only a subset of metrics are available after 90 days. Pro After 8 days Essentials After 3 days. Legacy Small Business, Startup, and Standard After 3 days. Lite After 2 hours. We retain your most recent data in one-minute increments. We also aggregate permanent metric data to day-size increments after 90 days. When looking at older data in small time windows, you may notice that charts show less detail. As data ages, it is aggregated into larger segments. Key metrics: reported by APM, Browser, and Mobile New Relic retains certain \"key\" metric timeslice data aggregations forever for Enterprise and Pro customers, for any number of applications. New Relic aggregates permanent key metric data to hour-size increments after 90 days. Product Key metrics APM Apdex, for app server Throughput and page views Response time, plus breakdown into tiers or categories on your app's main Overview chart Page load time, plus breakdown into segments Error rate CPU usage Memory usage Browser Apdex, for browser Browser page load time Throughput total. After 90 days, there is no breakout by browser type, and only the combined average value is available for the time range requested. Mobile Crash rate: For iOS and for Android Network throughput Network response time Network error rates Interaction traces Trace data: reported by APM, Browser, and Mobile Depending on the product, New Relic retains different types of trace data: Product Trace data APM Types of trace data: Transaction traces Distributed tracing Slow query samples Error details See APM data retention details. Browser Types of trace data: Session traces Browser traces JavaScript errors* See Browser data retention details. Mobile Types of trace data: App crash stack traces Interaction traces See Mobile data retention details. * JavaScript errors in the stack trace UI are saved as trace data. JS errors are also saved as events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.07448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of data retention (<em>original</em> <em>pricing</em> plan)",
        "sections": "Overview of data retention (<em>original</em> <em>pricing</em> plan)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> <em>Product</em>-<em>based</em> <em>pricing</em>. If you&#x27;re on our New Relic One <em>pricing</em> plan, see Manage your data. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. If you&#x27;re on the <em>original</em> <em>product</em>-<em>based</em> <em>pricing</em> plan, you retain your existing subscriptions and data"
      },
      "id": "6043f75364441f6967378ec6"
    }
  ],
  "/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign": [
    {
      "sections": [
        "Okta SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Okta's New Relic app",
        "Step 3. Configure provisioning",
        "Step 4. Assign users and groups",
        "Assignments tab",
        "Push groups tab",
        "Step 5. Manage user type",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO",
        "Additional considerations",
        "Moving users between groups"
      ],
      "title": "Okta SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "7a00399a6ce11aaa2cb52046f994a80f5986c0e4",
      "image": "https://docs.newrelic.com/static/3f3318e1dc8c9049231c207a7b4e5c54/c1b63/okta-add-user-type-to-profile.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration/",
      "published_at": "2021-10-24T23:01:21Z",
      "updated_at": "2021-10-07T19:07:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up Okta's New Relic app Next, set up Okta's New Relic SCIM/SSO application: Go to okta.com/ and sign in with an account that has administrator permissions. From the Okta home page, click on Admin. From the Okta admin Dashboard, choose the Applications page. Click Browse app catalog and search for \"New Relic by organization\" (not \"New Relic by account\") and choose that from the results. From the New Relic by Organization page, click on Add. From the Add New Relic by organization page, check the two Application visibility \"Do not display...\" checkboxes and click on Done. We will make the application visible later after configuration is complete and provisioning has begun. Step 3. Configure provisioning Configure Okta's New Relic SCIM/SSO application to automatically provision your users to New Relic: From the app, click on the Provisioning tab. From the Integration form, click on Configure API integration. Check the Enable API integration checkbox. Take the API token you saved in Step 1 and input it in the Okta New Relic app's API token field. Optional: click on Test API credentials to verify a SCIM connection can be established to New Relic. If a connection can be established, a success message is displayed. If a connection was not established, re-enter the API Token and try the test again. Click Save. Note that the save process does a test of the API credentials. If a connection is not established to New Relic, the save will fail. On the newly displayed To App form, click on Edit. Check the Enable checkbox in the Create users, Update user attributes, and Deactivate users sections. Click Save. Step 4. Assign users and groups Next, you'll assign users in Okta's New Relic application. Assigning users is done using two different tabs in the app. We recommend having your New Relic users selected on the Assignments tab and their associated groups selected on the Push groups tab. Assignments tab In the app, click on the Assignments tab. From the Assignments form, click on Assign. From the pop up menu, click on Assign to groups. From the Assign ... to groups form, click on Assign for the group you wish to assign to the application. Highly recommended: Set your users' time zones in Okta. The time zone affects how date/times for that user are shown in New Relic. Users without a time zone configured will be shown in UTC time in New Relic. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). There are several ways in Okta to assign users' time zone, so consult the Okta docs for more information if needed. Here is one way to do this in the Assignments tab: In the Time zone field, enter the default time zone for members of the group. Click on Save and go back. Repeat the steps to add a group until all desired groups have been assigned to the application. Click Done. Push groups tab In the app, click on the Push groups tab. From the Push groups form, click on Push groups. From the pop up menu, click on Find groups by name. From the Push groups to... form, in the search field enter the first few characters of the name of the group you want to send to New Relic. Leave the Push group memberships immediately checkbox checked. Click on your group in the pop up search results list. In the Match result & push action section, No match found should be displayed, meaning that the group does not yet exist at New Relic. Leave the selector set to Create group and leave the default name for the group. The intent here is to have a group of the same name created at New Relic. If this is the last group you wish to send to New Relic, click on Save. Otherwise, if you have more groups to configure, click on Save & add another and repeat the steps to add a group. When you've added one or more groups, you should be able to see the users you've added by going to the User management UI page. Step 5. Manage user type If your organization is on New Relic One pricing, the count of your full users is a billing factor. To change some of your users to free basic users, you have two choices: Manage user type from New Relic using the User management UI, OR Manage user type from Okta (described below). To manage your users' user type from Okta: Go to the New Relic authentication domain UI and click Enable Manage user type with SCIM. Note that when this is enabled, you can’t manage user type from the New Relic UI and can only manage it from Okta. Go into your Okta instance. The rest of these instructions are done from Okta. Next, you'll configure Okta to be able to send a new attribute nrUserType. Steps: Go to the Profile editor. In the Attributes section, click Add attribute. Set your settings to match the screenshot below (except for the variable name, which is created automatically). The only two fields that must match exactly are External name and External namespace. The value for External namespace must be urn:ietf:params:scim:schemas:extension:newrelic:2.0:User Next, you'll configure your Okta user profile to have this field. Steps: In the Profile editor, go to Users and click the User (default) profile. Add a new New Relic user type attribute to that profile (see Okta user profile instructions). How you set this will depend on your own setup and preferences for defining user type. Note that the expected values for user type are Basic user and Full user. Below is an example with information filled in. In the People section, define the user type for your users. How you do this will depend on your setup and preferences. For example, you may choose to set this manually by setting each user’s user type, or you may use Okta to manage these in bulk. Next, you’ll set up mapping for that attribute. Steps: In the app's Provisioning section, click Unmapped attributes. Go into edit mode for the unmapped New Relic user type attribute. Configure it based on how you want to set the user type. To learn about why you'd set them as basic users or full users, see User type. Learn more about Okta attribute mappings. Step 6. Assign access grants Once these steps are completed, you're able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO, see the SAML instructions. Additional considerations In this section we discuss other important things to know when using the New Relic SCIM/SSO application. This section includes tips to work around potential issues that could cause undesired results when integrating between Okta and New Relic. Moving users between groups When moving a user between groups, you must manually synchronize the old group's membership with New Relic. This is because Okta does not send a SCIM request to remove a user from a group. So, the admin needs to push the old group's membership to New Relic manually to inform New Relic that the user is no longer a member of the old group. Here are the steps to manually synchronize a group's membership: From the New Relic SCIM/SSO application page, click on the Push groups tab. From the Push groups form, open the pick list on the desired group's button under the Push Status column. From the displayed pick list on the button, click Push now. This causes an immediate synchronization of the group's membership with New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.56958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 5. <em>Manage</em> <em>user</em> type",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "Our <em>automated</em> <em>user</em> <em>management</em> (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f5cae7b9d2758b579a0c"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>User</em> permissions",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " in, select Remember me when logging in. If one of your login options reads &quot;Original <em>account</em>&quot;, that means it&#x27;s a <em>user</em> record on our original <em>user</em> model. For more information, see this Explorers Hub post about multiple <em>accounts</em>. Related docs: <em>User</em> permission factors <em>Account</em> structure Login and password"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "OneLogin SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up OneLogin's New Relic app",
        "Step 3. Configure SCIM/SSO application",
        "Fill in the configuration form",
        "Fill in the rules form",
        "A rule that only uses actions",
        "Fill in the provisioning form",
        "Tip",
        "Fill in the Parameters form",
        "Save your changes",
        "Step 4. Assign users",
        "Step 5. Downgrade some users to basic",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO"
      ],
      "title": "OneLogin SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d298162c055490c99117f564c3ea9c2ea5dfd8d1",
      "image": "https://docs.newrelic.com/static/8f585557ea58f70d94a746e6439bf1ad/c1b63/onelogin_rules_conditions_actions.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/onelogin-scimsso-application-configuration/",
      "published_at": "2021-10-24T23:59:27Z",
      "updated_at": "2021-09-08T12:26:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides OneLogin-specific details on how to configure the New Relic OneLogin SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up OneLogin's New Relic app Next, you'll be setting up OneLogin's New Relic SAML/SCIM app. To set this up: Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click on Administration. From the OneLogin Administration page, choose the Applications menu. From the OneLogin Applications page, click on Add App. In the search field on the OneLogin Find Applications page, enter \"New Relic by organization\" (not \"New Relic by account\") and then click on the application when it shows in the search results. From the Add New Relic by Organization page, click on Save. Step 3. Configure SCIM/SSO application Configuration for the New Relic SCIM/SSO application is split across several forms. This section describes the different forms that need to be configured. From the New Relic by organization application page, fill in the following forms: Fill in the configuration form In the left pane, select Configuration and complete the following: Get the authentication domain ID (top of New Relic's authentication domain UI and SCIM bearer token (in authentication domain UI as \"SAML 2.0 endpoint) and input them into the appropriate fields in the OneLogin app. Leave the API Connection disabled until all the configuration described in the following sections is completed. After completing all the configuration, enable the connection. Fill in the rules form Configure the user groups to send to New Relic using rules. OneLogin provides this documentation which describes how to use rules to provision groups for users. Decide what type of groups to send along with your users to New Relic. If your organization is using Active Directory or LDAP, you might choose to use security groups to define your users capabilities at New Relic. Another reasonable group choice is OneLogin role. On the New Relic side, your user's groups define their capabilities. The groups that are sent with users will be mapped to New Relic capability groups. Note that at the moment, there is no way to delete a group from the OneLogin side. This is a known limitation from OneLogin. Removing or changing rules does not delete groups already sent to New Relic. If you wish to no longer use a group, removing all the users from the group will prevent it from being used at New Relic. A rule that only uses actions Here's an example rule configuration does not use any conditions. The conditions are left empty to avoid applying any filtering logic to the users. All users will be sent in this example. If you want to send only a subset of users, you need to specify conditions to select the subset. The actions describe where to retrieve the value for the group name and how to parse the value. In this example, we retrieve the group name from the OneLogin role field. The OneLogin role field only has a single value, but sometimes the source for the group name contains other fields besides group name. In other words, some sources give you a list of fields and values and only one of those fields has the value you want to use. In this case, you can insert a regular expression in with value that matches field to find and extract the value for the group name. This example uses the entire value of the For each field for the group name. Fill in the provisioning form In the left pane, select Provisioning and complete the following: Check Enable provisioning. Under Require admin approval before this action is performed, uncheck these options: Create user Delete user Update user Tip If you do not uncheck these options, SCIM provisioning requests will not be sent until an administrator approves them. Set When users are deleted in OneLogin, or the user's app access is removed, perform the below action to Delete. Set When user accounts are suspended in OneLogin, perform the following action to Suspend. Fill in the Parameters form In the left pane, select Parameters and complete the following: Click Groups field. Check Include in User Provisioning. Click Save. Save your changes After you complete the above forms, click Save. Then, return to the Configuration form and enable the API connection. Step 4. Assign users After New Relic SCIM/SSO application configuration is finished and New Relic side configuration is finished, you can begin to assign users to the application. Assign the New Relic SCIM/SSO application to a user: Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click Administration. From the OneLogin Administration page, choose the Users menu Users item. From the OneLogin Users page, click the user you want to assign the application to. From the user's page, click Applications. From the user's application page, click the plus sign and select the \"New Relic by Organization\" application. Important: Updating users' time zones is important, as charts and other user assets display times. Default is UMT. From the Edit New Relic by Organization login for user page, enter the user's time zone in IANA Time Zone database format (also known as the Olson time zone database format) and click Save. If you're using Roles to define your New Relic capability groups, from the user's application page, click the proper role(s) for the user and then click Save User. Step 5. Downgrade some users to basic When your users are provisioned in New Relic, you're able to see them in the User management UI. Users provisioned via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, you can use one of two options: Use the User management UI to set users to basic. Configure the OneLogin app to send user type. Step 6. Assign access grants Once these steps are completed, you should be able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO for your users, see the SAML instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.7301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 4. Assign <em>users</em>",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "Our <em>automated</em> <em>user</em> <em>management</em> (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides OneLogin-specific details on how to configure the New Relic OneLogin SCIM&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f34228ccbccafb2c606a"
    }
  ],
  "/docs/accounts/accounts/automated-user-management/azure-ad-scimsso-application-configuration": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 368.88965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "New Relic lets you set up <em>automated</em> <em>user</em> <em>management</em> (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of <em>automated</em> <em>user</em> <em>management</em>, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "Okta SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Okta's New Relic app",
        "Step 3. Configure provisioning",
        "Step 4. Assign users and groups",
        "Assignments tab",
        "Push groups tab",
        "Step 5. Manage user type",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO",
        "Additional considerations",
        "Moving users between groups"
      ],
      "title": "Okta SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "7a00399a6ce11aaa2cb52046f994a80f5986c0e4",
      "image": "https://docs.newrelic.com/static/3f3318e1dc8c9049231c207a7b4e5c54/c1b63/okta-add-user-type-to-profile.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration/",
      "published_at": "2021-10-24T23:01:21Z",
      "updated_at": "2021-10-07T19:07:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up Okta's New Relic app Next, set up Okta's New Relic SCIM/SSO application: Go to okta.com/ and sign in with an account that has administrator permissions. From the Okta home page, click on Admin. From the Okta admin Dashboard, choose the Applications page. Click Browse app catalog and search for \"New Relic by organization\" (not \"New Relic by account\") and choose that from the results. From the New Relic by Organization page, click on Add. From the Add New Relic by organization page, check the two Application visibility \"Do not display...\" checkboxes and click on Done. We will make the application visible later after configuration is complete and provisioning has begun. Step 3. Configure provisioning Configure Okta's New Relic SCIM/SSO application to automatically provision your users to New Relic: From the app, click on the Provisioning tab. From the Integration form, click on Configure API integration. Check the Enable API integration checkbox. Take the API token you saved in Step 1 and input it in the Okta New Relic app's API token field. Optional: click on Test API credentials to verify a SCIM connection can be established to New Relic. If a connection can be established, a success message is displayed. If a connection was not established, re-enter the API Token and try the test again. Click Save. Note that the save process does a test of the API credentials. If a connection is not established to New Relic, the save will fail. On the newly displayed To App form, click on Edit. Check the Enable checkbox in the Create users, Update user attributes, and Deactivate users sections. Click Save. Step 4. Assign users and groups Next, you'll assign users in Okta's New Relic application. Assigning users is done using two different tabs in the app. We recommend having your New Relic users selected on the Assignments tab and their associated groups selected on the Push groups tab. Assignments tab In the app, click on the Assignments tab. From the Assignments form, click on Assign. From the pop up menu, click on Assign to groups. From the Assign ... to groups form, click on Assign for the group you wish to assign to the application. Highly recommended: Set your users' time zones in Okta. The time zone affects how date/times for that user are shown in New Relic. Users without a time zone configured will be shown in UTC time in New Relic. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). There are several ways in Okta to assign users' time zone, so consult the Okta docs for more information if needed. Here is one way to do this in the Assignments tab: In the Time zone field, enter the default time zone for members of the group. Click on Save and go back. Repeat the steps to add a group until all desired groups have been assigned to the application. Click Done. Push groups tab In the app, click on the Push groups tab. From the Push groups form, click on Push groups. From the pop up menu, click on Find groups by name. From the Push groups to... form, in the search field enter the first few characters of the name of the group you want to send to New Relic. Leave the Push group memberships immediately checkbox checked. Click on your group in the pop up search results list. In the Match result & push action section, No match found should be displayed, meaning that the group does not yet exist at New Relic. Leave the selector set to Create group and leave the default name for the group. The intent here is to have a group of the same name created at New Relic. If this is the last group you wish to send to New Relic, click on Save. Otherwise, if you have more groups to configure, click on Save & add another and repeat the steps to add a group. When you've added one or more groups, you should be able to see the users you've added by going to the User management UI page. Step 5. Manage user type If your organization is on New Relic One pricing, the count of your full users is a billing factor. To change some of your users to free basic users, you have two choices: Manage user type from New Relic using the User management UI, OR Manage user type from Okta (described below). To manage your users' user type from Okta: Go to the New Relic authentication domain UI and click Enable Manage user type with SCIM. Note that when this is enabled, you can’t manage user type from the New Relic UI and can only manage it from Okta. Go into your Okta instance. The rest of these instructions are done from Okta. Next, you'll configure Okta to be able to send a new attribute nrUserType. Steps: Go to the Profile editor. In the Attributes section, click Add attribute. Set your settings to match the screenshot below (except for the variable name, which is created automatically). The only two fields that must match exactly are External name and External namespace. The value for External namespace must be urn:ietf:params:scim:schemas:extension:newrelic:2.0:User Next, you'll configure your Okta user profile to have this field. Steps: In the Profile editor, go to Users and click the User (default) profile. Add a new New Relic user type attribute to that profile (see Okta user profile instructions). How you set this will depend on your own setup and preferences for defining user type. Note that the expected values for user type are Basic user and Full user. Below is an example with information filled in. In the People section, define the user type for your users. How you do this will depend on your setup and preferences. For example, you may choose to set this manually by setting each user’s user type, or you may use Okta to manage these in bulk. Next, you’ll set up mapping for that attribute. Steps: In the app's Provisioning section, click Unmapped attributes. Go into edit mode for the unmapped New Relic user type attribute. Configure it based on how you want to set the user type. To learn about why you'd set them as basic users or full users, see User type. Learn more about Okta attribute mappings. Step 6. Assign access grants Once these steps are completed, you're able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO, see the SAML instructions. Additional considerations In this section we discuss other important things to know when using the New Relic SCIM/SSO application. This section includes tips to work around potential issues that could cause undesired results when integrating between Okta and New Relic. Moving users between groups When moving a user between groups, you must manually synchronize the old group's membership with New Relic. This is because Okta does not send a SCIM request to remove a user from a group. So, the admin needs to push the old group's membership to New Relic manually to inform New Relic that the user is no longer a member of the old group. Here are the steps to manually synchronize a group's membership: From the New Relic SCIM/SSO application page, click on the Push groups tab. From the Push groups form, open the pick list on the desired group's button under the Push Status column. From the displayed pick list on the button, click Push now. This causes an immediate synchronization of the group's membership with New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.56958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 5. <em>Manage</em> <em>user</em> type",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "Our <em>automated</em> <em>user</em> <em>management</em> (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f5cae7b9d2758b579a0c"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>User</em> permissions",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " in, select Remember me when logging in. If one of your login options reads &quot;Original <em>account</em>&quot;, that means it&#x27;s a <em>user</em> record on our original <em>user</em> model. For more information, see this Explorers Hub post about multiple <em>accounts</em>. Related docs: <em>User</em> permission factors <em>Account</em> structure Login and password"
      },
      "id": "60bee5c064441f0505d543bb"
    }
  ],
  "/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 368.88943,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "New Relic lets you set up <em>automated</em> <em>user</em> <em>management</em> (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of <em>automated</em> <em>user</em> <em>management</em>, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31454,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>User</em> permissions",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " in, select Remember me when logging in. If one of your login options reads &quot;Original <em>account</em>&quot;, that means it&#x27;s a <em>user</em> record on our original <em>user</em> model. For more information, see this Explorers Hub post about multiple <em>accounts</em>. Related docs: <em>User</em> permission factors <em>Account</em> structure Login and password"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "OneLogin SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up OneLogin's New Relic app",
        "Step 3. Configure SCIM/SSO application",
        "Fill in the configuration form",
        "Fill in the rules form",
        "A rule that only uses actions",
        "Fill in the provisioning form",
        "Tip",
        "Fill in the Parameters form",
        "Save your changes",
        "Step 4. Assign users",
        "Step 5. Downgrade some users to basic",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO"
      ],
      "title": "OneLogin SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d298162c055490c99117f564c3ea9c2ea5dfd8d1",
      "image": "https://docs.newrelic.com/static/8f585557ea58f70d94a746e6439bf1ad/c1b63/onelogin_rules_conditions_actions.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/onelogin-scimsso-application-configuration/",
      "published_at": "2021-10-24T23:59:27Z",
      "updated_at": "2021-09-08T12:26:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides OneLogin-specific details on how to configure the New Relic OneLogin SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up OneLogin's New Relic app Next, you'll be setting up OneLogin's New Relic SAML/SCIM app. To set this up: Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click on Administration. From the OneLogin Administration page, choose the Applications menu. From the OneLogin Applications page, click on Add App. In the search field on the OneLogin Find Applications page, enter \"New Relic by organization\" (not \"New Relic by account\") and then click on the application when it shows in the search results. From the Add New Relic by Organization page, click on Save. Step 3. Configure SCIM/SSO application Configuration for the New Relic SCIM/SSO application is split across several forms. This section describes the different forms that need to be configured. From the New Relic by organization application page, fill in the following forms: Fill in the configuration form In the left pane, select Configuration and complete the following: Get the authentication domain ID (top of New Relic's authentication domain UI and SCIM bearer token (in authentication domain UI as \"SAML 2.0 endpoint) and input them into the appropriate fields in the OneLogin app. Leave the API Connection disabled until all the configuration described in the following sections is completed. After completing all the configuration, enable the connection. Fill in the rules form Configure the user groups to send to New Relic using rules. OneLogin provides this documentation which describes how to use rules to provision groups for users. Decide what type of groups to send along with your users to New Relic. If your organization is using Active Directory or LDAP, you might choose to use security groups to define your users capabilities at New Relic. Another reasonable group choice is OneLogin role. On the New Relic side, your user's groups define their capabilities. The groups that are sent with users will be mapped to New Relic capability groups. Note that at the moment, there is no way to delete a group from the OneLogin side. This is a known limitation from OneLogin. Removing or changing rules does not delete groups already sent to New Relic. If you wish to no longer use a group, removing all the users from the group will prevent it from being used at New Relic. A rule that only uses actions Here's an example rule configuration does not use any conditions. The conditions are left empty to avoid applying any filtering logic to the users. All users will be sent in this example. If you want to send only a subset of users, you need to specify conditions to select the subset. The actions describe where to retrieve the value for the group name and how to parse the value. In this example, we retrieve the group name from the OneLogin role field. The OneLogin role field only has a single value, but sometimes the source for the group name contains other fields besides group name. In other words, some sources give you a list of fields and values and only one of those fields has the value you want to use. In this case, you can insert a regular expression in with value that matches field to find and extract the value for the group name. This example uses the entire value of the For each field for the group name. Fill in the provisioning form In the left pane, select Provisioning and complete the following: Check Enable provisioning. Under Require admin approval before this action is performed, uncheck these options: Create user Delete user Update user Tip If you do not uncheck these options, SCIM provisioning requests will not be sent until an administrator approves them. Set When users are deleted in OneLogin, or the user's app access is removed, perform the below action to Delete. Set When user accounts are suspended in OneLogin, perform the following action to Suspend. Fill in the Parameters form In the left pane, select Parameters and complete the following: Click Groups field. Check Include in User Provisioning. Click Save. Save your changes After you complete the above forms, click Save. Then, return to the Configuration form and enable the API connection. Step 4. Assign users After New Relic SCIM/SSO application configuration is finished and New Relic side configuration is finished, you can begin to assign users to the application. Assign the New Relic SCIM/SSO application to a user: Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click Administration. From the OneLogin Administration page, choose the Users menu Users item. From the OneLogin Users page, click the user you want to assign the application to. From the user's page, click Applications. From the user's application page, click the plus sign and select the \"New Relic by Organization\" application. Important: Updating users' time zones is important, as charts and other user assets display times. Default is UMT. From the Edit New Relic by Organization login for user page, enter the user's time zone in IANA Time Zone database format (also known as the Olson time zone database format) and click Save. If you're using Roles to define your New Relic capability groups, from the user's application page, click the proper role(s) for the user and then click Save User. Step 5. Downgrade some users to basic When your users are provisioned in New Relic, you're able to see them in the User management UI. Users provisioned via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, you can use one of two options: Use the User management UI to set users to basic. Configure the OneLogin app to send user type. Step 6. Assign access grants Once these steps are completed, you should be able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO for your users, see the SAML instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.73009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 4. Assign <em>users</em>",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "Our <em>automated</em> <em>user</em> <em>management</em> (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides OneLogin-specific details on how to configure the New Relic OneLogin SCIM&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f34228ccbccafb2c606a"
    }
  ],
  "/docs/accounts/accounts/automated-user-management/onelogin-scimsso-application-configuration": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 368.88943,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "New Relic lets you set up <em>automated</em> <em>user</em> <em>management</em> (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of <em>automated</em> <em>user</em> <em>management</em>, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "Okta SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Okta's New Relic app",
        "Step 3. Configure provisioning",
        "Step 4. Assign users and groups",
        "Assignments tab",
        "Push groups tab",
        "Step 5. Manage user type",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO",
        "Additional considerations",
        "Moving users between groups"
      ],
      "title": "Okta SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "7a00399a6ce11aaa2cb52046f994a80f5986c0e4",
      "image": "https://docs.newrelic.com/static/3f3318e1dc8c9049231c207a7b4e5c54/c1b63/okta-add-user-type-to-profile.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration/",
      "published_at": "2021-10-24T23:01:21Z",
      "updated_at": "2021-10-07T19:07:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up Okta's New Relic app Next, set up Okta's New Relic SCIM/SSO application: Go to okta.com/ and sign in with an account that has administrator permissions. From the Okta home page, click on Admin. From the Okta admin Dashboard, choose the Applications page. Click Browse app catalog and search for \"New Relic by organization\" (not \"New Relic by account\") and choose that from the results. From the New Relic by Organization page, click on Add. From the Add New Relic by organization page, check the two Application visibility \"Do not display...\" checkboxes and click on Done. We will make the application visible later after configuration is complete and provisioning has begun. Step 3. Configure provisioning Configure Okta's New Relic SCIM/SSO application to automatically provision your users to New Relic: From the app, click on the Provisioning tab. From the Integration form, click on Configure API integration. Check the Enable API integration checkbox. Take the API token you saved in Step 1 and input it in the Okta New Relic app's API token field. Optional: click on Test API credentials to verify a SCIM connection can be established to New Relic. If a connection can be established, a success message is displayed. If a connection was not established, re-enter the API Token and try the test again. Click Save. Note that the save process does a test of the API credentials. If a connection is not established to New Relic, the save will fail. On the newly displayed To App form, click on Edit. Check the Enable checkbox in the Create users, Update user attributes, and Deactivate users sections. Click Save. Step 4. Assign users and groups Next, you'll assign users in Okta's New Relic application. Assigning users is done using two different tabs in the app. We recommend having your New Relic users selected on the Assignments tab and their associated groups selected on the Push groups tab. Assignments tab In the app, click on the Assignments tab. From the Assignments form, click on Assign. From the pop up menu, click on Assign to groups. From the Assign ... to groups form, click on Assign for the group you wish to assign to the application. Highly recommended: Set your users' time zones in Okta. The time zone affects how date/times for that user are shown in New Relic. Users without a time zone configured will be shown in UTC time in New Relic. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). There are several ways in Okta to assign users' time zone, so consult the Okta docs for more information if needed. Here is one way to do this in the Assignments tab: In the Time zone field, enter the default time zone for members of the group. Click on Save and go back. Repeat the steps to add a group until all desired groups have been assigned to the application. Click Done. Push groups tab In the app, click on the Push groups tab. From the Push groups form, click on Push groups. From the pop up menu, click on Find groups by name. From the Push groups to... form, in the search field enter the first few characters of the name of the group you want to send to New Relic. Leave the Push group memberships immediately checkbox checked. Click on your group in the pop up search results list. In the Match result & push action section, No match found should be displayed, meaning that the group does not yet exist at New Relic. Leave the selector set to Create group and leave the default name for the group. The intent here is to have a group of the same name created at New Relic. If this is the last group you wish to send to New Relic, click on Save. Otherwise, if you have more groups to configure, click on Save & add another and repeat the steps to add a group. When you've added one or more groups, you should be able to see the users you've added by going to the User management UI page. Step 5. Manage user type If your organization is on New Relic One pricing, the count of your full users is a billing factor. To change some of your users to free basic users, you have two choices: Manage user type from New Relic using the User management UI, OR Manage user type from Okta (described below). To manage your users' user type from Okta: Go to the New Relic authentication domain UI and click Enable Manage user type with SCIM. Note that when this is enabled, you can’t manage user type from the New Relic UI and can only manage it from Okta. Go into your Okta instance. The rest of these instructions are done from Okta. Next, you'll configure Okta to be able to send a new attribute nrUserType. Steps: Go to the Profile editor. In the Attributes section, click Add attribute. Set your settings to match the screenshot below (except for the variable name, which is created automatically). The only two fields that must match exactly are External name and External namespace. The value for External namespace must be urn:ietf:params:scim:schemas:extension:newrelic:2.0:User Next, you'll configure your Okta user profile to have this field. Steps: In the Profile editor, go to Users and click the User (default) profile. Add a new New Relic user type attribute to that profile (see Okta user profile instructions). How you set this will depend on your own setup and preferences for defining user type. Note that the expected values for user type are Basic user and Full user. Below is an example with information filled in. In the People section, define the user type for your users. How you do this will depend on your setup and preferences. For example, you may choose to set this manually by setting each user’s user type, or you may use Okta to manage these in bulk. Next, you’ll set up mapping for that attribute. Steps: In the app's Provisioning section, click Unmapped attributes. Go into edit mode for the unmapped New Relic user type attribute. Configure it based on how you want to set the user type. To learn about why you'd set them as basic users or full users, see User type. Learn more about Okta attribute mappings. Step 6. Assign access grants Once these steps are completed, you're able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO, see the SAML instructions. Additional considerations In this section we discuss other important things to know when using the New Relic SCIM/SSO application. This section includes tips to work around potential issues that could cause undesired results when integrating between Okta and New Relic. Moving users between groups When moving a user between groups, you must manually synchronize the old group's membership with New Relic. This is because Okta does not send a SCIM request to remove a user from a group. So, the admin needs to push the old group's membership to New Relic manually to inform New Relic that the user is no longer a member of the old group. Here are the steps to manually synchronize a group's membership: From the New Relic SCIM/SSO application page, click on the Push groups tab. From the Push groups form, open the pick list on the desired group's button under the Push Status column. From the displayed pick list on the button, click Push now. This causes an immediate synchronization of the group's membership with New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.56955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 5. <em>Manage</em> <em>user</em> type",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "Our <em>automated</em> <em>user</em> <em>management</em> (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f5cae7b9d2758b579a0c"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31454,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>User</em> permissions",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " in, select Remember me when logging in. If one of your login options reads &quot;Original <em>account</em>&quot;, that means it&#x27;s a <em>user</em> record on our original <em>user</em> model. For more information, see this Explorers Hub post about multiple <em>accounts</em>. Related docs: <em>User</em> permission factors <em>Account</em> structure Login and password"
      },
      "id": "60bee5c064441f0505d543bb"
    }
  ],
  "/docs/accounts/accounts/automated-user-management/roles-permissions-automated-user-management": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 368.88922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "New Relic lets you set up <em>automated</em> <em>user</em> <em>management</em> (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of <em>automated</em> <em>user</em> <em>management</em>, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "Okta SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Okta's New Relic app",
        "Step 3. Configure provisioning",
        "Step 4. Assign users and groups",
        "Assignments tab",
        "Push groups tab",
        "Step 5. Manage user type",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO",
        "Additional considerations",
        "Moving users between groups"
      ],
      "title": "Okta SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "7a00399a6ce11aaa2cb52046f994a80f5986c0e4",
      "image": "https://docs.newrelic.com/static/3f3318e1dc8c9049231c207a7b4e5c54/c1b63/okta-add-user-type-to-profile.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration/",
      "published_at": "2021-10-24T23:01:21Z",
      "updated_at": "2021-10-07T19:07:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up Okta's New Relic app Next, set up Okta's New Relic SCIM/SSO application: Go to okta.com/ and sign in with an account that has administrator permissions. From the Okta home page, click on Admin. From the Okta admin Dashboard, choose the Applications page. Click Browse app catalog and search for \"New Relic by organization\" (not \"New Relic by account\") and choose that from the results. From the New Relic by Organization page, click on Add. From the Add New Relic by organization page, check the two Application visibility \"Do not display...\" checkboxes and click on Done. We will make the application visible later after configuration is complete and provisioning has begun. Step 3. Configure provisioning Configure Okta's New Relic SCIM/SSO application to automatically provision your users to New Relic: From the app, click on the Provisioning tab. From the Integration form, click on Configure API integration. Check the Enable API integration checkbox. Take the API token you saved in Step 1 and input it in the Okta New Relic app's API token field. Optional: click on Test API credentials to verify a SCIM connection can be established to New Relic. If a connection can be established, a success message is displayed. If a connection was not established, re-enter the API Token and try the test again. Click Save. Note that the save process does a test of the API credentials. If a connection is not established to New Relic, the save will fail. On the newly displayed To App form, click on Edit. Check the Enable checkbox in the Create users, Update user attributes, and Deactivate users sections. Click Save. Step 4. Assign users and groups Next, you'll assign users in Okta's New Relic application. Assigning users is done using two different tabs in the app. We recommend having your New Relic users selected on the Assignments tab and their associated groups selected on the Push groups tab. Assignments tab In the app, click on the Assignments tab. From the Assignments form, click on Assign. From the pop up menu, click on Assign to groups. From the Assign ... to groups form, click on Assign for the group you wish to assign to the application. Highly recommended: Set your users' time zones in Okta. The time zone affects how date/times for that user are shown in New Relic. Users without a time zone configured will be shown in UTC time in New Relic. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). There are several ways in Okta to assign users' time zone, so consult the Okta docs for more information if needed. Here is one way to do this in the Assignments tab: In the Time zone field, enter the default time zone for members of the group. Click on Save and go back. Repeat the steps to add a group until all desired groups have been assigned to the application. Click Done. Push groups tab In the app, click on the Push groups tab. From the Push groups form, click on Push groups. From the pop up menu, click on Find groups by name. From the Push groups to... form, in the search field enter the first few characters of the name of the group you want to send to New Relic. Leave the Push group memberships immediately checkbox checked. Click on your group in the pop up search results list. In the Match result & push action section, No match found should be displayed, meaning that the group does not yet exist at New Relic. Leave the selector set to Create group and leave the default name for the group. The intent here is to have a group of the same name created at New Relic. If this is the last group you wish to send to New Relic, click on Save. Otherwise, if you have more groups to configure, click on Save & add another and repeat the steps to add a group. When you've added one or more groups, you should be able to see the users you've added by going to the User management UI page. Step 5. Manage user type If your organization is on New Relic One pricing, the count of your full users is a billing factor. To change some of your users to free basic users, you have two choices: Manage user type from New Relic using the User management UI, OR Manage user type from Okta (described below). To manage your users' user type from Okta: Go to the New Relic authentication domain UI and click Enable Manage user type with SCIM. Note that when this is enabled, you can’t manage user type from the New Relic UI and can only manage it from Okta. Go into your Okta instance. The rest of these instructions are done from Okta. Next, you'll configure Okta to be able to send a new attribute nrUserType. Steps: Go to the Profile editor. In the Attributes section, click Add attribute. Set your settings to match the screenshot below (except for the variable name, which is created automatically). The only two fields that must match exactly are External name and External namespace. The value for External namespace must be urn:ietf:params:scim:schemas:extension:newrelic:2.0:User Next, you'll configure your Okta user profile to have this field. Steps: In the Profile editor, go to Users and click the User (default) profile. Add a new New Relic user type attribute to that profile (see Okta user profile instructions). How you set this will depend on your own setup and preferences for defining user type. Note that the expected values for user type are Basic user and Full user. Below is an example with information filled in. In the People section, define the user type for your users. How you do this will depend on your setup and preferences. For example, you may choose to set this manually by setting each user’s user type, or you may use Okta to manage these in bulk. Next, you’ll set up mapping for that attribute. Steps: In the app's Provisioning section, click Unmapped attributes. Go into edit mode for the unmapped New Relic user type attribute. Configure it based on how you want to set the user type. To learn about why you'd set them as basic users or full users, see User type. Learn more about Okta attribute mappings. Step 6. Assign access grants Once these steps are completed, you're able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO, see the SAML instructions. Additional considerations In this section we discuss other important things to know when using the New Relic SCIM/SSO application. This section includes tips to work around potential issues that could cause undesired results when integrating between Okta and New Relic. Moving users between groups When moving a user between groups, you must manually synchronize the old group's membership with New Relic. This is because Okta does not send a SCIM request to remove a user from a group. So, the admin needs to push the old group's membership to New Relic manually to inform New Relic that the user is no longer a member of the old group. Here are the steps to manually synchronize a group's membership: From the New Relic SCIM/SSO application page, click on the Push groups tab. From the Push groups form, open the pick list on the desired group's button under the Push Status column. From the displayed pick list on the button, click Push now. This causes an immediate synchronization of the group's membership with New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.56952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 5. <em>Manage</em> <em>user</em> type",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "Our <em>automated</em> <em>user</em> <em>management</em> (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f5cae7b9d2758b579a0c"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>User</em> permissions",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " in, select Remember me when logging in. If one of your login options reads &quot;Original <em>account</em>&quot;, that means it&#x27;s a <em>user</em> record on our original <em>user</em> model. For more information, see this Explorers Hub post about multiple <em>accounts</em>. Related docs: <em>User</em> permission factors <em>Account</em> structure Login and password"
      },
      "id": "60bee5c064441f0505d543bb"
    }
  ],
  "/docs/accounts/accounts/automated-user-management/scim-support-automated-user-management": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 368.88922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "New Relic lets you set up <em>automated</em> <em>user</em> <em>management</em> (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of <em>automated</em> <em>user</em> <em>management</em>, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "Okta SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Okta's New Relic app",
        "Step 3. Configure provisioning",
        "Step 4. Assign users and groups",
        "Assignments tab",
        "Push groups tab",
        "Step 5. Manage user type",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO",
        "Additional considerations",
        "Moving users between groups"
      ],
      "title": "Okta SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "7a00399a6ce11aaa2cb52046f994a80f5986c0e4",
      "image": "https://docs.newrelic.com/static/3f3318e1dc8c9049231c207a7b4e5c54/c1b63/okta-add-user-type-to-profile.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration/",
      "published_at": "2021-10-24T23:01:21Z",
      "updated_at": "2021-10-07T19:07:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up Okta's New Relic app Next, set up Okta's New Relic SCIM/SSO application: Go to okta.com/ and sign in with an account that has administrator permissions. From the Okta home page, click on Admin. From the Okta admin Dashboard, choose the Applications page. Click Browse app catalog and search for \"New Relic by organization\" (not \"New Relic by account\") and choose that from the results. From the New Relic by Organization page, click on Add. From the Add New Relic by organization page, check the two Application visibility \"Do not display...\" checkboxes and click on Done. We will make the application visible later after configuration is complete and provisioning has begun. Step 3. Configure provisioning Configure Okta's New Relic SCIM/SSO application to automatically provision your users to New Relic: From the app, click on the Provisioning tab. From the Integration form, click on Configure API integration. Check the Enable API integration checkbox. Take the API token you saved in Step 1 and input it in the Okta New Relic app's API token field. Optional: click on Test API credentials to verify a SCIM connection can be established to New Relic. If a connection can be established, a success message is displayed. If a connection was not established, re-enter the API Token and try the test again. Click Save. Note that the save process does a test of the API credentials. If a connection is not established to New Relic, the save will fail. On the newly displayed To App form, click on Edit. Check the Enable checkbox in the Create users, Update user attributes, and Deactivate users sections. Click Save. Step 4. Assign users and groups Next, you'll assign users in Okta's New Relic application. Assigning users is done using two different tabs in the app. We recommend having your New Relic users selected on the Assignments tab and their associated groups selected on the Push groups tab. Assignments tab In the app, click on the Assignments tab. From the Assignments form, click on Assign. From the pop up menu, click on Assign to groups. From the Assign ... to groups form, click on Assign for the group you wish to assign to the application. Highly recommended: Set your users' time zones in Okta. The time zone affects how date/times for that user are shown in New Relic. Users without a time zone configured will be shown in UTC time in New Relic. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). There are several ways in Okta to assign users' time zone, so consult the Okta docs for more information if needed. Here is one way to do this in the Assignments tab: In the Time zone field, enter the default time zone for members of the group. Click on Save and go back. Repeat the steps to add a group until all desired groups have been assigned to the application. Click Done. Push groups tab In the app, click on the Push groups tab. From the Push groups form, click on Push groups. From the pop up menu, click on Find groups by name. From the Push groups to... form, in the search field enter the first few characters of the name of the group you want to send to New Relic. Leave the Push group memberships immediately checkbox checked. Click on your group in the pop up search results list. In the Match result & push action section, No match found should be displayed, meaning that the group does not yet exist at New Relic. Leave the selector set to Create group and leave the default name for the group. The intent here is to have a group of the same name created at New Relic. If this is the last group you wish to send to New Relic, click on Save. Otherwise, if you have more groups to configure, click on Save & add another and repeat the steps to add a group. When you've added one or more groups, you should be able to see the users you've added by going to the User management UI page. Step 5. Manage user type If your organization is on New Relic One pricing, the count of your full users is a billing factor. To change some of your users to free basic users, you have two choices: Manage user type from New Relic using the User management UI, OR Manage user type from Okta (described below). To manage your users' user type from Okta: Go to the New Relic authentication domain UI and click Enable Manage user type with SCIM. Note that when this is enabled, you can’t manage user type from the New Relic UI and can only manage it from Okta. Go into your Okta instance. The rest of these instructions are done from Okta. Next, you'll configure Okta to be able to send a new attribute nrUserType. Steps: Go to the Profile editor. In the Attributes section, click Add attribute. Set your settings to match the screenshot below (except for the variable name, which is created automatically). The only two fields that must match exactly are External name and External namespace. The value for External namespace must be urn:ietf:params:scim:schemas:extension:newrelic:2.0:User Next, you'll configure your Okta user profile to have this field. Steps: In the Profile editor, go to Users and click the User (default) profile. Add a new New Relic user type attribute to that profile (see Okta user profile instructions). How you set this will depend on your own setup and preferences for defining user type. Note that the expected values for user type are Basic user and Full user. Below is an example with information filled in. In the People section, define the user type for your users. How you do this will depend on your setup and preferences. For example, you may choose to set this manually by setting each user’s user type, or you may use Okta to manage these in bulk. Next, you’ll set up mapping for that attribute. Steps: In the app's Provisioning section, click Unmapped attributes. Go into edit mode for the unmapped New Relic user type attribute. Configure it based on how you want to set the user type. To learn about why you'd set them as basic users or full users, see User type. Learn more about Okta attribute mappings. Step 6. Assign access grants Once these steps are completed, you're able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO, see the SAML instructions. Additional considerations In this section we discuss other important things to know when using the New Relic SCIM/SSO application. This section includes tips to work around potential issues that could cause undesired results when integrating between Okta and New Relic. Moving users between groups When moving a user between groups, you must manually synchronize the old group's membership with New Relic. This is because Okta does not send a SCIM request to remove a user from a group. So, the admin needs to push the old group's membership to New Relic manually to inform New Relic that the user is no longer a member of the old group. Here are the steps to manually synchronize a group's membership: From the New Relic SCIM/SSO application page, click on the Push groups tab. From the Push groups form, open the pick list on the desired group's button under the Push Status column. From the displayed pick list on the button, click Push now. This causes an immediate synchronization of the group's membership with New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.56952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 5. <em>Manage</em> <em>user</em> type",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "Our <em>automated</em> <em>user</em> <em>management</em> (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f5cae7b9d2758b579a0c"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>User</em> permissions",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " in, select Remember me when logging in. If one of your login options reads &quot;Original <em>account</em>&quot;, that means it&#x27;s a <em>user</em> record on our original <em>user</em> model. For more information, see this Explorers Hub post about multiple <em>accounts</em>. Related docs: <em>User</em> permission factors <em>Account</em> structure Login and password"
      },
      "id": "60bee5c064441f0505d543bb"
    }
  ],
  "/docs/accounts/accounts/automated-user-management/tutorial-manage-users-groups-scim": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 733.0762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to <em>automated</em> <em>user</em> <em>management</em> (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Automated</em> <em>user</em> <em>management</em>",
        "body": "<em>New</em> <em>Relic</em> lets you set up <em>automated</em> <em>user</em> <em>management</em> (AUM), which allows you to import, update, and deactivate your <em>New</em> <em>Relic</em> users from an identity provider, like Azure AD, Okta, or <em>One</em>Login. Benefits Before reading the benefits of <em>automated</em> <em>user</em> <em>management</em>, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic user versus full user)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-10-24T20:29:42Z",
      "updated_at": "2021-10-07T01:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full user) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic user versus full user) Note that there are limits around how many times full users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 592.06085,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to <em>manage</em> <em>users</em>",
        "sections": "Give <em>users</em> access to <em>accounts</em> <em>and</em> roles (access grants)",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> <em>management</em>",
        "body": "For users on our <em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model, we provide various <em>user</em> <em>management</em> features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to <em>user</em> groups Create custom <em>user</em> groups Grant <em>user</em> groups access to specific roles and <em>accounts</em> Important"
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "sections": [
        "Tutorials on user management tasks: access grants, custom roles, and adding users (New Relic One user model)",
        "Requirements",
        "Overview",
        "Add users",
        "View available accounts",
        "Grant access to accounts and roles",
        "Create custom role",
        "Add users to groups"
      ],
      "title": "Tutorials on user management tasks: access grants, custom roles, and adding users (New Relic One user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "b1e5f303b6446f264c9d8c5020871a6990e052fd",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/tutorial-add-new-user-groups-roles-new-relic-one-user-model/",
      "published_at": "2021-10-24T20:31:18Z",
      "updated_at": "2021-10-07T07:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This tutorial will walk you through some common procedures for managing users on the New Relic One user model. Requirements Some notes on requirements: This tutorial is for users on our New Relic One user model. Creating access grants requires Pro or Enterprise edition. For details, see user management requirements. Role requirements: Using the Organization and access UI to manage group access requires Authentication domain manager and Organization manager roles. Using the User management UI to add/edit users requires Authentication domain manager role. Overview Before using this tutorial, we recommend you check out: Understand what an access grant is Videos that show the user management UI in action This tutorial will walk you through how to: Add users View available accounts Grant groups access to roles and accounts Create custom roles Add users to groups Add users Adding users to New Relic is a separate process from creating access grants. In other words, you can do either procedure first. The key point is that if you're trying to give a user access to a role or an account that they don't yet have, they won't have that access until they're both a) in a group and b) that group has the correct access grant (access to a specific role on a specific account). There are two ways to add users: With the user management UI (described below) With automated user management, also known as SCIM provisioning: use of this method means that groups are defined in your identity provider and so you can't edit a user's group from the New Relic UI. To add users from the UI: From the top right of the New Relic UI, click the account dropdown, click Administration, and click User management. If you have multiple authentication domains, choose one from the authentication domain dropdown. Click Add user. Complete the process, including choosing user type and user group. Relevant tips: For how to bulk edit users' user type, see Edit user type. When choosing a group, you can choose either one of our default groups or a custom group that you've defined an access grant for. For more on creating access grants, keep reading. View available accounts When thinking about creating access grants for granting access to different accounts, it can help you to understand what accounts there are in your organization. To view the accounts in your organization: go to the account dropdown, click Administration, click Organizations and access, and then click Accounts. Grant access to accounts and roles Groups are used to group your users and manage what your users are able to do in New Relic: by creating an access grant, you assign a group access to a) a specific role on b) a specific account. By default, organizations on the New Relic One user model have two available groups: Admin and User. These default groups automatically have access to specific standard roles and are assigned to the account in which they were initially added. To view existing access grants: from the account dropdown, click Administration, and then click Organization and access. Even if you haven't created any custom access grants, you will see the default-created grants there that are present for our default groups. This is what you might see when you go to the Organization and access UI and view groups. The default available groups of Admin and User have access grants automatically created that grant users in those groups access to the roles associated with those groups and to the initial account those users were added in. To create a new access grant that gives a user group access to a role and an account: From the Organization and access UI, click Group access. If you don't see that UI, it may be because you're logged in with an original user model record, or because you don't have the ability to manage users. For more on such factors, see Factors affecting access. Choose one of the following: Existing: If there is already a group you want to add an access grant to, you can use this. For example, if you want to gives users in the default Admin or User group access to new accounts, you might choose this and then select the Admin Default or Admin User role. New: If you need to create a new group, choose this. You'll also need to choose the authentication domain that group is inside of (for an explanation of what \"Default\" means, see Default groups. If your organization strategy requires a good amount of restrictions over access to accounts and access to roles, you'll probably need to create a good amount of access grants. Next, under Access grant, you'll choose one of following: Account: Choose this to be able to select from the roles that are account-scoped. These are the roles that have to do with using and configuring our platform features (and not about organization and user management). Organization: Choose this to be able to select from the roles that are organization-scoped. These are the roles that govern organization- and user management. (Note that these users must also already belong to an account-scoped role. This is true for most users but if it's not, you may see a message that the user doesn't belong to an organization.) Select the Role you want to assign. Roles are organization-wide, so regardless of the authentication domain you're in, you have access to our standard roles and any custom roles you've created. For tips on selecting roles, see the tips after these instructions. Select the Account you want to add access to from the dropdown. If you don't see an account that you'd expect to see, this may be for a few reasons. One is that you yourself don't have the proper permissions for that account. Another is that that account is not actually in your organization. For more information, see Factors affecting access. If you are still having problems, talk to your account representative. If you want to continue adding more grants for that same group, select Add another at the bottom before clicking Add access. When you're done, if your users are already in the group you've added the grant to, they should have access within a few minutes (although for EU region New Relic accounts, this can take up to twenty minutes or so). If your users are not yet in that group (which would be true if you just created an access grant with a new group), you'll need to go to the User management UI and add that group to those users. Some tips for using this UI: Note that if a user has the organization-scoped Organization manager and/or Authentication domain manager roles, which is true of users in the default Admin group, those users will always have those capabilities because those are organization-scoped abilities. This means that when you go to add those users to another account, you only have to add an account-scoped role, and not an organization-scoped role. In other words, once the users in a group have those organization-scoped roles, they will always have them in that organization unless removed. When selecting from amongst our standard roles, it's important to understand the difference between All product admin and Standard user. In short, All product admin is more popular a choice because it gives the ability to configure platform features. If you wanted to have your users be able to use platform features but not configure them, you'd choose Standard user. If your users are managed via automated user management, there are some restrictions that may apply. For example, you wouldn't be able to use the User management UI to add users to groups, because groups are managed and imported from your identity provider. If a group has basic users in it, their basic user status overrides any group-related restrictions. Create custom role When creating an access grant, you can use our standard roles, or you can create your own roles with unique sets of capabilities. To view existing roles: from the account dropdown, click Administration, then click Organization and access, and then click Roles. To create a custom role, click Add new custom role. Review the list of available capabilities and decide which ones your custom role needs. For more information about how roles and capabilities work, see Capabilities. Once you're finished creating a custom role, you will probably want to use it in a new access grant. Add users to groups In the user management UI, you can see your users and the groups they've been assigned to. Your users only have access to the access grants associated with the groups they've been added to. To view users and see their groups: from the account dropdown, click Administration, and click User management. If you don’t see that option, review the requirements. Groups reside within the boundaries of an authentication domain. If your organization has more than one authentication domain, the domain switcher in the top left will show which one you’re in. To add a user, click Add user. Complete the prompts in the UI, including choosing the user type and group. Any custom groups you’ve added should be available from the group dropdown. If the custom group you choose has been granted access to a role and an account, once you add the user to that group, that user will now have access. To edit a user’s group or other details: click on the user you want to edit and make changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 576.73303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tutorials on <em>user</em> <em>management</em> tasks: access grants, custom roles, <em>and</em> adding <em>users</em> (<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model)",
        "sections": "Tutorials on <em>user</em> <em>management</em> tasks: access grants, custom roles, <em>and</em> adding <em>users</em> (<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model)",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> <em>management</em>",
        "body": " and so you can&#x27;t edit a <em>user</em>&#x27;s group from the <em>New</em> <em>Relic</em> UI. To add users from the UI: From the top right of the <em>New</em> <em>Relic</em> UI, click the <em>account</em> dropdown, click Administration, and click <em>User</em> <em>management</em>. If you have multiple authentication domains, choose <em>one</em> from the authentication domain dropdown"
      },
      "id": "603e7d67196a671e26a83dc5"
    }
  ],
  "/docs/accounts/accounts/billing/view-or-change-account-tax-information": [
    {
      "sections": [
        "Introduction to account settings",
        "Pricing, billing, and usage UI",
        "Manage users",
        "Add accounts",
        "Other account settings"
      ],
      "title": "Introduction to account settings",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "1dbac104fa7e60637c32a61a80b8b709f6fd84c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-10-19T03:52:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view and edit account-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the account dropdown. Keep reading for tips on how to find different kinds of account settings in the UI. Pricing, billing, and usage UI Note that user permissions may impact your access to some account settings. To find billing-related UI, go to one.newrelic.com and, in the upper right corner, click the account dropdown to access various account settings. Here's what you can find there: Manage your plan: Options for viewing and managing billing-related settings. Manage your data: Options for managing ingest of data, which can be a billing factor. Learn more about managing data. View your usage: View of your billing-related usage. Administration: Options related to billing, usage, and user management (this UI available only for users on our New Relic One user model). Account settings: Options related to subscription and usage, and user management (this UI available only to users on our original user model). Related topics: Pricing details: Original pricing plan | New Relic One pricing Manage data Manage users How you manage users depends on which user model you're on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the account dropdown, click Account settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you're on? See Determine user model. Add accounts Learn more about adding accounts. Other account settings See the account settings docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.20544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>account</em> <em>settings</em>",
        "sections": "Introduction to <em>account</em> <em>settings</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "To view and edit <em>account</em>-related and user-management-related <em>settings</em>, go to one.newrelic.com and in the top right corner, select the <em>account</em> dropdown. Keep reading for tips on how to find different kinds of <em>account</em> <em>settings</em> in the UI. Pricing, <em>billing</em>, and usage UI Note that user permissions may"
      },
      "id": "6043f38a196a679ae4960f5e"
    },
    {
      "sections": [
        "Set or change password",
        "Change your password",
        "Important",
        "Reset password"
      ],
      "title": "Set or change password",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "817d8d17dca7f361429109d8364eff931a1cb392",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-passwords-user-preferences/",
      "published_at": "2021-10-24T20:28:55Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains information on New Relic password requirements. Change your password New Relic account passwords don't expire. However, users can change their own password and other personal account information anytime. Your ability to change your password from the UI may depend on your user and organization level settings. To change your password from the UI: From one.newrelic.com, click the account dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length At least one letter (a-z, A-Z) At least one number (0-9), special character, or space Special characters allowed include ~ ` ! @ # $ % ^ & * ( ) _ - + = { [ } ] : ; \" ' < , > . ? / | \\. Spaces are also allowed. Important In addition to New Relic's requirements, follow your organization's guidelines for password length, use of upper or lower case letters, numbers, and special characters. Reset password If you forgot your own password or need to request a password reset, you can use New Relic's self-service options. Admins can't reset passwords for other users. If you need to reset someone else's password, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Set</em> or change password",
        "sections": "<em>Set</em> or change password",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " and organization level <em>settings</em>. To change your password from the UI: From one.newrelic.com, click the <em>account</em> dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length"
      },
      "id": "603eb55a64441f9f8f4e889c"
    },
    {
      "sections": [
        "Change account or user name",
        "Change user name",
        "Change account name",
        "Important"
      ],
      "title": "Change account or user name",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "328b3ae3afa62555d246baee53ec49add7ad470c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-your-new-relic-account-name/",
      "published_at": "2021-10-24T20:28:56Z",
      "updated_at": "2021-08-26T14:42:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Change user name To change your user name: From the account dropdown, select User preferences. On the right side, click Full name. Change account name Only users on our original user model are able to change their New Relic account name. To do this: From the account dropdown, select Account settings. On the right side, edit the Name field. Important If you're on our New Relic One user model and want to change your account name, contact your account representative or support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.12032,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change <em>account</em> or user name",
        "sections": "Change <em>account</em> or user name",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " <em>settings</em>. On the right side, edit the Name field. Important If you&#x27;re on our New Relic One user model and want to change your <em>account</em> name, contact your <em>account</em> representative or support."
      },
      "id": "6043ce92e7b9d215e55799e4"
    }
  ],
  "/docs/accounts/accounts/roles-permissions/bulk-user-actions-add-delete-or-update-batches-users": [
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.55882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure SAML with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Configure SAML with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up SSO for <em>users</em> on our <em>original</em> <em>user</em> model. For SSO for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic&#x27;s default entity ID"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Overview of data retention (original pricing plan)",
        "Important",
        "Limits on editing and deleting data",
        "Product and API data retention policies",
        "APM",
        "APM data retention policies",
        "Legacy APM data retention policies",
        "Browser",
        "Infrastructure",
        "Tip",
        "Infrastructure downsampling and data retention",
        "Integration compute unit event limits",
        "Insights",
        "Logs",
        "Logs in context data retention",
        "Mobile",
        "Mobile data retention policies",
        "Standard Mobile (legacy) data retention policies",
        "Plugins",
        "Plugins data retention",
        "Legacy Plugins data retention",
        "Synthetics",
        "Synthetics data retention policies",
        "Metric API",
        "Trace API",
        "Data components",
        "Event data: reported by most products",
        "Metric timeslice data: reported by APM, Browser, and Mobile",
        "Aggregate metric timeslice data: reported by APM, Browser, and Mobile",
        "Key metrics: reported by APM, Browser, and Mobile",
        "Trace data: reported by APM, Browser, and Mobile"
      ],
      "title": "Overview of data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "22d5ab9f4d623ead28ee7bb82c118d91804dee22",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-based-pricing/overview-data-retention-components/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-09-14T14:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on our New Relic One pricing plan, see Manage your data. Not sure which you're on? See Overview of pricing plans. If you're on the original product-based pricing plan, you retain your existing subscriptions and data retention values. You manage these existing retention settings from the Data management hub in New Relic One. To manage your retention settings, go to the Data management UI. You'll see your existing retention settings. Adjust retention values by clicking Edit retention. New Relic stores different types of data for different periods of time. The retention period for a type of data will vary depending on the product, the subscription level, and the feature. Limits on editing and deleting data Once telemetry data (events, metrics, logs, traces) is reported to New Relic and available for querying, that data cannot be edited or deleted. This is a purposeful design decision that optimizes New Relic's speed and performance. Data will expire after its data retention ends. If you sent unwanted data or sensitive data to New Relic that must be removed, contact your account representative at New Relic, or get support at support.newrelic.com. Product and API data retention policies Select a New Relic product to see details about its data retention: APM Specific retention policies apply to each APM subscription level, including Lite, Essentials, Pro, and Enterprise. This includes metric timeslice data, key metrics, trace data, and event data. In addition to retention limits, your data is subject to aggregation (averaging) after certain elapsed time periods. For more information, see the aggregate metric data description. APM data retention policies For accounts on our original product-based pricing, APM data retention policies depend on your APM product subscription level. Component Lite Essentials Pro Metric timeslice data 24 hours 3 days 90 days Key metrics none forever forever Distributed tracing and logs in context none none 8 days Other trace data * 1 day 3 days 7 days Event data * * 1 day 3 days 8 days * If you view a transaction trace in the New Relic UI, New Relic stores that trace data for up to one year. * * Learn about how to extend the retention of event data. Legacy APM data retention policies Component Standard Startup Small Business Enterprise Metric timeslice data 7 days 14 days 30 days 90 days Key metrics none none none forever Trace data 7 days 7 days 7 days 7 days Event data none 8 days 8 days 8 days Browser For accounts on our original product-based pricing, Browser data is stored depending on your subscription level: Component Lite Pro Metric data 24 hours 90 days Key metrics 24 hours forever Trace data 7 days 7 days Event data * 1 day 8 days SPA data Unavailable 8 days * Learn about how to extend the retention of event data. Infrastructure For accounts on our original product-based pricing, Infrastructure data retention policies depend on your Infrastructure subscription level and your New Relic Infrastructure compute units pricing model. Data retention rules apply the same whether that data is displayed in the UI or queried. Tip Infrastructure data retention is not governed by your Insights subscription. Infrastructure downsampling and data retention Types of data are stored depending on your subscription level: Component Essentials Pro Infrastructure data 3 months 13 months Host count Host count will stop reflecting a host whose agent is no longer reporting after three minutes. However, host data will be available, subject to other retention criteria. 3 minutes 3 minutes Inventory attributes removed Inventory attributes for a host are retained for 24 hours after the agent stops reporting. 24 hours 24 hours Integration data Not available with Essentials Limit of 2275 integration events per compute unit per month In addition, Infrastructure downsamples your data on the fly, as it's generated. All Infrastructure metric data types (including On-Host Integrations metrics) will display different granularity depending on the age of the data and the size of the time window. The following table illustrates when different downsampled buckets will be used, both in the Infrastructure UI and for queries: Bucket Size Used For Time Windows Covering... Data Retained For... Raw (5, 10 or 15 second) 0 to 59 minutes 7 days 1 minute 60 minutes to 6 hours 30 days 10 minutes 6 hours to 3 days Full account retention period 1 hour 3 days to 14 days Full account retention period 3 hours 14+ days Full account retention period Integration compute unit event limits The 2275 limit on integration events per compute unit per month is a limit on total Infrastructure integration events. It's not a limit of 2275 for each integration's events. Additional details and clarifications about this limit: This limit applies to all events from all integrations (cloud integrations and on-host integrations). The events are all handled the same. Default data received by the Infrastructure agent does not count against the 2275 event per compute unit limit. If you exceed your limit, we do not enforce this limit. If you exceed your limit, we'll review pricing options with you to ensure you get the most cost-effective pricing for your organization's integrations. Insights For accounts on our original product-based pricing, an Insights subscription extends your event data retention. An Insights Pro subscription allows you to customize the length of your event data retention. Logs For accounts on our original product-based pricing, log data can be retained for up to 30 days by New Relic. Shorter retention periods of 8 or 15 days are also available. Logs in context data retention New Relic Logs logs in context data retention policy is based on your current APM product subscription level. For more information, see APM data retention. Mobile For accounts on our original product-based pricing, Mobile data retention policies depend on your New Relic Mobile product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and event data. For information about your subscription-related data usage, see Mobile subscription usage. Mobile data retention policies Component Lite Enterprise Overview page data 24 hours 90 days Crash data and stack traces 24 hours 90 days HTTP requests (except errors) as metric data Unavailable 90 days HTTP request errors as metric data Unavailable 3 days Interaction traces Unavailable 90 days Custom events * Unavailable 1 day Mobile events * 1 day 8 days MobileBreadcrumb events * Unavailable 3 days MobileCrash events * 1 day 90 days MobileHandledException events * Unavailable 3 days MobileJSError events (React Native beta) * Unavailable 3 days MobileRequest events * Unavailable 3 days MobileRequestError events * Unavailable 3 days MobileSession events * 1 day 90 days * Learn how to extend retention of event data. Standard Mobile (legacy) data retention policies Unless otherwise noted, Insights event data is unavailable for Standard subscriptions. Component Standard Overview page data 7 days Crash data and stack traces 7 days HTTP requests (except errors) as metric data 7 days HTTP request errors as metric data 3 days Interaction traces Unavailable MobileCrash events 8 days MobileSession events 8 days Plugins The retention period for historical data depends on the product and subscription level. The following data retention periods exist for New Relic Plugins. Important Plugins is not supported with accounts that host data in the EU region data center. Plugins data retention Component Lite Essentials Pro Enterprise Metric data 24 hours 3 days 90 days 90 days Legacy Plugins data retention Component Standard Startup Small Business Metric data 7 days 14 days 30 days Synthetics For accounts on our original product-based pricing, Synthetics data retention policies depend on your Synthetics product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and Insights events. Tip Synthetics events do not count against an Insights Pro subscription. Your current subscription level appears in the right column of the Account summary page: Go to synthetics.newrelic.com > (account dropdown) > Account settings > Account > Summary. Synthetics data retention policies Component Lite Pro Synthetics monitor data 2 weeks 13 months Event data 2 weeks 13 months Also see the data retention details for APIs, including: Metric API All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Trace API See Trace API general requirements and limits. Data components For accounts on our original product-based pricing, the section below provides an explanation of some types of data components governed by the data retention rules of specific products: Event data: reported by most products See Event data retention for information on the event data type. Metric timeslice data: reported by APM, Browser, and Mobile Metric timeslice data is a specific type of data that is used for most metric charts and reports in APM, mobile, and browser. Important Note that metric timeslice data differs from other metric data types. All metric timeslice data is aggregated, but New Relic deals with fresh data and old data in different ways. Fresh data has specific policies applied to the data to keep granular views of performance as aggregate metrics. As data ages and becomes less useful in a granular state, we summarize that data and only keep key metrics. Aggregate metric timeslice data: reported by APM, Browser, and Mobile Aggregate metric timeslice data summarizes calls to specific methods in your application: how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on your subscription level. Subscription Level Aggregate retention Enterprise Aggregates (averages) to 1-hour periods after 8 days. After 90 days, the permanent metric data continues to be stored in 1-hour periods. This means you cannot obtain data granularity of less than 1 hour after 8 days, and only a subset of metrics are available after 90 days. Pro After 8 days Essentials After 3 days. Legacy Small Business, Startup, and Standard After 3 days. Lite After 2 hours. We retain your most recent data in one-minute increments. We also aggregate permanent metric data to day-size increments after 90 days. When looking at older data in small time windows, you may notice that charts show less detail. As data ages, it is aggregated into larger segments. Key metrics: reported by APM, Browser, and Mobile New Relic retains certain \"key\" metric timeslice data aggregations forever for Enterprise and Pro customers, for any number of applications. New Relic aggregates permanent key metric data to hour-size increments after 90 days. Product Key metrics APM Apdex, for app server Throughput and page views Response time, plus breakdown into tiers or categories on your app's main Overview chart Page load time, plus breakdown into segments Error rate CPU usage Memory usage Browser Apdex, for browser Browser page load time Throughput total. After 90 days, there is no breakout by browser type, and only the combined average value is available for the time range requested. Mobile Crash rate: For iOS and for Android Network throughput Network response time Network error rates Interaction traces Trace data: reported by APM, Browser, and Mobile Depending on the product, New Relic retains different types of trace data: Product Trace data APM Types of trace data: Transaction traces Distributed tracing Slow query samples Error details See APM data retention details. Browser Types of trace data: Session traces Browser traces JavaScript errors* See Browser data retention details. Mobile Types of trace data: App crash stack traces Interaction traces See Mobile data retention details. * JavaScript errors in the stack trace UI are saved as trace data. JS errors are also saved as events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.35728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of data retention (<em>original</em> pricing plan)",
        "sections": "Overview of data retention (<em>original</em> pricing plan)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based pricing. If you&#x27;re on our New Relic One pricing plan, see Manage your data. Not sure which you&#x27;re on? See Overview of pricing plans. If you&#x27;re on the <em>original</em> product-based pricing plan, you retain your existing subscriptions and data"
      },
      "id": "6043f75364441f6967378ec6"
    },
    {
      "sections": [
        "Event data retention (original pricing plan)",
        "Important",
        "Data retention UI",
        "Overview of event data retention",
        "Extend your event retention",
        "Insights Pro",
        "How number of events stored is calculated",
        "Insights Pro event overage example",
        "Disable/enable Transaction and Pageview event reporting",
        "Tip",
        "Flexible data retention",
        "How it works",
        "Manage retention via UI",
        "Glossary",
        "For more help"
      ],
      "title": "Event data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "76d1289aad7de08b355bb8c313f9e7a42a5779d8",
      "image": "https://docs.newrelic.com/static/e53a1e416eb6116545627d3ec880d08e/e9c9b/flex-2.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-data-retention/event-data-retention-original-pricing-plan/",
      "published_at": "2021-10-24T19:51:24Z",
      "updated_at": "2021-08-27T08:49:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original pricing plan, not our New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For organizations on New Relic One pricing, our various New Relic products report a wide range of event data. Different products have different data retention periods, and different ways to extend event data retention. You can customize the length of your event data retention through flexible event retention. Data retention UI For how to find the data retention UI, see Manage data. Overview of event data retention All New Relic product subscriptions come with a certain level of data retention that governs how long different types of data are retained. One type of data governed by data retention rules is event data. Event data is available in some UI charts and tables, and also available for querying via NRQL, our querying language. There are events reported from products by default, and there are custom events: each have their own retention rules, depending on the product and subscription level. Here are some examples of how different product subscriptions can affect event data retention: Free/Lite APM subscription: default-reported events available for 1 day. No custom events available. Pro APM subscription: default-reported events available for 8 days. Custom events available for 1 day (and able to be extended with Insight Pro). To see your subscriptions, go to the Account summary page. Extend your event retention Product Method APM, Browser, and Mobile Event data retention can be extended with a paid subscription to these products (see product data retention). To extend retention of both default-reported events and custom events further, you need an Insights Pro subscription. Infrastructure Event data retention can be extended with a paid Infrastructure subscription. See Infrastructure data retention rules. Synthetics Event data retention can be extended with a paid Synthetics subscription. See Synthetics data retention rules. Custom events Custom events reported by agent APIs or the Event API: Extension requires an Insights Pro subscription. Insights Pro Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. A paid Insights subscription is what governs the extension of event data retention for: Our APM, Browser, Mobile, and Serverless products Custom events that come from an agent API or from the Event API Important Note that having an Insights Pro subscription doesn't require use of the Insights UI (insights.newrelic.com) to query your data: there are other querying options available. To see the data retention governed by your Insights subscription: go to the usage UI and select Insights usage. With an Insights Pro subscription, you can use flexible retention to customize how your event data is retained. This lets you keep only the data you need, for as long as you need it. How number of events stored is calculated This is an explanation of how the number of stored events are calculated by default for an Insights Pro subscription. (Note that with flexible retention, you have more fine-grained control over the retention period.) The events stored is calculated based on 1) total events stored over time (calculated based on the events generated per week) and 2) the weeks of data retention available. This equation can be represented like this: events stored = (events generated per week) * (weeks of retention) Copy An Insights Pro subscription provides a given number of weeks of data retention as well as a given number of events over that retention period. For example: (200M transactions per week) * (4 weeks of retention) = 800M events stored in Insights (16M transactions per week) * (50 weeks of retention) = 800M events stored in Insights For Insights Pro subscriptions, data is purged based on retention window, not volume. It is deleted from the system once it's past the retention window. For example: If your Insights license is for 800 million events with a 4 week retention period, your data would start being purged after it is older than four weeks. Temporary spikes in data exceeding your subscription level will still be recorded, but consistent overage should be solved by upgrading your subscription level or decreasing data collected. For customers without an Insights Pro subscription, New Relic may throttle or downsample events to a limit of not more than than 4,000 events per host per minute. Insights Pro event overage example In this example, you have an Insights Pro subscription with a license for 800 million events over 4 weeks, a rate of 200 million events per week. You have APM Pro, Browser Pro, and Mobile Enterprise. A fifth week of data is added via your subscriptions, bumping you to a total of 1 billion events stored within your plan: If you are using 975 million events, you are not over your retention. If you are using 1.25 billion events, you are over your retention. Disable/enable Transaction and Pageview event reporting Tip Owners or Admins The Insights Data summary UI page is used to see the types of events being reported. You can also use this page to enable and disable the reporting of PageView and Transaction events. To view Data summary: Go to insights.newrelic.com > Manage data. Select the Summary tab. Note: if you disable PageView or Transaction event reporting, this can affect some New Relic UI elements. You may see some empty charts on some UI pages that rely on this data. Go to insights.newrelic.com > Manage data > Summary. From the Summary tab, select Configure data sources. Toggle the appropriate switch on or off, then save. Toggling Transaction on or off will cause reporting agents to restart themselves. For more about configuring event reporting, see Event data retention. Flexible data retention With an Insights Pro subscription, you get access to flexible retention, which lets you define how some types of event data are retained. This lets you keep only the event data you need, for as long as you need it. You can manage your flexible retention through the UI or through our GraphQL API. Requirements to use this feature: An Insights Pro subscription or equivalent trial. Applies only for events governed by an Insights Pro subscription. To use this feature, you must be an account Owner or data retention add-on manager for your account. How it works To understand how standard event data retention works, first read Event data retention. With flexible retention, you specify the data retention for applicable event namespaces across your accounts. This gives you per-event namespace control of your data. The retention that you specify for an event namespace will be shared by all the event types under that namespace. If some namespaces are not relevant to you, you can avoid collecting their event data entirely. Your retention value can’t be lower than the included retention or higher than the default retention. You can control data retention either in our UI or by API. Manage retention via UI You can control data retention either using our GraphQL API or in the UI. To do this with the UI, go to the data retention UI. Your retention changes take effect within 24 hours after updating. Glossary To understand the terms used with flexible retention, see the following: Term Description Event namespace An event's namespace corresponds to one or more event types that share a single data retention value. For more information, see Event namespaces (types). You can also use NerdGraph to get the list of customizable event namespaces. Retention value The number (in days) that specifies how long your event data is stored. Retention rule The event namespace and retention value pair that you specify to override the current retention. Licensed retention Retention period that’s determined in weeks by your Insights Pro subscription contract. Included retention Retention period for which your data is stored but not charged under the Insights Pro subscription. For details, see the data retention details for a specific product. Paid retention Retention period for which your data is stored and is charged under the Insights Pro subscription. By default, your licensed retention determines this value but Flexible retention lets you override it. Default retention Retention period that comes out of the box. This is based on the total of included retention plus licensed retention. For information on managing retention settings with APIs, see the Manage data retention documentation. For more help For details about the data retention of other products or integrations, see that specific documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.64838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Event data retention (<em>original</em> pricing plan)",
        "sections": "Event data retention (<em>original</em> pricing plan)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> pricing plan, not our New Relic One pricing plan. Not sure which you&#x27;re on? See Overview of pricing plans. For organizations on New Relic One pricing, our various New Relic products report a wide range of event data. Different products have"
      },
      "id": "6043f713e7b9d2ccee579a1d"
    }
  ],
  "/docs/accounts/accounts/saml-single-sign/add-users-saml-accounts": [
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.87354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. In the <em>SAML</em> protocol, the entity ID uniquely identifies the service provider (New Relic) to your <em>SAML</em> provider. New Relic&#x27;s default entity ID"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Intro to authentication (SAML SSO) for users on original user model",
        "Original pricing plan",
        "Overview",
        "Requirements",
        "SSO settings UI page",
        "Providers supported by New Relic",
        "SAML information in New Relic account",
        "New Relic SAML requirements"
      ],
      "title": "Intro to authentication (SAML SSO) for users on original user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "80a96fa16d37d34d8f66c5564f2df32b081536ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/saml-service-providers/",
      "published_at": "2021-10-24T22:52:36Z",
      "updated_at": "2021-09-14T10:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. These docs are for setting up SSO for users on our original user model. Single Sign On (SSO) allows a computer user to log in to multiple systems via a single portal. If you are a New Relic account Owner setting up SSO integration for your organization, you must obtain a SAML certificate that identifies the SSO login URL (and possibly logout URL) for your organization. The other types of information required for SSO integration will vary depending on the SAML service provider being used. Requirements Requirements include: These docs apply for managing users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. Access to this feature requires Pro or Enterprise edition. Owner role required SSO settings UI page To find the New Relic SSO settings page: from the account dropdown, click Account settings, then click Security and authentication, then click Single sign on. If you don't see this UI, review the requirements. Providers supported by New Relic For a list of the SAML service providers that New Relic currently supports for SSO integration: From the New Relic title bar, select (account dropdown) > Account settings > Security and authentication > Single sign on. Providers include: Active Directory Federation Services (ADFS) Auth0 Azure AD (Microsoft Azure Active Directory) Okta OneLogin Ping Identity Salesforce Generic support for SSO systems that use SAML 2.0 SAML information in New Relic account To integrate with an SAML provider, the provider will need information from you about your New Relic account. Most of the information you will need is visible on the New Relic SSO settings UI page: Metadata URL: Contains multiple pieces of information in a single XML message SAML version: 2.0 Assertion consumer URL: The endpoint to New Relic SSO (for example, https://rpm.newrelic.com/accounts/ACCOUNTID/sso/saml/finalize) Consumer binding: Transmission method is HTTP-POST NameID format: Email address Attributes: None required Entity ID: Account URL (default of rpm.newrelic.com) New Relic SAML requirements For SAML providers and service providers like New Relic to be able to work together, their processes must align in certain ways. Here are some aspects of how New Relic implements SSO integration. This will be useful if you are verifying that a specific SAML provider will be able to work with New Relic or if you are troubleshooting implementation problems. SSO considerations New Relic functions and preferences Scope of user credentials (IdP) Should be all users. Type of connection Must be both IdP initiated and SP initiated. Expected SAML profile New Relic uses a POST binding for SP-initiated requests. Expected NameID value format Must be email address. Sensitive info exchanged in SAML assertion? No, only the email address is sent. Session management and logout Does your organization use a redirect URL for logout? If not, New Relic can provide a logout landing page. Plan for users who no longer need access Typically manual deletion by the account Owner or Administrator. Clock synchronization Ensure the SAML identity provider clocks are maintained by NTP.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.43967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "sections": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "<em>Original</em> pricing plan This doc is for <em>users</em> on our <em>original</em> <em>user</em> model. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. Single Sign On (<em>SSO</em>) allows a computer <em>user</em> to log"
      },
      "id": "6043f3c4196a674d5f960f88"
    },
    {
      "sections": [
        "Delete the SSO configuration (original user model)",
        "Important",
        "Caution"
      ],
      "title": "Delete the SSO configuration (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "f3e83fa8322e5c639a0163fdec775348030b20be",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/delete-sso-configuration/",
      "published_at": "2021-10-24T22:51:13Z",
      "updated_at": "2021-08-08T23:51:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. For requirements, including which New Relic users this feature applies to, see Requirements. Caution If you delete your SAML SSO integration with New Relic, you cannot restore it. However, you can follow standard procedures to set up your configuration again. For users on our original user model, here's how to delete your SAML SSO configuration completely: Sign in to New Relic by using your SAML SSO login URL. From the New Relic menu bar, select: account dropdown > Account settings > Security and authentication > Single sign-on. Select Delete SAML Configuration. At the confirmation prompt, select OK.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.10666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Delete the <em>SSO</em> configuration (<em>original</em> <em>user</em> model)",
        "sections": "Delete the <em>SSO</em> configuration (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. For requirements, including which New Relic <em>users</em> this feature applies to, see Requirements. Caution If you delete your <em>SAML</em> <em>SSO</em> integration"
      },
      "id": "6043f605e7b9d22e54579a01"
    }
  ],
  "/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts": [
    {
      "sections": [
        "Intro to authentication (SAML SSO) for users on original user model",
        "Original pricing plan",
        "Overview",
        "Requirements",
        "SSO settings UI page",
        "Providers supported by New Relic",
        "SAML information in New Relic account",
        "New Relic SAML requirements"
      ],
      "title": "Intro to authentication (SAML SSO) for users on original user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "80a96fa16d37d34d8f66c5564f2df32b081536ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/saml-service-providers/",
      "published_at": "2021-10-24T22:52:36Z",
      "updated_at": "2021-09-14T10:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. These docs are for setting up SSO for users on our original user model. Single Sign On (SSO) allows a computer user to log in to multiple systems via a single portal. If you are a New Relic account Owner setting up SSO integration for your organization, you must obtain a SAML certificate that identifies the SSO login URL (and possibly logout URL) for your organization. The other types of information required for SSO integration will vary depending on the SAML service provider being used. Requirements Requirements include: These docs apply for managing users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. Access to this feature requires Pro or Enterprise edition. Owner role required SSO settings UI page To find the New Relic SSO settings page: from the account dropdown, click Account settings, then click Security and authentication, then click Single sign on. If you don't see this UI, review the requirements. Providers supported by New Relic For a list of the SAML service providers that New Relic currently supports for SSO integration: From the New Relic title bar, select (account dropdown) > Account settings > Security and authentication > Single sign on. Providers include: Active Directory Federation Services (ADFS) Auth0 Azure AD (Microsoft Azure Active Directory) Okta OneLogin Ping Identity Salesforce Generic support for SSO systems that use SAML 2.0 SAML information in New Relic account To integrate with an SAML provider, the provider will need information from you about your New Relic account. Most of the information you will need is visible on the New Relic SSO settings UI page: Metadata URL: Contains multiple pieces of information in a single XML message SAML version: 2.0 Assertion consumer URL: The endpoint to New Relic SSO (for example, https://rpm.newrelic.com/accounts/ACCOUNTID/sso/saml/finalize) Consumer binding: Transmission method is HTTP-POST NameID format: Email address Attributes: None required Entity ID: Account URL (default of rpm.newrelic.com) New Relic SAML requirements For SAML providers and service providers like New Relic to be able to work together, their processes must align in certain ways. Here are some aspects of how New Relic implements SSO integration. This will be useful if you are verifying that a specific SAML provider will be able to work with New Relic or if you are troubleshooting implementation problems. SSO considerations New Relic functions and preferences Scope of user credentials (IdP) Should be all users. Type of connection Must be both IdP initiated and SP initiated. Expected SAML profile New Relic uses a POST binding for SP-initiated requests. Expected NameID value format Must be email address. Sensitive info exchanged in SAML assertion? No, only the email address is sent. Session management and logout Does your organization use a redirect URL for logout? If not, New Relic can provide a logout landing page. Plan for users who no longer need access Typically manual deletion by the account Owner or Administrator. Clock synchronization Ensure the SAML identity provider clocks are maintained by NTP.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.43967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "sections": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "<em>Original</em> pricing plan This doc is for <em>users</em> on our <em>original</em> <em>user</em> model. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. Single Sign On (<em>SSO</em>) allows a computer <em>user</em> to log"
      },
      "id": "6043f3c4196a674d5f960f88"
    },
    {
      "sections": [
        "Add users to SAML accounts (original user model)",
        "Important",
        "Overview",
        "Requirements",
        "Add and confirm users",
        "Caution",
        "Bypass email confirmation"
      ],
      "title": "Add users to SAML accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1ab1cb53dc639014a77f74442c2a89c37b021cc0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/add-users-saml-accounts/",
      "published_at": "2021-10-24T22:50:23Z",
      "updated_at": "2021-08-26T20:52:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For an overview of SAML and SCIM options, see Introduction to SAML SSO and SCIM. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. As an additional security measure for SAML single sign-on (SSO) accounts, users are not added until they complete the email confirmation that New Relic sends automatically. Users in the pending state (not yet confirmed) won't receive notifications, such as alerts. For accounts without SAML SSO integration, the account Owner and Admins can add new users without requiring confirmation. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Add and confirm users Follow this process to add and confirm users on our original user model that are authenticating via SAML SSO: The account's Owner or an Administrator adds new users: Go to: account dropdown > Account settings > Account > Summary. On SAML-enabled accounts, New Relic flags the users as Pending and sends an email confirmation. (Pending users will not receive notifications associated with their user role, such as alert notifications.) Users select the link in the email to confirm their account, which directs them to the SAML provider's login URL. When users successfully sign into their SAML SSO end point (Auth0, Okta, OneLogin, Ping Identity, Salesforce, etc.), New Relic flags the users as Active. Caution If you disable SAML SSO, New Relic automatically flags all of your Pending users as Active. If you decide to re-enable SAML SSO later, New Relic automatically flags all users except the Owner as Pending, and they will need to confirm their account access by email. Bypass email confirmation Depending on your subscription level, you may have the option to claim the domain names that you own and bypass the SAML SSO confirmation process. When the account Owner or Administrators add new users and their email address has a domain that matches the account's domains, New Relic automatically adds them as Active users. Benefits of identifying domain ownership include: Adds a useful feature to your account. Claims domains as your own. Makes it easier for your employees to get started with New Relic, because they do not need to confirm their account access. Maintains security when adding users outside of your organization. To flag your account as owning one or more domain names, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.4152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For an overview of <em>SAML</em> and SCIM options, see Introduction to <em>SAML</em> <em>SSO</em> and SCIM. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. As an additional security measure"
      },
      "id": "6043f342e7b9d20ca55799fa"
    },
    {
      "sections": [
        "Delete the SSO configuration (original user model)",
        "Important",
        "Caution"
      ],
      "title": "Delete the SSO configuration (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "f3e83fa8322e5c639a0163fdec775348030b20be",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/delete-sso-configuration/",
      "published_at": "2021-10-24T22:51:13Z",
      "updated_at": "2021-08-08T23:51:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. For requirements, including which New Relic users this feature applies to, see Requirements. Caution If you delete your SAML SSO integration with New Relic, you cannot restore it. However, you can follow standard procedures to set up your configuration again. For users on our original user model, here's how to delete your SAML SSO configuration completely: Sign in to New Relic by using your SAML SSO login URL. From the New Relic menu bar, select: account dropdown > Account settings > Security and authentication > Single sign-on. Select Delete SAML Configuration. At the confirmation prompt, select OK.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.10666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Delete the <em>SSO</em> configuration (<em>original</em> <em>user</em> model)",
        "sections": "Delete the <em>SSO</em> configuration (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. For requirements, including which New Relic <em>users</em> this feature applies to, see Requirements. Caution If you delete your <em>SAML</em> <em>SSO</em> integration"
      },
      "id": "6043f605e7b9d22e54579a01"
    }
  ],
  "/docs/accounts/accounts/saml-single-sign/delete-sso-configuration": [
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.87335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. In the <em>SAML</em> protocol, the entity ID uniquely identifies the service provider (New Relic) to your <em>SAML</em> provider. New Relic&#x27;s default entity ID"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Intro to authentication (SAML SSO) for users on original user model",
        "Original pricing plan",
        "Overview",
        "Requirements",
        "SSO settings UI page",
        "Providers supported by New Relic",
        "SAML information in New Relic account",
        "New Relic SAML requirements"
      ],
      "title": "Intro to authentication (SAML SSO) for users on original user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "80a96fa16d37d34d8f66c5564f2df32b081536ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/saml-service-providers/",
      "published_at": "2021-10-24T22:52:36Z",
      "updated_at": "2021-09-14T10:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. These docs are for setting up SSO for users on our original user model. Single Sign On (SSO) allows a computer user to log in to multiple systems via a single portal. If you are a New Relic account Owner setting up SSO integration for your organization, you must obtain a SAML certificate that identifies the SSO login URL (and possibly logout URL) for your organization. The other types of information required for SSO integration will vary depending on the SAML service provider being used. Requirements Requirements include: These docs apply for managing users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. Access to this feature requires Pro or Enterprise edition. Owner role required SSO settings UI page To find the New Relic SSO settings page: from the account dropdown, click Account settings, then click Security and authentication, then click Single sign on. If you don't see this UI, review the requirements. Providers supported by New Relic For a list of the SAML service providers that New Relic currently supports for SSO integration: From the New Relic title bar, select (account dropdown) > Account settings > Security and authentication > Single sign on. Providers include: Active Directory Federation Services (ADFS) Auth0 Azure AD (Microsoft Azure Active Directory) Okta OneLogin Ping Identity Salesforce Generic support for SSO systems that use SAML 2.0 SAML information in New Relic account To integrate with an SAML provider, the provider will need information from you about your New Relic account. Most of the information you will need is visible on the New Relic SSO settings UI page: Metadata URL: Contains multiple pieces of information in a single XML message SAML version: 2.0 Assertion consumer URL: The endpoint to New Relic SSO (for example, https://rpm.newrelic.com/accounts/ACCOUNTID/sso/saml/finalize) Consumer binding: Transmission method is HTTP-POST NameID format: Email address Attributes: None required Entity ID: Account URL (default of rpm.newrelic.com) New Relic SAML requirements For SAML providers and service providers like New Relic to be able to work together, their processes must align in certain ways. Here are some aspects of how New Relic implements SSO integration. This will be useful if you are verifying that a specific SAML provider will be able to work with New Relic or if you are troubleshooting implementation problems. SSO considerations New Relic functions and preferences Scope of user credentials (IdP) Should be all users. Type of connection Must be both IdP initiated and SP initiated. Expected SAML profile New Relic uses a POST binding for SP-initiated requests. Expected NameID value format Must be email address. Sensitive info exchanged in SAML assertion? No, only the email address is sent. Session management and logout Does your organization use a redirect URL for logout? If not, New Relic can provide a logout landing page. Plan for users who no longer need access Typically manual deletion by the account Owner or Administrator. Clock synchronization Ensure the SAML identity provider clocks are maintained by NTP.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.43964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "sections": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "<em>Original</em> pricing plan This doc is for <em>users</em> on our <em>original</em> <em>user</em> model. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. Single Sign On (<em>SSO</em>) allows a computer <em>user</em> to log"
      },
      "id": "6043f3c4196a674d5f960f88"
    },
    {
      "sections": [
        "Add users to SAML accounts (original user model)",
        "Important",
        "Overview",
        "Requirements",
        "Add and confirm users",
        "Caution",
        "Bypass email confirmation"
      ],
      "title": "Add users to SAML accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1ab1cb53dc639014a77f74442c2a89c37b021cc0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/add-users-saml-accounts/",
      "published_at": "2021-10-24T22:50:23Z",
      "updated_at": "2021-08-26T20:52:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For an overview of SAML and SCIM options, see Introduction to SAML SSO and SCIM. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. As an additional security measure for SAML single sign-on (SSO) accounts, users are not added until they complete the email confirmation that New Relic sends automatically. Users in the pending state (not yet confirmed) won't receive notifications, such as alerts. For accounts without SAML SSO integration, the account Owner and Admins can add new users without requiring confirmation. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Add and confirm users Follow this process to add and confirm users on our original user model that are authenticating via SAML SSO: The account's Owner or an Administrator adds new users: Go to: account dropdown > Account settings > Account > Summary. On SAML-enabled accounts, New Relic flags the users as Pending and sends an email confirmation. (Pending users will not receive notifications associated with their user role, such as alert notifications.) Users select the link in the email to confirm their account, which directs them to the SAML provider's login URL. When users successfully sign into their SAML SSO end point (Auth0, Okta, OneLogin, Ping Identity, Salesforce, etc.), New Relic flags the users as Active. Caution If you disable SAML SSO, New Relic automatically flags all of your Pending users as Active. If you decide to re-enable SAML SSO later, New Relic automatically flags all users except the Owner as Pending, and they will need to confirm their account access by email. Bypass email confirmation Depending on your subscription level, you may have the option to claim the domain names that you own and bypass the SAML SSO confirmation process. When the account Owner or Administrators add new users and their email address has a domain that matches the account's domains, New Relic automatically adds them as Active users. Benefits of identifying domain ownership include: Adds a useful feature to your account. Claims domains as your own. Makes it easier for your employees to get started with New Relic, because they do not need to confirm their account access. Maintains security when adding users outside of your organization. To flag your account as owning one or more domain names, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.4152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For an overview of <em>SAML</em> and SCIM options, see Introduction to <em>SAML</em> <em>SSO</em> and SCIM. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. As an additional security measure"
      },
      "id": "6043f342e7b9d20ca55799fa"
    }
  ],
  "/docs/accounts/accounts/saml-single-sign/maintain-sso-settings": [
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.87335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. In the <em>SAML</em> protocol, the entity ID uniquely identifies the service provider (New Relic) to your <em>SAML</em> provider. New Relic&#x27;s default entity ID"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Intro to authentication (SAML SSO) for users on original user model",
        "Original pricing plan",
        "Overview",
        "Requirements",
        "SSO settings UI page",
        "Providers supported by New Relic",
        "SAML information in New Relic account",
        "New Relic SAML requirements"
      ],
      "title": "Intro to authentication (SAML SSO) for users on original user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "80a96fa16d37d34d8f66c5564f2df32b081536ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/saml-service-providers/",
      "published_at": "2021-10-24T22:52:36Z",
      "updated_at": "2021-09-14T10:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. These docs are for setting up SSO for users on our original user model. Single Sign On (SSO) allows a computer user to log in to multiple systems via a single portal. If you are a New Relic account Owner setting up SSO integration for your organization, you must obtain a SAML certificate that identifies the SSO login URL (and possibly logout URL) for your organization. The other types of information required for SSO integration will vary depending on the SAML service provider being used. Requirements Requirements include: These docs apply for managing users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. Access to this feature requires Pro or Enterprise edition. Owner role required SSO settings UI page To find the New Relic SSO settings page: from the account dropdown, click Account settings, then click Security and authentication, then click Single sign on. If you don't see this UI, review the requirements. Providers supported by New Relic For a list of the SAML service providers that New Relic currently supports for SSO integration: From the New Relic title bar, select (account dropdown) > Account settings > Security and authentication > Single sign on. Providers include: Active Directory Federation Services (ADFS) Auth0 Azure AD (Microsoft Azure Active Directory) Okta OneLogin Ping Identity Salesforce Generic support for SSO systems that use SAML 2.0 SAML information in New Relic account To integrate with an SAML provider, the provider will need information from you about your New Relic account. Most of the information you will need is visible on the New Relic SSO settings UI page: Metadata URL: Contains multiple pieces of information in a single XML message SAML version: 2.0 Assertion consumer URL: The endpoint to New Relic SSO (for example, https://rpm.newrelic.com/accounts/ACCOUNTID/sso/saml/finalize) Consumer binding: Transmission method is HTTP-POST NameID format: Email address Attributes: None required Entity ID: Account URL (default of rpm.newrelic.com) New Relic SAML requirements For SAML providers and service providers like New Relic to be able to work together, their processes must align in certain ways. Here are some aspects of how New Relic implements SSO integration. This will be useful if you are verifying that a specific SAML provider will be able to work with New Relic or if you are troubleshooting implementation problems. SSO considerations New Relic functions and preferences Scope of user credentials (IdP) Should be all users. Type of connection Must be both IdP initiated and SP initiated. Expected SAML profile New Relic uses a POST binding for SP-initiated requests. Expected NameID value format Must be email address. Sensitive info exchanged in SAML assertion? No, only the email address is sent. Session management and logout Does your organization use a redirect URL for logout? If not, New Relic can provide a logout landing page. Plan for users who no longer need access Typically manual deletion by the account Owner or Administrator. Clock synchronization Ensure the SAML identity provider clocks are maintained by NTP.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.43964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "sections": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "<em>Original</em> pricing plan This doc is for <em>users</em> on our <em>original</em> <em>user</em> model. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. Single Sign On (<em>SSO</em>) allows a computer <em>user</em> to log"
      },
      "id": "6043f3c4196a674d5f960f88"
    },
    {
      "sections": [
        "Add users to SAML accounts (original user model)",
        "Important",
        "Overview",
        "Requirements",
        "Add and confirm users",
        "Caution",
        "Bypass email confirmation"
      ],
      "title": "Add users to SAML accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1ab1cb53dc639014a77f74442c2a89c37b021cc0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/add-users-saml-accounts/",
      "published_at": "2021-10-24T22:50:23Z",
      "updated_at": "2021-08-26T20:52:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For an overview of SAML and SCIM options, see Introduction to SAML SSO and SCIM. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. As an additional security measure for SAML single sign-on (SSO) accounts, users are not added until they complete the email confirmation that New Relic sends automatically. Users in the pending state (not yet confirmed) won't receive notifications, such as alerts. For accounts without SAML SSO integration, the account Owner and Admins can add new users without requiring confirmation. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Add and confirm users Follow this process to add and confirm users on our original user model that are authenticating via SAML SSO: The account's Owner or an Administrator adds new users: Go to: account dropdown > Account settings > Account > Summary. On SAML-enabled accounts, New Relic flags the users as Pending and sends an email confirmation. (Pending users will not receive notifications associated with their user role, such as alert notifications.) Users select the link in the email to confirm their account, which directs them to the SAML provider's login URL. When users successfully sign into their SAML SSO end point (Auth0, Okta, OneLogin, Ping Identity, Salesforce, etc.), New Relic flags the users as Active. Caution If you disable SAML SSO, New Relic automatically flags all of your Pending users as Active. If you decide to re-enable SAML SSO later, New Relic automatically flags all users except the Owner as Pending, and they will need to confirm their account access by email. Bypass email confirmation Depending on your subscription level, you may have the option to claim the domain names that you own and bypass the SAML SSO confirmation process. When the account Owner or Administrators add new users and their email address has a domain that matches the account's domains, New Relic automatically adds them as Active users. Benefits of identifying domain ownership include: Adds a useful feature to your account. Claims domains as your own. Makes it easier for your employees to get started with New Relic, because they do not need to confirm their account access. Maintains security when adding users outside of your organization. To flag your account as owning one or more domain names, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.4152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For an overview of <em>SAML</em> and SCIM options, see Introduction to <em>SAML</em> <em>SSO</em> and SCIM. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. As an additional security measure"
      },
      "id": "6043f342e7b9d20ca55799fa"
    }
  ],
  "/docs/accounts/accounts/saml-single-sign/new-relic-partners-saml-sso": [
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.87317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. In the <em>SAML</em> protocol, the entity ID uniquely identifies the service provider (New Relic) to your <em>SAML</em> provider. New Relic&#x27;s default entity ID"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Intro to authentication (SAML SSO) for users on original user model",
        "Original pricing plan",
        "Overview",
        "Requirements",
        "SSO settings UI page",
        "Providers supported by New Relic",
        "SAML information in New Relic account",
        "New Relic SAML requirements"
      ],
      "title": "Intro to authentication (SAML SSO) for users on original user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "80a96fa16d37d34d8f66c5564f2df32b081536ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/saml-service-providers/",
      "published_at": "2021-10-24T22:52:36Z",
      "updated_at": "2021-09-14T10:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. These docs are for setting up SSO for users on our original user model. Single Sign On (SSO) allows a computer user to log in to multiple systems via a single portal. If you are a New Relic account Owner setting up SSO integration for your organization, you must obtain a SAML certificate that identifies the SSO login URL (and possibly logout URL) for your organization. The other types of information required for SSO integration will vary depending on the SAML service provider being used. Requirements Requirements include: These docs apply for managing users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. Access to this feature requires Pro or Enterprise edition. Owner role required SSO settings UI page To find the New Relic SSO settings page: from the account dropdown, click Account settings, then click Security and authentication, then click Single sign on. If you don't see this UI, review the requirements. Providers supported by New Relic For a list of the SAML service providers that New Relic currently supports for SSO integration: From the New Relic title bar, select (account dropdown) > Account settings > Security and authentication > Single sign on. Providers include: Active Directory Federation Services (ADFS) Auth0 Azure AD (Microsoft Azure Active Directory) Okta OneLogin Ping Identity Salesforce Generic support for SSO systems that use SAML 2.0 SAML information in New Relic account To integrate with an SAML provider, the provider will need information from you about your New Relic account. Most of the information you will need is visible on the New Relic SSO settings UI page: Metadata URL: Contains multiple pieces of information in a single XML message SAML version: 2.0 Assertion consumer URL: The endpoint to New Relic SSO (for example, https://rpm.newrelic.com/accounts/ACCOUNTID/sso/saml/finalize) Consumer binding: Transmission method is HTTP-POST NameID format: Email address Attributes: None required Entity ID: Account URL (default of rpm.newrelic.com) New Relic SAML requirements For SAML providers and service providers like New Relic to be able to work together, their processes must align in certain ways. Here are some aspects of how New Relic implements SSO integration. This will be useful if you are verifying that a specific SAML provider will be able to work with New Relic or if you are troubleshooting implementation problems. SSO considerations New Relic functions and preferences Scope of user credentials (IdP) Should be all users. Type of connection Must be both IdP initiated and SP initiated. Expected SAML profile New Relic uses a POST binding for SP-initiated requests. Expected NameID value format Must be email address. Sensitive info exchanged in SAML assertion? No, only the email address is sent. Session management and logout Does your organization use a redirect URL for logout? If not, New Relic can provide a logout landing page. Plan for users who no longer need access Typically manual deletion by the account Owner or Administrator. Clock synchronization Ensure the SAML identity provider clocks are maintained by NTP.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.43964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "sections": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "<em>Original</em> pricing plan This doc is for <em>users</em> on our <em>original</em> <em>user</em> model. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. Single Sign On (<em>SSO</em>) allows a computer <em>user</em> to log"
      },
      "id": "6043f3c4196a674d5f960f88"
    },
    {
      "sections": [
        "Add users to SAML accounts (original user model)",
        "Important",
        "Overview",
        "Requirements",
        "Add and confirm users",
        "Caution",
        "Bypass email confirmation"
      ],
      "title": "Add users to SAML accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1ab1cb53dc639014a77f74442c2a89c37b021cc0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/add-users-saml-accounts/",
      "published_at": "2021-10-24T22:50:23Z",
      "updated_at": "2021-08-26T20:52:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For an overview of SAML and SCIM options, see Introduction to SAML SSO and SCIM. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. As an additional security measure for SAML single sign-on (SSO) accounts, users are not added until they complete the email confirmation that New Relic sends automatically. Users in the pending state (not yet confirmed) won't receive notifications, such as alerts. For accounts without SAML SSO integration, the account Owner and Admins can add new users without requiring confirmation. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Add and confirm users Follow this process to add and confirm users on our original user model that are authenticating via SAML SSO: The account's Owner or an Administrator adds new users: Go to: account dropdown > Account settings > Account > Summary. On SAML-enabled accounts, New Relic flags the users as Pending and sends an email confirmation. (Pending users will not receive notifications associated with their user role, such as alert notifications.) Users select the link in the email to confirm their account, which directs them to the SAML provider's login URL. When users successfully sign into their SAML SSO end point (Auth0, Okta, OneLogin, Ping Identity, Salesforce, etc.), New Relic flags the users as Active. Caution If you disable SAML SSO, New Relic automatically flags all of your Pending users as Active. If you decide to re-enable SAML SSO later, New Relic automatically flags all users except the Owner as Pending, and they will need to confirm their account access by email. Bypass email confirmation Depending on your subscription level, you may have the option to claim the domain names that you own and bypass the SAML SSO confirmation process. When the account Owner or Administrators add new users and their email address has a domain that matches the account's domains, New Relic automatically adds them as Active users. Benefits of identifying domain ownership include: Adds a useful feature to your account. Claims domains as your own. Makes it easier for your employees to get started with New Relic, because they do not need to confirm their account access. Maintains security when adding users outside of your organization. To flag your account as owning one or more domain names, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.4152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For an overview of <em>SAML</em> and SCIM options, see Introduction to <em>SAML</em> <em>SSO</em> and SCIM. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. As an additional security measure"
      },
      "id": "6043f342e7b9d20ca55799fa"
    }
  ],
  "/docs/accounts/accounts/saml-single-sign/saml-service-providers": [
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.87317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. In the <em>SAML</em> protocol, the entity ID uniquely identifies the service provider (New Relic) to your <em>SAML</em> provider. New Relic&#x27;s default entity ID"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Add users to SAML accounts (original user model)",
        "Important",
        "Overview",
        "Requirements",
        "Add and confirm users",
        "Caution",
        "Bypass email confirmation"
      ],
      "title": "Add users to SAML accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1ab1cb53dc639014a77f74442c2a89c37b021cc0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/add-users-saml-accounts/",
      "published_at": "2021-10-24T22:50:23Z",
      "updated_at": "2021-08-26T20:52:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For an overview of SAML and SCIM options, see Introduction to SAML SSO and SCIM. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. As an additional security measure for SAML single sign-on (SSO) accounts, users are not added until they complete the email confirmation that New Relic sends automatically. Users in the pending state (not yet confirmed) won't receive notifications, such as alerts. For accounts without SAML SSO integration, the account Owner and Admins can add new users without requiring confirmation. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Add and confirm users Follow this process to add and confirm users on our original user model that are authenticating via SAML SSO: The account's Owner or an Administrator adds new users: Go to: account dropdown > Account settings > Account > Summary. On SAML-enabled accounts, New Relic flags the users as Pending and sends an email confirmation. (Pending users will not receive notifications associated with their user role, such as alert notifications.) Users select the link in the email to confirm their account, which directs them to the SAML provider's login URL. When users successfully sign into their SAML SSO end point (Auth0, Okta, OneLogin, Ping Identity, Salesforce, etc.), New Relic flags the users as Active. Caution If you disable SAML SSO, New Relic automatically flags all of your Pending users as Active. If you decide to re-enable SAML SSO later, New Relic automatically flags all users except the Owner as Pending, and they will need to confirm their account access by email. Bypass email confirmation Depending on your subscription level, you may have the option to claim the domain names that you own and bypass the SAML SSO confirmation process. When the account Owner or Administrators add new users and their email address has a domain that matches the account's domains, New Relic automatically adds them as Active users. Benefits of identifying domain ownership include: Adds a useful feature to your account. Claims domains as your own. Makes it easier for your employees to get started with New Relic, because they do not need to confirm their account access. Maintains security when adding users outside of your organization. To flag your account as owning one or more domain names, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.4152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For an overview of <em>SAML</em> and SCIM options, see Introduction to <em>SAML</em> <em>SSO</em> and SCIM. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. As an additional security measure"
      },
      "id": "6043f342e7b9d20ca55799fa"
    },
    {
      "sections": [
        "Delete the SSO configuration (original user model)",
        "Important",
        "Caution"
      ],
      "title": "Delete the SSO configuration (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "f3e83fa8322e5c639a0163fdec775348030b20be",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/delete-sso-configuration/",
      "published_at": "2021-10-24T22:51:13Z",
      "updated_at": "2021-08-08T23:51:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. For requirements, including which New Relic users this feature applies to, see Requirements. Caution If you delete your SAML SSO integration with New Relic, you cannot restore it. However, you can follow standard procedures to set up your configuration again. For users on our original user model, here's how to delete your SAML SSO configuration completely: Sign in to New Relic by using your SAML SSO login URL. From the New Relic menu bar, select: account dropdown > Account settings > Security and authentication > Single sign-on. Select Delete SAML Configuration. At the confirmation prompt, select OK.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.10664,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Delete the <em>SSO</em> configuration (<em>original</em> <em>user</em> model)",
        "sections": "Delete the <em>SSO</em> configuration (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. For requirements, including which New Relic <em>users</em> this feature applies to, see Requirements. Caution If you delete your <em>SAML</em> <em>SSO</em> integration"
      },
      "id": "6043f605e7b9d22e54579a01"
    }
  ],
  "/docs/accounts/accounts/saml-single-sign/set-sso": [
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.87317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Configure <em>SAML</em> with multiple <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For <em>SSO</em> for <em>users</em> on New Relic One <em>user</em> model, see Authentication domains. In the <em>SAML</em> protocol, the entity ID uniquely identifies the service provider (New Relic) to your <em>SAML</em> provider. New Relic&#x27;s default entity ID"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Intro to authentication (SAML SSO) for users on original user model",
        "Original pricing plan",
        "Overview",
        "Requirements",
        "SSO settings UI page",
        "Providers supported by New Relic",
        "SAML information in New Relic account",
        "New Relic SAML requirements"
      ],
      "title": "Intro to authentication (SAML SSO) for users on original user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "80a96fa16d37d34d8f66c5564f2df32b081536ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/saml-service-providers/",
      "published_at": "2021-10-24T22:52:36Z",
      "updated_at": "2021-09-14T10:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. These docs are for setting up SSO for users on our original user model. Single Sign On (SSO) allows a computer user to log in to multiple systems via a single portal. If you are a New Relic account Owner setting up SSO integration for your organization, you must obtain a SAML certificate that identifies the SSO login URL (and possibly logout URL) for your organization. The other types of information required for SSO integration will vary depending on the SAML service provider being used. Requirements Requirements include: These docs apply for managing users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. Access to this feature requires Pro or Enterprise edition. Owner role required SSO settings UI page To find the New Relic SSO settings page: from the account dropdown, click Account settings, then click Security and authentication, then click Single sign on. If you don't see this UI, review the requirements. Providers supported by New Relic For a list of the SAML service providers that New Relic currently supports for SSO integration: From the New Relic title bar, select (account dropdown) > Account settings > Security and authentication > Single sign on. Providers include: Active Directory Federation Services (ADFS) Auth0 Azure AD (Microsoft Azure Active Directory) Okta OneLogin Ping Identity Salesforce Generic support for SSO systems that use SAML 2.0 SAML information in New Relic account To integrate with an SAML provider, the provider will need information from you about your New Relic account. Most of the information you will need is visible on the New Relic SSO settings UI page: Metadata URL: Contains multiple pieces of information in a single XML message SAML version: 2.0 Assertion consumer URL: The endpoint to New Relic SSO (for example, https://rpm.newrelic.com/accounts/ACCOUNTID/sso/saml/finalize) Consumer binding: Transmission method is HTTP-POST NameID format: Email address Attributes: None required Entity ID: Account URL (default of rpm.newrelic.com) New Relic SAML requirements For SAML providers and service providers like New Relic to be able to work together, their processes must align in certain ways. Here are some aspects of how New Relic implements SSO integration. This will be useful if you are verifying that a specific SAML provider will be able to work with New Relic or if you are troubleshooting implementation problems. SSO considerations New Relic functions and preferences Scope of user credentials (IdP) Should be all users. Type of connection Must be both IdP initiated and SP initiated. Expected SAML profile New Relic uses a POST binding for SP-initiated requests. Expected NameID value format Must be email address. Sensitive info exchanged in SAML assertion? No, only the email address is sent. Session management and logout Does your organization use a redirect URL for logout? If not, New Relic can provide a logout landing page. Plan for users who no longer need access Typically manual deletion by the account Owner or Administrator. Clock synchronization Ensure the SAML identity provider clocks are maintained by NTP.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.43964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "sections": "Intro to authentication (<em>SAML</em> <em>SSO</em>) for <em>users</em> on <em>original</em> <em>user</em> model",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "<em>Original</em> pricing plan This doc is for <em>users</em> on our <em>original</em> <em>user</em> model. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. Single Sign On (<em>SSO</em>) allows a computer <em>user</em> to log"
      },
      "id": "6043f3c4196a674d5f960f88"
    },
    {
      "sections": [
        "Add users to SAML accounts (original user model)",
        "Important",
        "Overview",
        "Requirements",
        "Add and confirm users",
        "Caution",
        "Bypass email confirmation"
      ],
      "title": "Add users to SAML accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1ab1cb53dc639014a77f74442c2a89c37b021cc0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/add-users-saml-accounts/",
      "published_at": "2021-10-24T22:50:23Z",
      "updated_at": "2021-08-26T20:52:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For an overview of SAML and SCIM options, see Introduction to SAML SSO and SCIM. Overview For an overview of our SAML SSO and SCIM docs, first read Introduction to SAML SSO and SCIM. As an additional security measure for SAML single sign-on (SSO) accounts, users are not added until they complete the email confirmation that New Relic sends automatically. Users in the pending state (not yet confirmed) won't receive notifications, such as alerts. For accounts without SAML SSO integration, the account Owner and Admins can add new users without requiring confirmation. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Add and confirm users Follow this process to add and confirm users on our original user model that are authenticating via SAML SSO: The account's Owner or an Administrator adds new users: Go to: account dropdown > Account settings > Account > Summary. On SAML-enabled accounts, New Relic flags the users as Pending and sends an email confirmation. (Pending users will not receive notifications associated with their user role, such as alert notifications.) Users select the link in the email to confirm their account, which directs them to the SAML provider's login URL. When users successfully sign into their SAML SSO end point (Auth0, Okta, OneLogin, Ping Identity, Salesforce, etc.), New Relic flags the users as Active. Caution If you disable SAML SSO, New Relic automatically flags all of your Pending users as Active. If you decide to re-enable SAML SSO later, New Relic automatically flags all users except the Owner as Pending, and they will need to confirm their account access by email. Bypass email confirmation Depending on your subscription level, you may have the option to claim the domain names that you own and bypass the SAML SSO confirmation process. When the account Owner or Administrators add new users and their email address has a domain that matches the account's domains, New Relic automatically adds them as Active users. Benefits of identifying domain ownership include: Adds a useful feature to your account. Claims domains as your own. Makes it easier for your employees to get started with New Relic, because they do not need to confirm their account access. Maintains security when adding users outside of your organization. To flag your account as owning one or more domain names, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.4152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "sections": "Add <em>users</em> to <em>SAML</em> <em>accounts</em> (<em>original</em> <em>user</em> model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important These docs are for setting up <em>SSO</em> for <em>users</em> on our <em>original</em> <em>user</em> model. For an overview of <em>SAML</em> and SCIM options, see Introduction to <em>SAML</em> <em>SSO</em> and SCIM. Overview For an overview of our <em>SAML</em> <em>SSO</em> and SCIM docs, first read Introduction to <em>SAML</em> <em>SSO</em> and SCIM. As an additional security measure"
      },
      "id": "6043f342e7b9d20ca55799fa"
    }
  ],
  "/docs/accounts/accounts/subscription-pricing/eligibility-guidelines-new-relic-nonprofit-program": [
    {
      "sections": [
        "Introduction to account settings",
        "Pricing, billing, and usage UI",
        "Manage users",
        "Add accounts",
        "Other account settings"
      ],
      "title": "Introduction to account settings",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "1dbac104fa7e60637c32a61a80b8b709f6fd84c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-10-19T03:52:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view and edit account-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the account dropdown. Keep reading for tips on how to find different kinds of account settings in the UI. Pricing, billing, and usage UI Note that user permissions may impact your access to some account settings. To find billing-related UI, go to one.newrelic.com and, in the upper right corner, click the account dropdown to access various account settings. Here's what you can find there: Manage your plan: Options for viewing and managing billing-related settings. Manage your data: Options for managing ingest of data, which can be a billing factor. Learn more about managing data. View your usage: View of your billing-related usage. Administration: Options related to billing, usage, and user management (this UI available only for users on our New Relic One user model). Account settings: Options related to subscription and usage, and user management (this UI available only to users on our original user model). Related topics: Pricing details: Original pricing plan | New Relic One pricing Manage data Manage users How you manage users depends on which user model you're on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the account dropdown, click Account settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you're on? See Determine user model. Add accounts Learn more about adding accounts. Other account settings See the account settings docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.20508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>account</em> <em>settings</em>",
        "sections": "Introduction to <em>account</em> <em>settings</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "To view and edit <em>account</em>-related and user-management-related <em>settings</em>, go to one.newrelic.com and in the top right corner, select the <em>account</em> dropdown. Keep reading for tips on how to find different kinds of <em>account</em> <em>settings</em> in the UI. Pricing, <em>billing</em>, and usage UI Note that user permissions may"
      },
      "id": "6043f38a196a679ae4960f5e"
    },
    {
      "sections": [
        "Set or change password",
        "Change your password",
        "Important",
        "Reset password"
      ],
      "title": "Set or change password",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "817d8d17dca7f361429109d8364eff931a1cb392",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-passwords-user-preferences/",
      "published_at": "2021-10-24T20:28:55Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains information on New Relic password requirements. Change your password New Relic account passwords don't expire. However, users can change their own password and other personal account information anytime. Your ability to change your password from the UI may depend on your user and organization level settings. To change your password from the UI: From one.newrelic.com, click the account dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length At least one letter (a-z, A-Z) At least one number (0-9), special character, or space Special characters allowed include ~ ` ! @ # $ % ^ & * ( ) _ - + = { [ } ] : ; \" ' < , > . ? / | \\. Spaces are also allowed. Important In addition to New Relic's requirements, follow your organization's guidelines for password length, use of upper or lower case letters, numbers, and special characters. Reset password If you forgot your own password or need to request a password reset, you can use New Relic's self-service options. Admins can't reset passwords for other users. If you need to reset someone else's password, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51773,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Set</em> or change password",
        "sections": "<em>Set</em> or change password",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " and organization level <em>settings</em>. To change your password from the UI: From one.newrelic.com, click the <em>account</em> dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length"
      },
      "id": "603eb55a64441f9f8f4e889c"
    },
    {
      "sections": [
        "Change account or user name",
        "Change user name",
        "Change account name",
        "Important"
      ],
      "title": "Change account or user name",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "328b3ae3afa62555d246baee53ec49add7ad470c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-your-new-relic-account-name/",
      "published_at": "2021-10-24T20:28:56Z",
      "updated_at": "2021-08-26T14:42:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Change user name To change your user name: From the account dropdown, select User preferences. On the right side, click Full name. Change account name Only users on our original user model are able to change their New Relic account name. To do this: From the account dropdown, select Account settings. On the right side, edit the Name field. Important If you're on our New Relic One user model and want to change your account name, contact your account representative or support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.1203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change <em>account</em> or user name",
        "sections": "Change <em>account</em> or user name",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " <em>settings</em>. On the right side, edit the Name field. Important If you&#x27;re on our New Relic One user model and want to change your <em>account</em> name, contact your <em>account</em> representative or support."
      },
      "id": "6043ce92e7b9d215e55799e4"
    }
  ],
  "/docs/accounts/accounts-billing/account-setup/create-your-new-relic-account": [
    {
      "image": "https://docs.newrelic.com/static/d2a9c929c7541b67b6fe4c87844fc01b/ae694/prometheus_grafana_dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2020/08/create-grafana-dashboards-prometheus-data-stored-new-relic/",
      "sections": [
        "Create Grafana dashboards with Prometheus data stored in New Relic",
        "Step 1: Get data flowing into New Relic with the Prometheus remote write integration",
        "Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic"
      ],
      "published_at": "2021-10-25T01:03:57Z",
      "title": "Create Grafana dashboards with Prometheus data stored in New Relic",
      "updated_at": "2021-10-19T05:58:32Z",
      "type": "docs",
      "external_id": "da09ab47a2ac806ad3ed1fa67e3a02dd54394383",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’ve teamed up with Grafana Labs so you can use our platform as a data source for Prometheus metrics and see them in your existing dashboards, seamlessly tapping into the reliability, scale, and security provided by New Relic. Follow the steps below or use this more detailed walkthrough to send Prometheus data to New Relic, so that Grafana can populate your existing Prometheus-specific dashboards with that data. This process requires Prometheus version 2.15.0 or higher and Grafana version 6.7.0 or higher. You’ll also need to sign up for New Relic. Here's an example of how these Grafana dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to Instrument Everything – US or Instrument Everything – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get your remote_write URL. For more information on how to set up the Prometheus remote write integration, check out our docs. Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic For more information on how to configure New Relic as a Prometheus data source for Grafana, check out our docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 849.37164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create Grafana dashboards with Prometheus data stored in <em>New</em> <em>Relic</em>",
        "sections": "Create Grafana dashboards with Prometheus data stored in <em>New</em> <em>Relic</em>",
        "body": " Prometheus data to <em>New</em> <em>Relic</em>, so that Grafana can populate your existing Prometheus-specific dashboards with that data. This process requires Prometheus version 2.15.0 or higher and Grafana version 6.7.0 or higher. You’ll also need to <em>sign</em> <em>up</em> for <em>New</em> <em>Relic</em>. Here&#x27;s an example of how these Grafana"
      },
      "id": "60445821e7b9d23b585799e4"
    },
    {
      "sections": [
        "Introduction to New Relic for Node.js",
        "Why it matters",
        "Installation",
        "Extend your instrumentation",
        "Troubleshoot your installation",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Node.js",
      "type": "docs",
      "tags": [
        "Agents",
        "Nodejs agent",
        "Getting started"
      ],
      "external_id": "ed1db81e3ecf2a097db43baa318c847ec2e1ad7d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/nodejs-agent/getting-started/introduction-new-relic-nodejs/",
      "published_at": "2021-10-25T15:53:28Z",
      "updated_at": "2021-10-23T21:37:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Pinpoint and solve issues down to the line of code with Node.js monitoring from New Relic. With features like service maps and error analytics, our Node.js agent helps you get the full picture of your app environment. Why it matters Many Node application requests are based on raw URLs. Our solution is different. New Relic for Node.js assumes it can group requests to your application into transactions instead of HTTP requests. Transactions are defined by giving one or more request paths a name. These names are used to: Visualize where your app is spending its time (in transaction breakdowns). Identify slow requests. Group metrics. Show you which portions of your application are suffering from slow database performance. Installation To install our agent, you need to sign up for New Relic first. Once you're logged in, follow the instructions or use our launcher to get data flowing in. Review the system requirements. Read the install docs. Go directly to the New Relic UI to add Node.js data. Extend your instrumentation After installing the Node.js agent, extend your instrumentation: Extend your instrumentation Comments Customization Implement Node.js custom instrumentation. Collect custom metrics via an API call. Use our Node.js agent API to control, customize, or extend the agent's functionality. Open source telemetry To create your own integrations, use our Node Telemetry SDK. To gain visibility into your GraphQL payloads, use our Apollo Server plugin. Traces Enable distributed tracing. VM measurements Collect key metric timeslice data from the Node.js virtual machine. View detailed VM statistics in the New Relic UI. End-user activity Integrate the Node.js agent with browser monitoring. Gain visibility into user activity with browser monitoring's page load timing process. Troubleshoot your installation If you encounter issues with your Node.js agent, see our troubleshooting information: Large memory usage: If you've installed the Node.js agent and your memory usage has increased, check out these possible solutions. Troubleshooting your Node.js installation: Try these steps if you don't see any data, cannot log files, or encounter other installation problems with the Node.js agent. Troubleshooting browser instrumentation: If you encounter problems with browser data, see these additional tips for Node.js. You can also view all troubleshooting docs. If you need additional assistance, get support at support.newrelic.com. Check the source code Our Node.js agent is open source software. You can browse the source code and send improvements, or create your own fork and build it. For more information, see the node-newrelic README on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 742.1117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>for</em> Node.js",
        "sections": "Introduction to <em>New</em> <em>Relic</em> <em>for</em> Node.js",
        "body": "). Identify slow requests. Group metrics. Show you which portions of your application are suffering from slow database performance. Installation To install our agent, you need to <em>sign</em> <em>up</em> for <em>New</em> <em>Relic</em> first. Once you&#x27;re logged in, follow the instructions or use our launcher to get data flowing"
      },
      "id": "617480b664441fdadc5fbef8"
    },
    {
      "sections": [
        "Introduction to New Relic for PHP",
        "Monitor app performance",
        "Architecture",
        "Tip",
        "Install the agent",
        "Configure the agent",
        "Extend agent instrumentation",
        "Troubleshoot your installation",
        "For more help"
      ],
      "title": "Introduction to New Relic for PHP",
      "type": "docs",
      "tags": [
        "Agents",
        "PHP agent",
        "Getting started"
      ],
      "external_id": "0a6a630fe7b32cde81bef63e2e2ca6aeec9de174",
      "image": "https://docs.newrelic.com/static/7e5643352388bedfe89a8f53bcde978d/c1b63/PHP_Agent_Diagram_5.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/php-agent/getting-started/introduction-new-relic-php/",
      "published_at": "2021-10-25T16:00:19Z",
      "updated_at": "2021-10-23T22:44:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our PHP agent monitors your application to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Monitor app performance one.newrelic.com > APM > (select an app) > Summary: After installing the PHP agent, view a summary of your app's performance. View the big picture of your app Monitor your app's Apdex (user satisfaction) Get a high-level summary of your app Create architectural maps of your app Find errors and problems quickly Track key transactions Search and create customizable charts for the metric timeslice data most important to you, including any custom metrics you are sending to New Relic. Alert your team when errors or problems occur before they affect your users Track performance after a deploy Drill down into performance details Examine code-level transaction traces Examine database query traces Examine error traces Analyze business data Use the PHP agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own Query your data using NRQL Send your own event data Create and share customizable, interactive dashboards Architecture The PHP agent has two binaries that work together to forward data to New Relic: The agent handles automatic and API instrumentation of your PHP code. The daemon acts as a proxy between the agent and the New Relic platform. You can connect up to 500 applications/agents to one daemon. The daemon imposes sampling when the harvest cycle limits are reached, so consider this when deciding how many applications/agents to connect to a single daemon. Tip The number of applications/agents per daemon may be lower when running in separate Docker containers, depending on the capacity of the connection between containers. The flow of data from your PHP applications to New Relic. The workflow between your application and New Relic must occur in this order: The agent establishes a socket connection with the daemon by sending the first payload of instrumentation data. The daemon establishes an HTTPS link with the New Relic platform. The daemon must be invoked before your instrumented application is invoked. This is called agent mode and is the default. To avoid losing reported data, make sure your instrumented application doesn't send transactions before both connections are established. Install the agent Before you install the PHP agent, ensure your system meets the system requirements. The PHP agent supports many of the most common PHP frameworks, databases, and libraries. You can also use the agent in a Google App Engine (GAE) flexible environment. Tip If you are installing the agent on a shared hosting service, ensure you have root permissions to install the agent or contact your hosting provider for technical assistance. To install the agent, sign up for New Relic first. Once logged in, use our launcher, or see the instructions for specific installations. Add PHP data For standard installations, see: PHP agent installation overview (the basic installation steps for the most common setups). Installing on RedHat or CentOS Installing on Ubuntu or Debian Installing with tar archive (generic method to use on any supported systems such as Linux variants, OpenSolaris, SmartOS, FreeBSD, macOS, etc) The newrelic-install script (how to use the interactive script that automates some installation tasks) For other types of PHP installations and advanced installation topics, see: PHP agent installation: Non-standard PHP Starting the PHP daemon (a standard New Relic installation starts the daemon automatically, but you can also start the daemon manually) Silent mode for the install script Google App Engine (GAE) flex environment installation for New Relic's PHP agent Configure the agent The agent includes a variety of configuration options to further customize and fine-tune your installation. Tip The most important part of agent configuration is to give your app a descriptive name. New Relic uses this app name to aggregate metrics when you have multiple apps or hosts. After changing any agent configuration options, restart your web server. Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Integrate the PHP agent with browser monitoring to gain visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshoot your installation If you encounter issues with the PHP agent, see our full list of troubleshooting documentation. Common installation issues include: No data appears (PHP) Determining permissions requirements INI settings not taking effect immediately Why and when to restart your web server (PHP) For more help If you need more help, check out these support and learning resources: Suggest a change and learn how to contribute to our PHP agent open source repository. Browse the Explorers Hub to get help from the community and join in discussions. Find answers on our sites and learn how to use our support portal. Run New Relic Diagnostics, our troubleshooting tool for Linux, Windows, and macOS. Review New Relic's data security and licenses documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 507.37555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>for</em> PHP",
        "sections": "Introduction to <em>New</em> <em>Relic</em> <em>for</em> PHP",
        "body": " the agent, <em>sign</em> <em>up</em> for <em>New</em> <em>Relic</em> first. Once logged in, use our launcher, or see the instructions for specific installations. Add PHP data For standard installations, see: PHP agent installation overview (the basic installation steps for the most common setups). Installing on RedHat or CentOS Installing"
      },
      "id": "61749062e7b9d2458313ca07"
    }
  ],
  "/docs/accounts/accounts-billing/account-setup/downgradecancel-account": [
    {
      "sections": [
        "Troubleshoot password, email address, and login issues",
        "Tip",
        "Account access issues",
        "Password solutions",
        "Forgot your password, or your password does not work.",
        "Important",
        "Reset password.",
        "Password error messages.",
        "Password reset link expired.",
        "Added existing user to another New Relic account.",
        "Email solutions",
        "Did not receive new account confirmation email.",
        "Email address does not work or email error messages.",
        "Received message that your email account already exists.",
        "Email link does not redirect to the password reset page.",
        "Asked to verify email during login.",
        "General system solutions",
        "Delete an account you recently created.",
        "SAML single sign-on (SSO) problems prevent login.",
        "System failure errors prevent login.",
        "Mobile device solutions",
        "Solutions for other situations",
        "Unable to log in from your New Relic partner account."
      ],
      "title": "Troubleshoot password, email address, and login issues",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account setup"
      ],
      "external_id": "fc93486097659dacf04d90cfc6b435cc6791ce6d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/troubleshoot-new-relics-password-email-address-login-problems/",
      "published_at": "2021-10-24T19:50:24Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have problems with your email address or password when logging in to New Relic, review these troubleshooting tips. Tip To learn about factors affecting access to features and data, see Factors affecting access. Account access issues If you're logged into New Relic but don't see the accounts or data you expect, see Factors affecting access. Password solutions New Relic requires a valid email address and a valid password in order for you to log in and to receive information from New Relic. If you are unable to create your account successfully, or if you have password or other login problems, review these troubleshooting suggestions to try to identify a resolution. Forgot your password, or your password does not work. If you have forgotten your New Relic account password, or if your password does not work, request a password reset from New Relic. If you have access to multiple New Relic logins, also ensure you are using the correct password for the login method you're using Go to New Relic's login page. Select Forgot your password. Type your account email address, and select Send my reset link. When you receive a confirmation email from New Relic, select the password reset link, and follow New Relic's password requirements to complete the process to reset your password. Important The password reset link expires after 12 hours. If you do not quickly receive an email from New Relic, check your spam filters, contact your organization's email administrator for troubleshooting suggestions, get support at support.newrelic.com. Reset password. If you forgot your own password or need to request a password reset for your account email, you can use New Relic's self-service options. Admin-level users cannot reset passwords for other users. If you need to reset someone else's password, get support at support.newrelic.com. Password error messages. If you complete the signup process and are unable to log in to your account due to password error messages, get support at support.newrelic.com. Password reset link expired. If you want to change your password but you see a message that the password reset link expired, try using a private browser or clearing your browser cache and cookies. Important The password reset link expires after 12 hours. If you do not quickly receive an email from New Relic after you select the reset link, check your spam filters, contact your organization's email administrator for troubleshooting suggestions, get support at support.newrelic.com. Added existing user to another New Relic account. If you're an existing New Relic account user and you have been added to another account, you don't need to create a new password. Your existing password will work for each account, and you can switch between accounts after logging in. Email solutions New Relic requires a valid email address and a valid password in order for you to log in and to receive information from New Relic. If you're unable to create your account successfully, or if you have email or other login problems, review these troubleshooting suggestions to try to identify a resolution. Did not receive new account confirmation email. When you first create your account, New Relic sends a confirmation email so you can complete the setup process and sign in. If you cannot locate your original account confirmation email: Go to New Relic's login page at login.newrelic.com/login. Select Forgot your password. Type your account email address, and select Send my password. When New Relic's system returns an email message, select the link in it to confirm your account again. If you don't receive an email from New Relic: Check your spam filters. If applicable, add New Relic to your email allow list. Get support at support.newrelic.com. Email address does not work or email error messages. If you complete the signup process and are unable to log in to your account due to email or password error messages, get support at support.newrelic.com. Received message that your email account already exists. If you are trying to create a new account and receive a message that your email account already exists, get support at support.newrelic.com. Email link does not redirect to the password reset page. If you have used your password reset link but are not redirected to the password reset page, troubleshoot the following: Your password reset link has expired. You will need to request a new link from the New Relic website. You are experiencing a caching issue. Clear your browsing cache or use a private browsing window before trying the link again. Tip Private browsing, also known as incognito mode, is a privacy feature to disable browsing history and the web cache. To open a private browsing window, you can use the keyboard shortcut CTRL+Shift+N on Windows and Command+Shift+N on Mac for most browsing applications. If this still doesn't solve your problem, get support at support.newrelic.com. Asked to verify email during login. If your email is associated with multiple accounts, you will be given the option to verify your email during login. This will allow you to choose which account to access. If you do not verify your email address, New Relic will attempt to log you in with the most recently created user record associated with your email address. To avoid verifying your email during each login, click the Remember Me checkbox in the login screen. General system solutions Some general system problems and solutions: Delete an account you recently created. If you created a New Relic account unnecessarily and want to delete it, and if that account is a simple one, you may be able to delete it yourself. See Delete simple organization. SAML single sign-on (SSO) problems prevent login. If your organization uses a SAML Single Sign On (SSO) solution, you can skip the Password field when you log in. If you need to reset your password, contact your organization's system administrator or IT department as applicable. If you're an administrator who has recently enabled or made changes to your SAML SSO settings and are unable to log in, there might be an issue with your configuration. Customers on the New Relic One user model can use a special recovery flow to fix any issues. Visit login.newrelic.com/recovery_access to bypass SSO and gain one-time access to your organization. System failure errors prevent login. If you receive failure errors while trying to sign up, a third-party password manager may be triggering New Relic's spam trap. To work around this, try these solutions: Bypass your password manager. Use a different browser to sign up with New Relic. Get support at support.newrelic.com. Mobile device solutions If you are unable to log in from your mobile device, the new user authentication time frame may have expired. You must complete this process within 20 minutes of receiving New Relic's confirmation message for your mobile device. To solve this problem, request another confirmation message to be sent to your device. Also, depending on your New Relic account, additional installation or authentication steps may be required for your iOS or Android app account. Solutions for other situations Here are suggestions for other unique situations. Unable to log in from your New Relic partner account. With partner accounts, SAML SSO authentication to sign in to New Relic is controlled by the partnership. Depending on the partnership, you may or may not be able to log in directly to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.64478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot password, email address, <em>and</em> login issues",
        "sections": "<em>Account</em> access issues",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "If you have problems with your email address or password when logging in to New Relic, review these troubleshooting tips. Tip To learn about factors affecting access to features and data, see Factors affecting access. <em>Account</em> access issues If you&#x27;re logged into New Relic but don&#x27;t see the <em>accounts</em>"
      },
      "id": "6043f38b28ccbc04a22fd1aa"
    },
    {
      "sections": [
        "Account ID"
      ],
      "title": "Account ID",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account setup"
      ],
      "external_id": "3771d53b48cfcf2f29d303b1d77a3884e4bae480",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/account-id/",
      "published_at": "2021-10-24T20:23:33Z",
      "updated_at": "2021-09-13T20:41:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic procedures require use of your account ID (for example, some API calls). Your account ID is the ID number we assign to a New Relic account. Note that some New Relic organizations contain multiple accounts. Options for finding your account ID: If your organization has multiple accounts: From one.newrelic.com, use the account selector dropdown near the top of the page to switch between accounts and see their IDs. There are other options, depending on which user model you're on: New Relic One user model: Click the account dropdown and then click Administration. Click Organization and access and then Accounts to see account IDs. Original user model: Click the account dropdown, click Account settings, and then click API keys. The account ID is displayed there. For more on how account access works, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.51117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Account</em> ID",
        "sections": "<em>Account</em> ID",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "Some New Relic procedures require use of your <em>account</em> ID (for example, some API calls). Your <em>account</em> ID is the ID number we assign to a New Relic <em>account</em>. Note that some New Relic organizations contain multiple <em>accounts</em>. Options for finding your <em>account</em> ID: If your organization has multiple"
      },
      "id": "61271c84196a67ed0c00b367"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.52206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    }
  ],
  "/docs/accounts/accounts-billing/account-setup/troubleshoot-new-relics-password-email-address-login-problems": [
    {
      "sections": [
        "Account ID"
      ],
      "title": "Account ID",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account setup"
      ],
      "external_id": "3771d53b48cfcf2f29d303b1d77a3884e4bae480",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/account-id/",
      "published_at": "2021-10-24T20:23:33Z",
      "updated_at": "2021-09-13T20:41:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic procedures require use of your account ID (for example, some API calls). Your account ID is the ID number we assign to a New Relic account. Note that some New Relic organizations contain multiple accounts. Options for finding your account ID: If your organization has multiple accounts: From one.newrelic.com, use the account selector dropdown near the top of the page to switch between accounts and see their IDs. There are other options, depending on which user model you're on: New Relic One user model: Click the account dropdown and then click Administration. Click Organization and access and then Accounts to see account IDs. Original user model: Click the account dropdown, click Account settings, and then click API keys. The account ID is displayed there. For more on how account access works, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.51117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Account</em> ID",
        "sections": "<em>Account</em> ID",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "Some New Relic procedures require use of your <em>account</em> ID (for example, some API calls). Your <em>account</em> ID is the ID number we assign to a New Relic <em>account</em>. Note that some New Relic organizations contain multiple <em>accounts</em>. Options for finding your <em>account</em> ID: If your organization has multiple"
      },
      "id": "61271c84196a67ed0c00b367"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.52206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Downgrade or cancel account/organization",
        "Reduce data ingest",
        "Downgrade organization",
        "Pro or Enterprise edition downgrade",
        "Standard edition downgrade",
        "Cancel organization",
        "Pro or Enterprise edition cancel",
        "Standard edition: cancel simple organization",
        "Standard edition: cancel other organizations"
      ],
      "title": "Downgrade or cancel account/organization",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account setup"
      ],
      "external_id": "3a75d74fd723f17050d69fe6da4fe162b6965bc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/downgradecancel-account/",
      "published_at": "2021-10-24T22:52:55Z",
      "updated_at": "2021-05-28T12:03:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Depending on your pricing edition and other factors, we offer various options for reducing data ingest, deleting or uninstalling an agent or integration, or downgrading or cancelling your organization (your account or group of accounts). Reduce data ingest If you want to stop reporting some data to New Relic without downgrading or cancelling, you can configure our tools to send less data. For how to manage data ingest, see Manage your data. To uninstall agents or integrations, here are some recommended procedures: Remove APM, browser, and mobile apps Remove infrastructure agent For how to disable other New Relic tools, see their specific docs. You can search New Relic integrations here. Downgrade organization Options for downgrading your New Relic organization will differ depending on your pricing edition: Pro or Enterprise edition downgrade To downgrade your Pro or Enterprise organization, contact your New Relic account representative. Standard edition downgrade Options for downgrading for Standard edition: If you're being billed and want to downgrade: From one.newrelic.com, click the account dropdown, click Manage your plan, and then click Downgrade account. Once you are downgraded, you’ll still be able to access New Relic via the login page. If you're not being billed and haven't input your credit card, you don’t need to downgrade and can continue using New Relic at a free level. Cancel organization If you've accidentally signed up for New Relic and want to delete that account, see Delete simple organization. Other options for cancelling your organization depend on your pricing edition: Pro or Enterprise edition cancel To cancel your Pro or Enterprise organization, contact your New Relic account representative. Standard edition: cancel simple organization If you've created a new New Relic organization that you don't need, and if it meets some requirements (below), you can delete that organization with these steps: click the account dropdown, select Organization and access, and then click Delete organization. Requirements for being able to self-delete an organization: Organization has a single account, and single user. Was created after July 2020 (and hence is on the new pricing plan and the New Relic One user model). Standard edition: cancel other organizations First consider removing monitoring tools or downgrading. If you still have questions, contact support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.28041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Downgrade or cancel <em>account</em>&#x2F;organization",
        "sections": "Downgrade or cancel <em>account</em>&#x2F;organization",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "Depending on your pricing edition and other factors, we offer various options for reducing data ingest, deleting or uninstalling an agent or integration, or downgrading or cancelling your organization (your <em>account</em> or group of <em>accounts</em>). Reduce data ingest If you want to stop reporting some data"
      },
      "id": "6043f3c4196a677821960f65"
    }
  ],
  "/docs/accounts/accounts-billing/account-structure/account-id": [
    {
      "sections": [
        "Troubleshoot password, email address, and login issues",
        "Tip",
        "Account access issues",
        "Password solutions",
        "Forgot your password, or your password does not work.",
        "Important",
        "Reset password.",
        "Password error messages.",
        "Password reset link expired.",
        "Added existing user to another New Relic account.",
        "Email solutions",
        "Did not receive new account confirmation email.",
        "Email address does not work or email error messages.",
        "Received message that your email account already exists.",
        "Email link does not redirect to the password reset page.",
        "Asked to verify email during login.",
        "General system solutions",
        "Delete an account you recently created.",
        "SAML single sign-on (SSO) problems prevent login.",
        "System failure errors prevent login.",
        "Mobile device solutions",
        "Solutions for other situations",
        "Unable to log in from your New Relic partner account."
      ],
      "title": "Troubleshoot password, email address, and login issues",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account setup"
      ],
      "external_id": "fc93486097659dacf04d90cfc6b435cc6791ce6d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/troubleshoot-new-relics-password-email-address-login-problems/",
      "published_at": "2021-10-24T19:50:24Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have problems with your email address or password when logging in to New Relic, review these troubleshooting tips. Tip To learn about factors affecting access to features and data, see Factors affecting access. Account access issues If you're logged into New Relic but don't see the accounts or data you expect, see Factors affecting access. Password solutions New Relic requires a valid email address and a valid password in order for you to log in and to receive information from New Relic. If you are unable to create your account successfully, or if you have password or other login problems, review these troubleshooting suggestions to try to identify a resolution. Forgot your password, or your password does not work. If you have forgotten your New Relic account password, or if your password does not work, request a password reset from New Relic. If you have access to multiple New Relic logins, also ensure you are using the correct password for the login method you're using Go to New Relic's login page. Select Forgot your password. Type your account email address, and select Send my reset link. When you receive a confirmation email from New Relic, select the password reset link, and follow New Relic's password requirements to complete the process to reset your password. Important The password reset link expires after 12 hours. If you do not quickly receive an email from New Relic, check your spam filters, contact your organization's email administrator for troubleshooting suggestions, get support at support.newrelic.com. Reset password. If you forgot your own password or need to request a password reset for your account email, you can use New Relic's self-service options. Admin-level users cannot reset passwords for other users. If you need to reset someone else's password, get support at support.newrelic.com. Password error messages. If you complete the signup process and are unable to log in to your account due to password error messages, get support at support.newrelic.com. Password reset link expired. If you want to change your password but you see a message that the password reset link expired, try using a private browser or clearing your browser cache and cookies. Important The password reset link expires after 12 hours. If you do not quickly receive an email from New Relic after you select the reset link, check your spam filters, contact your organization's email administrator for troubleshooting suggestions, get support at support.newrelic.com. Added existing user to another New Relic account. If you're an existing New Relic account user and you have been added to another account, you don't need to create a new password. Your existing password will work for each account, and you can switch between accounts after logging in. Email solutions New Relic requires a valid email address and a valid password in order for you to log in and to receive information from New Relic. If you're unable to create your account successfully, or if you have email or other login problems, review these troubleshooting suggestions to try to identify a resolution. Did not receive new account confirmation email. When you first create your account, New Relic sends a confirmation email so you can complete the setup process and sign in. If you cannot locate your original account confirmation email: Go to New Relic's login page at login.newrelic.com/login. Select Forgot your password. Type your account email address, and select Send my password. When New Relic's system returns an email message, select the link in it to confirm your account again. If you don't receive an email from New Relic: Check your spam filters. If applicable, add New Relic to your email allow list. Get support at support.newrelic.com. Email address does not work or email error messages. If you complete the signup process and are unable to log in to your account due to email or password error messages, get support at support.newrelic.com. Received message that your email account already exists. If you are trying to create a new account and receive a message that your email account already exists, get support at support.newrelic.com. Email link does not redirect to the password reset page. If you have used your password reset link but are not redirected to the password reset page, troubleshoot the following: Your password reset link has expired. You will need to request a new link from the New Relic website. You are experiencing a caching issue. Clear your browsing cache or use a private browsing window before trying the link again. Tip Private browsing, also known as incognito mode, is a privacy feature to disable browsing history and the web cache. To open a private browsing window, you can use the keyboard shortcut CTRL+Shift+N on Windows and Command+Shift+N on Mac for most browsing applications. If this still doesn't solve your problem, get support at support.newrelic.com. Asked to verify email during login. If your email is associated with multiple accounts, you will be given the option to verify your email during login. This will allow you to choose which account to access. If you do not verify your email address, New Relic will attempt to log you in with the most recently created user record associated with your email address. To avoid verifying your email during each login, click the Remember Me checkbox in the login screen. General system solutions Some general system problems and solutions: Delete an account you recently created. If you created a New Relic account unnecessarily and want to delete it, and if that account is a simple one, you may be able to delete it yourself. See Delete simple organization. SAML single sign-on (SSO) problems prevent login. If your organization uses a SAML Single Sign On (SSO) solution, you can skip the Password field when you log in. If you need to reset your password, contact your organization's system administrator or IT department as applicable. If you're an administrator who has recently enabled or made changes to your SAML SSO settings and are unable to log in, there might be an issue with your configuration. Customers on the New Relic One user model can use a special recovery flow to fix any issues. Visit login.newrelic.com/recovery_access to bypass SSO and gain one-time access to your organization. System failure errors prevent login. If you receive failure errors while trying to sign up, a third-party password manager may be triggering New Relic's spam trap. To work around this, try these solutions: Bypass your password manager. Use a different browser to sign up with New Relic. Get support at support.newrelic.com. Mobile device solutions If you are unable to log in from your mobile device, the new user authentication time frame may have expired. You must complete this process within 20 minutes of receiving New Relic's confirmation message for your mobile device. To solve this problem, request another confirmation message to be sent to your device. Also, depending on your New Relic account, additional installation or authentication steps may be required for your iOS or Android app account. Solutions for other situations Here are suggestions for other unique situations. Unable to log in from your New Relic partner account. With partner accounts, SAML SSO authentication to sign in to New Relic is controlled by the partnership. Depending on the partnership, you may or may not be able to log in directly to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.64474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot password, email address, <em>and</em> login issues",
        "sections": "<em>Account</em> access issues",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "If you have problems with your email address or password when logging in to New Relic, review these troubleshooting tips. Tip To learn about factors affecting access to features and data, see Factors affecting access. <em>Account</em> access issues If you&#x27;re logged into New Relic but don&#x27;t see the <em>accounts</em>"
      },
      "id": "6043f38b28ccbc04a22fd1aa"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.52194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Downgrade or cancel account/organization",
        "Reduce data ingest",
        "Downgrade organization",
        "Pro or Enterprise edition downgrade",
        "Standard edition downgrade",
        "Cancel organization",
        "Pro or Enterprise edition cancel",
        "Standard edition: cancel simple organization",
        "Standard edition: cancel other organizations"
      ],
      "title": "Downgrade or cancel account/organization",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account setup"
      ],
      "external_id": "3a75d74fd723f17050d69fe6da4fe162b6965bc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/downgradecancel-account/",
      "published_at": "2021-10-24T22:52:55Z",
      "updated_at": "2021-05-28T12:03:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Depending on your pricing edition and other factors, we offer various options for reducing data ingest, deleting or uninstalling an agent or integration, or downgrading or cancelling your organization (your account or group of accounts). Reduce data ingest If you want to stop reporting some data to New Relic without downgrading or cancelling, you can configure our tools to send less data. For how to manage data ingest, see Manage your data. To uninstall agents or integrations, here are some recommended procedures: Remove APM, browser, and mobile apps Remove infrastructure agent For how to disable other New Relic tools, see their specific docs. You can search New Relic integrations here. Downgrade organization Options for downgrading your New Relic organization will differ depending on your pricing edition: Pro or Enterprise edition downgrade To downgrade your Pro or Enterprise organization, contact your New Relic account representative. Standard edition downgrade Options for downgrading for Standard edition: If you're being billed and want to downgrade: From one.newrelic.com, click the account dropdown, click Manage your plan, and then click Downgrade account. Once you are downgraded, you’ll still be able to access New Relic via the login page. If you're not being billed and haven't input your credit card, you don’t need to downgrade and can continue using New Relic at a free level. Cancel organization If you've accidentally signed up for New Relic and want to delete that account, see Delete simple organization. Other options for cancelling your organization depend on your pricing edition: Pro or Enterprise edition cancel To cancel your Pro or Enterprise organization, contact your New Relic account representative. Standard edition: cancel simple organization If you've created a new New Relic organization that you don't need, and if it meets some requirements (below), you can delete that organization with these steps: click the account dropdown, select Organization and access, and then click Delete organization. Requirements for being able to self-delete an organization: Organization has a single account, and single user. Was created after July 2020 (and hence is on the new pricing plan and the New Relic One user model). Standard edition: cancel other organizations First consider removing monitoring tools or downgrading. If you still have questions, contact support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.28041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Downgrade or cancel <em>account</em>&#x2F;organization",
        "sections": "Downgrade or cancel <em>account</em>&#x2F;organization",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "Depending on your pricing edition and other factors, we offer various options for reducing data ingest, deleting or uninstalling an agent or integration, or downgrading or cancelling your organization (your <em>account</em> or group of <em>accounts</em>). Reduce data ingest If you want to stop reporting some data"
      },
      "id": "6043f3c4196a677821960f65"
    }
  ],
  "/docs/accounts/accounts-billing/account-structure/add-accounts": [
    {
      "sections": [
        "Introduction to account settings",
        "Pricing, billing, and usage UI",
        "Manage users",
        "Add accounts",
        "Other account settings"
      ],
      "title": "Introduction to account settings",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "1dbac104fa7e60637c32a61a80b8b709f6fd84c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-10-19T03:52:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view and edit account-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the account dropdown. Keep reading for tips on how to find different kinds of account settings in the UI. Pricing, billing, and usage UI Note that user permissions may impact your access to some account settings. To find billing-related UI, go to one.newrelic.com and, in the upper right corner, click the account dropdown to access various account settings. Here's what you can find there: Manage your plan: Options for viewing and managing billing-related settings. Manage your data: Options for managing ingest of data, which can be a billing factor. Learn more about managing data. View your usage: View of your billing-related usage. Administration: Options related to billing, usage, and user management (this UI available only for users on our New Relic One user model). Account settings: Options related to subscription and usage, and user management (this UI available only to users on our original user model). Related topics: Pricing details: Original pricing plan | New Relic One pricing Manage data Manage users How you manage users depends on which user model you're on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the account dropdown, click Account settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you're on? See Determine user model. Add accounts Learn more about adding accounts. Other account settings See the account settings docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>account</em> settings",
        "sections": "<em>Add</em> <em>accounts</em>",
        "tags": "<em>Accounts</em>",
        "body": " model you&#x27;re on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the <em>account</em> dropdown, click <em>Account</em> settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you&#x27;re on? See Determine user model. <em>Add</em> <em>accounts</em> Learn more about adding <em>accounts</em>. Other <em>account</em> settings See the <em>account</em> settings docs."
      },
      "id": "6043f38a196a679ae4960f5e"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/new-relic-account-structure/",
      "sections": [
        "Organization and account structure",
        "Important",
        "New Relic One user model",
        "How users access accounts",
        "Original user model"
      ],
      "published_at": "2021-10-24T23:49:09Z",
      "title": "Organization and account structure",
      "updated_at": "2021-10-24T23:49:08Z",
      "type": "docs",
      "external_id": "4f5a4cde293d0b599f489eff010f69c021ccb539",
      "document_type": "page",
      "popularity": 1,
      "body": "Depending on your user model, you have different options for adding and managing accounts and assigning users to them. We have two models: New Relic One user model Original user model Important Note that the user model is not directly related to our two pricing plans. New Relic One user model Important This section is about organizations on the New Relic One user model, not the original model. Learn more about the difference. At New Relic, an \"organization\" represents a New Relic customer. The organization contains everything relevant to a New Relic customer: its accounts, its users, and its data. A New Relic \"account\" can be considered a workspace. For example, you might have an account for a specific app, or a set of related hosts and services for a specific initiative or project, or you might have an account for a specific team. Each account has its own account ID, and that ID is used for some account-specific tasks, like making API calls. Our Standard edition allows for a single account per organization. Pro and Enterprise editions allow for multiple accounts per organization. Currently you can't add accounts to your organization on your own. To add accounts, talk to your New Relic account representative. How users access accounts In your organization, your New Relic users are granted access to specific accounts that are relevant to their duties and responsibilities. To manage users’ access to accounts, you create access grants, which assign a group of users to a specific role on a specific account. For example, you may assign a user group the ability to manage billing on some accounts with the Billing manager role, and assign some users as non-admin full users on some accounts, and assign some users as basic users on some accounts. Our user management system allows you to create the user access you need, whether that’s a relatively simple setup with just a few roles across a few accounts, or a complex one with many roles across many accounts. Learn more about user management. Note that some features, like dashboards and workloads, can display data from across different accounts in an organization. This means that if a user isn’t granted access to all relevant accounts, they may experience missing data. To learn more about access issues, see Factors affecting access. Original user model See Original user model structure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Organization and <em>account</em> structure",
        "sections": "How users access <em>accounts</em>",
        "body": " is used for some <em>account</em>-specific tasks, like making API calls. Our Standard edition allows for a single <em>account</em> per organization. Pro and Enterprise editions allow for multiple <em>accounts</em> per organization. Currently you can&#x27;t <em>add</em> <em>accounts</em> to your organization on your own. To <em>add</em> <em>accounts</em>, talk to your New"
      },
      "id": "60bee5c028ccbc2413e667e4"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    }
  ],
  "/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data": [
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, who have access to our more curated UI experiences. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.22217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One pricing <em>and</em> <em>billing</em> ",
        "sections": "New Relic One pricing <em>and</em> <em>billing</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " <em>billing</em> and usage in the UI, see Pricing and <em>billing</em> UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. <em>Billing</em> calculation details For <em>accounts</em> on New Relic One pricing, some high-level <em>billing</em> information is displayed in the UI. Here"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.32635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to automated user management (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to automated user management (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " to implement this feature), talk to your New Relic <em>account</em> representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "Introduction to account settings",
        "Pricing, billing, and usage UI",
        "Manage users",
        "Add accounts",
        "Other account settings"
      ],
      "title": "Introduction to account settings",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "1dbac104fa7e60637c32a61a80b8b709f6fd84c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-10-19T03:52:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view and edit account-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the account dropdown. Keep reading for tips on how to find different kinds of account settings in the UI. Pricing, billing, and usage UI Note that user permissions may impact your access to some account settings. To find billing-related UI, go to one.newrelic.com and, in the upper right corner, click the account dropdown to access various account settings. Here's what you can find there: Manage your plan: Options for viewing and managing billing-related settings. Manage your data: Options for managing ingest of data, which can be a billing factor. Learn more about managing data. View your usage: View of your billing-related usage. Administration: Options related to billing, usage, and user management (this UI available only for users on our New Relic One user model). Account settings: Options related to subscription and usage, and user management (this UI available only to users on our original user model). Related topics: Pricing details: Original pricing plan | New Relic One pricing Manage data Manage users How you manage users depends on which user model you're on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the account dropdown, click Account settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you're on? See Determine user model. Add accounts Learn more about adding accounts. Other account settings See the account settings docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.51968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>account</em> settings",
        "sections": "Pricing, <em>billing</em>, <em>and</em> usage UI",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "To view and edit <em>account</em>-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the <em>account</em> dropdown. Keep reading for tips on how to find different kinds of <em>account</em> settings in the UI. Pricing, <em>billing</em>, and usage UI Note that user permissions may"
      },
      "id": "6043f38a196a679ae4960f5e"
    }
  ],
  "/docs/accounts/accounts-billing/account-structure/new-relic-account-structure": [
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic user versus full user)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-10-24T20:29:42Z",
      "updated_at": "2021-10-07T01:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full user) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic user versus full user) Note that there are limits around how many times full users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 711.45807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Give users access to <em>accounts</em> <em>and</em> roles (access grants)",
        "tags": "<em>Accounts</em> <em>and</em> billing",
        "body": " we use there: A New Relic <em>organization</em> is the representation of your <em>organization</em>, containing all your accounts, users, and data. For more information, see <em>Organization</em> and <em>account</em> <em>structure</em>. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities"
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-users-roles/original-account-structure/",
      "sections": [
        "Organization and account structure (original user model)",
        "Important"
      ],
      "published_at": "2021-10-24T22:54:19Z",
      "title": "Organization and account structure (original user model)",
      "updated_at": "2021-09-14T10:49:03Z",
      "type": "docs",
      "external_id": "5fba4aaa95de18df4cd4ce1dabcb7e81477718c2",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is about organizations on our original user model, not the New Relic One model. Learn more about the difference. Since July 30, 2020, new signups to New Relic are on our New Relic One user model. Older customers who have not yet migrated to the new model are still on our original user model. The original user model will be increasingly deprecated as more New Relic customers are migrated to the new model. Important Note that the user model is not directly related to our two different pricing plans. Here are some important aspects of the original user model and links to important docs: Our original user model did not have firm boundaries between organizations/customers, and was much more user-centric. This meant that a user could be granted access to data from different organizations, and could access that data from a single login. Read more about the differences between the old and new model. On the original user model, a user’s access to accounts is based on: a) being added to a specific account, or b) having access to a parent account and inheriting access to that account’s child accounts. See our original user management docs. See an explanation of how parent/child accounts work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 540.68665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Organization</em> <em>and</em> <em>account</em> <em>structure</em> (original user model)",
        "sections": "<em>Organization</em> <em>and</em> <em>account</em> <em>structure</em> (original user model)",
        "body": " between the old and new model. On the original user model, a user’s access to accounts is based on: a) being added to a specific <em>account</em>, or b) having access to a parent <em>account</em> and inheriting access to that <em>account</em>’s child accounts. See our original user management docs. See an explanation of how parent&#x2F;child accounts work."
      },
      "id": "60d60855196a67b29e5e1629"
    },
    {
      "image": "https://docs.newrelic.com/static/565d4ebddf52a4592c594032696516b9/c1b63/New-Relic-capabilities-UI-screenshot.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/new-relic-one-user-model-understand-user-structure/",
      "sections": [
        "Users, roles, permissions (New Relic One user model)",
        "Important",
        "Overview",
        "User type: basic and full",
        "Compare full vs basic capabilities",
        "Tips on choosing user type",
        "Understand user-related billing",
        "Have questions about why you can't access something?",
        "Default groups: Admin and User",
        "How do user type, roles, and groups relate to each other?",
        "Roles and capabilities",
        "Standard (default) roles",
        "Capabilities",
        "Manage users",
        "2020 user model changes"
      ],
      "published_at": "2021-10-24T20:31:19Z",
      "title": "Users, roles, permissions (New Relic One user model)",
      "updated_at": "2021-10-24T20:31:18Z",
      "type": "docs",
      "external_id": "169383c2678ce973404db07195b2dee6eda9163d",
      "document_type": "page",
      "popularity": 1,
      "body": "Your New Relic users can be on one of two user models: this doc explains the New Relic One user model. Important If your New Relic organization was created before July 30 2020 and you haven't gone through a user migration process, your users are likely on our original user model. For more on this, see User model changes. Overview This doc will explain the structure of the New Relic One user model, including: User type (basic user versus full user) Default user groups, including Admin and User Roles and capabilities For how to add and manage users in the UI, see User management. User type: basic and full Important This section is for users on our New Relic One user model. If you're on our original user model, see Original users. A user's user type determines if they have access to our basic features (basic user) or can access all of our curated observability UI features (full user). The user type is something meant to be set long-term based on that user's expected New Relic responsibilities. Below are details on the two user types. Note that full users are billable only if you're on New Relic One pricing. Basic user. Details: These users are free and have access to a wide range of features, including setting up and configuring any New Relic data-reporting tool, running queries of your data, using our logs UI, making custom charts and dashboards, and setting up alerts. Unlike full users, they do not have access to our more curated observability UI experiences or some Applied Intelligence features (for a detailed comparison, see Capabilities). Basic users will see prompts to become a full user when they attempt to access unavailable features. For details, see Upgrade. Full user. Details: Full users have access to everything (depending on any role restrictions), including all our observability UI experiences, such as APM, infrastructure monitoring, browser monitoring, mobile monitoring, synthetic monitors, access to New Relic One apps, and more. For details, see Capabilities. Standard edition includes one free full user and up to five total full users. A full user can downgrade to a basic user twice in a 12-month period. To view and edit the user type of your users, use the User management UI. Learn more about basic user versus full user differences: Compare full vs basic capabilities Below is a table comparing what basic users and full users can do. A simple way to think about it is that full users have theoretical access (dependent on any chosen role restrictions) to all of our curated UI experiences, while basic users are restricted to fairly basic capabilities. Features Full user Basic user Observability UI experiences Application performance monitoring (APM) UI Infrastructure monitoring UI Digital Experience Monitoring UI, which includes: Browser monitoring UI Mobile monitoring UI Synthetic monitoring UI Synthetics checks Serverless monitoring UI Logs in context Distributed tracing Infinite Tracing (Pro and Enterprise edition) Assorted UI experiences, including: Kubernetes cluster explorer UI Key transaction UI Workloads UI Manage other users Access to New Relic One apps Can build apps but can't access other apps Applied Intelligence Automatic anomaly detection Correlated alerts and events Anomaly/alert analysis Root cause details in issues Basic platform capabilities Data ingest from any source (agents, integrations, APIs) Query your data Create custom charts and dashboards Alerts and notifications Our APIs, including NerdGraph (GraphQL) (with some restrictions) Query and chart log data Build New Relic One apps (but cannot access other apps) Encryption at rest Standard data retention Security and compliance Data management Note that the pricing edition (Standard, Pro, or Enterprise) will also affect what features you have access to. For organizations with New Relic One pricing, learn more about how full users impact billing. Tips on choosing user type A user's type (basic user vs full user) is meant to be a long-term assignment, based on the New Relic responsibilities that user is expected to perform. A full user can be downgraded to a basic user only twice in one year. Below are tips for why you'd choose full user versus basic user. Reasons to make someone a full user: They play a key role in the development, testing, deployment, and maintenance phases of the application development lifecycle. They break/fix code regularly; they are responsible for triaging workflows, troubleshooting, or managing users and roles for their team. They have DevOps practices (i.e. version control systems and implement CI/CD). They need to use New Relic's curated dashboards and experiences (not just the ability to create their own custom queries and charts); in other words, they need full access to our platform. They need to be able to manage users and/or billing. Reasons to make someone a basic user: They play a key role in the planning phase of the application development lifecycle. They use and configure New Relic agents, APIs, and integrations to send us data, and access, configure, and use alerts on such data (not necessarily responsible for triaging workflows, troubleshooting, or managing users and roles for their team). They want to see high-level analytics and business metrics for future planning (such as C-Suite executives). They do not need to use our curated experiences and dashboards, but would benefit from the ability to create their own custom queries and charts of data; in other words, they don't need full access to the platform. They don't manage users. For accounts on New Relic One pricing, learn more about user-related billing calculations. Understand user-related billing If you're on the New Relic One pricing plan, full users are billable, and there are restrictions around how often a full user can downgrade to a basic user. For details, see User count billing details. For how to query and alert on usage data, see Query usage data. Have questions about why you can't access something? See Factors affecting access. Default groups: Admin and User For users on our New Relic One user model, a \"group\" is what allows the grouping together and managing of multiple users at the same time. Your New Relic users are assigned to a group, and that group is granted access to specific roles on specific accounts. We have two default groups: User: This group allows a user to use and configure monitoring/analysis features but not perform account-related tasks like managing billing or users. It has access to the All product admin role, which gives access to our observability platform tools but not to the organization and user management capabilities governed by the Organization manager and Authentication manager roles. Admin: has full access and capabilities, including the organization-level admin abilities. This is the equivalent of having the All product admin, the Billing user, the Organization manager and the Authentication domain manager roles. These groups are added inside your default authentication domain, which includes the default settings of users a) being managed via New Relic and b) logging in via standard email and password. If you add other authentication domains (for SAML SSO and/or SCIM provisioning of users), you'd have new custom groups in those new domains to govern those users. Note that groups, whether default or custom, are not what limit a user's capabilities: it is the role that is assigned to that group (with any basic user restrictions on top of that). If your organization is Pro or Enterprise edition and you want to understand how users are granted access to specific roles and accounts, see Access grants. To change the group a user is in, use the User management UI. How do user type, roles, and groups relate to each other? For users on the New Relic One user model, here's a table explaining how user type (basic vs full user), roles, and groups relate to each other: Full user Basic user Group Full users can be assigned to default groups (User and Admin) or custom groups. When basic users are added to a group, that group's role-related restrictions apply. A basic user's capabilities can be restricted in that way, but a basic user can never be granted more capabilities than they start with. For Standard edition, basic users can't be assigned to groups. For Pro and Enterprise edition, they can. Role For an explanation of the roles our default groups have, see Default groups. Custom groups can have either our default standard roles, or custom roles. A basic user's abilities aren't directly defined by a specific role. A basic user can best be described as having the All product admin role but without access to our more curated UI experiences (learn more about user type). When basic users are added to a group, that group's role-related restrictions apply, but a basic user can never be granted more capabilities than they start with. Roles and capabilities For users on the New Relic One user model, a \"role\" can be defined as \"a set of capabilities.\" A capability is defined as the ability to do a specific New Relic task, like 'Delete alert conditions' (learn more about capabilities). Roles are assigned to user groups. Our default groups Admin and User already have our standard roles (defined below) assigned. Organizations on Pro or Enterprise edition can also create custom roles. Standard (default) roles Roles are sets of capabilities. We have several \"standard roles,\" which are roles that satisfy some commonly needed use cases. To view roles and their associated capabilities, use the Organization and access UI. Important Note that some of our standard roles have hidden, non-exposed capabilities that are not available for selection when creating a custom role. The only standard roles that can be replicated with a custom role are Standard user and Read only; all others have some hidden capabilities. Our standard roles include: Standard roles Scope Description All product admin Account Provides admin-level access to observability platform features but not organization-level and user management features. In other words, this role includes all New Relic capabilities with the exception of managing users (Authentication domain manager role), managing organization/account-structure settings (Organization manager role), and managing billing (Billing user role). Note: the Standard user role is essentially the All product admin role minus observability feature configuration capabilities. Standard user Account Provides access to observability platform features, but lacks permissions for configuring those features (for example, ability to configure synthetic monitor secure credentials) and lacks organization-level and user management permissions. Note: the Standard user role is essentially the All product admin role without that role's ability to configure platform features. Billing user Account Provides ability to manage subscriptions and billing setup, and read-only access to the rest of the platform. For organizations with multiple accounts, billing is aggregated in the primary (first-created) account, which is why assigning this role to that primary account grants billing permissions for the entire organization. Organization manager Organization Provides the ability to manage organization settings, including organization structure, name, and preferences. Due to our recent switch to the New Relic One user model, this role currently has few abilities but more will be added over time. For how to grant this role, see Add user management capability. Organization read only Organization Provides the ability to view organization-level settings. For how to grant this role, see Add user management capability. Authentication domain manager Organization Provides ability to add and manage users, and configure authentication domains for users on the New Relic One user model. For how to grant this role, see Add user management capability. Authentication domain read only Organization Provides the ability to view users in your organization and view the configuration of authentication domains. For how to grant this role, see Add user management capability. Read only Account Provides read-only access to the New Relic platform (except for synthetic monitor secure credentials). Manage v1 users Account For New Relic organizations that existed before July 30 2020 and have users on our original user model, this role lets you manage those \"v1\" users. For more about how you'd assign roles to groups and create custom roles, see the user management tutorial. Capabilities A role, whether one of our standard roles or a custom role, is defined as a set of capabilities. To view roles and their associated capabilities, use the Organization and access UI. Important Some of our standard roles have hidden capabilities that aren't available for selection when creating a custom role. For details, see Standard roles. A view of the capabilities associated with the All product admin role. When creating a custom role, you select a custom set of capabilities. Note that the capabilities we expose may change over time: this screenshot was taken in April of 2021. For how to set up roles with custom capabilities, see the user management tutorial. Manage users To learn how to add users, assign them to groups, and create custom groups and roles, see Manage users. 2020 user model changes If you'd like to understand how our user model changed in 2020 and what the impacts of that change were, see User model changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 498.07843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "User type: basic <em>and</em> full",
        "body": " (Authentication domain manager role), managing <em>organization</em>&#x2F;<em>account</em>-<em>structure</em> settings (<em>Organization</em> manager role), and managing billing (Billing user role). Note: the Standard user role is essentially the All product admin role minus observability feature configuration capabilities. Standard user <em>Account</em>"
      },
      "id": "603e88e328ccbcfcbaeba7a8"
    }
  ],
  "/docs/accounts/accounts-billing/general-account-settings/default-time-zone-setting": [
    {
      "sections": [
        "Introduction to account settings",
        "Pricing, billing, and usage UI",
        "Manage users",
        "Add accounts",
        "Other account settings"
      ],
      "title": "Introduction to account settings",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "1dbac104fa7e60637c32a61a80b8b709f6fd84c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-10-19T03:52:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view and edit account-related and user-management-related settings, go to one.newrelic.com and in the top right corner, select the account dropdown. Keep reading for tips on how to find different kinds of account settings in the UI. Pricing, billing, and usage UI Note that user permissions may impact your access to some account settings. To find billing-related UI, go to one.newrelic.com and, in the upper right corner, click the account dropdown to access various account settings. Here's what you can find there: Manage your plan: Options for viewing and managing billing-related settings. Manage your data: Options for managing ingest of data, which can be a billing factor. Learn more about managing data. View your usage: View of your billing-related usage. Administration: Options related to billing, usage, and user management (this UI available only for users on our New Relic One user model). Account settings: Options related to subscription and usage, and user management (this UI available only to users on our original user model). Related topics: Pricing details: Original pricing plan | New Relic One pricing Manage data Manage users How you manage users depends on which user model you're on: New Relic One user model: see Manage users. Original user model: from one.newrelic.com, click the account dropdown, click Account settings, and then click Users and roles. For more on user management, see Original users. Not sure which user model you're on? See Determine user model. Add accounts Learn more about adding accounts. Other account settings See the account settings docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.2047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>account</em> <em>settings</em>",
        "sections": "Introduction to <em>account</em> <em>settings</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "To view and edit <em>account</em>-related and user-management-related <em>settings</em>, go to one.newrelic.com and in the top right corner, select the <em>account</em> dropdown. Keep reading for tips on how to find different kinds of <em>account</em> <em>settings</em> in the UI. Pricing, <em>billing</em>, and usage UI Note that user permissions may"
      },
      "id": "6043f38a196a679ae4960f5e"
    },
    {
      "sections": [
        "Set or change password",
        "Change your password",
        "Important",
        "Reset password"
      ],
      "title": "Set or change password",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "817d8d17dca7f361429109d8364eff931a1cb392",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-passwords-user-preferences/",
      "published_at": "2021-10-24T20:28:55Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains information on New Relic password requirements. Change your password New Relic account passwords don't expire. However, users can change their own password and other personal account information anytime. Your ability to change your password from the UI may depend on your user and organization level settings. To change your password from the UI: From one.newrelic.com, click the account dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length At least one letter (a-z, A-Z) At least one number (0-9), special character, or space Special characters allowed include ~ ` ! @ # $ % ^ & * ( ) _ - + = { [ } ] : ; \" ' < , > . ? / | \\. Spaces are also allowed. Important In addition to New Relic's requirements, follow your organization's guidelines for password length, use of upper or lower case letters, numbers, and special characters. Reset password If you forgot your own password or need to request a password reset, you can use New Relic's self-service options. Admins can't reset passwords for other users. If you need to reset someone else's password, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Set</em> or change password",
        "sections": "<em>Set</em> or change password",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " and organization level <em>settings</em>. To change your password from the UI: From one.newrelic.com, click the <em>account</em> dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length"
      },
      "id": "603eb55a64441f9f8f4e889c"
    },
    {
      "sections": [
        "Change account or user name",
        "Change user name",
        "Change account name",
        "Important"
      ],
      "title": "Change account or user name",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "328b3ae3afa62555d246baee53ec49add7ad470c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-your-new-relic-account-name/",
      "published_at": "2021-10-24T20:28:56Z",
      "updated_at": "2021-08-26T14:42:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Change user name To change your user name: From the account dropdown, select User preferences. On the right side, click Full name. Change account name Only users on our original user model are able to change their New Relic account name. To do this: From the account dropdown, select Account settings. On the right side, edit the Name field. Important If you're on our New Relic One user model and want to change your account name, contact your account representative or support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.12027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change <em>account</em> or user name",
        "sections": "Change <em>account</em> or user name",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " <em>settings</em>. On the right side, edit the Name field. Important If you&#x27;re on our New Relic One user model and want to change your <em>account</em> name, contact your <em>account</em> representative or support."
      },
      "id": "6043ce92e7b9d215e55799e4"
    }
  ],
  "/docs/accounts/accounts-billing/general-account-settings/introduction-account-settings": [
    {
      "sections": [
        "Set or change password",
        "Change your password",
        "Important",
        "Reset password"
      ],
      "title": "Set or change password",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "817d8d17dca7f361429109d8364eff931a1cb392",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-passwords-user-preferences/",
      "published_at": "2021-10-24T20:28:55Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains information on New Relic password requirements. Change your password New Relic account passwords don't expire. However, users can change their own password and other personal account information anytime. Your ability to change your password from the UI may depend on your user and organization level settings. To change your password from the UI: From one.newrelic.com, click the account dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length At least one letter (a-z, A-Z) At least one number (0-9), special character, or space Special characters allowed include ~ ` ! @ # $ % ^ & * ( ) _ - + = { [ } ] : ; \" ' < , > . ? / | \\. Spaces are also allowed. Important In addition to New Relic's requirements, follow your organization's guidelines for password length, use of upper or lower case letters, numbers, and special characters. Reset password If you forgot your own password or need to request a password reset, you can use New Relic's self-service options. Admins can't reset passwords for other users. If you need to reset someone else's password, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Set</em> or change password",
        "sections": "<em>Set</em> or change password",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " and organization level <em>settings</em>. To change your password from the UI: From one.newrelic.com, click the <em>account</em> dropdown and select User preferences. When creating a password, adhere to the password requirements below. Your password must meet these minimum requirements: 8 to 50 characters in length"
      },
      "id": "603eb55a64441f9f8f4e889c"
    },
    {
      "sections": [
        "Change account or user name",
        "Change user name",
        "Change account name",
        "Important"
      ],
      "title": "Change account or user name",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "328b3ae3afa62555d246baee53ec49add7ad470c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/change-your-new-relic-account-name/",
      "published_at": "2021-10-24T20:28:56Z",
      "updated_at": "2021-08-26T14:42:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Change user name To change your user name: From the account dropdown, select User preferences. On the right side, click Full name. Change account name Only users on our original user model are able to change their New Relic account name. To do this: From the account dropdown, select Account settings. On the right side, edit the Name field. Important If you're on our New Relic One user model and want to change your account name, contact your account representative or support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.12027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change <em>account</em> or user name",
        "sections": "Change <em>account</em> or user name",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": " <em>settings</em>. On the right side, edit the Name field. Important If you&#x27;re on our New Relic One user model and want to change your <em>account</em> name, contact your <em>account</em> representative or support."
      },
      "id": "6043ce92e7b9d215e55799e4"
    },
    {
      "sections": [
        "Default time zone setting",
        "Change your default time zone",
        "Exceptions"
      ],
      "title": "Default time zone setting",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "General account settings"
      ],
      "external_id": "3a7abaee77b5d140836c96007766fa8eb9109b6b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/general-account-settings/default-time-zone-setting/",
      "published_at": "2021-10-24T23:48:21Z",
      "updated_at": "2021-08-26T14:04:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your personal timezone setting controls most time-related settings in the New Relic UI, with a few exceptions, as explained in this document. If you change your timezone setting, this may take up to 24 hours to be reflected in the UI. Change your default time zone To change your default time zone for your New Relic account: Go to one.newrelic.com. Select the account dropdown, then select User preferences. Exceptions Users managed via automated user management (AUM) can't change their time zone in the UI. That must be configured in your identity provider. Some New Relic features do not rely on the User preferences time zone settings. The following use Coordinated Universal Time (UTC) and aren't affected by user preferences: Alerts REST API v2 There may be other features where the time zone doesn't rely on your default time zone settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.10873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default time zone <em>setting</em>",
        "sections": "Default time zone <em>setting</em>",
        "tags": "<em>General</em> <em>account</em> <em>settings</em>",
        "body": "Your personal timezone setting controls most time-related <em>settings</em> in the New Relic UI, with a few exceptions, as explained in this document. If you change your timezone setting, this may take up to 24 hours to be reflected in the UI. Change your default time zone To change your default time zone"
      },
      "id": "6043f38a28ccbc97e62c6090"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing": [
    {
      "sections": [
        "Query and alert on billing/usage data",
        "Available data types",
        "Query examples",
        "Data usage queries",
        "Daily data usage",
        "Daily usage by source",
        "Metrics ingest by source",
        "Month-to-date data usage",
        "Month-to-date estimated data cost",
        "User count queries",
        "Month-to-date full users",
        "Projected monthly full user count",
        "Count full users and basic users",
        "Set usage alerts",
        "Caution",
        "Ingested gigabytes exceed a fixed value",
        "Usage exceeds fixed threshold for GBs",
        "Usage exceeds fixed threshold for users",
        "Usage exceeds fixed threshold for estimated cost",
        "Available attributes"
      ],
      "title": "Query and alert on billing/usage data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "e22ae9e26686d11726a82ad4036ff58520b4a439",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/",
      "published_at": "2021-10-24T23:50:03Z",
      "updated_at": "2021-10-17T11:38:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For accounts on our New Relic One pricing plan, we provide a View your usage UI for understanding billing-related usage and a Manage your data UI for managing billing-related data. Additionally, you can: Query your usage data to get more detail than is available in the UI. Set up NRQL alert conditions to get notifications about changes in your usage. Note that account hierarchy may affect queried data. See Account structure. Available data types Usage data is attached to these events: NrConsumption records usage every hour, and is the equivalent of \"real-time\" usage. Use this event to observe usage trends over time. NrMTDConsumption generates aggregate values from the NrConsumption event. Use this event to see usage or estimated cost for a billing period. NrUsage records usage every hour and is used to see usage reported per product. To see changes made to your account (for example, user management changes), you can query NrAuditEvent. Query examples The View your usage UI displays your data usage and billable user count. If you need more detail than that UI provides, you can use these NRQL queries. For definitions of some of the attributes used in these queries, see Attributes. Data usage queries Here are some data usage query examples: Daily data usage This query totals your billable ingested data, and displays a daily value for the past three months: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago TIMESERIES 1 day Copy Daily usage by source This query totals your billable ingested data, and displays a daily value for the past three months faceted by the source: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago FACET usageMetric TIMESERIES 1 day Copy Metrics ingest by source This query breaks down Metric data by the top ten metric names. You could also facet by appName or host to adjust the analysis. FROM Metric SELECT bytecountestimate()/10e8 as 'GB Estimate' SINCE '2021-04-01' UNTIL '2021-04-08' FACET metricName LIMIT 10 TIMESERIES 1 day Copy Month-to-date data usage This query shows the current full user count. In other words, it shows how much you'd be billed for your data for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE this month Copy Month-to-date estimated data cost This query shows the estimated cost of your ingested data: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month Copy User count queries Here are some user-related query examples. For details on how users are counted, see User count calculations. Month-to-date full users This query shows the billable full users for the month. In other words, it shows how much you'd be billed for your users for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(usersBillable) SINCE this month Copy This query shows how many full users were counted by hour. This is useful for seeing how the full user count changed over time. from NrConsumption SELECT max(FullUsers) SINCE 10 days ago TIMESERIES 1 hour Copy Projected monthly full user count This query shows a projected count of monthly users. This query would not be good for using in a dashboard; it requires values based on a) the days remaining in the month, b) the start of the month. Here's an example querying the projected end-of-month count with 10 days left in that month: FROM NrMTDConsumption SELECT predictLinear(FullUsers, 10 days) SINCE '2020-09-01' Copy Count full users and basic users The usage UI shows the count of full users and basic users. The query used is: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric Copy To see the count of full and basic users over time: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric TIMESERIES 1 hour Copy Set usage alerts To help manage your billable data, you can set alerts to notify you of unexpected increases in usage. Learn how to create alerts with NRQL queries here. Caution When creating alert conditions, you should use the Event Timer method, which works very well with infrequent data. Here are some NRQL alert condition examples. For attribute definitions, see Attributes. Ingested gigabytes exceed a fixed value This query will create an alert when your hourly usage exceeds a fixed value: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy If you have multiple child accounts, you may want to set threshold alerts for a specific subaccount: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' AND consumingAccountId = YOUR_CHILD-ACCOUNT_ID Copy Usage exceeds fixed threshold for GBs This query will create an alert when your usage exceeds fixed monthly threshold for GBs: FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy Usage exceeds fixed threshold for users This query will create an alert when your usage exceeds fixed monthly threshold for billable users: FROM NrMTDConsumption SELECT latest(usersBillable) Copy Usage exceeds fixed threshold for estimated cost This query will create an alert when your usage exceeds fixed threshold for estimated cost: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month Copy Available attributes Below are some of the important attributes attached to usage events. Attribute Description productLine The category of usage. There are four options: DataPlatform, FullStackObservability, IncidentIntelligence, or ProactiveDetection. For more details about these categories, see New Relic platform. metric Consolidates multiple categories of usage into a single metric. Helpful when faceting by productLine. consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. estimatedCost Calculates a cost estimate based on usage and metric cost. This is an estimate of costs to date, not your monthly invoice. For more attributes, see the data dictionary.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 546.344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>and</em> alert on <em>billing</em>&#x2F;usage data",
        "sections": "Query <em>and</em> alert on <em>billing</em>&#x2F;usage data",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "body": "For <em>accounts</em> on our <em>New</em> <em>Relic</em> <em>One</em> <em>pricing</em> plan, we provide a View your usage UI for understanding <em>billing</em>-related usage and a Manage your data UI for managing <em>billing</em>-related data. Additionally, you can: Query your usage data to get more detail than is available in the UI. Set up NRQL alert"
      },
      "id": "6175f12b64441f53a35fc21c"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 382.97574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " and permissions work depends on which user model you&#x27;re on: Original user model roles <em>New</em> <em>Relic</em> <em>One</em> user model roles If you think your permissions are preventing you from accessing something, talk to your <em>New</em> <em>Relic</em> administrators. <em>Account</em> access If you&#x27;re having trouble finding an <em>account</em>, here"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.38007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to automated user management (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to automated user management (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "<em>New</em> <em>Relic</em> lets you set up automated user management (AUM), which allows you to import, update, and deactivate your <em>New</em> <em>Relic</em> users from an identity provider, like Azure AD, Okta, or <em>One</em>Login. Benefits Before reading the benefits of automated user management, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts": [
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, who have access to our more curated UI experiences. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 697.609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>One</em> <em>pricing</em> <em>and</em> <em>billing</em> ",
        "sections": "<em>New</em> <em>Relic</em> <em>One</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "body": " <em>billing</em> and usage in the UI, see <em>Pricing</em> and <em>billing</em> UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. <em>Billing</em> calculation details For <em>accounts</em> on <em>New</em> <em>Relic</em> <em>One</em> <em>pricing</em>, some high-level <em>billing</em> information is displayed in the UI. Here"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 382.97574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " and permissions work depends on which user model you&#x27;re on: Original user model roles <em>New</em> <em>Relic</em> <em>One</em> user model roles If you think your permissions are preventing you from accessing something, talk to your <em>New</em> <em>Relic</em> administrators. <em>Account</em> access If you&#x27;re having trouble finding an <em>account</em>, here"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.38007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to automated user management (AUM) <em>and</em> single-sign on (SSO)",
        "sections": "Introduction to automated user management (AUM) <em>and</em> single-sign on (SSO)",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": "<em>New</em> <em>Relic</em> lets you set up automated user management (AUM), which allows you to import, update, and deactivate your <em>New</em> <em>Relic</em> users from an identity provider, like Azure AD, Okta, or <em>One</em>Login. Benefits Before reading the benefits of automated user management, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles": [
    {
      "sections": [
        "Tutorials on user management tasks: access grants, custom roles, and adding users (New Relic One user model)",
        "Requirements",
        "Overview",
        "Add users",
        "View available accounts",
        "Grant access to accounts and roles",
        "Create custom role",
        "Add users to groups"
      ],
      "title": "Tutorials on user management tasks: access grants, custom roles, and adding users (New Relic One user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "b1e5f303b6446f264c9d8c5020871a6990e052fd",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/tutorial-add-new-user-groups-roles-new-relic-one-user-model/",
      "published_at": "2021-10-24T20:31:18Z",
      "updated_at": "2021-10-07T07:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This tutorial will walk you through some common procedures for managing users on the New Relic One user model. Requirements Some notes on requirements: This tutorial is for users on our New Relic One user model. Creating access grants requires Pro or Enterprise edition. For details, see user management requirements. Role requirements: Using the Organization and access UI to manage group access requires Authentication domain manager and Organization manager roles. Using the User management UI to add/edit users requires Authentication domain manager role. Overview Before using this tutorial, we recommend you check out: Understand what an access grant is Videos that show the user management UI in action This tutorial will walk you through how to: Add users View available accounts Grant groups access to roles and accounts Create custom roles Add users to groups Add users Adding users to New Relic is a separate process from creating access grants. In other words, you can do either procedure first. The key point is that if you're trying to give a user access to a role or an account that they don't yet have, they won't have that access until they're both a) in a group and b) that group has the correct access grant (access to a specific role on a specific account). There are two ways to add users: With the user management UI (described below) With automated user management, also known as SCIM provisioning: use of this method means that groups are defined in your identity provider and so you can't edit a user's group from the New Relic UI. To add users from the UI: From the top right of the New Relic UI, click the account dropdown, click Administration, and click User management. If you have multiple authentication domains, choose one from the authentication domain dropdown. Click Add user. Complete the process, including choosing user type and user group. Relevant tips: For how to bulk edit users' user type, see Edit user type. When choosing a group, you can choose either one of our default groups or a custom group that you've defined an access grant for. For more on creating access grants, keep reading. View available accounts When thinking about creating access grants for granting access to different accounts, it can help you to understand what accounts there are in your organization. To view the accounts in your organization: go to the account dropdown, click Administration, click Organizations and access, and then click Accounts. Grant access to accounts and roles Groups are used to group your users and manage what your users are able to do in New Relic: by creating an access grant, you assign a group access to a) a specific role on b) a specific account. By default, organizations on the New Relic One user model have two available groups: Admin and User. These default groups automatically have access to specific standard roles and are assigned to the account in which they were initially added. To view existing access grants: from the account dropdown, click Administration, and then click Organization and access. Even if you haven't created any custom access grants, you will see the default-created grants there that are present for our default groups. This is what you might see when you go to the Organization and access UI and view groups. The default available groups of Admin and User have access grants automatically created that grant users in those groups access to the roles associated with those groups and to the initial account those users were added in. To create a new access grant that gives a user group access to a role and an account: From the Organization and access UI, click Group access. If you don't see that UI, it may be because you're logged in with an original user model record, or because you don't have the ability to manage users. For more on such factors, see Factors affecting access. Choose one of the following: Existing: If there is already a group you want to add an access grant to, you can use this. For example, if you want to gives users in the default Admin or User group access to new accounts, you might choose this and then select the Admin Default or Admin User role. New: If you need to create a new group, choose this. You'll also need to choose the authentication domain that group is inside of (for an explanation of what \"Default\" means, see Default groups. If your organization strategy requires a good amount of restrictions over access to accounts and access to roles, you'll probably need to create a good amount of access grants. Next, under Access grant, you'll choose one of following: Account: Choose this to be able to select from the roles that are account-scoped. These are the roles that have to do with using and configuring our platform features (and not about organization and user management). Organization: Choose this to be able to select from the roles that are organization-scoped. These are the roles that govern organization- and user management. (Note that these users must also already belong to an account-scoped role. This is true for most users but if it's not, you may see a message that the user doesn't belong to an organization.) Select the Role you want to assign. Roles are organization-wide, so regardless of the authentication domain you're in, you have access to our standard roles and any custom roles you've created. For tips on selecting roles, see the tips after these instructions. Select the Account you want to add access to from the dropdown. If you don't see an account that you'd expect to see, this may be for a few reasons. One is that you yourself don't have the proper permissions for that account. Another is that that account is not actually in your organization. For more information, see Factors affecting access. If you are still having problems, talk to your account representative. If you want to continue adding more grants for that same group, select Add another at the bottom before clicking Add access. When you're done, if your users are already in the group you've added the grant to, they should have access within a few minutes (although for EU region New Relic accounts, this can take up to twenty minutes or so). If your users are not yet in that group (which would be true if you just created an access grant with a new group), you'll need to go to the User management UI and add that group to those users. Some tips for using this UI: Note that if a user has the organization-scoped Organization manager and/or Authentication domain manager roles, which is true of users in the default Admin group, those users will always have those capabilities because those are organization-scoped abilities. This means that when you go to add those users to another account, you only have to add an account-scoped role, and not an organization-scoped role. In other words, once the users in a group have those organization-scoped roles, they will always have them in that organization unless removed. When selecting from amongst our standard roles, it's important to understand the difference between All product admin and Standard user. In short, All product admin is more popular a choice because it gives the ability to configure platform features. If you wanted to have your users be able to use platform features but not configure them, you'd choose Standard user. If your users are managed via automated user management, there are some restrictions that may apply. For example, you wouldn't be able to use the User management UI to add users to groups, because groups are managed and imported from your identity provider. If a group has basic users in it, their basic user status overrides any group-related restrictions. Create custom role When creating an access grant, you can use our standard roles, or you can create your own roles with unique sets of capabilities. To view existing roles: from the account dropdown, click Administration, then click Organization and access, and then click Roles. To create a custom role, click Add new custom role. Review the list of available capabilities and decide which ones your custom role needs. For more information about how roles and capabilities work, see Capabilities. Once you're finished creating a custom role, you will probably want to use it in a new access grant. Add users to groups In the user management UI, you can see your users and the groups they've been assigned to. Your users only have access to the access grants associated with the groups they've been added to. To view users and see their groups: from the account dropdown, click Administration, and click User management. If you don’t see that option, review the requirements. Groups reside within the boundaries of an authentication domain. If your organization has more than one authentication domain, the domain switcher in the top left will show which one you’re in. To add a user, click Add user. Complete the prompts in the UI, including choosing the user type and group. Any custom groups you’ve added should be available from the group dropdown. If the custom group you choose has been granted access to a role and an account, once you add the user to that group, that user will now have access. To edit a user’s group or other details: click on the user you want to edit and make changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 461.4705,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tutorials on <em>user</em> <em>management</em> tasks: access grants, custom roles, <em>and</em> adding <em>users</em> (<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model)",
        "sections": "Tutorials on <em>user</em> <em>management</em> tasks: access grants, custom roles, <em>and</em> adding <em>users</em> (<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model)",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> <em>management</em>",
        "body": " and so you can&#x27;t edit a <em>user</em>&#x27;s group from the <em>New</em> <em>Relic</em> UI. To add users from the UI: From the top right of the <em>New</em> <em>Relic</em> UI, click the <em>account</em> dropdown, click Administration, and click <em>User</em> <em>management</em>. If you have multiple authentication domains, choose <em>one</em> from the authentication domain dropdown"
      },
      "id": "603e7d67196a671e26a83dc5"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, who have access to our more curated UI experiences. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 413.14212,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em> ",
        "sections": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em>",
        "body": " want. If all sources are removed, no data is sent to Incident Intelligence. Full <em>user</em> count <em>billing</em> details For <em>accounts</em> with <em>New</em> <em>Relic</em> <em>One</em> pricing, the monthly count of provisioned full users is <em>one</em> <em>billing</em> factor. To give an example: if you&#x27;re on the Pro pricing edition and your organization has"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Introduction to user management",
        "New pricing plan",
        "User management docs"
      ],
      "title": "Introduction to user management",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "6c2f39333fa3c6931fe616669244cb44f183a167",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/introduction-managing-users/",
      "published_at": "2021-10-24T23:50:03Z",
      "updated_at": "2021-09-14T10:25:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New pricing plan This doc is for users on our New Relic One user model. Some important things to note before starting: The docs in this section are for managing users on the New Relic One user model. Learn about user models. Note that this is a separate topic from our two different pricing plans. For managing users on our original user model, see Original users. User management docs Here are our main docs for managing these users: User model/structure: learn some basic aspects of our user model, such as what basic users and full users are, how groups (like Admin and User) work, and how roles and capabilities work. How to manage users: an overview of user management concepts, where to manage users in the UI, and some common user management tasks. Authentication domain settings: configure an authentication domain, which governs how your users are added to New Relic (manually versus SCIM provisioning), the authentication method they use (manual login versus SAML SSO), managing how basic users become full users, and user session settings. For an overview of SAML SSO and SCIM options, see Introduction to SAML and SCIM. A tutorial on how to create access grants, which is how you give users access to roles and accounts. Want to understand how user count affects billing? See User-related billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 403.05966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>user</em> <em>management</em>",
        "sections": "Introduction to <em>user</em> <em>management</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> <em>management</em>",
        "body": "<em>New</em> pricing plan This doc is for users on our <em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model. Some important things to note before starting: The docs in this section are for managing users on the <em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model. Learn about <em>user</em> models. Note that this is a separate topic from our two different pricing plans"
      },
      "id": "6043f3c4196a67a215960f3c"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-user-management/authentication-domains-saml-sso-scim-more": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 473.59973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to automated user management (AUM) <em>and</em> single-sign on (<em>SSO</em>)",
        "sections": "Introduction to automated user management (AUM) <em>and</em> single-sign on (<em>SSO</em>)",
        "tags": "Accounts <em>and</em> billing",
        "body": " to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the <em>Authentication</em> <em>domain</em> manager and the Organization manager role (users in the default group Admin have these). Supports <em>SAML</em> 2.0 standard for single sign on (<em>SSO</em>). Supports <em>SCIM</em>"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic user versus full user)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-10-24T20:29:42Z",
      "updated_at": "2021-10-07T01:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full user) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic user versus full user) Note that there are limits around how many times full users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.75317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Set</em> up <em>SAML</em> <em>SSO</em> <em>and</em>&#x2F;or <em>SCIM</em> provisioning",
        "tags": "Accounts <em>and</em> billing",
        "body": ", and access grants, and to <em>set</em> up <em>SAML</em> <em>SSO</em> and <em>SCIM</em> provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can&#x27;t see these UI pages, it may be because you&#x27;re on our original user model or because you don&#x27;t have the required user"
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "sections": [
        "Okta SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Okta's New Relic app",
        "Step 3. Configure provisioning",
        "Step 4. Assign users and groups",
        "Assignments tab",
        "Push groups tab",
        "Step 5. Manage user type",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO",
        "Additional considerations",
        "Moving users between groups"
      ],
      "title": "Okta SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "7a00399a6ce11aaa2cb52046f994a80f5986c0e4",
      "image": "https://docs.newrelic.com/static/3f3318e1dc8c9049231c207a7b4e5c54/c1b63/okta-add-user-type-to-profile.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration/",
      "published_at": "2021-10-24T23:01:21Z",
      "updated_at": "2021-10-07T19:07:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up Okta's New Relic app Next, set up Okta's New Relic SCIM/SSO application: Go to okta.com/ and sign in with an account that has administrator permissions. From the Okta home page, click on Admin. From the Okta admin Dashboard, choose the Applications page. Click Browse app catalog and search for \"New Relic by organization\" (not \"New Relic by account\") and choose that from the results. From the New Relic by Organization page, click on Add. From the Add New Relic by organization page, check the two Application visibility \"Do not display...\" checkboxes and click on Done. We will make the application visible later after configuration is complete and provisioning has begun. Step 3. Configure provisioning Configure Okta's New Relic SCIM/SSO application to automatically provision your users to New Relic: From the app, click on the Provisioning tab. From the Integration form, click on Configure API integration. Check the Enable API integration checkbox. Take the API token you saved in Step 1 and input it in the Okta New Relic app's API token field. Optional: click on Test API credentials to verify a SCIM connection can be established to New Relic. If a connection can be established, a success message is displayed. If a connection was not established, re-enter the API Token and try the test again. Click Save. Note that the save process does a test of the API credentials. If a connection is not established to New Relic, the save will fail. On the newly displayed To App form, click on Edit. Check the Enable checkbox in the Create users, Update user attributes, and Deactivate users sections. Click Save. Step 4. Assign users and groups Next, you'll assign users in Okta's New Relic application. Assigning users is done using two different tabs in the app. We recommend having your New Relic users selected on the Assignments tab and their associated groups selected on the Push groups tab. Assignments tab In the app, click on the Assignments tab. From the Assignments form, click on Assign. From the pop up menu, click on Assign to groups. From the Assign ... to groups form, click on Assign for the group you wish to assign to the application. Highly recommended: Set your users' time zones in Okta. The time zone affects how date/times for that user are shown in New Relic. Users without a time zone configured will be shown in UTC time in New Relic. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). There are several ways in Okta to assign users' time zone, so consult the Okta docs for more information if needed. Here is one way to do this in the Assignments tab: In the Time zone field, enter the default time zone for members of the group. Click on Save and go back. Repeat the steps to add a group until all desired groups have been assigned to the application. Click Done. Push groups tab In the app, click on the Push groups tab. From the Push groups form, click on Push groups. From the pop up menu, click on Find groups by name. From the Push groups to... form, in the search field enter the first few characters of the name of the group you want to send to New Relic. Leave the Push group memberships immediately checkbox checked. Click on your group in the pop up search results list. In the Match result & push action section, No match found should be displayed, meaning that the group does not yet exist at New Relic. Leave the selector set to Create group and leave the default name for the group. The intent here is to have a group of the same name created at New Relic. If this is the last group you wish to send to New Relic, click on Save. Otherwise, if you have more groups to configure, click on Save & add another and repeat the steps to add a group. When you've added one or more groups, you should be able to see the users you've added by going to the User management UI page. Step 5. Manage user type If your organization is on New Relic One pricing, the count of your full users is a billing factor. To change some of your users to free basic users, you have two choices: Manage user type from New Relic using the User management UI, OR Manage user type from Okta (described below). To manage your users' user type from Okta: Go to the New Relic authentication domain UI and click Enable Manage user type with SCIM. Note that when this is enabled, you can’t manage user type from the New Relic UI and can only manage it from Okta. Go into your Okta instance. The rest of these instructions are done from Okta. Next, you'll configure Okta to be able to send a new attribute nrUserType. Steps: Go to the Profile editor. In the Attributes section, click Add attribute. Set your settings to match the screenshot below (except for the variable name, which is created automatically). The only two fields that must match exactly are External name and External namespace. The value for External namespace must be urn:ietf:params:scim:schemas:extension:newrelic:2.0:User Next, you'll configure your Okta user profile to have this field. Steps: In the Profile editor, go to Users and click the User (default) profile. Add a new New Relic user type attribute to that profile (see Okta user profile instructions). How you set this will depend on your own setup and preferences for defining user type. Note that the expected values for user type are Basic user and Full user. Below is an example with information filled in. In the People section, define the user type for your users. How you do this will depend on your setup and preferences. For example, you may choose to set this manually by setting each user’s user type, or you may use Okta to manage these in bulk. Next, you’ll set up mapping for that attribute. Steps: In the app's Provisioning section, click Unmapped attributes. Go into edit mode for the unmapped New Relic user type attribute. Configure it based on how you want to set the user type. To learn about why you'd set them as basic users or full users, see User type. Learn more about Okta attribute mappings. Step 6. Assign access grants Once these steps are completed, you're able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO, see the SAML instructions. Additional considerations In this section we discuss other important things to know when using the New Relic SCIM/SSO application. This section includes tips to work around potential issues that could cause undesired results when integrating between Okta and New Relic. Moving users between groups When moving a user between groups, you must manually synchronize the old group's membership with New Relic. This is because Okta does not send a SCIM request to remove a user from a group. So, the admin needs to push the old group's membership to New Relic manually to inform New Relic that the user is no longer a member of the old group. Here are the steps to manually synchronize a group's membership: From the New Relic SCIM/SSO application page, click on the Push groups tab. From the Push groups form, open the pick list on the desired group's button under the Push Status column. From the displayed pick list on the button, click Push now. This causes an immediate synchronization of the group's membership with New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Okta <em>SCIM</em>&#x2F;<em>SSO</em> application configuration",
        "sections": "Step 1. Create <em>authentication</em> <em>domain</em> <em>and</em> enable <em>SCIM</em>",
        "tags": "Accounts <em>and</em> billing",
        "body": " requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create <em>authentication</em> <em>domain</em> and enable <em>SCIM</em> To get to the New Relic <em>authentication</em> <em>domain</em> UI: From one.newrelic.com, click the account dropdown, click Organization and access"
      },
      "id": "6043f5cae7b9d2758b579a0c"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-user-management/introduction-managing-users": [
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic user versus full user)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-10-24T20:29:42Z",
      "updated_at": "2021-10-07T01:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full user) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic user versus full user) Note that there are limits around how many times full users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 463.58768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to <em>manage</em> <em>users</em>",
        "sections": "Give <em>users</em> access to <em>accounts</em> <em>and</em> roles (access grants)",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> <em>management</em>",
        "body": "For users on our <em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model, we provide various <em>user</em> <em>management</em> features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to <em>user</em> groups Create custom <em>user</em> groups Grant <em>user</em> groups access to specific roles and <em>accounts</em> Important"
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "sections": [
        "Tutorials on user management tasks: access grants, custom roles, and adding users (New Relic One user model)",
        "Requirements",
        "Overview",
        "Add users",
        "View available accounts",
        "Grant access to accounts and roles",
        "Create custom role",
        "Add users to groups"
      ],
      "title": "Tutorials on user management tasks: access grants, custom roles, and adding users (New Relic One user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "b1e5f303b6446f264c9d8c5020871a6990e052fd",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/tutorial-add-new-user-groups-roles-new-relic-one-user-model/",
      "published_at": "2021-10-24T20:31:18Z",
      "updated_at": "2021-10-07T07:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This tutorial will walk you through some common procedures for managing users on the New Relic One user model. Requirements Some notes on requirements: This tutorial is for users on our New Relic One user model. Creating access grants requires Pro or Enterprise edition. For details, see user management requirements. Role requirements: Using the Organization and access UI to manage group access requires Authentication domain manager and Organization manager roles. Using the User management UI to add/edit users requires Authentication domain manager role. Overview Before using this tutorial, we recommend you check out: Understand what an access grant is Videos that show the user management UI in action This tutorial will walk you through how to: Add users View available accounts Grant groups access to roles and accounts Create custom roles Add users to groups Add users Adding users to New Relic is a separate process from creating access grants. In other words, you can do either procedure first. The key point is that if you're trying to give a user access to a role or an account that they don't yet have, they won't have that access until they're both a) in a group and b) that group has the correct access grant (access to a specific role on a specific account). There are two ways to add users: With the user management UI (described below) With automated user management, also known as SCIM provisioning: use of this method means that groups are defined in your identity provider and so you can't edit a user's group from the New Relic UI. To add users from the UI: From the top right of the New Relic UI, click the account dropdown, click Administration, and click User management. If you have multiple authentication domains, choose one from the authentication domain dropdown. Click Add user. Complete the process, including choosing user type and user group. Relevant tips: For how to bulk edit users' user type, see Edit user type. When choosing a group, you can choose either one of our default groups or a custom group that you've defined an access grant for. For more on creating access grants, keep reading. View available accounts When thinking about creating access grants for granting access to different accounts, it can help you to understand what accounts there are in your organization. To view the accounts in your organization: go to the account dropdown, click Administration, click Organizations and access, and then click Accounts. Grant access to accounts and roles Groups are used to group your users and manage what your users are able to do in New Relic: by creating an access grant, you assign a group access to a) a specific role on b) a specific account. By default, organizations on the New Relic One user model have two available groups: Admin and User. These default groups automatically have access to specific standard roles and are assigned to the account in which they were initially added. To view existing access grants: from the account dropdown, click Administration, and then click Organization and access. Even if you haven't created any custom access grants, you will see the default-created grants there that are present for our default groups. This is what you might see when you go to the Organization and access UI and view groups. The default available groups of Admin and User have access grants automatically created that grant users in those groups access to the roles associated with those groups and to the initial account those users were added in. To create a new access grant that gives a user group access to a role and an account: From the Organization and access UI, click Group access. If you don't see that UI, it may be because you're logged in with an original user model record, or because you don't have the ability to manage users. For more on such factors, see Factors affecting access. Choose one of the following: Existing: If there is already a group you want to add an access grant to, you can use this. For example, if you want to gives users in the default Admin or User group access to new accounts, you might choose this and then select the Admin Default or Admin User role. New: If you need to create a new group, choose this. You'll also need to choose the authentication domain that group is inside of (for an explanation of what \"Default\" means, see Default groups. If your organization strategy requires a good amount of restrictions over access to accounts and access to roles, you'll probably need to create a good amount of access grants. Next, under Access grant, you'll choose one of following: Account: Choose this to be able to select from the roles that are account-scoped. These are the roles that have to do with using and configuring our platform features (and not about organization and user management). Organization: Choose this to be able to select from the roles that are organization-scoped. These are the roles that govern organization- and user management. (Note that these users must also already belong to an account-scoped role. This is true for most users but if it's not, you may see a message that the user doesn't belong to an organization.) Select the Role you want to assign. Roles are organization-wide, so regardless of the authentication domain you're in, you have access to our standard roles and any custom roles you've created. For tips on selecting roles, see the tips after these instructions. Select the Account you want to add access to from the dropdown. If you don't see an account that you'd expect to see, this may be for a few reasons. One is that you yourself don't have the proper permissions for that account. Another is that that account is not actually in your organization. For more information, see Factors affecting access. If you are still having problems, talk to your account representative. If you want to continue adding more grants for that same group, select Add another at the bottom before clicking Add access. When you're done, if your users are already in the group you've added the grant to, they should have access within a few minutes (although for EU region New Relic accounts, this can take up to twenty minutes or so). If your users are not yet in that group (which would be true if you just created an access grant with a new group), you'll need to go to the User management UI and add that group to those users. Some tips for using this UI: Note that if a user has the organization-scoped Organization manager and/or Authentication domain manager roles, which is true of users in the default Admin group, those users will always have those capabilities because those are organization-scoped abilities. This means that when you go to add those users to another account, you only have to add an account-scoped role, and not an organization-scoped role. In other words, once the users in a group have those organization-scoped roles, they will always have them in that organization unless removed. When selecting from amongst our standard roles, it's important to understand the difference between All product admin and Standard user. In short, All product admin is more popular a choice because it gives the ability to configure platform features. If you wanted to have your users be able to use platform features but not configure them, you'd choose Standard user. If your users are managed via automated user management, there are some restrictions that may apply. For example, you wouldn't be able to use the User management UI to add users to groups, because groups are managed and imported from your identity provider. If a group has basic users in it, their basic user status overrides any group-related restrictions. Create custom role When creating an access grant, you can use our standard roles, or you can create your own roles with unique sets of capabilities. To view existing roles: from the account dropdown, click Administration, then click Organization and access, and then click Roles. To create a custom role, click Add new custom role. Review the list of available capabilities and decide which ones your custom role needs. For more information about how roles and capabilities work, see Capabilities. Once you're finished creating a custom role, you will probably want to use it in a new access grant. Add users to groups In the user management UI, you can see your users and the groups they've been assigned to. Your users only have access to the access grants associated with the groups they've been added to. To view users and see their groups: from the account dropdown, click Administration, and click User management. If you don’t see that option, review the requirements. Groups reside within the boundaries of an authentication domain. If your organization has more than one authentication domain, the domain switcher in the top left will show which one you’re in. To add a user, click Add user. Complete the prompts in the UI, including choosing the user type and group. Any custom groups you’ve added should be available from the group dropdown. If the custom group you choose has been granted access to a role and an account, once you add the user to that group, that user will now have access. To edit a user’s group or other details: click on the user you want to edit and make changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 461.47046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tutorials on <em>user</em> <em>management</em> tasks: access grants, custom roles, <em>and</em> adding <em>users</em> (<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model)",
        "sections": "Tutorials on <em>user</em> <em>management</em> tasks: access grants, custom roles, <em>and</em> adding <em>users</em> (<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model)",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> <em>management</em>",
        "body": " and so you can&#x27;t edit a <em>user</em>&#x27;s group from the <em>New</em> <em>Relic</em> UI. To add users from the UI: From the top right of the <em>New</em> <em>Relic</em> UI, click the <em>account</em> dropdown, click Administration, and click <em>User</em> <em>management</em>. If you have multiple authentication domains, choose <em>one</em> from the authentication domain dropdown"
      },
      "id": "603e7d67196a671e26a83dc5"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, who have access to our more curated UI experiences. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 413.14188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em> ",
        "sections": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em>",
        "body": " want. If all sources are removed, no data is sent to Incident Intelligence. Full <em>user</em> count <em>billing</em> details For <em>accounts</em> with <em>New</em> <em>Relic</em> <em>One</em> pricing, the monthly count of provisioned full users is <em>one</em> <em>billing</em> factor. To give an example: if you&#x27;re on the Pro pricing edition and your organization has"
      },
      "id": "6043f69a64441f7b26378eda"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-user-management/introduction-saml-scim": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2717.5815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to automated user management (AUM) <em>and</em> single-sign on (<em>SSO</em>)",
        "sections": "Introduction to automated user management (AUM) <em>and</em> single-sign on (<em>SSO</em>)",
        "tags": "Accounts <em>and</em> billing",
        "body": " with <em>SAML</em> <em>SSO</em> and <em>SCIM</em>. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic user versus full user)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-10-24T20:29:42Z",
      "updated_at": "2021-10-07T01:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full user) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic user versus full user) Note that there are limits around how many times full users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1389.2582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Set up <em>SAML</em> <em>SSO</em> <em>and</em>&#x2F;<em>or</em> <em>SCIM</em> provisioning",
        "tags": "Accounts <em>and</em> billing",
        "body": " type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up <em>SAML</em> <em>SSO</em> and&#x2F;or <em>SCIM</em> provisioning See <em>Get</em> <em>started</em> with <em>SAML</em> <em>SSO</em> or <em>SCIM</em>"
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "image": "https://docs.newrelic.com/static/49612c40721bfa27afa90fafcba0e95c/c1b63/login-multiple-accounts-found.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-users-roles/users-roles-original-user-model/",
      "sections": [
        "Users, roles, permissions (original user model)",
        "Requirements",
        "Updates about our new user model",
        "View and manage users in UI",
        "Tip",
        "Add a new user",
        "Important",
        "Manage user type (basic vs full) and full user upgrades",
        "Determine full user count",
        "Enable SAML SSO and/or SCIM",
        "View pending SAML SSO users",
        "Update account roles",
        "Delete a user",
        "Update the account Owner",
        "User types: basic user and full user",
        "Account roles",
        "Add-on roles",
        "View roles",
        "Assign a managed role",
        "Create a custom role",
        "Assign a custom role",
        "Edit or delete a custom role",
        "Account permissions",
        "Alert permissions",
        "APM permissions",
        "Browser permissions",
        "Infrastructure permissions",
        "Insights permissions",
        "Mobile permissions",
        "Synthetics permissions",
        "Workloads permissions"
      ],
      "published_at": "2021-10-24T23:52:40Z",
      "title": "Users, roles, permissions (original user model)",
      "updated_at": "2021-10-24T23:52:40Z",
      "type": "docs",
      "external_id": "95ae42f3474b43dec394245cfc3e23628449a1ed",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our original user model, an introduction to how the user model works, including user roles and permissions, and how to add and manage users. Requirements This doc and the surrounding section of docs shows you how to manage users on our original user model. If you were a New Relic customer before July 30 2020 and haven't migrated your users to the new model, your users are on our original user model (and not the New Relic One model). If you're an admin and want to see if you have users on the original model: If you can see users in the Users and roles UI, those users are on our original user model. Updates about our new user model In July of 2020, we released a new user model called the New Relic One user model, which offers many benefits in terms of how you manage your organization and users. At first this was only available to new sign-ups but over time we've been migrating more older customers to the new model. Some older customers are able to migrate their users on their own. We'll continue working on migrating users to the new model until the original model is fully deprecated. One impact of the new user model is that it's possible now for users to have multiple logins associated with the same email. For example, a user with access to multiple organizations (like a contractor) may have their user record updated to the new user model in one organization, resulting in them having their original login method and records and a New Relic One user model record. This may result in the user being logged in to New Relic and not being able to find an account they're looking for. For more on that, see Factors affecting access. If a user's email is associated with more than one login, they'll see a \"multiple accounts found\" note when logging in. View and manage users in UI If your New Relic account has users on our original user model, you can use the Users and roles UI. To access this: Click the account dropdown, click Account settings, and then click Users and roles. Some features in the UI are visible only to account Owners and Admins. Tip You can also use the New Relic REST API to obtain a list of everyone and their roles in your New Relic account. Here are some instructions and tips for adding and managing users via the UI: Add a new user Tip Owner or Admins To add a new user to your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. In the upper right corner, click New user. Enter the appropriate name and email address. Select their base role as either Admin, User, or Restricted. Select Add user. The new user will receive an email notification automatically from New Relic. Important New Relic recommends a maximum of 1,000 accounts per user. Additional accounts may result in limited access to some New Relic features. Manage user type (basic vs full) and full user upgrades Note that billing-related aspects of your count of full users only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. To update a user's type (basic user versus full user): Go to: account dropdown > Account settings > Users and roles > Users. Either select a user and edit their type or bulk update the type for multiple useres. To control how basic users upgrade to become full users, from the Users and roles UI you can select Access requests. You have two options: Automatic approval: With this option, basic users can automatically upgrade to be full users. This option allows your users to more easily troubleshoot problems. Require review: With this option, your admins get a notification when basic users request an upgrade and must upgrade them first. You can approve them either from the notification email or from the user's entry in the Users and roles UI. For more about user type, see User type. Determine full user count If you're on New Relic One pricing plan, your count of full users is a factor in your billing. To see your count of full users, click the account dropdown and then click View your usage. If you have a parent/child account structure (including a customer partnership), your count of full users may not match what you see when you go to Account settings > Users and roles. To examine users on a parent account's children accounts, go to a parent account's Account settings UI page, click on a child account, and go to that account's Users and roles UI page. Enable SAML SSO and/or SCIM For an introduction to using SAML SSO and/or SCIM provisioning, see Get started with SAML SSO or SCIM. View pending SAML SSO users New Relic accounts with SAML Single Sign On (SSO) may have a list of Pending users. These are individuals who have been added to the SAML-enabled account but have not yet confirmed. Update account roles Tip Owner or Admins To update a person's role and capabilities: Go to: account dropdown > Account settings > Users and roles > Users. Select the person's name. Under Roles and capabilities, select their base role as Admin, User, or Restricted. The account Owner must update the Owner role. Delete a user Tip Owner or Admins To remove a user from your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. Click on the name of the person you would like to update. Click Delete User. Tip You can also add, update, or delete users in bulk via CSV file. Update the account Owner A New Relic account can have only one Owner role at any time. You must be the current account Owner to change your role to someone who currently has an Admin role for the account. If the current Owner is unavailable, contact your account representative at New Relic, or get support at support.newrelic.com. You cannot delete or remove your assigned Owner role. However, if the account has one or more Admin role, you can change an Owner to an Admin. Go to: account dropdown > Account settings > Account > Users and roles. Above the Active users list, select Change owner. If an account has no Admins, this button won't be available. Select someone who currently has an Admin role for the account. Refresh the page for changes to take effect. Your previous Owner role automatically changes to an Admin role. To find out who is the current assigned Owner: Go to: account dropdown > Account settings > Account > Users and roles. View the Base role column to locate your account Owner. The Change owner button is only visible to the current account Owner. If the current Owner is unable to change the role (for example, that person no longer is with your organization), contact your account representative at New Relic, or get support at support.newrelic.com. User types: basic user and full user Important This section is for users on our original user model. If you're on our New Relic One user model, see our New Relic One user docs. Starting March 2021, we ended the preview period for basic users on our original user model. The preview period gave these basic users the same permissions as full users. For more on this, see our Explorers Hub post on user type changes. The user type (basic user or full user) determines what features a user has access to. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. Basic user. Details: These users have access to basic features like setting up reporting of data, running queries of data, making custom charts and dashboards, and setting up alerts. They do not have access to our more curated observability UI experiences (for more details on feature access, see Capabilities). Depending on access request settings, basic users can either upgrade themselves to be full users or request upgrade access from admins. Full user. Details: Full users have access to everything (dependent on role restrictions), which includes our curated observability UI experiences, such as APM, infrastructure monitoring, browser monitoring, mobile monitoring, and synthetic monitors. For details, see Capabilities. For organizations on New Relic One pricing: these users are billable. The Standard edition includes one free full user and up to five total. If a user in your organization is set as a basic user in one account and a full user in another, the user is considered a full user and has full user access on all accounts in that organization. For how to edit a user's type, see Manage users. Account roles A New Relic account can have only one Owner. To share an account with other users in your organization, create Admins, Users, or Restricted Users. Account role Description Owner The person who initially creates the New Relic account and receives all billing queries. The Owner has complete access to all of the account information. Admin Can add, edit, and delete users, and can enable or set up features. User Can use (and optionally set up) New Relic features. In general, Admins take responsibility for setting up features, and Users and Restricted Users can use them. Restricted User One or more individuals who can view (but not set up or change) any New Relic features. The Restricted User role is useful, for example, for demos. You can change your New Relic session settings so that Restricted User logins do not time out, and then set the user interface to Kiosk mode. Add-on roles With add-on roles, you can grant variable levels of access to all users in your account, across the entire platform of New Relic products. This allows you to tailor your account permissions levels to suit the needs of Users and Restricted Users within your account. Giving a User or Restricted User add-on manager access to a product grants them the equivalent of Admin capabilities within the product. They will continue to have User or Restricted User capabilities for all other New Relic products. For example, you could make a software engineer in your company a User in most products, but assign Admin-level access to APM. For another example, you might assign the Nerdpack manager role to a user, and that gives them the ability to subscribe and unsubscribe New Relic One applications to an account. There are two types of add-on roles: Add-on Manager roles are available to grant permissions on a per-product basis. Giving a User or Restricted User managed add-on access to a product grants them the equivalent of Admin capabilities within the product. Custom add-on roles can grant feature-specific permissions across different New Relic products. For example, a group of Users could have the ability to acknowledge incidents and close violations in New Relic Alerts, but not have the ability to modify your existing alert preferences. Individuals on a parent account automatically have the same level of access for all the child accounts of the parent account. Below are options for managing both managed add-on roles and custom add-on roles: View roles To view the list of individuals assigned to your account and their current roles: Go to account dropdown > Account settings > Users and roles. Assign a managed role Tip Owner and Admins Managed add-on roles are available by default for each New Relic product. Adding a managed role for a user grants them Admin-level permissions for the assigned product. They cannot be edited or deleted. To assign a managed add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles. From the list of users associated with your account, select their name. Under Add-on roles, select the type of manager role for the user. To understand which capabilities may be added, use the Capabilities preview chart. Features in the Capabilities preview chart may not exactly match what features are available for your subscription level. Tip You can also add, update, or delete users in bulk by using a CSV file. Create a custom role To create a custom add-on role for your account: Go to account dropdown > Account settings > Users and roles > Roles. Select New custom add-on role. Select the capabilities necessary for the new custom role, then Create role. Assign a custom role Tip Owners and Admins You must create a custom role before assigning it to a user. To assign a custom add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles > Users. From the list of users associated with your account, select their name ]. Under Add-on roles, select a custom role for the user. Click Update user. Edit or delete a custom role Tip Owners and Admins You cannot edit or delete New Relic's default roles. However, you can edit or delete custom add-on roles for your account: Go to account dropdown > Account settings > Users and roles > Roles. From the Add-on roles list, select the custom add-on role, then select Edit role or Delete role as appropriate. Account permissions Here is a summary of user permissions. Individuals on a parent account automatically have the same level of access for all the child accounts of that parent account. However, they won't receive email notifications for alerts or weekly reports for child accounts unless they are explicitly granted permission on those accounts. Function Owner Admin User Restricted Maintain billing information. Change the account Owner. Add, update, and delete account Admins, Users, and Restricted Users. When the account Owner and Admins add individuals to the account, New Relic automatically sends them an email message. Update users' job titles and roles from Account settings in the New Relic UI. Create, modify and delete child accounts from Account settings in the New Relic UI. Update your own account information (name, password change or password reset request, default account, email preferences, etc.) from User preferences in the New Relic UI. Change someone else's password. You cannot reset passwords for anyone else on the account, even if you are an Owner or Admin. Instead, follow standard procedures to request a password reset from New Relic. View the list of individuals on the account from (account dropdown) > Account settings > Account > Summary in the New Relic UI. Manage flexible data retention. Subscribe and unsubscribe applications to New Relic One Add, update, and delete Proactive Detection configurations. Alert permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Alerts. To allow a User or Restricted User to execute any of these functions in New Relic Alerts, assign an Alerts add-on manager role. Admin and manager capabilities for Alerts include: Create or name alert policies. Specify incident preferences. Disable or define alert conditions. Provide runbook instructions. Select product targets. Alter alert condition thresholds. Create, modify, or delete notification channels. APM permissions Here is a summary of Admin and Add-on manager capabilities with APM. To allow a User or Restricted User to execute any of these functions in APM, assign an APM add-on manager role. Admin and manager capabilities for APM include: Remove applications from the New Relic UI. Delete app traces and error traces. Browser permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Browser. To allow a User or Restricted User to execute any of these functions in New Relic Browser, assign a Browser add-on manager role. Admin and manager capabilities for Browser include: Add, rename, or delete applications. Manage whitelists. Manage domain conditions. Infrastructure permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Infrastructure. To allow a User or Restricted User to execute any of these functions in New Relic Infrastructure, assign an Infrastructure manager role. Admin and manager capabilities for Infrastructure include: Create alert conditions in New Relic Infrastructure, including conditions for host not reporting. Add or modify integrations. Insights permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Insights. To allow a User or Restricted User to execute any of these functions, assign an Insights manager role. These functions include: Create, view, modify, or delete Query API keys or Insert API keys. Tip New Relic Insights includes permission levels to share your Insights dashboards with others. Mobile permissions To give permission to delete a mobile app from New Relic, you can assign an Admin or Mobile manager role. Synthetics permissions Here's a summary of Admin and Add-on manager capabilities with New Relic Synthetics. To allow a User or Restricted User to execute any of these functions in New Relic Synthetics, assign a Synthetics add-on manager role. Admin and manager capabilities for Synthetics include: Create, edit, or delete monitors. Edit monitor scripts. Create, edit, or delete private locations. Create, edit, or delete monitor downtimes. Create, view, edit, or delete secure credentials. For more information, see User roles in Synthetics. Workloads permissions Here's a summary of Admin and Add-on manager capabilities with New Relic One workloads: Create, duplicate, modify, or delete workloads. Link dashboards to workloads and save filters. To allow a User or Restricted User to execute these functions, assign the workloads manager add-on role.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1054.3346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Users, roles, permissions (<em>original</em> user model)",
        "sections": "Enable <em>SAML</em> <em>SSO</em> <em>and</em>&#x2F;<em>or</em> <em>SCIM</em>",
        "body": " and&#x2F;or <em>SCIM</em> provisioning, see <em>Get</em> <em>started</em> with <em>SAML</em> <em>SSO</em> or <em>SCIM</em>. View pending <em>SAML</em> <em>SSO</em> users New Relic accounts with <em>SAML</em> Single Sign On (<em>SSO</em>) may have a list of Pending users. These are individuals who have been added to the <em>SAML</em>-enabled account but have not yet confirmed. Update account roles Tip Owner"
      },
      "id": "603e88b2e7b9d2a3f12a07d5"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-user-management/new-relic-one-user-model-understand-user-structure": [
    {
      "sections": [
        "Introduction to New Relic One",
        "Tip",
        "Quickly understand context",
        "Query your data more easily",
        "Enhanced dashboards",
        "Build on New Relic One",
        "What’s next?"
      ],
      "title": "Introduction to New Relic One",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Get started"
      ],
      "external_id": "c9ba93c83a579625a4ba3364c6046f3c475cba3a",
      "image": "https://docs.newrelic.com/static/2bc08b6d64c16b39697bb43d8e66870e/c1b63/nrone20210722.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/get-started/introduction-new-relic-one/",
      "published_at": "2021-10-24T17:36:54Z",
      "updated_at": "2021-10-24T17:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One is the platform that gives you access to core platform capabilities like querying data and building charts, our more curated observability UI experiences features, and our alerting and Applied Intelligence tools. With New Relic One, you can see and act on all the data throughout your entire system. To access New Relic One: Go to one.newrelic.com. Or, if you report data to the EU data center go to one.eu.newrelic.com. Tip Learn more about New Relic One’s basic UI features. Quickly understand context We provide multiple ways to understand your system's dependencies, so you can easily see how everything fits together and troubleshoot problems. New Relic One gives you and your teams a connected view that cuts through complexity! If you want to... Use this Have an overall view of your system, and drill down to get performance details. Use the New Relic Explorer as the front door to New Relic One: observe, group, and filter the performance data from all the entities (that is, all applications, services, hosts, or containers) in your system. Gain extensive visibility into each entity in your solution, its alert status, and how the entities are connected. Use the New Relic Navigator to give you a high density overview of all your entities so you can detect any issues at a glance. And use the New Relic Lookout to spot entities recently experiencing behavior deviations. Provide context for your entities. Add tags to all your entities. Or create tags for teams and all the services they monitor. Use tags to illustrate relationships and contextual information for what you monitor. By thoughtfully tagging your entities, you can connect all the data your teams need to understand their increasingly complex and interdependent systems. See how each part of your system is connected. Service maps illustrate your upstream and downstream dependencies. Visualize the aggregated health and activity data from all you monitor. Group and monitor any entities together into functional team-focused, project-focused groupings, or any other attribute, with workloads. Fetch and analyze specific data. Get more context while you query with the query builder, which surfaces data definitions as you craft and edit queries. Create visuals that showcase your business needs at a glance. Tailor custom dashboards for your unique needs. Find a service or dashboard in a complex environment. Search by name across all accounts in the unified search, or filter the explorer by tags or text. View everything you’re monitoring in one place, like entities or dashboards across your organization. View a list of all the dependencies for a service. The dependencies view tab in an entity summary shows all the dependencies of the entity you’re viewing. Track activity as it moves across your distributed system. Distributed tracing helps you analyze your modern environment. Understand how everything is connected via API. The NerdGraph GraphiQL explorer manages all your entities, tags, and relationships. Query your data more easily On the Browse data menu on the top navigation menu you can easily access your basic telemetry data (metrics, events, logs, and traces). Wherever you go in the UI, Query your data is available. No matter your level of proficiency with our query language, you can create custom queries and charts: Browse your data in a query-less experience with our data explorer. Use your NRQL (our query language) expertise to build custom charts in the query builder. Run PromQL-style queries in the query builder. one.newrelic.com > Query your data: Build NRQL and PROMQL-like queries. Enhanced dashboards one.newrelic.com > Dashboards: Quickly create information dense custom views into the data that matters most to you with dashboards in New Relic One. New Relic One dashboards let you build better visualizations more easily, with more options to customize. Dashboard features include: Perform NRQL queries and create charts and dashboards everywhere in the platform using the query builder. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our agents, integrations, and APIs. Share dashboards or charts as a .pdf, or embed a chart in an external site. Tip If you previously used New Relic Insights to create dashboards, these are available as New Relic One dashboards. Build on New Relic One If custom charts and dashboards don't solve your current challenge, we give you a framework for building React JavaScript applications that: Live on New Relic One, alongside your other New Relic-monitored data. Feature highly tailored visualizations. Display data from any source you want, whether from a New Relic-monitored entity or data from any service or API. And you can use open source apps built by the community, and contribute your own open source apps. To learn more, see New Relic One applications. What’s next? To get started understanding how to get around in New Relic One: See what data you have available with the data explorer. Browse your monitored entities with the New Relic Explorer. Use our NerdGraph API to add tags to your data. Learn about dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.1308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>One</em>",
        "sections": "Introduction to <em>New</em> <em>Relic</em> <em>One</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em>",
        "body": "<em>New</em> <em>Relic</em> <em>One</em> is the platform that gives you access to core platform capabilities like querying data and building charts, our more curated observability UI experiences features, and our alerting and Applied Intelligence tools. With <em>New</em> <em>Relic</em> <em>One</em>, you can see and act on all the data throughout your"
      },
      "id": "603ec19164441f9e704e8896"
    },
    {
      "image": "https://docs.newrelic.com/static/49612c40721bfa27afa90fafcba0e95c/c1b63/login-multiple-accounts-found.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-users-roles/users-roles-original-user-model/",
      "sections": [
        "Users, roles, permissions (original user model)",
        "Requirements",
        "Updates about our new user model",
        "View and manage users in UI",
        "Tip",
        "Add a new user",
        "Important",
        "Manage user type (basic vs full) and full user upgrades",
        "Determine full user count",
        "Enable SAML SSO and/or SCIM",
        "View pending SAML SSO users",
        "Update account roles",
        "Delete a user",
        "Update the account Owner",
        "User types: basic user and full user",
        "Account roles",
        "Add-on roles",
        "View roles",
        "Assign a managed role",
        "Create a custom role",
        "Assign a custom role",
        "Edit or delete a custom role",
        "Account permissions",
        "Alert permissions",
        "APM permissions",
        "Browser permissions",
        "Infrastructure permissions",
        "Insights permissions",
        "Mobile permissions",
        "Synthetics permissions",
        "Workloads permissions"
      ],
      "published_at": "2021-10-24T23:52:40Z",
      "title": "Users, roles, permissions (original user model)",
      "updated_at": "2021-10-24T23:52:40Z",
      "type": "docs",
      "external_id": "95ae42f3474b43dec394245cfc3e23628449a1ed",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our original user model, an introduction to how the user model works, including user roles and permissions, and how to add and manage users. Requirements This doc and the surrounding section of docs shows you how to manage users on our original user model. If you were a New Relic customer before July 30 2020 and haven't migrated your users to the new model, your users are on our original user model (and not the New Relic One model). If you're an admin and want to see if you have users on the original model: If you can see users in the Users and roles UI, those users are on our original user model. Updates about our new user model In July of 2020, we released a new user model called the New Relic One user model, which offers many benefits in terms of how you manage your organization and users. At first this was only available to new sign-ups but over time we've been migrating more older customers to the new model. Some older customers are able to migrate their users on their own. We'll continue working on migrating users to the new model until the original model is fully deprecated. One impact of the new user model is that it's possible now for users to have multiple logins associated with the same email. For example, a user with access to multiple organizations (like a contractor) may have their user record updated to the new user model in one organization, resulting in them having their original login method and records and a New Relic One user model record. This may result in the user being logged in to New Relic and not being able to find an account they're looking for. For more on that, see Factors affecting access. If a user's email is associated with more than one login, they'll see a \"multiple accounts found\" note when logging in. View and manage users in UI If your New Relic account has users on our original user model, you can use the Users and roles UI. To access this: Click the account dropdown, click Account settings, and then click Users and roles. Some features in the UI are visible only to account Owners and Admins. Tip You can also use the New Relic REST API to obtain a list of everyone and their roles in your New Relic account. Here are some instructions and tips for adding and managing users via the UI: Add a new user Tip Owner or Admins To add a new user to your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. In the upper right corner, click New user. Enter the appropriate name and email address. Select their base role as either Admin, User, or Restricted. Select Add user. The new user will receive an email notification automatically from New Relic. Important New Relic recommends a maximum of 1,000 accounts per user. Additional accounts may result in limited access to some New Relic features. Manage user type (basic vs full) and full user upgrades Note that billing-related aspects of your count of full users only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. To update a user's type (basic user versus full user): Go to: account dropdown > Account settings > Users and roles > Users. Either select a user and edit their type or bulk update the type for multiple useres. To control how basic users upgrade to become full users, from the Users and roles UI you can select Access requests. You have two options: Automatic approval: With this option, basic users can automatically upgrade to be full users. This option allows your users to more easily troubleshoot problems. Require review: With this option, your admins get a notification when basic users request an upgrade and must upgrade them first. You can approve them either from the notification email or from the user's entry in the Users and roles UI. For more about user type, see User type. Determine full user count If you're on New Relic One pricing plan, your count of full users is a factor in your billing. To see your count of full users, click the account dropdown and then click View your usage. If you have a parent/child account structure (including a customer partnership), your count of full users may not match what you see when you go to Account settings > Users and roles. To examine users on a parent account's children accounts, go to a parent account's Account settings UI page, click on a child account, and go to that account's Users and roles UI page. Enable SAML SSO and/or SCIM For an introduction to using SAML SSO and/or SCIM provisioning, see Get started with SAML SSO or SCIM. View pending SAML SSO users New Relic accounts with SAML Single Sign On (SSO) may have a list of Pending users. These are individuals who have been added to the SAML-enabled account but have not yet confirmed. Update account roles Tip Owner or Admins To update a person's role and capabilities: Go to: account dropdown > Account settings > Users and roles > Users. Select the person's name. Under Roles and capabilities, select their base role as Admin, User, or Restricted. The account Owner must update the Owner role. Delete a user Tip Owner or Admins To remove a user from your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. Click on the name of the person you would like to update. Click Delete User. Tip You can also add, update, or delete users in bulk via CSV file. Update the account Owner A New Relic account can have only one Owner role at any time. You must be the current account Owner to change your role to someone who currently has an Admin role for the account. If the current Owner is unavailable, contact your account representative at New Relic, or get support at support.newrelic.com. You cannot delete or remove your assigned Owner role. However, if the account has one or more Admin role, you can change an Owner to an Admin. Go to: account dropdown > Account settings > Account > Users and roles. Above the Active users list, select Change owner. If an account has no Admins, this button won't be available. Select someone who currently has an Admin role for the account. Refresh the page for changes to take effect. Your previous Owner role automatically changes to an Admin role. To find out who is the current assigned Owner: Go to: account dropdown > Account settings > Account > Users and roles. View the Base role column to locate your account Owner. The Change owner button is only visible to the current account Owner. If the current Owner is unable to change the role (for example, that person no longer is with your organization), contact your account representative at New Relic, or get support at support.newrelic.com. User types: basic user and full user Important This section is for users on our original user model. If you're on our New Relic One user model, see our New Relic One user docs. Starting March 2021, we ended the preview period for basic users on our original user model. The preview period gave these basic users the same permissions as full users. For more on this, see our Explorers Hub post on user type changes. The user type (basic user or full user) determines what features a user has access to. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. Basic user. Details: These users have access to basic features like setting up reporting of data, running queries of data, making custom charts and dashboards, and setting up alerts. They do not have access to our more curated observability UI experiences (for more details on feature access, see Capabilities). Depending on access request settings, basic users can either upgrade themselves to be full users or request upgrade access from admins. Full user. Details: Full users have access to everything (dependent on role restrictions), which includes our curated observability UI experiences, such as APM, infrastructure monitoring, browser monitoring, mobile monitoring, and synthetic monitors. For details, see Capabilities. For organizations on New Relic One pricing: these users are billable. The Standard edition includes one free full user and up to five total. If a user in your organization is set as a basic user in one account and a full user in another, the user is considered a full user and has full user access on all accounts in that organization. For how to edit a user's type, see Manage users. Account roles A New Relic account can have only one Owner. To share an account with other users in your organization, create Admins, Users, or Restricted Users. Account role Description Owner The person who initially creates the New Relic account and receives all billing queries. The Owner has complete access to all of the account information. Admin Can add, edit, and delete users, and can enable or set up features. User Can use (and optionally set up) New Relic features. In general, Admins take responsibility for setting up features, and Users and Restricted Users can use them. Restricted User One or more individuals who can view (but not set up or change) any New Relic features. The Restricted User role is useful, for example, for demos. You can change your New Relic session settings so that Restricted User logins do not time out, and then set the user interface to Kiosk mode. Add-on roles With add-on roles, you can grant variable levels of access to all users in your account, across the entire platform of New Relic products. This allows you to tailor your account permissions levels to suit the needs of Users and Restricted Users within your account. Giving a User or Restricted User add-on manager access to a product grants them the equivalent of Admin capabilities within the product. They will continue to have User or Restricted User capabilities for all other New Relic products. For example, you could make a software engineer in your company a User in most products, but assign Admin-level access to APM. For another example, you might assign the Nerdpack manager role to a user, and that gives them the ability to subscribe and unsubscribe New Relic One applications to an account. There are two types of add-on roles: Add-on Manager roles are available to grant permissions on a per-product basis. Giving a User or Restricted User managed add-on access to a product grants them the equivalent of Admin capabilities within the product. Custom add-on roles can grant feature-specific permissions across different New Relic products. For example, a group of Users could have the ability to acknowledge incidents and close violations in New Relic Alerts, but not have the ability to modify your existing alert preferences. Individuals on a parent account automatically have the same level of access for all the child accounts of the parent account. Below are options for managing both managed add-on roles and custom add-on roles: View roles To view the list of individuals assigned to your account and their current roles: Go to account dropdown > Account settings > Users and roles. Assign a managed role Tip Owner and Admins Managed add-on roles are available by default for each New Relic product. Adding a managed role for a user grants them Admin-level permissions for the assigned product. They cannot be edited or deleted. To assign a managed add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles. From the list of users associated with your account, select their name. Under Add-on roles, select the type of manager role for the user. To understand which capabilities may be added, use the Capabilities preview chart. Features in the Capabilities preview chart may not exactly match what features are available for your subscription level. Tip You can also add, update, or delete users in bulk by using a CSV file. Create a custom role To create a custom add-on role for your account: Go to account dropdown > Account settings > Users and roles > Roles. Select New custom add-on role. Select the capabilities necessary for the new custom role, then Create role. Assign a custom role Tip Owners and Admins You must create a custom role before assigning it to a user. To assign a custom add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles > Users. From the list of users associated with your account, select their name ]. Under Add-on roles, select a custom role for the user. Click Update user. Edit or delete a custom role Tip Owners and Admins You cannot edit or delete New Relic's default roles. However, you can edit or delete custom add-on roles for your account: Go to account dropdown > Account settings > Users and roles > Roles. From the Add-on roles list, select the custom add-on role, then select Edit role or Delete role as appropriate. Account permissions Here is a summary of user permissions. Individuals on a parent account automatically have the same level of access for all the child accounts of that parent account. However, they won't receive email notifications for alerts or weekly reports for child accounts unless they are explicitly granted permission on those accounts. Function Owner Admin User Restricted Maintain billing information. Change the account Owner. Add, update, and delete account Admins, Users, and Restricted Users. When the account Owner and Admins add individuals to the account, New Relic automatically sends them an email message. Update users' job titles and roles from Account settings in the New Relic UI. Create, modify and delete child accounts from Account settings in the New Relic UI. Update your own account information (name, password change or password reset request, default account, email preferences, etc.) from User preferences in the New Relic UI. Change someone else's password. You cannot reset passwords for anyone else on the account, even if you are an Owner or Admin. Instead, follow standard procedures to request a password reset from New Relic. View the list of individuals on the account from (account dropdown) > Account settings > Account > Summary in the New Relic UI. Manage flexible data retention. Subscribe and unsubscribe applications to New Relic One Add, update, and delete Proactive Detection configurations. Alert permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Alerts. To allow a User or Restricted User to execute any of these functions in New Relic Alerts, assign an Alerts add-on manager role. Admin and manager capabilities for Alerts include: Create or name alert policies. Specify incident preferences. Disable or define alert conditions. Provide runbook instructions. Select product targets. Alter alert condition thresholds. Create, modify, or delete notification channels. APM permissions Here is a summary of Admin and Add-on manager capabilities with APM. To allow a User or Restricted User to execute any of these functions in APM, assign an APM add-on manager role. Admin and manager capabilities for APM include: Remove applications from the New Relic UI. Delete app traces and error traces. Browser permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Browser. To allow a User or Restricted User to execute any of these functions in New Relic Browser, assign a Browser add-on manager role. Admin and manager capabilities for Browser include: Add, rename, or delete applications. Manage whitelists. Manage domain conditions. Infrastructure permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Infrastructure. To allow a User or Restricted User to execute any of these functions in New Relic Infrastructure, assign an Infrastructure manager role. Admin and manager capabilities for Infrastructure include: Create alert conditions in New Relic Infrastructure, including conditions for host not reporting. Add or modify integrations. Insights permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Insights. To allow a User or Restricted User to execute any of these functions, assign an Insights manager role. These functions include: Create, view, modify, or delete Query API keys or Insert API keys. Tip New Relic Insights includes permission levels to share your Insights dashboards with others. Mobile permissions To give permission to delete a mobile app from New Relic, you can assign an Admin or Mobile manager role. Synthetics permissions Here's a summary of Admin and Add-on manager capabilities with New Relic Synthetics. To allow a User or Restricted User to execute any of these functions in New Relic Synthetics, assign a Synthetics add-on manager role. Admin and manager capabilities for Synthetics include: Create, edit, or delete monitors. Edit monitor scripts. Create, edit, or delete private locations. Create, edit, or delete monitor downtimes. Create, view, edit, or delete secure credentials. For more information, see User roles in Synthetics. Workloads permissions Here's a summary of Admin and Add-on manager capabilities with New Relic One workloads: Create, duplicate, modify, or delete workloads. Link dashboards to workloads and save filters. To allow a User or Restricted User to execute these functions, assign the workloads manager add-on role.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 327.41412,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Users</em>, <em>roles</em>, <em>permissions</em> (original <em>user</em> <em>model</em>)",
        "sections": "<em>Users</em>, <em>roles</em>, <em>permissions</em> (original <em>user</em> <em>model</em>)",
        "body": "For <em>users</em> on our original <em>user</em> <em>model</em>, an introduction to how the <em>user</em> <em>model</em> works, including <em>user</em> <em>roles</em> and <em>permissions</em>, and how to add and manage <em>users</em>. Requirements This doc and the surrounding section of docs shows you how to manage <em>users</em> on our original <em>user</em> <em>model</em>. If you were a <em>New</em> <em>Relic</em>"
      },
      "id": "603e88b2e7b9d2a3f12a07d5"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.78192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> <em>One</em>",
        "sections": "Preview access for <em>New</em> <em>Relic</em> <em>One</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> <em>One</em> platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-user-management/tutorial-add-new-user-groups-roles-new-relic-one-user-model": [
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic user versus full user)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-10-24T20:29:42Z",
      "updated_at": "2021-10-07T01:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full user) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic user versus full user) Note that there are limits around how many times full users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 463.58762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to <em>manage</em> <em>users</em>",
        "sections": "Give <em>users</em> access to <em>accounts</em> <em>and</em> roles (access grants)",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> <em>management</em>",
        "body": "For users on our <em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model, we provide various <em>user</em> <em>management</em> features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to <em>user</em> groups Create custom <em>user</em> groups Grant <em>user</em> groups access to specific roles and <em>accounts</em> Important"
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, who have access to our more curated UI experiences. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 413.14166,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em> ",
        "sections": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> pricing <em>and</em> <em>billing</em>",
        "body": " want. If all sources are removed, no data is sent to Incident Intelligence. Full <em>user</em> count <em>billing</em> details For <em>accounts</em> with <em>New</em> <em>Relic</em> <em>One</em> pricing, the monthly count of provisioned full users is <em>one</em> <em>billing</em> factor. To give an example: if you&#x27;re on the Pro pricing edition and your organization has"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Introduction to user management",
        "New pricing plan",
        "User management docs"
      ],
      "title": "Introduction to user management",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "6c2f39333fa3c6931fe616669244cb44f183a167",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/introduction-managing-users/",
      "published_at": "2021-10-24T23:50:03Z",
      "updated_at": "2021-09-14T10:25:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New pricing plan This doc is for users on our New Relic One user model. Some important things to note before starting: The docs in this section are for managing users on the New Relic One user model. Learn about user models. Note that this is a separate topic from our two different pricing plans. For managing users on our original user model, see Original users. User management docs Here are our main docs for managing these users: User model/structure: learn some basic aspects of our user model, such as what basic users and full users are, how groups (like Admin and User) work, and how roles and capabilities work. How to manage users: an overview of user management concepts, where to manage users in the UI, and some common user management tasks. Authentication domain settings: configure an authentication domain, which governs how your users are added to New Relic (manually versus SCIM provisioning), the authentication method they use (manual login versus SAML SSO), managing how basic users become full users, and user session settings. For an overview of SAML SSO and SCIM options, see Introduction to SAML and SCIM. A tutorial on how to create access grants, which is how you give users access to roles and accounts. Want to understand how user count affects billing? See User-related billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 403.05963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>user</em> <em>management</em>",
        "sections": "Introduction to <em>user</em> <em>management</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> <em>user</em> <em>management</em>",
        "body": "<em>New</em> pricing plan This doc is for users on our <em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model. Some important things to note before starting: The docs in this section are for managing users on the <em>New</em> <em>Relic</em> <em>One</em> <em>user</em> model. Learn about <em>user</em> models. Note that this is a separate topic from our two different pricing plans"
      },
      "id": "6043f3c4196a67a215960f3c"
    }
  ],
  "/docs/accounts/accounts-billing/new-relic-one-user-management/user-mgmt-videos": [
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Benefits",
        "Requirements",
        "Set up automated user management (AUM)"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-10-24T23:00:29Z",
      "updated_at": "2021-10-24T23:00:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuring AUM requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. There are three identity providers that have a dedicated New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Set up automated user management (AUM) For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.58109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to automated <em>user</em> <em>management</em> (AUM) and single-sign on (SSO)",
        "sections": "Introduction to automated <em>user</em> <em>management</em> (AUM) and single-sign on (SSO)",
        "tags": "Automated <em>user</em> <em>management</em>",
        "body": "New Relic lets you set up automated <em>user</em> <em>management</em> (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated <em>user</em> <em>management</em>, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.03323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Log <em>management</em>",
        "body": "Parsing is the process of splitting unstructured log data into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following <em>video</em> tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.03009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Logs <em>UI</em>",
        "sections": "Use Logs <em>UI</em>",
        "tags": "Log <em>management</em>",
        "body": "Use the Logs <em>UI</em> at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    }
  ],
  "/docs/accounts/install-new-relic/partner-based-installation/google-app-engine-environment": [
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Log in to and install New Relic via partners",
        "Create a New Relic account (all partners)",
        "Sign into and deploy New Relic (most partners)",
        "Sign into and deploy New Relic (special partners)",
        "Tip",
        "A - M partners",
        "Amazon Web Services (AWS)",
        "Google Cloud Platform (GCP)",
        "Heroku",
        "Magento",
        "N - Z partners",
        "Pantheon",
        "Rackspace Cloud Tools",
        "W3 Edge and WordPress",
        "Windows Azure"
      ],
      "title": "Log in to and install New Relic via partners",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "d6c766c0328d09f6208426396d5443d115029fcc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/log-install-new-relic-partners/",
      "published_at": "2021-10-24T19:09:47Z",
      "updated_at": "2021-09-14T05:47:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you signed up for New Relic through one of New Relic's partners, you may need to follow additional single sign on (SSO) procedures to log in to start using New Relic. There also may be special steps needed to complete the deployment process. This document provides basic login procedures for accounts created through New Relic partners, with links to additional resources as applicable. Create a New Relic account (all partners) If you have received a special offer from a New Relic partner, follow the partner's link directly to create a New Relic account. Sign into and deploy New Relic (most partners) You will receive an email confirmation message with a link to confirm your account, sign into New Relic, and complete the deployment process. Sign into and deploy New Relic (special partners) These partners require specific login and deployment procedures for you to use your New Relic account. Tip If you signed up for a New Relic account through a partner that is not listed here, follow standard procedures to sign into and deploy New Relic. A - M partners Amazon Web Services (AWS) Different installation and page viewing procedures apply, depending on whether you want to install AWS for your app or your host. For more information, see Amazon Web Services (AWS) users. Google Cloud Platform (GCP) As a Google Cloud Platform (GCP) partner, New Relic supports the App Engine flexible environment. Each APM agent has its own requirements for the GAE flex environment. After you install the New Relic agent, you can view your app performance with APM. Heroku Heroku is a Platform as a Service (PaaS) solution capable of hosting web applications. With the New Relic Heroku add-on, you can extend Heroku with metrics from APM and browser monitoring. The New Relic add-on supports Java, Node.js, PHP, Python, and Ruby. For more information about installing and using New Relic with Heroku, see: Heroku dev center documentation New Relic's documentation for installing Heroku Magento Magento has partnered with New Relic to give merchants faster access to data and out-of-the-box tools. The New Relic Reporting Extension helps e-commerce businesses to make data-driven decisions. To create a New Relic account with Magento for your PHP app: Sign up via your Magento sales solution provider. After you sign up for your New Relic account, deploy the PHP agent to your Magento installation. Wait a few minutes, then check your app's performance in the APM Overview page. N - Z partners Pantheon To create a New Relic account through Pantheon and sign into New Relic: From Pantheon's partner page with New Relic, select the sign up link. Follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. After a few minutes, you can check your app's performance in the APM Overview page. For more information, see Pantheon's documentation. Rackspace Cloud Tools To create an account through Rackspace Cloud Tools and sign into New Relic, follow these basic procedures. For more information, see Rackspace Cloud Load Balancer plugin. Log in to your CloudTools account at cloudtools.rackspace.com/myapps. From Use Your Applications, select New Relic. Select your agent language (Java, .NET, PHP, Python, Ruby), then follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. Wait a few minutes, then check your app's performance in the APM Overview page. W3 Edge and WordPress Tip To create an account through W3 Total Cache and sign into New Relic, you must install and run the W3 PHP agent, not just get an API key. Deploying the agent requires administrative access, including: SSH/command line access Root or sudo access to run the New Relic installer and restart your web server If you are running an economy, shared hosting, or blogger package, or if you are not sure what are your account permissions, contact your hosting provider. For example, if your WordPress site is on shared servers, you may not be able to install New Relic. Your provider should be able to give you information about your account permissions, or upgrade your account if necessary. To install the New Relic plugin for W3 Edge/Wordpress users: Log in to your WordPress account at wordpress.org/support/bb-login.php. Follow New Relic's instructions to complete the installation process, or contact W3TC support for assistance. Wait for New Relic to begin collecting data. Within a few minutes after deploying the agent, performance data about your app will appear on APM's Applications Overview page. Tip WordPress also offers a plugin for our browser monitoring. Windows Azure Windows Azure is a Platform as a Service (PaaS) solution capable of hosting web applications using various languages, including .NET and Node.js. For more information about using our .NET agent with Azure, see: Installing the .NET agent on Azure Azure Preview Portal Azure Web Apps Azure Cloud Services For more information about installing and using our Node.js agent with Azure, see Node.js agent on Microsoft Azure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "sections": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " for <em>accounts</em> created through New Relic partners, with links to additional resources as applicable. Create a New Relic <em>account</em> (all partners) If you have received a special offer from a New Relic <em>partner</em>, follow the <em>partner</em>&#x27;s link directly to create a New Relic <em>account</em>. Sign into and deploy New Relic (most"
      },
      "id": "6043f447e7b9d2f5295799e5"
    },
    {
      "sections": [
        "RightScale users and New Relic",
        "Add New Relic RightScripts",
        "Example PHP RightScript installation",
        "View APM monitoring data",
        "Upgrade your New Relic subscription"
      ],
      "title": "RightScale users and New Relic",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "53775c11e82931aa08ef2d107aaa3f023368559b",
      "image": "https://docs.newrelic.com/static/84cd6a6ee1fe0ce671be3d3d710ab5a4/8c557/screen-nr-rightscale-applist.png",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/rightscale-users-new-relic/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-09-14T05:47:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "RightScale is a Software as a Service (SaaS) solution capable of hosting web applications. Supported languages for both New Relic and RightScale include Java, Ruby, .NET, PHP, and Python. In order to use New Relic through the RightScale partnership, you need a New Relic account. Before getting started, be sure to enable API access. Add New Relic RightScripts Before you can view data from New Relic in RightScale, add the appropriate New Relic RightScript to your ServerTemplates: From RightCloud, select Design > MultiCloud Marketplace > ServerTemplates. Import the New Relic Performance Monitoring Toolbox ServerTemplate into your Local view. After you import the ServerTemplate, you can use the associated New Relic RightScripts with your account and add them to your ServerTemplates as appropriate for your agent language. New Relic RightScript Notes Java Tomcat For use with Tomcat5 and Tomcat6 ServerTemplates. Installs our Java agent and configures it for use with Tomcat with APM. .NET Installs and configures the New Relic agent to monitor .NET applications. Using New Relic for .NET requires .NET 3.5 or higher on the target host. (If you have only 4.0 or higher installed, you must have .NET Version 3.5 installed on the target host.) With the 3.5 framework, New Relic instruments applications targeting .NET frameworks 2.0 or higher running on Windows Server 2003, Windows Server 2008, Windows Vista, Windows 7, and Windows Azure. PHP Installs and configures the New Relic PHP agent and a local proxy daemon. New Relic supports PHP versions 5.2 or higher on Apache 2.2 or 2.4. Python To install and configure the New Relic Python agent, do not use RightScripts. Instead, send an email to rightscale@newrelic.com. Ruby To use the New Relic agent for your Ruby on Rails application, see New Relic for Ruby. Example PHP RightScript installation Here is an example of adding the APP New Relic RPM for PHP RightScripts to a PHP application server. Add the APP New Relic RPM for PHP RightScript as a boot script to the ServerTemplate that is being used to run your PHP application servers. This will automatically deploy the New Relic agent when a new server is launched with that ServerTemplate. If your PHP application is already running on a server, you can add it as an operational script under the Scripts tab, and run the action on the running server. Be sure to define the following input value for the new script: NR_License_Key: Enter your New Relic license key. Copy You can either manually enter the license key or create a credential for it. View APM monitoring data When viewing the data that New Relic monitors, you will only see the names of the applications that are on servers where you have run the New Relic RightScript. A host is a server and an instance is an instance of an application. RightScale users: Example of apps you can view in New Relic. To view your New Relic data: Go to Reports > New Relic. From the list of application(s) in your New Relic RightScript deployment, select an application name. On your first login, be sure to change your password: From the (account dropdown in the New Relic UI, select User preferences. Use the New Relic menu options to view different performance data and charts. Upgrade your New Relic subscription For RightScale customers, all new accounts start with a free 14-day trial of New Relic's paid subscription features. If you want to upgrade your free account to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22081,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "RightScale users <em>and</em> New Relic",
        "sections": "Example PHP RightScript <em>installation</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " customers, all new <em>accounts</em> start with a free 14-day trial of New Relic&#x27;s paid subscription features. If you want to upgrade your free <em>account</em> to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale."
      },
      "id": "603eb08b28ccbc289aeba7a2"
    }
  ],
  "/docs/accounts/install-new-relic/partner-based-installation/heroku-install-new-relic-add": [
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Log in to and install New Relic via partners",
        "Create a New Relic account (all partners)",
        "Sign into and deploy New Relic (most partners)",
        "Sign into and deploy New Relic (special partners)",
        "Tip",
        "A - M partners",
        "Amazon Web Services (AWS)",
        "Google Cloud Platform (GCP)",
        "Heroku",
        "Magento",
        "N - Z partners",
        "Pantheon",
        "Rackspace Cloud Tools",
        "W3 Edge and WordPress",
        "Windows Azure"
      ],
      "title": "Log in to and install New Relic via partners",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "d6c766c0328d09f6208426396d5443d115029fcc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/log-install-new-relic-partners/",
      "published_at": "2021-10-24T19:09:47Z",
      "updated_at": "2021-09-14T05:47:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you signed up for New Relic through one of New Relic's partners, you may need to follow additional single sign on (SSO) procedures to log in to start using New Relic. There also may be special steps needed to complete the deployment process. This document provides basic login procedures for accounts created through New Relic partners, with links to additional resources as applicable. Create a New Relic account (all partners) If you have received a special offer from a New Relic partner, follow the partner's link directly to create a New Relic account. Sign into and deploy New Relic (most partners) You will receive an email confirmation message with a link to confirm your account, sign into New Relic, and complete the deployment process. Sign into and deploy New Relic (special partners) These partners require specific login and deployment procedures for you to use your New Relic account. Tip If you signed up for a New Relic account through a partner that is not listed here, follow standard procedures to sign into and deploy New Relic. A - M partners Amazon Web Services (AWS) Different installation and page viewing procedures apply, depending on whether you want to install AWS for your app or your host. For more information, see Amazon Web Services (AWS) users. Google Cloud Platform (GCP) As a Google Cloud Platform (GCP) partner, New Relic supports the App Engine flexible environment. Each APM agent has its own requirements for the GAE flex environment. After you install the New Relic agent, you can view your app performance with APM. Heroku Heroku is a Platform as a Service (PaaS) solution capable of hosting web applications. With the New Relic Heroku add-on, you can extend Heroku with metrics from APM and browser monitoring. The New Relic add-on supports Java, Node.js, PHP, Python, and Ruby. For more information about installing and using New Relic with Heroku, see: Heroku dev center documentation New Relic's documentation for installing Heroku Magento Magento has partnered with New Relic to give merchants faster access to data and out-of-the-box tools. The New Relic Reporting Extension helps e-commerce businesses to make data-driven decisions. To create a New Relic account with Magento for your PHP app: Sign up via your Magento sales solution provider. After you sign up for your New Relic account, deploy the PHP agent to your Magento installation. Wait a few minutes, then check your app's performance in the APM Overview page. N - Z partners Pantheon To create a New Relic account through Pantheon and sign into New Relic: From Pantheon's partner page with New Relic, select the sign up link. Follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. After a few minutes, you can check your app's performance in the APM Overview page. For more information, see Pantheon's documentation. Rackspace Cloud Tools To create an account through Rackspace Cloud Tools and sign into New Relic, follow these basic procedures. For more information, see Rackspace Cloud Load Balancer plugin. Log in to your CloudTools account at cloudtools.rackspace.com/myapps. From Use Your Applications, select New Relic. Select your agent language (Java, .NET, PHP, Python, Ruby), then follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. Wait a few minutes, then check your app's performance in the APM Overview page. W3 Edge and WordPress Tip To create an account through W3 Total Cache and sign into New Relic, you must install and run the W3 PHP agent, not just get an API key. Deploying the agent requires administrative access, including: SSH/command line access Root or sudo access to run the New Relic installer and restart your web server If you are running an economy, shared hosting, or blogger package, or if you are not sure what are your account permissions, contact your hosting provider. For example, if your WordPress site is on shared servers, you may not be able to install New Relic. Your provider should be able to give you information about your account permissions, or upgrade your account if necessary. To install the New Relic plugin for W3 Edge/Wordpress users: Log in to your WordPress account at wordpress.org/support/bb-login.php. Follow New Relic's instructions to complete the installation process, or contact W3TC support for assistance. Wait for New Relic to begin collecting data. Within a few minutes after deploying the agent, performance data about your app will appear on APM's Applications Overview page. Tip WordPress also offers a plugin for our browser monitoring. Windows Azure Windows Azure is a Platform as a Service (PaaS) solution capable of hosting web applications using various languages, including .NET and Node.js. For more information about using our .NET agent with Azure, see: Installing the .NET agent on Azure Azure Preview Portal Azure Web Apps Azure Cloud Services For more information about installing and using our Node.js agent with Azure, see Node.js agent on Microsoft Azure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "sections": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " for <em>accounts</em> created through New Relic partners, with links to additional resources as applicable. Create a New Relic <em>account</em> (all partners) If you have received a special offer from a New Relic <em>partner</em>, follow the <em>partner</em>&#x27;s link directly to create a New Relic <em>account</em>. Sign into and deploy New Relic (most"
      },
      "id": "6043f447e7b9d2f5295799e5"
    },
    {
      "sections": [
        "RightScale users and New Relic",
        "Add New Relic RightScripts",
        "Example PHP RightScript installation",
        "View APM monitoring data",
        "Upgrade your New Relic subscription"
      ],
      "title": "RightScale users and New Relic",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "53775c11e82931aa08ef2d107aaa3f023368559b",
      "image": "https://docs.newrelic.com/static/84cd6a6ee1fe0ce671be3d3d710ab5a4/8c557/screen-nr-rightscale-applist.png",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/rightscale-users-new-relic/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-09-14T05:47:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "RightScale is a Software as a Service (SaaS) solution capable of hosting web applications. Supported languages for both New Relic and RightScale include Java, Ruby, .NET, PHP, and Python. In order to use New Relic through the RightScale partnership, you need a New Relic account. Before getting started, be sure to enable API access. Add New Relic RightScripts Before you can view data from New Relic in RightScale, add the appropriate New Relic RightScript to your ServerTemplates: From RightCloud, select Design > MultiCloud Marketplace > ServerTemplates. Import the New Relic Performance Monitoring Toolbox ServerTemplate into your Local view. After you import the ServerTemplate, you can use the associated New Relic RightScripts with your account and add them to your ServerTemplates as appropriate for your agent language. New Relic RightScript Notes Java Tomcat For use with Tomcat5 and Tomcat6 ServerTemplates. Installs our Java agent and configures it for use with Tomcat with APM. .NET Installs and configures the New Relic agent to monitor .NET applications. Using New Relic for .NET requires .NET 3.5 or higher on the target host. (If you have only 4.0 or higher installed, you must have .NET Version 3.5 installed on the target host.) With the 3.5 framework, New Relic instruments applications targeting .NET frameworks 2.0 or higher running on Windows Server 2003, Windows Server 2008, Windows Vista, Windows 7, and Windows Azure. PHP Installs and configures the New Relic PHP agent and a local proxy daemon. New Relic supports PHP versions 5.2 or higher on Apache 2.2 or 2.4. Python To install and configure the New Relic Python agent, do not use RightScripts. Instead, send an email to rightscale@newrelic.com. Ruby To use the New Relic agent for your Ruby on Rails application, see New Relic for Ruby. Example PHP RightScript installation Here is an example of adding the APP New Relic RPM for PHP RightScripts to a PHP application server. Add the APP New Relic RPM for PHP RightScript as a boot script to the ServerTemplate that is being used to run your PHP application servers. This will automatically deploy the New Relic agent when a new server is launched with that ServerTemplate. If your PHP application is already running on a server, you can add it as an operational script under the Scripts tab, and run the action on the running server. Be sure to define the following input value for the new script: NR_License_Key: Enter your New Relic license key. Copy You can either manually enter the license key or create a credential for it. View APM monitoring data When viewing the data that New Relic monitors, you will only see the names of the applications that are on servers where you have run the New Relic RightScript. A host is a server and an instance is an instance of an application. RightScale users: Example of apps you can view in New Relic. To view your New Relic data: Go to Reports > New Relic. From the list of application(s) in your New Relic RightScript deployment, select an application name. On your first login, be sure to change your password: From the (account dropdown in the New Relic UI, select User preferences. Use the New Relic menu options to view different performance data and charts. Upgrade your New Relic subscription For RightScale customers, all new accounts start with a free 14-day trial of New Relic's paid subscription features. If you want to upgrade your free account to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22081,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "RightScale users <em>and</em> New Relic",
        "sections": "Example PHP RightScript <em>installation</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " customers, all new <em>accounts</em> start with a free 14-day trial of New Relic&#x27;s paid subscription features. If you want to upgrade your free <em>account</em> to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale."
      },
      "id": "603eb08b28ccbc289aeba7a2"
    }
  ],
  "/docs/accounts/install-new-relic/partner-based-installation/log-install-new-relic-partners": [
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "RightScale users and New Relic",
        "Add New Relic RightScripts",
        "Example PHP RightScript installation",
        "View APM monitoring data",
        "Upgrade your New Relic subscription"
      ],
      "title": "RightScale users and New Relic",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "53775c11e82931aa08ef2d107aaa3f023368559b",
      "image": "https://docs.newrelic.com/static/84cd6a6ee1fe0ce671be3d3d710ab5a4/8c557/screen-nr-rightscale-applist.png",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/rightscale-users-new-relic/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-09-14T05:47:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "RightScale is a Software as a Service (SaaS) solution capable of hosting web applications. Supported languages for both New Relic and RightScale include Java, Ruby, .NET, PHP, and Python. In order to use New Relic through the RightScale partnership, you need a New Relic account. Before getting started, be sure to enable API access. Add New Relic RightScripts Before you can view data from New Relic in RightScale, add the appropriate New Relic RightScript to your ServerTemplates: From RightCloud, select Design > MultiCloud Marketplace > ServerTemplates. Import the New Relic Performance Monitoring Toolbox ServerTemplate into your Local view. After you import the ServerTemplate, you can use the associated New Relic RightScripts with your account and add them to your ServerTemplates as appropriate for your agent language. New Relic RightScript Notes Java Tomcat For use with Tomcat5 and Tomcat6 ServerTemplates. Installs our Java agent and configures it for use with Tomcat with APM. .NET Installs and configures the New Relic agent to monitor .NET applications. Using New Relic for .NET requires .NET 3.5 or higher on the target host. (If you have only 4.0 or higher installed, you must have .NET Version 3.5 installed on the target host.) With the 3.5 framework, New Relic instruments applications targeting .NET frameworks 2.0 or higher running on Windows Server 2003, Windows Server 2008, Windows Vista, Windows 7, and Windows Azure. PHP Installs and configures the New Relic PHP agent and a local proxy daemon. New Relic supports PHP versions 5.2 or higher on Apache 2.2 or 2.4. Python To install and configure the New Relic Python agent, do not use RightScripts. Instead, send an email to rightscale@newrelic.com. Ruby To use the New Relic agent for your Ruby on Rails application, see New Relic for Ruby. Example PHP RightScript installation Here is an example of adding the APP New Relic RPM for PHP RightScripts to a PHP application server. Add the APP New Relic RPM for PHP RightScript as a boot script to the ServerTemplate that is being used to run your PHP application servers. This will automatically deploy the New Relic agent when a new server is launched with that ServerTemplate. If your PHP application is already running on a server, you can add it as an operational script under the Scripts tab, and run the action on the running server. Be sure to define the following input value for the new script: NR_License_Key: Enter your New Relic license key. Copy You can either manually enter the license key or create a credential for it. View APM monitoring data When viewing the data that New Relic monitors, you will only see the names of the applications that are on servers where you have run the New Relic RightScript. A host is a server and an instance is an instance of an application. RightScale users: Example of apps you can view in New Relic. To view your New Relic data: Go to Reports > New Relic. From the list of application(s) in your New Relic RightScript deployment, select an application name. On your first login, be sure to change your password: From the (account dropdown in the New Relic UI, select User preferences. Use the New Relic menu options to view different performance data and charts. Upgrade your New Relic subscription For RightScale customers, all new accounts start with a free 14-day trial of New Relic's paid subscription features. If you want to upgrade your free account to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.2208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "RightScale users <em>and</em> New Relic",
        "sections": "Example PHP RightScript <em>installation</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " customers, all new <em>accounts</em> start with a free 14-day trial of New Relic&#x27;s paid subscription features. If you want to upgrade your free <em>account</em> to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale."
      },
      "id": "603eb08b28ccbc289aeba7a2"
    },
    {
      "sections": [
        "Heroku: Install the New Relic add-on",
        "Install the New Relic add-on",
        "Configure the agent",
        "Java",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Manage your Heroku add-on accounts",
        "License key",
        "Account URL",
        "Account ID",
        "Log on to New Relic",
        "Sign in to New Relic add-on account through Heroku",
        "Sign in to regular New Relic accounts",
        "Set up deployment notifications",
        "Important"
      ],
      "title": "Heroku: Install the New Relic add-on",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "45ca4960759150545d4f9e586555d6e15daef3ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/heroku-install-new-relic-add/",
      "published_at": "2021-10-24T22:53:31Z",
      "updated_at": "2021-09-14T05:46:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Heroku is a Platform as a Service (PaaS) solution for hosting web applications in various agent languages. With New Relic, you can extend Heroku with metrics from our monitoring solutions, like APM and browser monitoring. The New Relic add-on supports Java, Node.js, PHP, Python, and Ruby. Install the New Relic add-on To set up the New Relic add-on, see Heroku's documentation, including available plan levels and Toolbelt procedures. If you have problems, use the Heroku support channels. Configure the agent After you install the New Relic add-on for Heroku, follow the configuration procedures for your APM agent. Java The minimum agent version for Java is 3.17.1 or higher. To install and configure New Relic's Java agent for your add-on, see our Java agent and Heroku documentation. Node.js To install and configure our Node.js agent for your add-on, see: New Relic's Node.js and Heroku documentation Blog post (2013) with a \"real world\" example of installing our Node.js agent for a Heroku app PHP To install and configure our PHP agent for your add-on, see our PHP agent and Heroku documentation. Python To install and configure our Python agent for your add-on, see our Python agent and Heroku documentation. Ruby To install and configure our Ruby agent for your add-on, see our Ruby agent and Heroku documentation. If you are using our Ruby agent with a non-Rails application, Heroku users need to install the plugin in your repository manually. For example, in a Sinatra app, add the newrelic gem to your Gemfile, and then add the following code to your app: configure :production do require 'newrelic_rpm' end Copy Manage your Heroku add-on accounts Every time you install the New Relic add-on for Heroku, New Relic will automatically create a new account, complete with a unique license key, account URL, and account ID. These three types of information are important for managing each of your Heroku add-on accounts. License key The license key identifies the account where your application reports. To check the license key your app is using: From a command line, run: heroku config | grep -i relic Copy Look for the value of NEW_RELIC_LICENSE_KEY. This license key environment variable will override any other license key that you hard-code into your New Relic config file. Account URL If you install the New Relic add-on multiple times and need to verify the URL your Heroku app uses for reporting to New Relic, look in your agent logs for a line indicating reporting to following by a URL using this format: rpm.newrelic.com/accounts/###/applications/###### Copy Account ID You cannot change your add-on's account ID directly. If you need to change the New Relic account your Heroku app uses for reporting to New Relic, change the current license key environment variable in its config file so that it points to the license key of the New Relic account you want to use: heroku config:set NEW_RELIC_LICENSE_KEY=changed_account_license_key Copy Log on to New Relic Heroku customers may have two different types of accounts with New Relic: Add-on accounts: New Relic accounts that customers installed on their Heroku application by using Heroku's New Relic add-on \"Regular\" accounts: Other New Relic accounts that customers did not install with Heroku's add-on Regular accounts provide a wider range of features than do add-on accounts, and are installed and managed differently. Different procedures apply, depending on which type of account you want to sign into. In accordance with the terms of New Relic's partnership with Heroku, customers who install New Relic via the Heroku add-on can only access their New Relic add-on accounts by signing in through Heroku. For this reason, if you have both add-on accounts and regular New Relic accounts, you cannot switch directly between them. Sign in to New Relic add-on account through Heroku To sign in to your New Relic add-on accounts: Sign in through Heroku's login page at id.heroku.com/login. Select the application that has the New Relic add-on installed. Select New Relic from your list of add-ons. If you sign in through Heroku, you will not see any of your regular New Relic accounts when you select account dropdown > Switch account. Sign in to regular New Relic accounts To sign into or switch between your regular New Relic accounts: Sign in to New Relic at one.newrelic.com. To switch from one regular New Relic account to another: Go to: **account dropdown and select an account. If you sign in directly through New Relic, you will not see any of your New Relic add-on accounts from Heroku when you select account dropdown > Switch account. Set up deployment notifications The Heroku add-on automatically sends deployment notifications to New Relic for one application per account. If you add multiple applications to your add-on account, you must use the New Relic REST API to manually send deployment notifications for your additional applications. You cannot use a post-deploy hook, because the New Relic REST API call requires a header, and Heroku's post-deploy hook does not allow headers. However, you can write a script that generates this API call whenever you deploy on Heroku. For instructions on recording deployments via the REST API, see Recording deployments. Important When you add a user to the Heroku add-on, this creates a user record for the user at New Relic. However, if you remove the user from the Heroku add-on, the user record is not automatically removed from New Relic. Instead, you must also manually remove the New Relic user record after removing the user from the Heroku add-on. You can do this by going to the User Management page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Heroku: <em>Install</em> the New Relic add-on",
        "sections": "Manage your Heroku add-on <em>accounts</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " the newrelic gem to your Gemfile, and then add the following code to your app: configure :production do require &#x27;newrelic_rpm&#x27; end Copy Manage your Heroku add-on <em>accounts</em> Every time you install the New Relic add-on for Heroku, New Relic will automatically create a new <em>account</em>, complete with a unique license"
      },
      "id": "603ebc9ae7b9d272c32a0810"
    }
  ],
  "/docs/accounts/install-new-relic/partner-based-installation/rackspace-cloud-load-balancer-plugin": [
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Log in to and install New Relic via partners",
        "Create a New Relic account (all partners)",
        "Sign into and deploy New Relic (most partners)",
        "Sign into and deploy New Relic (special partners)",
        "Tip",
        "A - M partners",
        "Amazon Web Services (AWS)",
        "Google Cloud Platform (GCP)",
        "Heroku",
        "Magento",
        "N - Z partners",
        "Pantheon",
        "Rackspace Cloud Tools",
        "W3 Edge and WordPress",
        "Windows Azure"
      ],
      "title": "Log in to and install New Relic via partners",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "d6c766c0328d09f6208426396d5443d115029fcc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/log-install-new-relic-partners/",
      "published_at": "2021-10-24T19:09:47Z",
      "updated_at": "2021-09-14T05:47:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you signed up for New Relic through one of New Relic's partners, you may need to follow additional single sign on (SSO) procedures to log in to start using New Relic. There also may be special steps needed to complete the deployment process. This document provides basic login procedures for accounts created through New Relic partners, with links to additional resources as applicable. Create a New Relic account (all partners) If you have received a special offer from a New Relic partner, follow the partner's link directly to create a New Relic account. Sign into and deploy New Relic (most partners) You will receive an email confirmation message with a link to confirm your account, sign into New Relic, and complete the deployment process. Sign into and deploy New Relic (special partners) These partners require specific login and deployment procedures for you to use your New Relic account. Tip If you signed up for a New Relic account through a partner that is not listed here, follow standard procedures to sign into and deploy New Relic. A - M partners Amazon Web Services (AWS) Different installation and page viewing procedures apply, depending on whether you want to install AWS for your app or your host. For more information, see Amazon Web Services (AWS) users. Google Cloud Platform (GCP) As a Google Cloud Platform (GCP) partner, New Relic supports the App Engine flexible environment. Each APM agent has its own requirements for the GAE flex environment. After you install the New Relic agent, you can view your app performance with APM. Heroku Heroku is a Platform as a Service (PaaS) solution capable of hosting web applications. With the New Relic Heroku add-on, you can extend Heroku with metrics from APM and browser monitoring. The New Relic add-on supports Java, Node.js, PHP, Python, and Ruby. For more information about installing and using New Relic with Heroku, see: Heroku dev center documentation New Relic's documentation for installing Heroku Magento Magento has partnered with New Relic to give merchants faster access to data and out-of-the-box tools. The New Relic Reporting Extension helps e-commerce businesses to make data-driven decisions. To create a New Relic account with Magento for your PHP app: Sign up via your Magento sales solution provider. After you sign up for your New Relic account, deploy the PHP agent to your Magento installation. Wait a few minutes, then check your app's performance in the APM Overview page. N - Z partners Pantheon To create a New Relic account through Pantheon and sign into New Relic: From Pantheon's partner page with New Relic, select the sign up link. Follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. After a few minutes, you can check your app's performance in the APM Overview page. For more information, see Pantheon's documentation. Rackspace Cloud Tools To create an account through Rackspace Cloud Tools and sign into New Relic, follow these basic procedures. For more information, see Rackspace Cloud Load Balancer plugin. Log in to your CloudTools account at cloudtools.rackspace.com/myapps. From Use Your Applications, select New Relic. Select your agent language (Java, .NET, PHP, Python, Ruby), then follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. Wait a few minutes, then check your app's performance in the APM Overview page. W3 Edge and WordPress Tip To create an account through W3 Total Cache and sign into New Relic, you must install and run the W3 PHP agent, not just get an API key. Deploying the agent requires administrative access, including: SSH/command line access Root or sudo access to run the New Relic installer and restart your web server If you are running an economy, shared hosting, or blogger package, or if you are not sure what are your account permissions, contact your hosting provider. For example, if your WordPress site is on shared servers, you may not be able to install New Relic. Your provider should be able to give you information about your account permissions, or upgrade your account if necessary. To install the New Relic plugin for W3 Edge/Wordpress users: Log in to your WordPress account at wordpress.org/support/bb-login.php. Follow New Relic's instructions to complete the installation process, or contact W3TC support for assistance. Wait for New Relic to begin collecting data. Within a few minutes after deploying the agent, performance data about your app will appear on APM's Applications Overview page. Tip WordPress also offers a plugin for our browser monitoring. Windows Azure Windows Azure is a Platform as a Service (PaaS) solution capable of hosting web applications using various languages, including .NET and Node.js. For more information about using our .NET agent with Azure, see: Installing the .NET agent on Azure Azure Preview Portal Azure Web Apps Azure Cloud Services For more information about installing and using our Node.js agent with Azure, see Node.js agent on Microsoft Azure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22081,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "sections": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " for <em>accounts</em> created through New Relic partners, with links to additional resources as applicable. Create a New Relic <em>account</em> (all partners) If you have received a special offer from a New Relic <em>partner</em>, follow the <em>partner</em>&#x27;s link directly to create a New Relic <em>account</em>. Sign into and deploy New Relic (most"
      },
      "id": "6043f447e7b9d2f5295799e5"
    },
    {
      "sections": [
        "RightScale users and New Relic",
        "Add New Relic RightScripts",
        "Example PHP RightScript installation",
        "View APM monitoring data",
        "Upgrade your New Relic subscription"
      ],
      "title": "RightScale users and New Relic",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "53775c11e82931aa08ef2d107aaa3f023368559b",
      "image": "https://docs.newrelic.com/static/84cd6a6ee1fe0ce671be3d3d710ab5a4/8c557/screen-nr-rightscale-applist.png",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/rightscale-users-new-relic/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-09-14T05:47:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "RightScale is a Software as a Service (SaaS) solution capable of hosting web applications. Supported languages for both New Relic and RightScale include Java, Ruby, .NET, PHP, and Python. In order to use New Relic through the RightScale partnership, you need a New Relic account. Before getting started, be sure to enable API access. Add New Relic RightScripts Before you can view data from New Relic in RightScale, add the appropriate New Relic RightScript to your ServerTemplates: From RightCloud, select Design > MultiCloud Marketplace > ServerTemplates. Import the New Relic Performance Monitoring Toolbox ServerTemplate into your Local view. After you import the ServerTemplate, you can use the associated New Relic RightScripts with your account and add them to your ServerTemplates as appropriate for your agent language. New Relic RightScript Notes Java Tomcat For use with Tomcat5 and Tomcat6 ServerTemplates. Installs our Java agent and configures it for use with Tomcat with APM. .NET Installs and configures the New Relic agent to monitor .NET applications. Using New Relic for .NET requires .NET 3.5 or higher on the target host. (If you have only 4.0 or higher installed, you must have .NET Version 3.5 installed on the target host.) With the 3.5 framework, New Relic instruments applications targeting .NET frameworks 2.0 or higher running on Windows Server 2003, Windows Server 2008, Windows Vista, Windows 7, and Windows Azure. PHP Installs and configures the New Relic PHP agent and a local proxy daemon. New Relic supports PHP versions 5.2 or higher on Apache 2.2 or 2.4. Python To install and configure the New Relic Python agent, do not use RightScripts. Instead, send an email to rightscale@newrelic.com. Ruby To use the New Relic agent for your Ruby on Rails application, see New Relic for Ruby. Example PHP RightScript installation Here is an example of adding the APP New Relic RPM for PHP RightScripts to a PHP application server. Add the APP New Relic RPM for PHP RightScript as a boot script to the ServerTemplate that is being used to run your PHP application servers. This will automatically deploy the New Relic agent when a new server is launched with that ServerTemplate. If your PHP application is already running on a server, you can add it as an operational script under the Scripts tab, and run the action on the running server. Be sure to define the following input value for the new script: NR_License_Key: Enter your New Relic license key. Copy You can either manually enter the license key or create a credential for it. View APM monitoring data When viewing the data that New Relic monitors, you will only see the names of the applications that are on servers where you have run the New Relic RightScript. A host is a server and an instance is an instance of an application. RightScale users: Example of apps you can view in New Relic. To view your New Relic data: Go to Reports > New Relic. From the list of application(s) in your New Relic RightScript deployment, select an application name. On your first login, be sure to change your password: From the (account dropdown in the New Relic UI, select User preferences. Use the New Relic menu options to view different performance data and charts. Upgrade your New Relic subscription For RightScale customers, all new accounts start with a free 14-day trial of New Relic's paid subscription features. If you want to upgrade your free account to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.2208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "RightScale users <em>and</em> New Relic",
        "sections": "Example PHP RightScript <em>installation</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " customers, all new <em>accounts</em> start with a free 14-day trial of New Relic&#x27;s paid subscription features. If you want to upgrade your free <em>account</em> to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale."
      },
      "id": "603eb08b28ccbc289aeba7a2"
    }
  ],
  "/docs/accounts/install-new-relic/partner-based-installation/rightscale-users-new-relic": [
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Log in to and install New Relic via partners",
        "Create a New Relic account (all partners)",
        "Sign into and deploy New Relic (most partners)",
        "Sign into and deploy New Relic (special partners)",
        "Tip",
        "A - M partners",
        "Amazon Web Services (AWS)",
        "Google Cloud Platform (GCP)",
        "Heroku",
        "Magento",
        "N - Z partners",
        "Pantheon",
        "Rackspace Cloud Tools",
        "W3 Edge and WordPress",
        "Windows Azure"
      ],
      "title": "Log in to and install New Relic via partners",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "d6c766c0328d09f6208426396d5443d115029fcc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/log-install-new-relic-partners/",
      "published_at": "2021-10-24T19:09:47Z",
      "updated_at": "2021-09-14T05:47:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you signed up for New Relic through one of New Relic's partners, you may need to follow additional single sign on (SSO) procedures to log in to start using New Relic. There also may be special steps needed to complete the deployment process. This document provides basic login procedures for accounts created through New Relic partners, with links to additional resources as applicable. Create a New Relic account (all partners) If you have received a special offer from a New Relic partner, follow the partner's link directly to create a New Relic account. Sign into and deploy New Relic (most partners) You will receive an email confirmation message with a link to confirm your account, sign into New Relic, and complete the deployment process. Sign into and deploy New Relic (special partners) These partners require specific login and deployment procedures for you to use your New Relic account. Tip If you signed up for a New Relic account through a partner that is not listed here, follow standard procedures to sign into and deploy New Relic. A - M partners Amazon Web Services (AWS) Different installation and page viewing procedures apply, depending on whether you want to install AWS for your app or your host. For more information, see Amazon Web Services (AWS) users. Google Cloud Platform (GCP) As a Google Cloud Platform (GCP) partner, New Relic supports the App Engine flexible environment. Each APM agent has its own requirements for the GAE flex environment. After you install the New Relic agent, you can view your app performance with APM. Heroku Heroku is a Platform as a Service (PaaS) solution capable of hosting web applications. With the New Relic Heroku add-on, you can extend Heroku with metrics from APM and browser monitoring. The New Relic add-on supports Java, Node.js, PHP, Python, and Ruby. For more information about installing and using New Relic with Heroku, see: Heroku dev center documentation New Relic's documentation for installing Heroku Magento Magento has partnered with New Relic to give merchants faster access to data and out-of-the-box tools. The New Relic Reporting Extension helps e-commerce businesses to make data-driven decisions. To create a New Relic account with Magento for your PHP app: Sign up via your Magento sales solution provider. After you sign up for your New Relic account, deploy the PHP agent to your Magento installation. Wait a few minutes, then check your app's performance in the APM Overview page. N - Z partners Pantheon To create a New Relic account through Pantheon and sign into New Relic: From Pantheon's partner page with New Relic, select the sign up link. Follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. After a few minutes, you can check your app's performance in the APM Overview page. For more information, see Pantheon's documentation. Rackspace Cloud Tools To create an account through Rackspace Cloud Tools and sign into New Relic, follow these basic procedures. For more information, see Rackspace Cloud Load Balancer plugin. Log in to your CloudTools account at cloudtools.rackspace.com/myapps. From Use Your Applications, select New Relic. Select your agent language (Java, .NET, PHP, Python, Ruby), then follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. Wait a few minutes, then check your app's performance in the APM Overview page. W3 Edge and WordPress Tip To create an account through W3 Total Cache and sign into New Relic, you must install and run the W3 PHP agent, not just get an API key. Deploying the agent requires administrative access, including: SSH/command line access Root or sudo access to run the New Relic installer and restart your web server If you are running an economy, shared hosting, or blogger package, or if you are not sure what are your account permissions, contact your hosting provider. For example, if your WordPress site is on shared servers, you may not be able to install New Relic. Your provider should be able to give you information about your account permissions, or upgrade your account if necessary. To install the New Relic plugin for W3 Edge/Wordpress users: Log in to your WordPress account at wordpress.org/support/bb-login.php. Follow New Relic's instructions to complete the installation process, or contact W3TC support for assistance. Wait for New Relic to begin collecting data. Within a few minutes after deploying the agent, performance data about your app will appear on APM's Applications Overview page. Tip WordPress also offers a plugin for our browser monitoring. Windows Azure Windows Azure is a Platform as a Service (PaaS) solution capable of hosting web applications using various languages, including .NET and Node.js. For more information about using our .NET agent with Azure, see: Installing the .NET agent on Azure Azure Preview Portal Azure Web Apps Azure Cloud Services For more information about installing and using our Node.js agent with Azure, see Node.js agent on Microsoft Azure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.2208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "sections": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " for <em>accounts</em> created through New Relic partners, with links to additional resources as applicable. Create a New Relic <em>account</em> (all partners) If you have received a special offer from a New Relic <em>partner</em>, follow the <em>partner</em>&#x27;s link directly to create a New Relic <em>account</em>. Sign into and deploy New Relic (most"
      },
      "id": "6043f447e7b9d2f5295799e5"
    },
    {
      "sections": [
        "Heroku: Install the New Relic add-on",
        "Install the New Relic add-on",
        "Configure the agent",
        "Java",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Manage your Heroku add-on accounts",
        "License key",
        "Account URL",
        "Account ID",
        "Log on to New Relic",
        "Sign in to New Relic add-on account through Heroku",
        "Sign in to regular New Relic accounts",
        "Set up deployment notifications",
        "Important"
      ],
      "title": "Heroku: Install the New Relic add-on",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "45ca4960759150545d4f9e586555d6e15daef3ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/heroku-install-new-relic-add/",
      "published_at": "2021-10-24T22:53:31Z",
      "updated_at": "2021-09-14T05:46:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Heroku is a Platform as a Service (PaaS) solution for hosting web applications in various agent languages. With New Relic, you can extend Heroku with metrics from our monitoring solutions, like APM and browser monitoring. The New Relic add-on supports Java, Node.js, PHP, Python, and Ruby. Install the New Relic add-on To set up the New Relic add-on, see Heroku's documentation, including available plan levels and Toolbelt procedures. If you have problems, use the Heroku support channels. Configure the agent After you install the New Relic add-on for Heroku, follow the configuration procedures for your APM agent. Java The minimum agent version for Java is 3.17.1 or higher. To install and configure New Relic's Java agent for your add-on, see our Java agent and Heroku documentation. Node.js To install and configure our Node.js agent for your add-on, see: New Relic's Node.js and Heroku documentation Blog post (2013) with a \"real world\" example of installing our Node.js agent for a Heroku app PHP To install and configure our PHP agent for your add-on, see our PHP agent and Heroku documentation. Python To install and configure our Python agent for your add-on, see our Python agent and Heroku documentation. Ruby To install and configure our Ruby agent for your add-on, see our Ruby agent and Heroku documentation. If you are using our Ruby agent with a non-Rails application, Heroku users need to install the plugin in your repository manually. For example, in a Sinatra app, add the newrelic gem to your Gemfile, and then add the following code to your app: configure :production do require 'newrelic_rpm' end Copy Manage your Heroku add-on accounts Every time you install the New Relic add-on for Heroku, New Relic will automatically create a new account, complete with a unique license key, account URL, and account ID. These three types of information are important for managing each of your Heroku add-on accounts. License key The license key identifies the account where your application reports. To check the license key your app is using: From a command line, run: heroku config | grep -i relic Copy Look for the value of NEW_RELIC_LICENSE_KEY. This license key environment variable will override any other license key that you hard-code into your New Relic config file. Account URL If you install the New Relic add-on multiple times and need to verify the URL your Heroku app uses for reporting to New Relic, look in your agent logs for a line indicating reporting to following by a URL using this format: rpm.newrelic.com/accounts/###/applications/###### Copy Account ID You cannot change your add-on's account ID directly. If you need to change the New Relic account your Heroku app uses for reporting to New Relic, change the current license key environment variable in its config file so that it points to the license key of the New Relic account you want to use: heroku config:set NEW_RELIC_LICENSE_KEY=changed_account_license_key Copy Log on to New Relic Heroku customers may have two different types of accounts with New Relic: Add-on accounts: New Relic accounts that customers installed on their Heroku application by using Heroku's New Relic add-on \"Regular\" accounts: Other New Relic accounts that customers did not install with Heroku's add-on Regular accounts provide a wider range of features than do add-on accounts, and are installed and managed differently. Different procedures apply, depending on which type of account you want to sign into. In accordance with the terms of New Relic's partnership with Heroku, customers who install New Relic via the Heroku add-on can only access their New Relic add-on accounts by signing in through Heroku. For this reason, if you have both add-on accounts and regular New Relic accounts, you cannot switch directly between them. Sign in to New Relic add-on account through Heroku To sign in to your New Relic add-on accounts: Sign in through Heroku's login page at id.heroku.com/login. Select the application that has the New Relic add-on installed. Select New Relic from your list of add-ons. If you sign in through Heroku, you will not see any of your regular New Relic accounts when you select account dropdown > Switch account. Sign in to regular New Relic accounts To sign into or switch between your regular New Relic accounts: Sign in to New Relic at one.newrelic.com. To switch from one regular New Relic account to another: Go to: **account dropdown and select an account. If you sign in directly through New Relic, you will not see any of your New Relic add-on accounts from Heroku when you select account dropdown > Switch account. Set up deployment notifications The Heroku add-on automatically sends deployment notifications to New Relic for one application per account. If you add multiple applications to your add-on account, you must use the New Relic REST API to manually send deployment notifications for your additional applications. You cannot use a post-deploy hook, because the New Relic REST API call requires a header, and Heroku's post-deploy hook does not allow headers. However, you can write a script that generates this API call whenever you deploy on Heroku. For instructions on recording deployments via the REST API, see Recording deployments. Important When you add a user to the Heroku add-on, this creates a user record for the user at New Relic. However, if you remove the user from the Heroku add-on, the user record is not automatically removed from New Relic. Instead, you must also manually remove the New Relic user record after removing the user from the Heroku add-on. You can do this by going to the User Management page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Heroku: <em>Install</em> the New Relic add-on",
        "sections": "Manage your Heroku add-on <em>accounts</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " the newrelic gem to your Gemfile, and then add the following code to your app: configure :production do require &#x27;newrelic_rpm&#x27; end Copy Manage your Heroku add-on <em>accounts</em> Every time you install the New Relic add-on for Heroku, New Relic will automatically create a new <em>account</em>, complete with a unique license"
      },
      "id": "603ebc9ae7b9d272c32a0810"
    }
  ],
  "/docs/accounts/install-new-relic/partner-based-installation/windows-azure-users-new-relic": [
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.31242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>Account</em> access",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " are some causes and solutions: If your organization has multiple <em>accounts</em> and you have access to those <em>accounts</em>, you will see an <em>account</em> switcher at the top left of most New Relic UI pages that will let you switch between <em>accounts</em>. If you&#x27;re logged into New Relic but can&#x27;t find an <em>account</em> or its data"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "Log in to and install New Relic via partners",
        "Create a New Relic account (all partners)",
        "Sign into and deploy New Relic (most partners)",
        "Sign into and deploy New Relic (special partners)",
        "Tip",
        "A - M partners",
        "Amazon Web Services (AWS)",
        "Google Cloud Platform (GCP)",
        "Heroku",
        "Magento",
        "N - Z partners",
        "Pantheon",
        "Rackspace Cloud Tools",
        "W3 Edge and WordPress",
        "Windows Azure"
      ],
      "title": "Log in to and install New Relic via partners",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "d6c766c0328d09f6208426396d5443d115029fcc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/log-install-new-relic-partners/",
      "published_at": "2021-10-24T19:09:47Z",
      "updated_at": "2021-09-14T05:47:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you signed up for New Relic through one of New Relic's partners, you may need to follow additional single sign on (SSO) procedures to log in to start using New Relic. There also may be special steps needed to complete the deployment process. This document provides basic login procedures for accounts created through New Relic partners, with links to additional resources as applicable. Create a New Relic account (all partners) If you have received a special offer from a New Relic partner, follow the partner's link directly to create a New Relic account. Sign into and deploy New Relic (most partners) You will receive an email confirmation message with a link to confirm your account, sign into New Relic, and complete the deployment process. Sign into and deploy New Relic (special partners) These partners require specific login and deployment procedures for you to use your New Relic account. Tip If you signed up for a New Relic account through a partner that is not listed here, follow standard procedures to sign into and deploy New Relic. A - M partners Amazon Web Services (AWS) Different installation and page viewing procedures apply, depending on whether you want to install AWS for your app or your host. For more information, see Amazon Web Services (AWS) users. Google Cloud Platform (GCP) As a Google Cloud Platform (GCP) partner, New Relic supports the App Engine flexible environment. Each APM agent has its own requirements for the GAE flex environment. After you install the New Relic agent, you can view your app performance with APM. Heroku Heroku is a Platform as a Service (PaaS) solution capable of hosting web applications. With the New Relic Heroku add-on, you can extend Heroku with metrics from APM and browser monitoring. The New Relic add-on supports Java, Node.js, PHP, Python, and Ruby. For more information about installing and using New Relic with Heroku, see: Heroku dev center documentation New Relic's documentation for installing Heroku Magento Magento has partnered with New Relic to give merchants faster access to data and out-of-the-box tools. The New Relic Reporting Extension helps e-commerce businesses to make data-driven decisions. To create a New Relic account with Magento for your PHP app: Sign up via your Magento sales solution provider. After you sign up for your New Relic account, deploy the PHP agent to your Magento installation. Wait a few minutes, then check your app's performance in the APM Overview page. N - Z partners Pantheon To create a New Relic account through Pantheon and sign into New Relic: From Pantheon's partner page with New Relic, select the sign up link. Follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. After a few minutes, you can check your app's performance in the APM Overview page. For more information, see Pantheon's documentation. Rackspace Cloud Tools To create an account through Rackspace Cloud Tools and sign into New Relic, follow these basic procedures. For more information, see Rackspace Cloud Load Balancer plugin. Log in to your CloudTools account at cloudtools.rackspace.com/myapps. From Use Your Applications, select New Relic. Select your agent language (Java, .NET, PHP, Python, Ruby), then follow the online instructions to complete the installation process. Wait for New Relic to begin collecting data for your app. Wait a few minutes, then check your app's performance in the APM Overview page. W3 Edge and WordPress Tip To create an account through W3 Total Cache and sign into New Relic, you must install and run the W3 PHP agent, not just get an API key. Deploying the agent requires administrative access, including: SSH/command line access Root or sudo access to run the New Relic installer and restart your web server If you are running an economy, shared hosting, or blogger package, or if you are not sure what are your account permissions, contact your hosting provider. For example, if your WordPress site is on shared servers, you may not be able to install New Relic. Your provider should be able to give you information about your account permissions, or upgrade your account if necessary. To install the New Relic plugin for W3 Edge/Wordpress users: Log in to your WordPress account at wordpress.org/support/bb-login.php. Follow New Relic's instructions to complete the installation process, or contact W3TC support for assistance. Wait for New Relic to begin collecting data. Within a few minutes after deploying the agent, performance data about your app will appear on APM's Applications Overview page. Tip WordPress also offers a plugin for our browser monitoring. Windows Azure Windows Azure is a Platform as a Service (PaaS) solution capable of hosting web applications using various languages, including .NET and Node.js. For more information about using our .NET agent with Azure, see: Installing the .NET agent on Azure Azure Preview Portal Azure Web Apps Azure Cloud Services For more information about installing and using our Node.js agent with Azure, see Node.js agent on Microsoft Azure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.2208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "sections": "Log in to <em>and</em> <em>install</em> New Relic via <em>partners</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " for <em>accounts</em> created through New Relic partners, with links to additional resources as applicable. Create a New Relic <em>account</em> (all partners) If you have received a special offer from a New Relic <em>partner</em>, follow the <em>partner</em>&#x27;s link directly to create a New Relic <em>account</em>. Sign into and deploy New Relic (most"
      },
      "id": "6043f447e7b9d2f5295799e5"
    },
    {
      "sections": [
        "RightScale users and New Relic",
        "Add New Relic RightScripts",
        "Example PHP RightScript installation",
        "View APM monitoring data",
        "Upgrade your New Relic subscription"
      ],
      "title": "RightScale users and New Relic",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Partner installation"
      ],
      "external_id": "53775c11e82931aa08ef2d107aaa3f023368559b",
      "image": "https://docs.newrelic.com/static/84cd6a6ee1fe0ce671be3d3d710ab5a4/8c557/screen-nr-rightscale-applist.png",
      "url": "https://docs.newrelic.com/docs/accounts/install-new-relic/partner-based-installation/rightscale-users-new-relic/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-09-14T05:47:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "RightScale is a Software as a Service (SaaS) solution capable of hosting web applications. Supported languages for both New Relic and RightScale include Java, Ruby, .NET, PHP, and Python. In order to use New Relic through the RightScale partnership, you need a New Relic account. Before getting started, be sure to enable API access. Add New Relic RightScripts Before you can view data from New Relic in RightScale, add the appropriate New Relic RightScript to your ServerTemplates: From RightCloud, select Design > MultiCloud Marketplace > ServerTemplates. Import the New Relic Performance Monitoring Toolbox ServerTemplate into your Local view. After you import the ServerTemplate, you can use the associated New Relic RightScripts with your account and add them to your ServerTemplates as appropriate for your agent language. New Relic RightScript Notes Java Tomcat For use with Tomcat5 and Tomcat6 ServerTemplates. Installs our Java agent and configures it for use with Tomcat with APM. .NET Installs and configures the New Relic agent to monitor .NET applications. Using New Relic for .NET requires .NET 3.5 or higher on the target host. (If you have only 4.0 or higher installed, you must have .NET Version 3.5 installed on the target host.) With the 3.5 framework, New Relic instruments applications targeting .NET frameworks 2.0 or higher running on Windows Server 2003, Windows Server 2008, Windows Vista, Windows 7, and Windows Azure. PHP Installs and configures the New Relic PHP agent and a local proxy daemon. New Relic supports PHP versions 5.2 or higher on Apache 2.2 or 2.4. Python To install and configure the New Relic Python agent, do not use RightScripts. Instead, send an email to rightscale@newrelic.com. Ruby To use the New Relic agent for your Ruby on Rails application, see New Relic for Ruby. Example PHP RightScript installation Here is an example of adding the APP New Relic RPM for PHP RightScripts to a PHP application server. Add the APP New Relic RPM for PHP RightScript as a boot script to the ServerTemplate that is being used to run your PHP application servers. This will automatically deploy the New Relic agent when a new server is launched with that ServerTemplate. If your PHP application is already running on a server, you can add it as an operational script under the Scripts tab, and run the action on the running server. Be sure to define the following input value for the new script: NR_License_Key: Enter your New Relic license key. Copy You can either manually enter the license key or create a credential for it. View APM monitoring data When viewing the data that New Relic monitors, you will only see the names of the applications that are on servers where you have run the New Relic RightScript. A host is a server and an instance is an instance of an application. RightScale users: Example of apps you can view in New Relic. To view your New Relic data: Go to Reports > New Relic. From the list of application(s) in your New Relic RightScript deployment, select an application name. On your first login, be sure to change your password: From the (account dropdown in the New Relic UI, select User preferences. Use the New Relic menu options to view different performance data and charts. Upgrade your New Relic subscription For RightScale customers, all new accounts start with a free 14-day trial of New Relic's paid subscription features. If you want to upgrade your free account to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.2208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "RightScale users <em>and</em> New Relic",
        "sections": "Example PHP RightScript <em>installation</em>",
        "tags": "<em>Accounts</em> <em>and</em> <em>billing</em>",
        "body": " customers, all new <em>accounts</em> start with a free 14-day trial of New Relic&#x27;s paid subscription features. If you want to upgrade your free <em>account</em> to a paid subscription, send an email to rightscale@newrelic.com. You cannot upgrade your New Relic subscription within RightScale."
      },
      "id": "603eb08b28ccbc289aeba7a2"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-data-retention/event-data-retention-original-pricing-plan": [
    {
      "sections": [
        "Overview of data retention (original pricing plan)",
        "Important",
        "Limits on editing and deleting data",
        "Product and API data retention policies",
        "APM",
        "APM data retention policies",
        "Legacy APM data retention policies",
        "Browser",
        "Infrastructure",
        "Tip",
        "Infrastructure downsampling and data retention",
        "Integration compute unit event limits",
        "Insights",
        "Logs",
        "Logs in context data retention",
        "Mobile",
        "Mobile data retention policies",
        "Standard Mobile (legacy) data retention policies",
        "Plugins",
        "Plugins data retention",
        "Legacy Plugins data retention",
        "Synthetics",
        "Synthetics data retention policies",
        "Metric API",
        "Trace API",
        "Data components",
        "Event data: reported by most products",
        "Metric timeslice data: reported by APM, Browser, and Mobile",
        "Aggregate metric timeslice data: reported by APM, Browser, and Mobile",
        "Key metrics: reported by APM, Browser, and Mobile",
        "Trace data: reported by APM, Browser, and Mobile"
      ],
      "title": "Overview of data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "22d5ab9f4d623ead28ee7bb82c118d91804dee22",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-based-pricing/overview-data-retention-components/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-09-14T14:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on our New Relic One pricing plan, see Manage your data. Not sure which you're on? See Overview of pricing plans. If you're on the original product-based pricing plan, you retain your existing subscriptions and data retention values. You manage these existing retention settings from the Data management hub in New Relic One. To manage your retention settings, go to the Data management UI. You'll see your existing retention settings. Adjust retention values by clicking Edit retention. New Relic stores different types of data for different periods of time. The retention period for a type of data will vary depending on the product, the subscription level, and the feature. Limits on editing and deleting data Once telemetry data (events, metrics, logs, traces) is reported to New Relic and available for querying, that data cannot be edited or deleted. This is a purposeful design decision that optimizes New Relic's speed and performance. Data will expire after its data retention ends. If you sent unwanted data or sensitive data to New Relic that must be removed, contact your account representative at New Relic, or get support at support.newrelic.com. Product and API data retention policies Select a New Relic product to see details about its data retention: APM Specific retention policies apply to each APM subscription level, including Lite, Essentials, Pro, and Enterprise. This includes metric timeslice data, key metrics, trace data, and event data. In addition to retention limits, your data is subject to aggregation (averaging) after certain elapsed time periods. For more information, see the aggregate metric data description. APM data retention policies For accounts on our original product-based pricing, APM data retention policies depend on your APM product subscription level. Component Lite Essentials Pro Metric timeslice data 24 hours 3 days 90 days Key metrics none forever forever Distributed tracing and logs in context none none 8 days Other trace data * 1 day 3 days 7 days Event data * * 1 day 3 days 8 days * If you view a transaction trace in the New Relic UI, New Relic stores that trace data for up to one year. * * Learn about how to extend the retention of event data. Legacy APM data retention policies Component Standard Startup Small Business Enterprise Metric timeslice data 7 days 14 days 30 days 90 days Key metrics none none none forever Trace data 7 days 7 days 7 days 7 days Event data none 8 days 8 days 8 days Browser For accounts on our original product-based pricing, Browser data is stored depending on your subscription level: Component Lite Pro Metric data 24 hours 90 days Key metrics 24 hours forever Trace data 7 days 7 days Event data * 1 day 8 days SPA data Unavailable 8 days * Learn about how to extend the retention of event data. Infrastructure For accounts on our original product-based pricing, Infrastructure data retention policies depend on your Infrastructure subscription level and your New Relic Infrastructure compute units pricing model. Data retention rules apply the same whether that data is displayed in the UI or queried. Tip Infrastructure data retention is not governed by your Insights subscription. Infrastructure downsampling and data retention Types of data are stored depending on your subscription level: Component Essentials Pro Infrastructure data 3 months 13 months Host count Host count will stop reflecting a host whose agent is no longer reporting after three minutes. However, host data will be available, subject to other retention criteria. 3 minutes 3 minutes Inventory attributes removed Inventory attributes for a host are retained for 24 hours after the agent stops reporting. 24 hours 24 hours Integration data Not available with Essentials Limit of 2275 integration events per compute unit per month In addition, Infrastructure downsamples your data on the fly, as it's generated. All Infrastructure metric data types (including On-Host Integrations metrics) will display different granularity depending on the age of the data and the size of the time window. The following table illustrates when different downsampled buckets will be used, both in the Infrastructure UI and for queries: Bucket Size Used For Time Windows Covering... Data Retained For... Raw (5, 10 or 15 second) 0 to 59 minutes 7 days 1 minute 60 minutes to 6 hours 30 days 10 minutes 6 hours to 3 days Full account retention period 1 hour 3 days to 14 days Full account retention period 3 hours 14+ days Full account retention period Integration compute unit event limits The 2275 limit on integration events per compute unit per month is a limit on total Infrastructure integration events. It's not a limit of 2275 for each integration's events. Additional details and clarifications about this limit: This limit applies to all events from all integrations (cloud integrations and on-host integrations). The events are all handled the same. Default data received by the Infrastructure agent does not count against the 2275 event per compute unit limit. If you exceed your limit, we do not enforce this limit. If you exceed your limit, we'll review pricing options with you to ensure you get the most cost-effective pricing for your organization's integrations. Insights For accounts on our original product-based pricing, an Insights subscription extends your event data retention. An Insights Pro subscription allows you to customize the length of your event data retention. Logs For accounts on our original product-based pricing, log data can be retained for up to 30 days by New Relic. Shorter retention periods of 8 or 15 days are also available. Logs in context data retention New Relic Logs logs in context data retention policy is based on your current APM product subscription level. For more information, see APM data retention. Mobile For accounts on our original product-based pricing, Mobile data retention policies depend on your New Relic Mobile product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and event data. For information about your subscription-related data usage, see Mobile subscription usage. Mobile data retention policies Component Lite Enterprise Overview page data 24 hours 90 days Crash data and stack traces 24 hours 90 days HTTP requests (except errors) as metric data Unavailable 90 days HTTP request errors as metric data Unavailable 3 days Interaction traces Unavailable 90 days Custom events * Unavailable 1 day Mobile events * 1 day 8 days MobileBreadcrumb events * Unavailable 3 days MobileCrash events * 1 day 90 days MobileHandledException events * Unavailable 3 days MobileJSError events (React Native beta) * Unavailable 3 days MobileRequest events * Unavailable 3 days MobileRequestError events * Unavailable 3 days MobileSession events * 1 day 90 days * Learn how to extend retention of event data. Standard Mobile (legacy) data retention policies Unless otherwise noted, Insights event data is unavailable for Standard subscriptions. Component Standard Overview page data 7 days Crash data and stack traces 7 days HTTP requests (except errors) as metric data 7 days HTTP request errors as metric data 3 days Interaction traces Unavailable MobileCrash events 8 days MobileSession events 8 days Plugins The retention period for historical data depends on the product and subscription level. The following data retention periods exist for New Relic Plugins. Important Plugins is not supported with accounts that host data in the EU region data center. Plugins data retention Component Lite Essentials Pro Enterprise Metric data 24 hours 3 days 90 days 90 days Legacy Plugins data retention Component Standard Startup Small Business Metric data 7 days 14 days 30 days Synthetics For accounts on our original product-based pricing, Synthetics data retention policies depend on your Synthetics product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and Insights events. Tip Synthetics events do not count against an Insights Pro subscription. Your current subscription level appears in the right column of the Account summary page: Go to synthetics.newrelic.com > (account dropdown) > Account settings > Account > Summary. Synthetics data retention policies Component Lite Pro Synthetics monitor data 2 weeks 13 months Event data 2 weeks 13 months Also see the data retention details for APIs, including: Metric API All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Trace API See Trace API general requirements and limits. Data components For accounts on our original product-based pricing, the section below provides an explanation of some types of data components governed by the data retention rules of specific products: Event data: reported by most products See Event data retention for information on the event data type. Metric timeslice data: reported by APM, Browser, and Mobile Metric timeslice data is a specific type of data that is used for most metric charts and reports in APM, mobile, and browser. Important Note that metric timeslice data differs from other metric data types. All metric timeslice data is aggregated, but New Relic deals with fresh data and old data in different ways. Fresh data has specific policies applied to the data to keep granular views of performance as aggregate metrics. As data ages and becomes less useful in a granular state, we summarize that data and only keep key metrics. Aggregate metric timeslice data: reported by APM, Browser, and Mobile Aggregate metric timeslice data summarizes calls to specific methods in your application: how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on your subscription level. Subscription Level Aggregate retention Enterprise Aggregates (averages) to 1-hour periods after 8 days. After 90 days, the permanent metric data continues to be stored in 1-hour periods. This means you cannot obtain data granularity of less than 1 hour after 8 days, and only a subset of metrics are available after 90 days. Pro After 8 days Essentials After 3 days. Legacy Small Business, Startup, and Standard After 3 days. Lite After 2 hours. We retain your most recent data in one-minute increments. We also aggregate permanent metric data to day-size increments after 90 days. When looking at older data in small time windows, you may notice that charts show less detail. As data ages, it is aggregated into larger segments. Key metrics: reported by APM, Browser, and Mobile New Relic retains certain \"key\" metric timeslice data aggregations forever for Enterprise and Pro customers, for any number of applications. New Relic aggregates permanent key metric data to hour-size increments after 90 days. Product Key metrics APM Apdex, for app server Throughput and page views Response time, plus breakdown into tiers or categories on your app's main Overview chart Page load time, plus breakdown into segments Error rate CPU usage Memory usage Browser Apdex, for browser Browser page load time Throughput total. After 90 days, there is no breakout by browser type, and only the combined average value is available for the time range requested. Mobile Crash rate: For iOS and for Android Network throughput Network response time Network error rates Interaction traces Trace data: reported by APM, Browser, and Mobile Depending on the product, New Relic retains different types of trace data: Product Trace data APM Types of trace data: Transaction traces Distributed tracing Slow query samples Error details See APM data retention details. Browser Types of trace data: Session traces Browser traces JavaScript errors* See Browser data retention details. Mobile Types of trace data: App crash stack traces Interaction traces See Mobile data retention details. * JavaScript errors in the stack trace UI are saved as trace data. JS errors are also saved as events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.48334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of <em>data</em> <em>retention</em> (<em>original</em> pricing plan)",
        "sections": "Overview of <em>data</em> <em>retention</em> (<em>original</em> pricing plan)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " timeslice <em>data</em>, key metrics, trace <em>data</em>, and event <em>data</em>. In addition to <em>retention</em> limits, your <em>data</em> is subject to aggregation (averaging) after certain elapsed time periods. For more information, see the aggregate metric <em>data</em> description. APM <em>data</em> <em>retention</em> policies For <em>accounts</em> on our <em>original</em> product"
      },
      "id": "6043f75364441f6967378ec6"
    },
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.55746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "sections": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled <em>account</em>. When you configure multiple New Relic <em>accounts</em> with SAML, your SAML provider typically requires each <em>account</em> to have a unique entity ID. If you need to configure multiple <em>accounts</em> with separate SAML identities"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Bulk user actions (original user model)",
        "Important",
        "Update users in bulk",
        "Example CSV file",
        "Troubleshooting",
        "If you have a backup CSV file",
        "If no backup file exists"
      ],
      "title": "Bulk user actions (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original users and roles"
      ],
      "external_id": "ebfb52863fb5b57a14a2c298a2518c42f23c0908",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/roles-permissions/bulk-user-actions-add-delete-or-update-batches-users/",
      "published_at": "2021-10-24T22:50:46Z",
      "updated_at": "2021-08-09T00:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains how to manage users on our original user model. Not sure which model you're on? See Overview of user models. With the Bulk user actions feature, you can add, update, or delete multiple users at once. This can be helpful for: adding roles when multiple new employees start deleting roles when multiple employees leave giving multiple employees Admin roles Update users in bulk Some important rules and recommendations for making bulk user actions: You cannot make updates to your own role or an Owner role. You cannot edit an existing user's email address or name. You should avoid editing an existing user by deleting and re-adding them because this can have unintended consequences (for example, API keys associated with the original user will be lost). To add new user roles, update existing user roles, or delete user roles for users on the original user model: Go to: account dropdown > Account settings > Users and roles, and add /bulk_actions at the end of the URL. Example URL: https://account.newrelic.com/accounts/123456789/users/bulk_actions Copy Download a Backup CSV file. Downloading a backup file keeps a record of the users in your account prior to changes being made, and allows you to easily re-add any users that may be removed accidentally. Download a CSV of users or a CSV template. Each bulk action (add, update, or delete) will require its own CSV file. New Relic recommends saving your files with an account number, date, and the bulk action being performed. For example: account_123456789_delete_users_2018-06-29 Populate that sheet with only the users whose roles you'll be applying the chosen bulk action for. Remove users from the spreadsheet whose roles you do not want to change. Bulk action Fields Add Required fields: user email, name, type, base role Optional field: add-on role Update Required fields: user email (do not edit), name (do not edit), base role Optional field: add-on role Delete Required fields: only user email Example CSV file The following is an example downloaded CSV of users that lists four users on the New Relic account. In this example, we want to delete the user Alex Datanerd. All other users must be removed before uploading the CSV. Email Name Type Base role Add-on roles Last active User1 @Company.com Jane Datanerd full Owner 2/6/20 User2 @Company.com Jamie Datanerd full Admin 6/6/20 User3 @Company.com Alex Datanerd full User apm_admin, browser_admin 7/25/20 User4 @Company.com Pat Datanerd basic User alerts_admin, insights_admin, apm_admin 4/6/20 The other three users, whose roles will remain unchanged, are removed. The final CSV only shows Alex's name. This file would then be uploaded using the Delete users in CSV option in the UI. Email Name Type Base role Add-on roles Last active User3 @Company.com Alex Datanerd full User apm_admin, browser_admin In the UI, select a CSV action: Add, Update, or Delete the users listed within the CSV file. Upload the new CSV, and select Save changes. Troubleshooting If a user is removed or changed during your CSV file upload by mistake, you can add them back through another CSV file upload. Important Be aware that associated permissions may be lost when a user is deleted and re-added. For example, associated API keys will need to be re-added. If you have a backup CSV file If you have a backup CSV file saved: Open the backup CSV file. Populate the backup CSV file with the users whose roles will be modified. Select a CSV action for the new CSV file: add, update, or delete Upload the new CSV, and select Save changes. If no backup file exists If no backup CSV file has been previously downloaded: Download the CSV file template. Populate the spreadsheet with the information required for the user to be restored. Action Required fields Add User email, name, type, base role. Optional: Add-on role Update User email, name, type, base role. Optional: Add-on role Delete User email Select a CSV action for the new CSV file: Add, Update, or Delete. Upload the new CSV, and select Save changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.73085,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bulk user actions (<em>original</em> user model)",
        "sections": "Bulk user actions (<em>original</em> user model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " to: <em>account</em> dropdown &gt; <em>Account</em> settings &gt; Users and roles, and add &#x2F;bulk_actions at the end of the URL. Example URL: https:&#x2F;&#x2F;<em>account</em>.newrelic.com&#x2F;<em>accounts</em>&#x2F;123456789&#x2F;users&#x2F;bulk_actions Copy Download a Backup CSV file. Downloading a backup file keeps a record of the users in your <em>account</em> prior to changes"
      },
      "id": "6043f605e7b9d264815799e1"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-pricing-plan-usage/apm-cu-based-subscription-usage": [
    {
      "sections": [
        "Infrastructure subscription usage",
        "Important",
        "Data generation",
        "Usage calculation",
        "Tip",
        "Table definitions",
        "General attributes",
        "Infrastructure attributes",
        "Query examples",
        "Compute units for last month",
        "Detailed host report (reproducing old usage report)",
        "Account hierarchy"
      ],
      "title": "Infrastructure subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "036858ab7d7fb54da536202e11788d0fc1029460",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/infrastructure-subscription-usage/",
      "published_at": "2021-10-24T19:09:48Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Infrastructure accounts. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, a New Relic Infrastructure account will generate an NrDailyUsage event for every unique host on which an application instance existed over the last 24 hours. All Infrastructure events have a productLine attribute value of Infrastructure. For more information, see query examples. Usage calculation Monthly billable CUs for a host are calculated by the size of the host running Infrastructure (number of CPUs + GBs of RAM) multiplied by the number of hours the host is connected to New Relic during that month. For more on how this is calculated, see CU-based pricing. If your usage is fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To view usage information in the UI: Go to the usage UI. On the Infrastructure usage page, set the time picker to Last 30 days. Multiply the Avg daily compute units by the number of days in the current month. For more information about the usage UI, see Introduction to subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns displayed depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily compute units The average daily compute units used. % of total usage The percentage of the total usage used. General attributes The following are general (not Infrastructure-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Infrastructure attributes The following are usage-related attributes generated by Infrastructure. To query this data, use a productLine attribute value of Infrastructure. Attribute Description agentHostname ID used to uniquely identify the host for which this usage is reported. Any given hour of usage for this host will be counted only once when calculating infrastructureHoursUsed. There are several possible host identifiers reported by the New Relic agent. The usage reporting system will always use the agent-reported hostname to uniquely identify the host for the Infrastructure product, but will also record the cloudInstanceId, if present, for informational purposes. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This will not be present if no cloud provider was detected by the agent. cloudInstanceSize Size of the cloud instance for this host for CU billing purposes, as calculated according to the formula for infrastructureBillingInstanceSize, using the CPU and memory sizes associated with the instance type defined by the cloud provider. Will not be present if no cloud provider was detected by the agent. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. infrastructureAgentVersion Version of the Infrastructure agent running on the host reporting this usage. If multiple agents are reporting from the same host, the version from the first agent seen in a given hour will be used. infrastructureAgentMemoryBytes Bytes of RAM available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureAgentProcessorCount Number of logical CPU cores available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedMemoryBytes Bytes of RAM available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedProcessorCount Number of logical CPU cores available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureBillingInstanceSize Size of the host, for CU billing purposes. Calculated as: number of processors multiplied by memory in GiB. infrastructureHoursUsed Number of hours for which usage was recorded for the given host. When a host is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. infrastructureComputeUnits Number of compute units (CUs) recorded for the given host. CUs are calculated as: infrastructureHoursUsed multiplied by infrastructureBillingInstanceSize. For more about compute unit calculation, see CU pricing. infrastructureComputeUnitRule Describes the algorithm used to calculate the host size for CU usage. Values include: agent_collected_calculated_data: Use the host size data collected by the agent from the OS environment. cloud_provider_data: Use the host size data from the cloud provider. missing_data: Some host size data was missing. This could be due to an agent and operating system combination for which CPU and memory sizes are not supported. This will result in the default host size (16) being applied. instanceSizeCapped This is True if the calculated host size was greater than 16 and therefore capped. missingCpuData True if the Infrastructure agent reports no CPU count. missingRamData True if the Infrastructure agent reports no memory count. productLine The New Relic product the usage data is from. Always use the value Infrastructure when querying for Infrastructure usage data. usageType The type of entity this event records values for. This value is Host for Infrastructure. Query examples Here are some examples of NRQL queries you can use with your Infrastructure subscription usage data. You can run NRQL queries, and use the resulting charts in dashboards. For general information about how to use NRQL queries to get focused usage data, see Intro to usage data. Compute units for last month This query produces a count of the CUs used over the last month: SELECT sum(infrastructureComputeUnits) FROM NrDailyUsage WHERE productLine='Infrastructure' AND usageType='Host' SINCE last month UNTIL this month Copy Detailed host report (reproducing old usage report) This query reproduces as closely as possible the report you would have gotten by downloading the CSV from the previously available Infrastructure subscription usage UI: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID',agentHostname,cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type',infrastructureBillingInstanceSize AS 'Instance size',infrastructureHoursUsed AS 'Hours used',infrastructureComputeUnits AS 'Usage (CU)', infrastructureCloudDerivedMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureCloudDerivedProcessorCount AS 'Logical processors',infrastructureAgentMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureAgentProcessorCount AS 'Logical processors',infrastructureComputeUnitRule AS 'Business rule',missingCpuData, missingRamData, instanceSizeCapped,cloudZone,cloudInstanceId WHERE productLine='Infrastructure' AND usageType='Host' SINCE 1 day ago LIMIT 1000 Copy This NRQL query is different than the legacy usage report: Detailed host query Comments Time period This query includes only the last day of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to 1000 NRQL limits the results to 1000. If you have more than 1000 hosts and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example, WHERE agentHostname LIKE ... to divide the data into groups). Business rule Business rule has been replaced with two attributes: infrastructureComputeUnitRule defines how the size of the host was calculated, depending on what data was available from the agent. It no longer describes whether the agent needs to be updated to provide more accurate host naming in a container environment (update_agent_for_container_environment). missingCpuData, missingRamData, and instanceSizeCapped are now boolean flags describing what the value missing_data means when it is present in the infrastructureComputeUnitRule attribute. Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure subscription <em>usage</em>",
        "sections": "Infrastructure subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e87a7196a676ed2a83db4"
    },
    {
      "sections": [
        "APM (host-based) subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "APM attributes (host-based)",
        "Query examples",
        "Usage for last month",
        "Usage per host per application",
        "Instance-hours per application",
        "Agent version information",
        "Account hierarchy",
        "Legacy per-host usage report",
        "Legacy host usage report (application listing)",
        "Use of Docker and other containers"
      ],
      "title": "APM (host-based) subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "afaa1272f61e4c003e687d26e904438c0391cda1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/apm-host-based-subscription-usage/",
      "published_at": "2021-10-24T20:32:07Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this doc explains how New Relic calculates billable usage for APM accounts that have host-based pricing (not CU-based pricing). This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, an APM account will generate an NrDailyUsage event for: Every application instance that existed during the last 24 hours Every unique host on which an application instance ran during the last 24 hours These two types of events allow your usage data to be queried and analyzed in many different ways. To query the application events, use a usageType attribute value of Application. To query the host events, use a usageType attribute value of Host. All APM events use a productLine attribute value of APM. For more information, see APM query examples. Usage calculations For host-based APM pricing, monthly billable usage is determined by the number of equivalent hosts used during that month. An equivalent host is defined as: 750 hours (standardized number of monthly hours) of connection to New Relic by a host or multiple hosts. For more on this calculation, see host-based pricing. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To get an estimate of the current month's billable usage: Go to the usage UI. On the APM usage page, set the time picker to Current month. See the Avg daily equivalent hosts for an account or grouping of accounts. The UI is meant to estimate your host usage but, especially for cloud environments, your usage may go up or down over time. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers in the UI table and CSV files. The columns you see depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Host ID The unique identifier for that host. If the host is in AWS, we use the AWS-provided instance ID. For other hosts, New Relic assigns a host ID. For more about how this value is created, see hostID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily equivalent hosts Average equivalent hosts for that day. Calculated as the total number of hours reported for all unique hosts in a day, divided by 24. For more on how this is calculated, see Host-based pricing. % of total usage The percentage of the total usage used. General attributes The following are general (not APM-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. APM attributes (host-based) The following are usage-related attributes generated by host-based APM accounts (not CU-based APM). To query APM-specific data, use a productLine attribute value of APM. Attribute Description agentHostname ID reported by the agent to uniquely identify the host for which this usage event is reported. This value can come from several sources in the application’s environment, but commonly is the value returned by the gethostname Linux syscall. In Docker environments, this attribute can take on the value (sometimes truncated) of the Docker container ID. agentHostname is one of three possible providers for the hostId value. apmAgentVersion Version of the New Relic APM agent running in the application instance reporting this usage. Present only for events where usageType equals Application. To update your agent version, see Update the New Relic agent. apmAppId ID uniquely identifying the application that is reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmAppName Name of the application reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmHoursUsed Number of hours for which usage was recorded for the given entity. When an entity is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. When calculating monthly APM host usage, the calculation for equivalent hosts for a month assumes that a standard month has 750 hours: ` apmHoursUsed / 750 ` . apmLanguage Name of the language that the usage-reporting application is written in, as reported by the New Relic agent. Examples: ruby, java, python. Present only for events where usageType equals Application. bootId Linux boot ID of host for which this usage is reported, which is unique for each boot lifetime of each Linux operating system instance. Will only be present when the New Relic agent is one of the following versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher bootId is one of three possible providers for the hostId value. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This is used to uniquely identify the host if the apmComputeUnitRule is cloud_provider_data. This will not be present if no cloud provider was detected by the agent. Agents with these versions will detect cloud provider data for AWS: Go: 1.11 or higher Java: 3.18.0 or higher .NET: 5.1.72.0 or higher Node.js: 1.21.0 or higher PHP: 5.5.0 or higher Python: 2.54.0.41 or higher Ruby: 3.12.1.298 or higher cloudInstanceId is one of three possible providers for the hostId value. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. containerId ID of the Docker or other Linux container in which the application instance is running. This will not be present if a container was not detected by the agent. Present only for events where usageType equals Application. This attribute is not used to uniquely identify hosts for billing purposes. hostId ID used to uniquely identify the host for which this usage is reported. Any given hour of APM usage for this host will be counted only once when calculating apmHoursUsed. There are several possible host identifiers reported by the New Relic agent. The attributes, if present, will be chosen to use in this order of precedence: cloudInstanceId, bootId, agentHostname. productLine The New Relic product the usage data is from. Always use the value APM when querying for APM CU usage data. usageType For APM, this value can be either Application or Host, depending on the type of entity this event records usage for (other New Relic products will have different values for usageType). Events with both values are recorded so that usage data can be analyzed in several ways. For Application: the event represents usage for a single unique application instance for that day. For Host: the event represents usage for a single unique host for that day. Only Host entities are used to calculate billable usage. Application entities are useful for comparing usage between applications, but are not used for billing or contract purposes. Query examples Here are some examples of NRQL queries you can use with your account usage data. You can run NRQL queries and use the resulting charts in dashboards. Usage for last month This query uses New Relic’s standard number of hours per month (750) for the purpose of calculating APM equivalent hosts over the last month. SELECT sum(apmHoursUsed)/750 AS 'Equivalent hosts' FROM NrDailyUsage WHERE usageType='Host' AND productLine='APM' SINCE last month UNTIL this month Copy Usage per host per application New Relic records usage per application instance, not strictly per application. This query gives an approximation of the usage for a given application on a given host. If unique application instances run sequentially on a host within a given day, this query could return an underestimate (this would be likely, for example, in a container environment). SELECT max(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName,hostId SINCE 1 day ago LIMIT 2000 Copy Instance-hours per application This query measures the total number of hours used by all instances (processes) of an application in the last 24 hours. It's useful for determining which applications are responsible for APM usage, but does not return results that match precisely how New Relic prices APM usage. Each application instance is counted separately in this query, even if it runs concurrently with another application instance on the same host, so the number of application instance-hours is likely to be greater than the number of host-hours (the billable quantity). SELECT sum(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName SINCE 1 day ago LIMIT 2000 Copy Agent version information Use this query to see which agent versions are running on your applications in the last 24 hours. This information can be useful in determining whether the agent needs to be upgraded to report a more accurate host name in a Docker container environment (either a Linux boot ID or a cloud provider instance ID). FROM NrDailyUsage SELECT count(*) WHERE productLine='APM' AND usageType='Application' FACET consumingAccountId, consumingAccountName, apmAppName, apmAgentVersion, apmLanguage SINCE 1 day ago LIMIT 2000 Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 2000 SINCE 1 day ago Copy Legacy per-host usage report This query produces a close approximation of the CSV report you would have seen in the deprecated UI system: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID', hostId, cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type', apmBillingInstanceSize AS 'Instance size', apmHoursUsed AS 'Hours used', apmComputeUnits AS 'Usage (CU)', apmMemoryBytes/(1024*1024*1024) AS 'Total RAM', apmProcessorCount AS 'Logical processors', apmContainerCount AS 'Container count', apmComputeUnitRule AS 'Business rule', missingCpuData, missingRamData, instanceSizeCapped, cloudZone, cloudInstanceId WHERE productLine='APM' AND usageType='Host' SINCE 1 day ago LIMIT 2000 Copy This NRQL query is different than the legacy usage report: Per-host query Comments Time period This query includes only the last 24 hours of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to a maximum number of rows NRQL limits the number of rows returned. If you have more hosts than the maximum number of rows returned and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example WHERE cloudInstanceId LIKE “%0”) to divide the data into up to 16 groups, modulo the last character in the AWS instance ID. Docker container IDs A single Docker container ID does not appear in this report. A Docker container ID is reported only at the application instance level of granularity (usageType='Application'). For the host (usageType='Host'), a count of unique containers is reported, since there are often very many. While choosing just one container ID to report for a host had been informative, now there is more data reported at the appropriate level of granularity. Business rule Business rule has been replaced with other attributes. It no longer is used to describe whether the agent needs to be updated. Legacy host usage report (application listing) This query returns data once provided in the \"host usage report\": a listing of applications running on each host. Note that while APM usage is counted on an hour-by-hour basis, per-hour usage data is no longer available via the API or UI. FROM NrDailyUsage SELECT min(timestamp) AS 'Earliest reporting day',max(timestamp) AS 'Latest reporting day' FACET apmAppName,hostId,agentHostname,consumingAccountName,consumingAccountId WHERE usageType='Application' AND productLine='APM' SINCE 1 month ago LIMIT 2000 Copy Use of Docker and other containers Some previous New Relic APM agents may miscount containers as hosts, which may lead to over-reporting of host-based usage. To fix this calculation for Linux-based containers (including Docker), upgrade your APM agent to these versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM (host-based) subscription <em>usage</em>",
        "sections": "APM (host-based) subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this doc explains how New Relic calculates billable"
      },
      "id": "603e834128ccbc66fdeba78b"
    },
    {
      "sections": [
        "Browser subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "Browser attributes",
        "Query examples",
        "Page views for the last complete month",
        "Page views for the last week by account",
        "Page views for the past month, by application:",
        "Account hierarchy",
        "SPA usage",
        "Notes on Insights subscription"
      ],
      "title": "Browser subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "1accc55c1dd4a3a35550f8d209f40a602b06a330",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-pricing-plan-usage/browser-subscription-usage/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-07-01T15:31:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Browser subscription usage. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. For details about single-page app (SPA) monitoring usage, see SPA usage. Data generation Once per hour, for every monitored application, a New Relic Browser account will generate a NrUsage event. Each event will summarize the usage for the last hour. When querying Browser usage data, use a productLine attribute value of Browser. For more information, see the Browser query examples. Usage calculations Monthly subscription usage equals the total number of page views that month across all end-user browsers. AJAX traffic does not count against your daily usage. If your page views are fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrUsage event. To view usage information in the UI: Go to: account dropdown > View your usage. On the Browser usage page, set the time picker to Last 30 days. Multiply the Avg daily page views by the number of days in the current month. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns visible depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account, or a customer partnership. Account ID New Relic account ID. Average daily page views The average daily page views for that account or application. % of total usage The percentage of the total usage used. General attributes The following are general (not Browser-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Browser attributes The following are usage-related attributes generated by New Relic Browser. To query Browser data, use a productLine attribute value of Browser. Attribute Description browserPageViewCount Number of page views for an application for that 24-hour period. For more on how events are generated, see Data generation.Page views for both Pro and Lite Browser agents are counted. productLine The New Relic product the usage data is from. For Browser data, this value is Browser. usageType The type of entity this event records values for. For Browser, this value is Application. browserAppId ID uniquely identifying the application reporting this usage, as it appears in the Browser product. isPrimaryApp Deprecated April 2, 2020. Boolean. true means the application is the primary app. false means the app is one of several apps that an agent reports data for. For more on multiple app names in APM and Browser, see Use multiple app names. The sum of events where this attribute is true will give an accurate total of page views when you are using the multiple app names feature. Counting events where this attribute is false will result in over-counting of usage. Query examples Here are some examples of NRQL queries you can use with your subscription usage data. You can run NRQL queries and use the resulting charts in dashboards. Page views for the last complete month This query shows a count of page views from the last complete month: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE last month UNTIL this month Copy Page views for the last week by account This query shows a count of page views from the last week by account: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 7 days ago FACET consumingAccountName Copy Page views for the past month, by application: This query shows a count of page views from the past month by application SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 30 days ago FACET browserAppID Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts): SELECT count(*) FROM NrUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy SPA usage Page views are used by New Relic Browser to determine customer data usage and product pricing. This document defines a page view in the context of New Relic Browser's SPA monitoring and explains why: SPA monitoring does not affect Browser data usage SPA monitoring will increase Insights data usage In New Relic Browser, a page view is defined as a complete load or reload of a page, signaled by the firing of the window.onload event. New Relic's SPA monitoring tracks traditional page views, but it also tracks changes in the browser that do not require a page load, such as: Route and hash changes Synchronous and asynchronous JavaScript Dynamic server-side updates to a page Route changes are tracked automatically, and by setting up custom instrumentation you can capture almost any type of browser interaction. With New Relic Browser Pro, pricing is based on an account's number of page views per month. If SPA monitoring is enabled, browser interactions that do not require a page load are not counted as page views for billing purposes. With SPA monitoring, you can track an unlimited number of route changes and other custom browser interactions that don't involve page loads. Notes on Insights subscription If you switch from standard Browser monitoring to SPA monitoring, and you also pay for Insights (and don't use only your complementary Insights subscription), your Insights data usage will increase. Because SPA monitoring is a more advanced way to monitor your application, it creates more Insights events than standard monitoring for the following reasons: Page views create not only PageView events, but also BrowserInteraction, AjaxRequest, and BrowserTiming events. For the typical SPA-architecture app, there are more route changes than there are standard page loads. If you pay for Insights and your current Insights license is not sufficient for the amount of events generated with SPA monitoring, we will notify you when you have exceeded your data usage plan. To remedy this, the following options are available: Upgrade your Insights plan. Turn off the reporting of some event types. Use the Browser API to manually turn off collection of some events Switch from Browser SPA monitoring back to standard monitoring",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.27458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser subscription <em>usage</em>",
        "sections": "Browser subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e8774e7b9d28a042a07d2"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-pricing-plan-usage/apm-host-based-subscription-usage": [
    {
      "sections": [
        "Infrastructure subscription usage",
        "Important",
        "Data generation",
        "Usage calculation",
        "Tip",
        "Table definitions",
        "General attributes",
        "Infrastructure attributes",
        "Query examples",
        "Compute units for last month",
        "Detailed host report (reproducing old usage report)",
        "Account hierarchy"
      ],
      "title": "Infrastructure subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "036858ab7d7fb54da536202e11788d0fc1029460",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/infrastructure-subscription-usage/",
      "published_at": "2021-10-24T19:09:48Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Infrastructure accounts. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, a New Relic Infrastructure account will generate an NrDailyUsage event for every unique host on which an application instance existed over the last 24 hours. All Infrastructure events have a productLine attribute value of Infrastructure. For more information, see query examples. Usage calculation Monthly billable CUs for a host are calculated by the size of the host running Infrastructure (number of CPUs + GBs of RAM) multiplied by the number of hours the host is connected to New Relic during that month. For more on how this is calculated, see CU-based pricing. If your usage is fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To view usage information in the UI: Go to the usage UI. On the Infrastructure usage page, set the time picker to Last 30 days. Multiply the Avg daily compute units by the number of days in the current month. For more information about the usage UI, see Introduction to subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns displayed depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily compute units The average daily compute units used. % of total usage The percentage of the total usage used. General attributes The following are general (not Infrastructure-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Infrastructure attributes The following are usage-related attributes generated by Infrastructure. To query this data, use a productLine attribute value of Infrastructure. Attribute Description agentHostname ID used to uniquely identify the host for which this usage is reported. Any given hour of usage for this host will be counted only once when calculating infrastructureHoursUsed. There are several possible host identifiers reported by the New Relic agent. The usage reporting system will always use the agent-reported hostname to uniquely identify the host for the Infrastructure product, but will also record the cloudInstanceId, if present, for informational purposes. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This will not be present if no cloud provider was detected by the agent. cloudInstanceSize Size of the cloud instance for this host for CU billing purposes, as calculated according to the formula for infrastructureBillingInstanceSize, using the CPU and memory sizes associated with the instance type defined by the cloud provider. Will not be present if no cloud provider was detected by the agent. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. infrastructureAgentVersion Version of the Infrastructure agent running on the host reporting this usage. If multiple agents are reporting from the same host, the version from the first agent seen in a given hour will be used. infrastructureAgentMemoryBytes Bytes of RAM available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureAgentProcessorCount Number of logical CPU cores available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedMemoryBytes Bytes of RAM available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedProcessorCount Number of logical CPU cores available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureBillingInstanceSize Size of the host, for CU billing purposes. Calculated as: number of processors multiplied by memory in GiB. infrastructureHoursUsed Number of hours for which usage was recorded for the given host. When a host is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. infrastructureComputeUnits Number of compute units (CUs) recorded for the given host. CUs are calculated as: infrastructureHoursUsed multiplied by infrastructureBillingInstanceSize. For more about compute unit calculation, see CU pricing. infrastructureComputeUnitRule Describes the algorithm used to calculate the host size for CU usage. Values include: agent_collected_calculated_data: Use the host size data collected by the agent from the OS environment. cloud_provider_data: Use the host size data from the cloud provider. missing_data: Some host size data was missing. This could be due to an agent and operating system combination for which CPU and memory sizes are not supported. This will result in the default host size (16) being applied. instanceSizeCapped This is True if the calculated host size was greater than 16 and therefore capped. missingCpuData True if the Infrastructure agent reports no CPU count. missingRamData True if the Infrastructure agent reports no memory count. productLine The New Relic product the usage data is from. Always use the value Infrastructure when querying for Infrastructure usage data. usageType The type of entity this event records values for. This value is Host for Infrastructure. Query examples Here are some examples of NRQL queries you can use with your Infrastructure subscription usage data. You can run NRQL queries, and use the resulting charts in dashboards. For general information about how to use NRQL queries to get focused usage data, see Intro to usage data. Compute units for last month This query produces a count of the CUs used over the last month: SELECT sum(infrastructureComputeUnits) FROM NrDailyUsage WHERE productLine='Infrastructure' AND usageType='Host' SINCE last month UNTIL this month Copy Detailed host report (reproducing old usage report) This query reproduces as closely as possible the report you would have gotten by downloading the CSV from the previously available Infrastructure subscription usage UI: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID',agentHostname,cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type',infrastructureBillingInstanceSize AS 'Instance size',infrastructureHoursUsed AS 'Hours used',infrastructureComputeUnits AS 'Usage (CU)', infrastructureCloudDerivedMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureCloudDerivedProcessorCount AS 'Logical processors',infrastructureAgentMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureAgentProcessorCount AS 'Logical processors',infrastructureComputeUnitRule AS 'Business rule',missingCpuData, missingRamData, instanceSizeCapped,cloudZone,cloudInstanceId WHERE productLine='Infrastructure' AND usageType='Host' SINCE 1 day ago LIMIT 1000 Copy This NRQL query is different than the legacy usage report: Detailed host query Comments Time period This query includes only the last day of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to 1000 NRQL limits the results to 1000. If you have more than 1000 hosts and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example, WHERE agentHostname LIKE ... to divide the data into groups). Business rule Business rule has been replaced with two attributes: infrastructureComputeUnitRule defines how the size of the host was calculated, depending on what data was available from the agent. It no longer describes whether the agent needs to be updated to provide more accurate host naming in a container environment (update_agent_for_container_environment). missingCpuData, missingRamData, and instanceSizeCapped are now boolean flags describing what the value missing_data means when it is present in the infrastructureComputeUnitRule attribute. Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure subscription <em>usage</em>",
        "sections": "Infrastructure subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e87a7196a676ed2a83db4"
    },
    {
      "sections": [
        "Browser subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "Browser attributes",
        "Query examples",
        "Page views for the last complete month",
        "Page views for the last week by account",
        "Page views for the past month, by application:",
        "Account hierarchy",
        "SPA usage",
        "Notes on Insights subscription"
      ],
      "title": "Browser subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "1accc55c1dd4a3a35550f8d209f40a602b06a330",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-pricing-plan-usage/browser-subscription-usage/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-07-01T15:31:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Browser subscription usage. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. For details about single-page app (SPA) monitoring usage, see SPA usage. Data generation Once per hour, for every monitored application, a New Relic Browser account will generate a NrUsage event. Each event will summarize the usage for the last hour. When querying Browser usage data, use a productLine attribute value of Browser. For more information, see the Browser query examples. Usage calculations Monthly subscription usage equals the total number of page views that month across all end-user browsers. AJAX traffic does not count against your daily usage. If your page views are fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrUsage event. To view usage information in the UI: Go to: account dropdown > View your usage. On the Browser usage page, set the time picker to Last 30 days. Multiply the Avg daily page views by the number of days in the current month. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns visible depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account, or a customer partnership. Account ID New Relic account ID. Average daily page views The average daily page views for that account or application. % of total usage The percentage of the total usage used. General attributes The following are general (not Browser-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Browser attributes The following are usage-related attributes generated by New Relic Browser. To query Browser data, use a productLine attribute value of Browser. Attribute Description browserPageViewCount Number of page views for an application for that 24-hour period. For more on how events are generated, see Data generation.Page views for both Pro and Lite Browser agents are counted. productLine The New Relic product the usage data is from. For Browser data, this value is Browser. usageType The type of entity this event records values for. For Browser, this value is Application. browserAppId ID uniquely identifying the application reporting this usage, as it appears in the Browser product. isPrimaryApp Deprecated April 2, 2020. Boolean. true means the application is the primary app. false means the app is one of several apps that an agent reports data for. For more on multiple app names in APM and Browser, see Use multiple app names. The sum of events where this attribute is true will give an accurate total of page views when you are using the multiple app names feature. Counting events where this attribute is false will result in over-counting of usage. Query examples Here are some examples of NRQL queries you can use with your subscription usage data. You can run NRQL queries and use the resulting charts in dashboards. Page views for the last complete month This query shows a count of page views from the last complete month: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE last month UNTIL this month Copy Page views for the last week by account This query shows a count of page views from the last week by account: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 7 days ago FACET consumingAccountName Copy Page views for the past month, by application: This query shows a count of page views from the past month by application SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 30 days ago FACET browserAppID Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts): SELECT count(*) FROM NrUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy SPA usage Page views are used by New Relic Browser to determine customer data usage and product pricing. This document defines a page view in the context of New Relic Browser's SPA monitoring and explains why: SPA monitoring does not affect Browser data usage SPA monitoring will increase Insights data usage In New Relic Browser, a page view is defined as a complete load or reload of a page, signaled by the firing of the window.onload event. New Relic's SPA monitoring tracks traditional page views, but it also tracks changes in the browser that do not require a page load, such as: Route and hash changes Synchronous and asynchronous JavaScript Dynamic server-side updates to a page Route changes are tracked automatically, and by setting up custom instrumentation you can capture almost any type of browser interaction. With New Relic Browser Pro, pricing is based on an account's number of page views per month. If SPA monitoring is enabled, browser interactions that do not require a page load are not counted as page views for billing purposes. With SPA monitoring, you can track an unlimited number of route changes and other custom browser interactions that don't involve page loads. Notes on Insights subscription If you switch from standard Browser monitoring to SPA monitoring, and you also pay for Insights (and don't use only your complementary Insights subscription), your Insights data usage will increase. Because SPA monitoring is a more advanced way to monitor your application, it creates more Insights events than standard monitoring for the following reasons: Page views create not only PageView events, but also BrowserInteraction, AjaxRequest, and BrowserTiming events. For the typical SPA-architecture app, there are more route changes than there are standard page loads. If you pay for Insights and your current Insights license is not sufficient for the amount of events generated with SPA monitoring, we will notify you when you have exceeded your data usage plan. To remedy this, the following options are available: Upgrade your Insights plan. Turn off the reporting of some event types. Use the Browser API to manually turn off collection of some events Switch from Browser SPA monitoring back to standard monitoring",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.27458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser subscription <em>usage</em>",
        "sections": "Browser subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e8774e7b9d28a042a07d2"
    },
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.55746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "sections": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled <em>account</em>. When you configure multiple New Relic <em>accounts</em> with SAML, your SAML provider typically requires each <em>account</em> to have a unique entity ID. If you need to configure multiple <em>accounts</em> with separate SAML identities"
      },
      "id": "6043f753e7b9d2156e5799d8"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-pricing-plan-usage/browser-subscription-usage": [
    {
      "sections": [
        "Infrastructure subscription usage",
        "Important",
        "Data generation",
        "Usage calculation",
        "Tip",
        "Table definitions",
        "General attributes",
        "Infrastructure attributes",
        "Query examples",
        "Compute units for last month",
        "Detailed host report (reproducing old usage report)",
        "Account hierarchy"
      ],
      "title": "Infrastructure subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "036858ab7d7fb54da536202e11788d0fc1029460",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/infrastructure-subscription-usage/",
      "published_at": "2021-10-24T19:09:48Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Infrastructure accounts. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, a New Relic Infrastructure account will generate an NrDailyUsage event for every unique host on which an application instance existed over the last 24 hours. All Infrastructure events have a productLine attribute value of Infrastructure. For more information, see query examples. Usage calculation Monthly billable CUs for a host are calculated by the size of the host running Infrastructure (number of CPUs + GBs of RAM) multiplied by the number of hours the host is connected to New Relic during that month. For more on how this is calculated, see CU-based pricing. If your usage is fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To view usage information in the UI: Go to the usage UI. On the Infrastructure usage page, set the time picker to Last 30 days. Multiply the Avg daily compute units by the number of days in the current month. For more information about the usage UI, see Introduction to subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns displayed depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily compute units The average daily compute units used. % of total usage The percentage of the total usage used. General attributes The following are general (not Infrastructure-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Infrastructure attributes The following are usage-related attributes generated by Infrastructure. To query this data, use a productLine attribute value of Infrastructure. Attribute Description agentHostname ID used to uniquely identify the host for which this usage is reported. Any given hour of usage for this host will be counted only once when calculating infrastructureHoursUsed. There are several possible host identifiers reported by the New Relic agent. The usage reporting system will always use the agent-reported hostname to uniquely identify the host for the Infrastructure product, but will also record the cloudInstanceId, if present, for informational purposes. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This will not be present if no cloud provider was detected by the agent. cloudInstanceSize Size of the cloud instance for this host for CU billing purposes, as calculated according to the formula for infrastructureBillingInstanceSize, using the CPU and memory sizes associated with the instance type defined by the cloud provider. Will not be present if no cloud provider was detected by the agent. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. infrastructureAgentVersion Version of the Infrastructure agent running on the host reporting this usage. If multiple agents are reporting from the same host, the version from the first agent seen in a given hour will be used. infrastructureAgentMemoryBytes Bytes of RAM available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureAgentProcessorCount Number of logical CPU cores available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedMemoryBytes Bytes of RAM available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedProcessorCount Number of logical CPU cores available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureBillingInstanceSize Size of the host, for CU billing purposes. Calculated as: number of processors multiplied by memory in GiB. infrastructureHoursUsed Number of hours for which usage was recorded for the given host. When a host is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. infrastructureComputeUnits Number of compute units (CUs) recorded for the given host. CUs are calculated as: infrastructureHoursUsed multiplied by infrastructureBillingInstanceSize. For more about compute unit calculation, see CU pricing. infrastructureComputeUnitRule Describes the algorithm used to calculate the host size for CU usage. Values include: agent_collected_calculated_data: Use the host size data collected by the agent from the OS environment. cloud_provider_data: Use the host size data from the cloud provider. missing_data: Some host size data was missing. This could be due to an agent and operating system combination for which CPU and memory sizes are not supported. This will result in the default host size (16) being applied. instanceSizeCapped This is True if the calculated host size was greater than 16 and therefore capped. missingCpuData True if the Infrastructure agent reports no CPU count. missingRamData True if the Infrastructure agent reports no memory count. productLine The New Relic product the usage data is from. Always use the value Infrastructure when querying for Infrastructure usage data. usageType The type of entity this event records values for. This value is Host for Infrastructure. Query examples Here are some examples of NRQL queries you can use with your Infrastructure subscription usage data. You can run NRQL queries, and use the resulting charts in dashboards. For general information about how to use NRQL queries to get focused usage data, see Intro to usage data. Compute units for last month This query produces a count of the CUs used over the last month: SELECT sum(infrastructureComputeUnits) FROM NrDailyUsage WHERE productLine='Infrastructure' AND usageType='Host' SINCE last month UNTIL this month Copy Detailed host report (reproducing old usage report) This query reproduces as closely as possible the report you would have gotten by downloading the CSV from the previously available Infrastructure subscription usage UI: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID',agentHostname,cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type',infrastructureBillingInstanceSize AS 'Instance size',infrastructureHoursUsed AS 'Hours used',infrastructureComputeUnits AS 'Usage (CU)', infrastructureCloudDerivedMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureCloudDerivedProcessorCount AS 'Logical processors',infrastructureAgentMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureAgentProcessorCount AS 'Logical processors',infrastructureComputeUnitRule AS 'Business rule',missingCpuData, missingRamData, instanceSizeCapped,cloudZone,cloudInstanceId WHERE productLine='Infrastructure' AND usageType='Host' SINCE 1 day ago LIMIT 1000 Copy This NRQL query is different than the legacy usage report: Detailed host query Comments Time period This query includes only the last day of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to 1000 NRQL limits the results to 1000. If you have more than 1000 hosts and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example, WHERE agentHostname LIKE ... to divide the data into groups). Business rule Business rule has been replaced with two attributes: infrastructureComputeUnitRule defines how the size of the host was calculated, depending on what data was available from the agent. It no longer describes whether the agent needs to be updated to provide more accurate host naming in a container environment (update_agent_for_container_environment). missingCpuData, missingRamData, and instanceSizeCapped are now boolean flags describing what the value missing_data means when it is present in the infrastructureComputeUnitRule attribute. Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure subscription <em>usage</em>",
        "sections": "Infrastructure subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e87a7196a676ed2a83db4"
    },
    {
      "sections": [
        "APM (host-based) subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "APM attributes (host-based)",
        "Query examples",
        "Usage for last month",
        "Usage per host per application",
        "Instance-hours per application",
        "Agent version information",
        "Account hierarchy",
        "Legacy per-host usage report",
        "Legacy host usage report (application listing)",
        "Use of Docker and other containers"
      ],
      "title": "APM (host-based) subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "afaa1272f61e4c003e687d26e904438c0391cda1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/apm-host-based-subscription-usage/",
      "published_at": "2021-10-24T20:32:07Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this doc explains how New Relic calculates billable usage for APM accounts that have host-based pricing (not CU-based pricing). This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, an APM account will generate an NrDailyUsage event for: Every application instance that existed during the last 24 hours Every unique host on which an application instance ran during the last 24 hours These two types of events allow your usage data to be queried and analyzed in many different ways. To query the application events, use a usageType attribute value of Application. To query the host events, use a usageType attribute value of Host. All APM events use a productLine attribute value of APM. For more information, see APM query examples. Usage calculations For host-based APM pricing, monthly billable usage is determined by the number of equivalent hosts used during that month. An equivalent host is defined as: 750 hours (standardized number of monthly hours) of connection to New Relic by a host or multiple hosts. For more on this calculation, see host-based pricing. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To get an estimate of the current month's billable usage: Go to the usage UI. On the APM usage page, set the time picker to Current month. See the Avg daily equivalent hosts for an account or grouping of accounts. The UI is meant to estimate your host usage but, especially for cloud environments, your usage may go up or down over time. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers in the UI table and CSV files. The columns you see depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Host ID The unique identifier for that host. If the host is in AWS, we use the AWS-provided instance ID. For other hosts, New Relic assigns a host ID. For more about how this value is created, see hostID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily equivalent hosts Average equivalent hosts for that day. Calculated as the total number of hours reported for all unique hosts in a day, divided by 24. For more on how this is calculated, see Host-based pricing. % of total usage The percentage of the total usage used. General attributes The following are general (not APM-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. APM attributes (host-based) The following are usage-related attributes generated by host-based APM accounts (not CU-based APM). To query APM-specific data, use a productLine attribute value of APM. Attribute Description agentHostname ID reported by the agent to uniquely identify the host for which this usage event is reported. This value can come from several sources in the application’s environment, but commonly is the value returned by the gethostname Linux syscall. In Docker environments, this attribute can take on the value (sometimes truncated) of the Docker container ID. agentHostname is one of three possible providers for the hostId value. apmAgentVersion Version of the New Relic APM agent running in the application instance reporting this usage. Present only for events where usageType equals Application. To update your agent version, see Update the New Relic agent. apmAppId ID uniquely identifying the application that is reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmAppName Name of the application reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmHoursUsed Number of hours for which usage was recorded for the given entity. When an entity is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. When calculating monthly APM host usage, the calculation for equivalent hosts for a month assumes that a standard month has 750 hours: ` apmHoursUsed / 750 ` . apmLanguage Name of the language that the usage-reporting application is written in, as reported by the New Relic agent. Examples: ruby, java, python. Present only for events where usageType equals Application. bootId Linux boot ID of host for which this usage is reported, which is unique for each boot lifetime of each Linux operating system instance. Will only be present when the New Relic agent is one of the following versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher bootId is one of three possible providers for the hostId value. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This is used to uniquely identify the host if the apmComputeUnitRule is cloud_provider_data. This will not be present if no cloud provider was detected by the agent. Agents with these versions will detect cloud provider data for AWS: Go: 1.11 or higher Java: 3.18.0 or higher .NET: 5.1.72.0 or higher Node.js: 1.21.0 or higher PHP: 5.5.0 or higher Python: 2.54.0.41 or higher Ruby: 3.12.1.298 or higher cloudInstanceId is one of three possible providers for the hostId value. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. containerId ID of the Docker or other Linux container in which the application instance is running. This will not be present if a container was not detected by the agent. Present only for events where usageType equals Application. This attribute is not used to uniquely identify hosts for billing purposes. hostId ID used to uniquely identify the host for which this usage is reported. Any given hour of APM usage for this host will be counted only once when calculating apmHoursUsed. There are several possible host identifiers reported by the New Relic agent. The attributes, if present, will be chosen to use in this order of precedence: cloudInstanceId, bootId, agentHostname. productLine The New Relic product the usage data is from. Always use the value APM when querying for APM CU usage data. usageType For APM, this value can be either Application or Host, depending on the type of entity this event records usage for (other New Relic products will have different values for usageType). Events with both values are recorded so that usage data can be analyzed in several ways. For Application: the event represents usage for a single unique application instance for that day. For Host: the event represents usage for a single unique host for that day. Only Host entities are used to calculate billable usage. Application entities are useful for comparing usage between applications, but are not used for billing or contract purposes. Query examples Here are some examples of NRQL queries you can use with your account usage data. You can run NRQL queries and use the resulting charts in dashboards. Usage for last month This query uses New Relic’s standard number of hours per month (750) for the purpose of calculating APM equivalent hosts over the last month. SELECT sum(apmHoursUsed)/750 AS 'Equivalent hosts' FROM NrDailyUsage WHERE usageType='Host' AND productLine='APM' SINCE last month UNTIL this month Copy Usage per host per application New Relic records usage per application instance, not strictly per application. This query gives an approximation of the usage for a given application on a given host. If unique application instances run sequentially on a host within a given day, this query could return an underestimate (this would be likely, for example, in a container environment). SELECT max(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName,hostId SINCE 1 day ago LIMIT 2000 Copy Instance-hours per application This query measures the total number of hours used by all instances (processes) of an application in the last 24 hours. It's useful for determining which applications are responsible for APM usage, but does not return results that match precisely how New Relic prices APM usage. Each application instance is counted separately in this query, even if it runs concurrently with another application instance on the same host, so the number of application instance-hours is likely to be greater than the number of host-hours (the billable quantity). SELECT sum(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName SINCE 1 day ago LIMIT 2000 Copy Agent version information Use this query to see which agent versions are running on your applications in the last 24 hours. This information can be useful in determining whether the agent needs to be upgraded to report a more accurate host name in a Docker container environment (either a Linux boot ID or a cloud provider instance ID). FROM NrDailyUsage SELECT count(*) WHERE productLine='APM' AND usageType='Application' FACET consumingAccountId, consumingAccountName, apmAppName, apmAgentVersion, apmLanguage SINCE 1 day ago LIMIT 2000 Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 2000 SINCE 1 day ago Copy Legacy per-host usage report This query produces a close approximation of the CSV report you would have seen in the deprecated UI system: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID', hostId, cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type', apmBillingInstanceSize AS 'Instance size', apmHoursUsed AS 'Hours used', apmComputeUnits AS 'Usage (CU)', apmMemoryBytes/(1024*1024*1024) AS 'Total RAM', apmProcessorCount AS 'Logical processors', apmContainerCount AS 'Container count', apmComputeUnitRule AS 'Business rule', missingCpuData, missingRamData, instanceSizeCapped, cloudZone, cloudInstanceId WHERE productLine='APM' AND usageType='Host' SINCE 1 day ago LIMIT 2000 Copy This NRQL query is different than the legacy usage report: Per-host query Comments Time period This query includes only the last 24 hours of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to a maximum number of rows NRQL limits the number of rows returned. If you have more hosts than the maximum number of rows returned and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example WHERE cloudInstanceId LIKE “%0”) to divide the data into up to 16 groups, modulo the last character in the AWS instance ID. Docker container IDs A single Docker container ID does not appear in this report. A Docker container ID is reported only at the application instance level of granularity (usageType='Application'). For the host (usageType='Host'), a count of unique containers is reported, since there are often very many. While choosing just one container ID to report for a host had been informative, now there is more data reported at the appropriate level of granularity. Business rule Business rule has been replaced with other attributes. It no longer is used to describe whether the agent needs to be updated. Legacy host usage report (application listing) This query returns data once provided in the \"host usage report\": a listing of applications running on each host. Note that while APM usage is counted on an hour-by-hour basis, per-hour usage data is no longer available via the API or UI. FROM NrDailyUsage SELECT min(timestamp) AS 'Earliest reporting day',max(timestamp) AS 'Latest reporting day' FACET apmAppName,hostId,agentHostname,consumingAccountName,consumingAccountId WHERE usageType='Application' AND productLine='APM' SINCE 1 month ago LIMIT 2000 Copy Use of Docker and other containers Some previous New Relic APM agents may miscount containers as hosts, which may lead to over-reporting of host-based usage. To fix this calculation for Linux-based containers (including Docker), upgrade your APM agent to these versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM (host-based) subscription <em>usage</em>",
        "sections": "APM (host-based) subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this doc explains how New Relic calculates billable"
      },
      "id": "603e834128ccbc66fdeba78b"
    },
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.55737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "sections": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled <em>account</em>. When you configure multiple New Relic <em>accounts</em> with SAML, your SAML provider typically requires each <em>account</em> to have a unique entity ID. If you need to configure multiple <em>accounts</em> with separate SAML identities"
      },
      "id": "6043f753e7b9d2156e5799d8"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-pricing-plan-usage/infrastructure-subscription-usage": [
    {
      "sections": [
        "APM (host-based) subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "APM attributes (host-based)",
        "Query examples",
        "Usage for last month",
        "Usage per host per application",
        "Instance-hours per application",
        "Agent version information",
        "Account hierarchy",
        "Legacy per-host usage report",
        "Legacy host usage report (application listing)",
        "Use of Docker and other containers"
      ],
      "title": "APM (host-based) subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "afaa1272f61e4c003e687d26e904438c0391cda1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/apm-host-based-subscription-usage/",
      "published_at": "2021-10-24T20:32:07Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this doc explains how New Relic calculates billable usage for APM accounts that have host-based pricing (not CU-based pricing). This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, an APM account will generate an NrDailyUsage event for: Every application instance that existed during the last 24 hours Every unique host on which an application instance ran during the last 24 hours These two types of events allow your usage data to be queried and analyzed in many different ways. To query the application events, use a usageType attribute value of Application. To query the host events, use a usageType attribute value of Host. All APM events use a productLine attribute value of APM. For more information, see APM query examples. Usage calculations For host-based APM pricing, monthly billable usage is determined by the number of equivalent hosts used during that month. An equivalent host is defined as: 750 hours (standardized number of monthly hours) of connection to New Relic by a host or multiple hosts. For more on this calculation, see host-based pricing. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To get an estimate of the current month's billable usage: Go to the usage UI. On the APM usage page, set the time picker to Current month. See the Avg daily equivalent hosts for an account or grouping of accounts. The UI is meant to estimate your host usage but, especially for cloud environments, your usage may go up or down over time. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers in the UI table and CSV files. The columns you see depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Host ID The unique identifier for that host. If the host is in AWS, we use the AWS-provided instance ID. For other hosts, New Relic assigns a host ID. For more about how this value is created, see hostID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily equivalent hosts Average equivalent hosts for that day. Calculated as the total number of hours reported for all unique hosts in a day, divided by 24. For more on how this is calculated, see Host-based pricing. % of total usage The percentage of the total usage used. General attributes The following are general (not APM-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. APM attributes (host-based) The following are usage-related attributes generated by host-based APM accounts (not CU-based APM). To query APM-specific data, use a productLine attribute value of APM. Attribute Description agentHostname ID reported by the agent to uniquely identify the host for which this usage event is reported. This value can come from several sources in the application’s environment, but commonly is the value returned by the gethostname Linux syscall. In Docker environments, this attribute can take on the value (sometimes truncated) of the Docker container ID. agentHostname is one of three possible providers for the hostId value. apmAgentVersion Version of the New Relic APM agent running in the application instance reporting this usage. Present only for events where usageType equals Application. To update your agent version, see Update the New Relic agent. apmAppId ID uniquely identifying the application that is reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmAppName Name of the application reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmHoursUsed Number of hours for which usage was recorded for the given entity. When an entity is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. When calculating monthly APM host usage, the calculation for equivalent hosts for a month assumes that a standard month has 750 hours: ` apmHoursUsed / 750 ` . apmLanguage Name of the language that the usage-reporting application is written in, as reported by the New Relic agent. Examples: ruby, java, python. Present only for events where usageType equals Application. bootId Linux boot ID of host for which this usage is reported, which is unique for each boot lifetime of each Linux operating system instance. Will only be present when the New Relic agent is one of the following versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher bootId is one of three possible providers for the hostId value. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This is used to uniquely identify the host if the apmComputeUnitRule is cloud_provider_data. This will not be present if no cloud provider was detected by the agent. Agents with these versions will detect cloud provider data for AWS: Go: 1.11 or higher Java: 3.18.0 or higher .NET: 5.1.72.0 or higher Node.js: 1.21.0 or higher PHP: 5.5.0 or higher Python: 2.54.0.41 or higher Ruby: 3.12.1.298 or higher cloudInstanceId is one of three possible providers for the hostId value. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. containerId ID of the Docker or other Linux container in which the application instance is running. This will not be present if a container was not detected by the agent. Present only for events where usageType equals Application. This attribute is not used to uniquely identify hosts for billing purposes. hostId ID used to uniquely identify the host for which this usage is reported. Any given hour of APM usage for this host will be counted only once when calculating apmHoursUsed. There are several possible host identifiers reported by the New Relic agent. The attributes, if present, will be chosen to use in this order of precedence: cloudInstanceId, bootId, agentHostname. productLine The New Relic product the usage data is from. Always use the value APM when querying for APM CU usage data. usageType For APM, this value can be either Application or Host, depending on the type of entity this event records usage for (other New Relic products will have different values for usageType). Events with both values are recorded so that usage data can be analyzed in several ways. For Application: the event represents usage for a single unique application instance for that day. For Host: the event represents usage for a single unique host for that day. Only Host entities are used to calculate billable usage. Application entities are useful for comparing usage between applications, but are not used for billing or contract purposes. Query examples Here are some examples of NRQL queries you can use with your account usage data. You can run NRQL queries and use the resulting charts in dashboards. Usage for last month This query uses New Relic’s standard number of hours per month (750) for the purpose of calculating APM equivalent hosts over the last month. SELECT sum(apmHoursUsed)/750 AS 'Equivalent hosts' FROM NrDailyUsage WHERE usageType='Host' AND productLine='APM' SINCE last month UNTIL this month Copy Usage per host per application New Relic records usage per application instance, not strictly per application. This query gives an approximation of the usage for a given application on a given host. If unique application instances run sequentially on a host within a given day, this query could return an underestimate (this would be likely, for example, in a container environment). SELECT max(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName,hostId SINCE 1 day ago LIMIT 2000 Copy Instance-hours per application This query measures the total number of hours used by all instances (processes) of an application in the last 24 hours. It's useful for determining which applications are responsible for APM usage, but does not return results that match precisely how New Relic prices APM usage. Each application instance is counted separately in this query, even if it runs concurrently with another application instance on the same host, so the number of application instance-hours is likely to be greater than the number of host-hours (the billable quantity). SELECT sum(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName SINCE 1 day ago LIMIT 2000 Copy Agent version information Use this query to see which agent versions are running on your applications in the last 24 hours. This information can be useful in determining whether the agent needs to be upgraded to report a more accurate host name in a Docker container environment (either a Linux boot ID or a cloud provider instance ID). FROM NrDailyUsage SELECT count(*) WHERE productLine='APM' AND usageType='Application' FACET consumingAccountId, consumingAccountName, apmAppName, apmAgentVersion, apmLanguage SINCE 1 day ago LIMIT 2000 Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 2000 SINCE 1 day ago Copy Legacy per-host usage report This query produces a close approximation of the CSV report you would have seen in the deprecated UI system: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID', hostId, cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type', apmBillingInstanceSize AS 'Instance size', apmHoursUsed AS 'Hours used', apmComputeUnits AS 'Usage (CU)', apmMemoryBytes/(1024*1024*1024) AS 'Total RAM', apmProcessorCount AS 'Logical processors', apmContainerCount AS 'Container count', apmComputeUnitRule AS 'Business rule', missingCpuData, missingRamData, instanceSizeCapped, cloudZone, cloudInstanceId WHERE productLine='APM' AND usageType='Host' SINCE 1 day ago LIMIT 2000 Copy This NRQL query is different than the legacy usage report: Per-host query Comments Time period This query includes only the last 24 hours of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to a maximum number of rows NRQL limits the number of rows returned. If you have more hosts than the maximum number of rows returned and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example WHERE cloudInstanceId LIKE “%0”) to divide the data into up to 16 groups, modulo the last character in the AWS instance ID. Docker container IDs A single Docker container ID does not appear in this report. A Docker container ID is reported only at the application instance level of granularity (usageType='Application'). For the host (usageType='Host'), a count of unique containers is reported, since there are often very many. While choosing just one container ID to report for a host had been informative, now there is more data reported at the appropriate level of granularity. Business rule Business rule has been replaced with other attributes. It no longer is used to describe whether the agent needs to be updated. Legacy host usage report (application listing) This query returns data once provided in the \"host usage report\": a listing of applications running on each host. Note that while APM usage is counted on an hour-by-hour basis, per-hour usage data is no longer available via the API or UI. FROM NrDailyUsage SELECT min(timestamp) AS 'Earliest reporting day',max(timestamp) AS 'Latest reporting day' FACET apmAppName,hostId,agentHostname,consumingAccountName,consumingAccountId WHERE usageType='Application' AND productLine='APM' SINCE 1 month ago LIMIT 2000 Copy Use of Docker and other containers Some previous New Relic APM agents may miscount containers as hosts, which may lead to over-reporting of host-based usage. To fix this calculation for Linux-based containers (including Docker), upgrade your APM agent to these versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM (host-based) subscription <em>usage</em>",
        "sections": "APM (host-based) subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this doc explains how New Relic calculates billable"
      },
      "id": "603e834128ccbc66fdeba78b"
    },
    {
      "sections": [
        "Browser subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "Browser attributes",
        "Query examples",
        "Page views for the last complete month",
        "Page views for the last week by account",
        "Page views for the past month, by application:",
        "Account hierarchy",
        "SPA usage",
        "Notes on Insights subscription"
      ],
      "title": "Browser subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "1accc55c1dd4a3a35550f8d209f40a602b06a330",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-pricing-plan-usage/browser-subscription-usage/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-07-01T15:31:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Browser subscription usage. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. For details about single-page app (SPA) monitoring usage, see SPA usage. Data generation Once per hour, for every monitored application, a New Relic Browser account will generate a NrUsage event. Each event will summarize the usage for the last hour. When querying Browser usage data, use a productLine attribute value of Browser. For more information, see the Browser query examples. Usage calculations Monthly subscription usage equals the total number of page views that month across all end-user browsers. AJAX traffic does not count against your daily usage. If your page views are fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrUsage event. To view usage information in the UI: Go to: account dropdown > View your usage. On the Browser usage page, set the time picker to Last 30 days. Multiply the Avg daily page views by the number of days in the current month. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns visible depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account, or a customer partnership. Account ID New Relic account ID. Average daily page views The average daily page views for that account or application. % of total usage The percentage of the total usage used. General attributes The following are general (not Browser-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Browser attributes The following are usage-related attributes generated by New Relic Browser. To query Browser data, use a productLine attribute value of Browser. Attribute Description browserPageViewCount Number of page views for an application for that 24-hour period. For more on how events are generated, see Data generation.Page views for both Pro and Lite Browser agents are counted. productLine The New Relic product the usage data is from. For Browser data, this value is Browser. usageType The type of entity this event records values for. For Browser, this value is Application. browserAppId ID uniquely identifying the application reporting this usage, as it appears in the Browser product. isPrimaryApp Deprecated April 2, 2020. Boolean. true means the application is the primary app. false means the app is one of several apps that an agent reports data for. For more on multiple app names in APM and Browser, see Use multiple app names. The sum of events where this attribute is true will give an accurate total of page views when you are using the multiple app names feature. Counting events where this attribute is false will result in over-counting of usage. Query examples Here are some examples of NRQL queries you can use with your subscription usage data. You can run NRQL queries and use the resulting charts in dashboards. Page views for the last complete month This query shows a count of page views from the last complete month: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE last month UNTIL this month Copy Page views for the last week by account This query shows a count of page views from the last week by account: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 7 days ago FACET consumingAccountName Copy Page views for the past month, by application: This query shows a count of page views from the past month by application SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 30 days ago FACET browserAppID Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts): SELECT count(*) FROM NrUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy SPA usage Page views are used by New Relic Browser to determine customer data usage and product pricing. This document defines a page view in the context of New Relic Browser's SPA monitoring and explains why: SPA monitoring does not affect Browser data usage SPA monitoring will increase Insights data usage In New Relic Browser, a page view is defined as a complete load or reload of a page, signaled by the firing of the window.onload event. New Relic's SPA monitoring tracks traditional page views, but it also tracks changes in the browser that do not require a page load, such as: Route and hash changes Synchronous and asynchronous JavaScript Dynamic server-side updates to a page Route changes are tracked automatically, and by setting up custom instrumentation you can capture almost any type of browser interaction. With New Relic Browser Pro, pricing is based on an account's number of page views per month. If SPA monitoring is enabled, browser interactions that do not require a page load are not counted as page views for billing purposes. With SPA monitoring, you can track an unlimited number of route changes and other custom browser interactions that don't involve page loads. Notes on Insights subscription If you switch from standard Browser monitoring to SPA monitoring, and you also pay for Insights (and don't use only your complementary Insights subscription), your Insights data usage will increase. Because SPA monitoring is a more advanced way to monitor your application, it creates more Insights events than standard monitoring for the following reasons: Page views create not only PageView events, but also BrowserInteraction, AjaxRequest, and BrowserTiming events. For the typical SPA-architecture app, there are more route changes than there are standard page loads. If you pay for Insights and your current Insights license is not sufficient for the amount of events generated with SPA monitoring, we will notify you when you have exceeded your data usage plan. To remedy this, the following options are available: Upgrade your Insights plan. Turn off the reporting of some event types. Use the Browser API to manually turn off collection of some events Switch from Browser SPA monitoring back to standard monitoring",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.27458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser subscription <em>usage</em>",
        "sections": "Browser subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e8774e7b9d28a042a07d2"
    },
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.55737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "sections": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled <em>account</em>. When you configure multiple New Relic <em>accounts</em> with SAML, your SAML provider typically requires each <em>account</em> to have a unique entity ID. If you need to configure multiple <em>accounts</em> with separate SAML identities"
      },
      "id": "6043f753e7b9d2156e5799d8"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-pricing-plan-usage/insights-subscription-usage": [
    {
      "sections": [
        "Infrastructure subscription usage",
        "Important",
        "Data generation",
        "Usage calculation",
        "Tip",
        "Table definitions",
        "General attributes",
        "Infrastructure attributes",
        "Query examples",
        "Compute units for last month",
        "Detailed host report (reproducing old usage report)",
        "Account hierarchy"
      ],
      "title": "Infrastructure subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "036858ab7d7fb54da536202e11788d0fc1029460",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/infrastructure-subscription-usage/",
      "published_at": "2021-10-24T19:09:48Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Infrastructure accounts. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, a New Relic Infrastructure account will generate an NrDailyUsage event for every unique host on which an application instance existed over the last 24 hours. All Infrastructure events have a productLine attribute value of Infrastructure. For more information, see query examples. Usage calculation Monthly billable CUs for a host are calculated by the size of the host running Infrastructure (number of CPUs + GBs of RAM) multiplied by the number of hours the host is connected to New Relic during that month. For more on how this is calculated, see CU-based pricing. If your usage is fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To view usage information in the UI: Go to the usage UI. On the Infrastructure usage page, set the time picker to Last 30 days. Multiply the Avg daily compute units by the number of days in the current month. For more information about the usage UI, see Introduction to subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns displayed depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily compute units The average daily compute units used. % of total usage The percentage of the total usage used. General attributes The following are general (not Infrastructure-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Infrastructure attributes The following are usage-related attributes generated by Infrastructure. To query this data, use a productLine attribute value of Infrastructure. Attribute Description agentHostname ID used to uniquely identify the host for which this usage is reported. Any given hour of usage for this host will be counted only once when calculating infrastructureHoursUsed. There are several possible host identifiers reported by the New Relic agent. The usage reporting system will always use the agent-reported hostname to uniquely identify the host for the Infrastructure product, but will also record the cloudInstanceId, if present, for informational purposes. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This will not be present if no cloud provider was detected by the agent. cloudInstanceSize Size of the cloud instance for this host for CU billing purposes, as calculated according to the formula for infrastructureBillingInstanceSize, using the CPU and memory sizes associated with the instance type defined by the cloud provider. Will not be present if no cloud provider was detected by the agent. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. infrastructureAgentVersion Version of the Infrastructure agent running on the host reporting this usage. If multiple agents are reporting from the same host, the version from the first agent seen in a given hour will be used. infrastructureAgentMemoryBytes Bytes of RAM available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureAgentProcessorCount Number of logical CPU cores available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedMemoryBytes Bytes of RAM available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedProcessorCount Number of logical CPU cores available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureBillingInstanceSize Size of the host, for CU billing purposes. Calculated as: number of processors multiplied by memory in GiB. infrastructureHoursUsed Number of hours for which usage was recorded for the given host. When a host is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. infrastructureComputeUnits Number of compute units (CUs) recorded for the given host. CUs are calculated as: infrastructureHoursUsed multiplied by infrastructureBillingInstanceSize. For more about compute unit calculation, see CU pricing. infrastructureComputeUnitRule Describes the algorithm used to calculate the host size for CU usage. Values include: agent_collected_calculated_data: Use the host size data collected by the agent from the OS environment. cloud_provider_data: Use the host size data from the cloud provider. missing_data: Some host size data was missing. This could be due to an agent and operating system combination for which CPU and memory sizes are not supported. This will result in the default host size (16) being applied. instanceSizeCapped This is True if the calculated host size was greater than 16 and therefore capped. missingCpuData True if the Infrastructure agent reports no CPU count. missingRamData True if the Infrastructure agent reports no memory count. productLine The New Relic product the usage data is from. Always use the value Infrastructure when querying for Infrastructure usage data. usageType The type of entity this event records values for. This value is Host for Infrastructure. Query examples Here are some examples of NRQL queries you can use with your Infrastructure subscription usage data. You can run NRQL queries, and use the resulting charts in dashboards. For general information about how to use NRQL queries to get focused usage data, see Intro to usage data. Compute units for last month This query produces a count of the CUs used over the last month: SELECT sum(infrastructureComputeUnits) FROM NrDailyUsage WHERE productLine='Infrastructure' AND usageType='Host' SINCE last month UNTIL this month Copy Detailed host report (reproducing old usage report) This query reproduces as closely as possible the report you would have gotten by downloading the CSV from the previously available Infrastructure subscription usage UI: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID',agentHostname,cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type',infrastructureBillingInstanceSize AS 'Instance size',infrastructureHoursUsed AS 'Hours used',infrastructureComputeUnits AS 'Usage (CU)', infrastructureCloudDerivedMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureCloudDerivedProcessorCount AS 'Logical processors',infrastructureAgentMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureAgentProcessorCount AS 'Logical processors',infrastructureComputeUnitRule AS 'Business rule',missingCpuData, missingRamData, instanceSizeCapped,cloudZone,cloudInstanceId WHERE productLine='Infrastructure' AND usageType='Host' SINCE 1 day ago LIMIT 1000 Copy This NRQL query is different than the legacy usage report: Detailed host query Comments Time period This query includes only the last day of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to 1000 NRQL limits the results to 1000. If you have more than 1000 hosts and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example, WHERE agentHostname LIKE ... to divide the data into groups). Business rule Business rule has been replaced with two attributes: infrastructureComputeUnitRule defines how the size of the host was calculated, depending on what data was available from the agent. It no longer describes whether the agent needs to be updated to provide more accurate host naming in a container environment (update_agent_for_container_environment). missingCpuData, missingRamData, and instanceSizeCapped are now boolean flags describing what the value missing_data means when it is present in the infrastructureComputeUnitRule attribute. Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure subscription <em>usage</em>",
        "sections": "Infrastructure subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e87a7196a676ed2a83db4"
    },
    {
      "sections": [
        "APM (host-based) subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "APM attributes (host-based)",
        "Query examples",
        "Usage for last month",
        "Usage per host per application",
        "Instance-hours per application",
        "Agent version information",
        "Account hierarchy",
        "Legacy per-host usage report",
        "Legacy host usage report (application listing)",
        "Use of Docker and other containers"
      ],
      "title": "APM (host-based) subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "afaa1272f61e4c003e687d26e904438c0391cda1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/apm-host-based-subscription-usage/",
      "published_at": "2021-10-24T20:32:07Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this doc explains how New Relic calculates billable usage for APM accounts that have host-based pricing (not CU-based pricing). This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, an APM account will generate an NrDailyUsage event for: Every application instance that existed during the last 24 hours Every unique host on which an application instance ran during the last 24 hours These two types of events allow your usage data to be queried and analyzed in many different ways. To query the application events, use a usageType attribute value of Application. To query the host events, use a usageType attribute value of Host. All APM events use a productLine attribute value of APM. For more information, see APM query examples. Usage calculations For host-based APM pricing, monthly billable usage is determined by the number of equivalent hosts used during that month. An equivalent host is defined as: 750 hours (standardized number of monthly hours) of connection to New Relic by a host or multiple hosts. For more on this calculation, see host-based pricing. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To get an estimate of the current month's billable usage: Go to the usage UI. On the APM usage page, set the time picker to Current month. See the Avg daily equivalent hosts for an account or grouping of accounts. The UI is meant to estimate your host usage but, especially for cloud environments, your usage may go up or down over time. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers in the UI table and CSV files. The columns you see depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Host ID The unique identifier for that host. If the host is in AWS, we use the AWS-provided instance ID. For other hosts, New Relic assigns a host ID. For more about how this value is created, see hostID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily equivalent hosts Average equivalent hosts for that day. Calculated as the total number of hours reported for all unique hosts in a day, divided by 24. For more on how this is calculated, see Host-based pricing. % of total usage The percentage of the total usage used. General attributes The following are general (not APM-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. APM attributes (host-based) The following are usage-related attributes generated by host-based APM accounts (not CU-based APM). To query APM-specific data, use a productLine attribute value of APM. Attribute Description agentHostname ID reported by the agent to uniquely identify the host for which this usage event is reported. This value can come from several sources in the application’s environment, but commonly is the value returned by the gethostname Linux syscall. In Docker environments, this attribute can take on the value (sometimes truncated) of the Docker container ID. agentHostname is one of three possible providers for the hostId value. apmAgentVersion Version of the New Relic APM agent running in the application instance reporting this usage. Present only for events where usageType equals Application. To update your agent version, see Update the New Relic agent. apmAppId ID uniquely identifying the application that is reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmAppName Name of the application reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmHoursUsed Number of hours for which usage was recorded for the given entity. When an entity is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. When calculating monthly APM host usage, the calculation for equivalent hosts for a month assumes that a standard month has 750 hours: ` apmHoursUsed / 750 ` . apmLanguage Name of the language that the usage-reporting application is written in, as reported by the New Relic agent. Examples: ruby, java, python. Present only for events where usageType equals Application. bootId Linux boot ID of host for which this usage is reported, which is unique for each boot lifetime of each Linux operating system instance. Will only be present when the New Relic agent is one of the following versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher bootId is one of three possible providers for the hostId value. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This is used to uniquely identify the host if the apmComputeUnitRule is cloud_provider_data. This will not be present if no cloud provider was detected by the agent. Agents with these versions will detect cloud provider data for AWS: Go: 1.11 or higher Java: 3.18.0 or higher .NET: 5.1.72.0 or higher Node.js: 1.21.0 or higher PHP: 5.5.0 or higher Python: 2.54.0.41 or higher Ruby: 3.12.1.298 or higher cloudInstanceId is one of three possible providers for the hostId value. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. containerId ID of the Docker or other Linux container in which the application instance is running. This will not be present if a container was not detected by the agent. Present only for events where usageType equals Application. This attribute is not used to uniquely identify hosts for billing purposes. hostId ID used to uniquely identify the host for which this usage is reported. Any given hour of APM usage for this host will be counted only once when calculating apmHoursUsed. There are several possible host identifiers reported by the New Relic agent. The attributes, if present, will be chosen to use in this order of precedence: cloudInstanceId, bootId, agentHostname. productLine The New Relic product the usage data is from. Always use the value APM when querying for APM CU usage data. usageType For APM, this value can be either Application or Host, depending on the type of entity this event records usage for (other New Relic products will have different values for usageType). Events with both values are recorded so that usage data can be analyzed in several ways. For Application: the event represents usage for a single unique application instance for that day. For Host: the event represents usage for a single unique host for that day. Only Host entities are used to calculate billable usage. Application entities are useful for comparing usage between applications, but are not used for billing or contract purposes. Query examples Here are some examples of NRQL queries you can use with your account usage data. You can run NRQL queries and use the resulting charts in dashboards. Usage for last month This query uses New Relic’s standard number of hours per month (750) for the purpose of calculating APM equivalent hosts over the last month. SELECT sum(apmHoursUsed)/750 AS 'Equivalent hosts' FROM NrDailyUsage WHERE usageType='Host' AND productLine='APM' SINCE last month UNTIL this month Copy Usage per host per application New Relic records usage per application instance, not strictly per application. This query gives an approximation of the usage for a given application on a given host. If unique application instances run sequentially on a host within a given day, this query could return an underestimate (this would be likely, for example, in a container environment). SELECT max(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName,hostId SINCE 1 day ago LIMIT 2000 Copy Instance-hours per application This query measures the total number of hours used by all instances (processes) of an application in the last 24 hours. It's useful for determining which applications are responsible for APM usage, but does not return results that match precisely how New Relic prices APM usage. Each application instance is counted separately in this query, even if it runs concurrently with another application instance on the same host, so the number of application instance-hours is likely to be greater than the number of host-hours (the billable quantity). SELECT sum(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName SINCE 1 day ago LIMIT 2000 Copy Agent version information Use this query to see which agent versions are running on your applications in the last 24 hours. This information can be useful in determining whether the agent needs to be upgraded to report a more accurate host name in a Docker container environment (either a Linux boot ID or a cloud provider instance ID). FROM NrDailyUsage SELECT count(*) WHERE productLine='APM' AND usageType='Application' FACET consumingAccountId, consumingAccountName, apmAppName, apmAgentVersion, apmLanguage SINCE 1 day ago LIMIT 2000 Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 2000 SINCE 1 day ago Copy Legacy per-host usage report This query produces a close approximation of the CSV report you would have seen in the deprecated UI system: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID', hostId, cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type', apmBillingInstanceSize AS 'Instance size', apmHoursUsed AS 'Hours used', apmComputeUnits AS 'Usage (CU)', apmMemoryBytes/(1024*1024*1024) AS 'Total RAM', apmProcessorCount AS 'Logical processors', apmContainerCount AS 'Container count', apmComputeUnitRule AS 'Business rule', missingCpuData, missingRamData, instanceSizeCapped, cloudZone, cloudInstanceId WHERE productLine='APM' AND usageType='Host' SINCE 1 day ago LIMIT 2000 Copy This NRQL query is different than the legacy usage report: Per-host query Comments Time period This query includes only the last 24 hours of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to a maximum number of rows NRQL limits the number of rows returned. If you have more hosts than the maximum number of rows returned and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example WHERE cloudInstanceId LIKE “%0”) to divide the data into up to 16 groups, modulo the last character in the AWS instance ID. Docker container IDs A single Docker container ID does not appear in this report. A Docker container ID is reported only at the application instance level of granularity (usageType='Application'). For the host (usageType='Host'), a count of unique containers is reported, since there are often very many. While choosing just one container ID to report for a host had been informative, now there is more data reported at the appropriate level of granularity. Business rule Business rule has been replaced with other attributes. It no longer is used to describe whether the agent needs to be updated. Legacy host usage report (application listing) This query returns data once provided in the \"host usage report\": a listing of applications running on each host. Note that while APM usage is counted on an hour-by-hour basis, per-hour usage data is no longer available via the API or UI. FROM NrDailyUsage SELECT min(timestamp) AS 'Earliest reporting day',max(timestamp) AS 'Latest reporting day' FACET apmAppName,hostId,agentHostname,consumingAccountName,consumingAccountId WHERE usageType='Application' AND productLine='APM' SINCE 1 month ago LIMIT 2000 Copy Use of Docker and other containers Some previous New Relic APM agents may miscount containers as hosts, which may lead to over-reporting of host-based usage. To fix this calculation for Linux-based containers (including Docker), upgrade your APM agent to these versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM (host-based) subscription <em>usage</em>",
        "sections": "APM (host-based) subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this doc explains how New Relic calculates billable"
      },
      "id": "603e834128ccbc66fdeba78b"
    },
    {
      "sections": [
        "Browser subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "Browser attributes",
        "Query examples",
        "Page views for the last complete month",
        "Page views for the last week by account",
        "Page views for the past month, by application:",
        "Account hierarchy",
        "SPA usage",
        "Notes on Insights subscription"
      ],
      "title": "Browser subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "1accc55c1dd4a3a35550f8d209f40a602b06a330",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-pricing-plan-usage/browser-subscription-usage/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-07-01T15:31:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Browser subscription usage. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. For details about single-page app (SPA) monitoring usage, see SPA usage. Data generation Once per hour, for every monitored application, a New Relic Browser account will generate a NrUsage event. Each event will summarize the usage for the last hour. When querying Browser usage data, use a productLine attribute value of Browser. For more information, see the Browser query examples. Usage calculations Monthly subscription usage equals the total number of page views that month across all end-user browsers. AJAX traffic does not count against your daily usage. If your page views are fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrUsage event. To view usage information in the UI: Go to: account dropdown > View your usage. On the Browser usage page, set the time picker to Last 30 days. Multiply the Avg daily page views by the number of days in the current month. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns visible depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account, or a customer partnership. Account ID New Relic account ID. Average daily page views The average daily page views for that account or application. % of total usage The percentage of the total usage used. General attributes The following are general (not Browser-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Browser attributes The following are usage-related attributes generated by New Relic Browser. To query Browser data, use a productLine attribute value of Browser. Attribute Description browserPageViewCount Number of page views for an application for that 24-hour period. For more on how events are generated, see Data generation.Page views for both Pro and Lite Browser agents are counted. productLine The New Relic product the usage data is from. For Browser data, this value is Browser. usageType The type of entity this event records values for. For Browser, this value is Application. browserAppId ID uniquely identifying the application reporting this usage, as it appears in the Browser product. isPrimaryApp Deprecated April 2, 2020. Boolean. true means the application is the primary app. false means the app is one of several apps that an agent reports data for. For more on multiple app names in APM and Browser, see Use multiple app names. The sum of events where this attribute is true will give an accurate total of page views when you are using the multiple app names feature. Counting events where this attribute is false will result in over-counting of usage. Query examples Here are some examples of NRQL queries you can use with your subscription usage data. You can run NRQL queries and use the resulting charts in dashboards. Page views for the last complete month This query shows a count of page views from the last complete month: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE last month UNTIL this month Copy Page views for the last week by account This query shows a count of page views from the last week by account: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 7 days ago FACET consumingAccountName Copy Page views for the past month, by application: This query shows a count of page views from the past month by application SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 30 days ago FACET browserAppID Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts): SELECT count(*) FROM NrUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy SPA usage Page views are used by New Relic Browser to determine customer data usage and product pricing. This document defines a page view in the context of New Relic Browser's SPA monitoring and explains why: SPA monitoring does not affect Browser data usage SPA monitoring will increase Insights data usage In New Relic Browser, a page view is defined as a complete load or reload of a page, signaled by the firing of the window.onload event. New Relic's SPA monitoring tracks traditional page views, but it also tracks changes in the browser that do not require a page load, such as: Route and hash changes Synchronous and asynchronous JavaScript Dynamic server-side updates to a page Route changes are tracked automatically, and by setting up custom instrumentation you can capture almost any type of browser interaction. With New Relic Browser Pro, pricing is based on an account's number of page views per month. If SPA monitoring is enabled, browser interactions that do not require a page load are not counted as page views for billing purposes. With SPA monitoring, you can track an unlimited number of route changes and other custom browser interactions that don't involve page loads. Notes on Insights subscription If you switch from standard Browser monitoring to SPA monitoring, and you also pay for Insights (and don't use only your complementary Insights subscription), your Insights data usage will increase. Because SPA monitoring is a more advanced way to monitor your application, it creates more Insights events than standard monitoring for the following reasons: Page views create not only PageView events, but also BrowserInteraction, AjaxRequest, and BrowserTiming events. For the typical SPA-architecture app, there are more route changes than there are standard page loads. If you pay for Insights and your current Insights license is not sufficient for the amount of events generated with SPA monitoring, we will notify you when you have exceeded your data usage plan. To remedy this, the following options are available: Upgrade your Insights plan. Turn off the reporting of some event types. Use the Browser API to manually turn off collection of some events Switch from Browser SPA monitoring back to standard monitoring",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.27458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser subscription <em>usage</em>",
        "sections": "Browser subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e8774e7b9d28a042a07d2"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-pricing-plan-usage/introduction-new-relic-subscription-usage-data": [
    {
      "sections": [
        "Infrastructure subscription usage",
        "Important",
        "Data generation",
        "Usage calculation",
        "Tip",
        "Table definitions",
        "General attributes",
        "Infrastructure attributes",
        "Query examples",
        "Compute units for last month",
        "Detailed host report (reproducing old usage report)",
        "Account hierarchy"
      ],
      "title": "Infrastructure subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "036858ab7d7fb54da536202e11788d0fc1029460",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/infrastructure-subscription-usage/",
      "published_at": "2021-10-24T19:09:48Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Infrastructure accounts. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, a New Relic Infrastructure account will generate an NrDailyUsage event for every unique host on which an application instance existed over the last 24 hours. All Infrastructure events have a productLine attribute value of Infrastructure. For more information, see query examples. Usage calculation Monthly billable CUs for a host are calculated by the size of the host running Infrastructure (number of CPUs + GBs of RAM) multiplied by the number of hours the host is connected to New Relic during that month. For more on how this is calculated, see CU-based pricing. If your usage is fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To view usage information in the UI: Go to the usage UI. On the Infrastructure usage page, set the time picker to Last 30 days. Multiply the Avg daily compute units by the number of days in the current month. For more information about the usage UI, see Introduction to subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns displayed depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily compute units The average daily compute units used. % of total usage The percentage of the total usage used. General attributes The following are general (not Infrastructure-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Infrastructure attributes The following are usage-related attributes generated by Infrastructure. To query this data, use a productLine attribute value of Infrastructure. Attribute Description agentHostname ID used to uniquely identify the host for which this usage is reported. Any given hour of usage for this host will be counted only once when calculating infrastructureHoursUsed. There are several possible host identifiers reported by the New Relic agent. The usage reporting system will always use the agent-reported hostname to uniquely identify the host for the Infrastructure product, but will also record the cloudInstanceId, if present, for informational purposes. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This will not be present if no cloud provider was detected by the agent. cloudInstanceSize Size of the cloud instance for this host for CU billing purposes, as calculated according to the formula for infrastructureBillingInstanceSize, using the CPU and memory sizes associated with the instance type defined by the cloud provider. Will not be present if no cloud provider was detected by the agent. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. infrastructureAgentVersion Version of the Infrastructure agent running on the host reporting this usage. If multiple agents are reporting from the same host, the version from the first agent seen in a given hour will be used. infrastructureAgentMemoryBytes Bytes of RAM available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureAgentProcessorCount Number of logical CPU cores available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedMemoryBytes Bytes of RAM available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedProcessorCount Number of logical CPU cores available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureBillingInstanceSize Size of the host, for CU billing purposes. Calculated as: number of processors multiplied by memory in GiB. infrastructureHoursUsed Number of hours for which usage was recorded for the given host. When a host is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. infrastructureComputeUnits Number of compute units (CUs) recorded for the given host. CUs are calculated as: infrastructureHoursUsed multiplied by infrastructureBillingInstanceSize. For more about compute unit calculation, see CU pricing. infrastructureComputeUnitRule Describes the algorithm used to calculate the host size for CU usage. Values include: agent_collected_calculated_data: Use the host size data collected by the agent from the OS environment. cloud_provider_data: Use the host size data from the cloud provider. missing_data: Some host size data was missing. This could be due to an agent and operating system combination for which CPU and memory sizes are not supported. This will result in the default host size (16) being applied. instanceSizeCapped This is True if the calculated host size was greater than 16 and therefore capped. missingCpuData True if the Infrastructure agent reports no CPU count. missingRamData True if the Infrastructure agent reports no memory count. productLine The New Relic product the usage data is from. Always use the value Infrastructure when querying for Infrastructure usage data. usageType The type of entity this event records values for. This value is Host for Infrastructure. Query examples Here are some examples of NRQL queries you can use with your Infrastructure subscription usage data. You can run NRQL queries, and use the resulting charts in dashboards. For general information about how to use NRQL queries to get focused usage data, see Intro to usage data. Compute units for last month This query produces a count of the CUs used over the last month: SELECT sum(infrastructureComputeUnits) FROM NrDailyUsage WHERE productLine='Infrastructure' AND usageType='Host' SINCE last month UNTIL this month Copy Detailed host report (reproducing old usage report) This query reproduces as closely as possible the report you would have gotten by downloading the CSV from the previously available Infrastructure subscription usage UI: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID',agentHostname,cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type',infrastructureBillingInstanceSize AS 'Instance size',infrastructureHoursUsed AS 'Hours used',infrastructureComputeUnits AS 'Usage (CU)', infrastructureCloudDerivedMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureCloudDerivedProcessorCount AS 'Logical processors',infrastructureAgentMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureAgentProcessorCount AS 'Logical processors',infrastructureComputeUnitRule AS 'Business rule',missingCpuData, missingRamData, instanceSizeCapped,cloudZone,cloudInstanceId WHERE productLine='Infrastructure' AND usageType='Host' SINCE 1 day ago LIMIT 1000 Copy This NRQL query is different than the legacy usage report: Detailed host query Comments Time period This query includes only the last day of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to 1000 NRQL limits the results to 1000. If you have more than 1000 hosts and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example, WHERE agentHostname LIKE ... to divide the data into groups). Business rule Business rule has been replaced with two attributes: infrastructureComputeUnitRule defines how the size of the host was calculated, depending on what data was available from the agent. It no longer describes whether the agent needs to be updated to provide more accurate host naming in a container environment (update_agent_for_container_environment). missingCpuData, missingRamData, and instanceSizeCapped are now boolean flags describing what the value missing_data means when it is present in the infrastructureComputeUnitRule attribute. Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure subscription <em>usage</em>",
        "sections": "Infrastructure subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e87a7196a676ed2a83db4"
    },
    {
      "sections": [
        "APM (host-based) subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "APM attributes (host-based)",
        "Query examples",
        "Usage for last month",
        "Usage per host per application",
        "Instance-hours per application",
        "Agent version information",
        "Account hierarchy",
        "Legacy per-host usage report",
        "Legacy host usage report (application listing)",
        "Use of Docker and other containers"
      ],
      "title": "APM (host-based) subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "afaa1272f61e4c003e687d26e904438c0391cda1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/apm-host-based-subscription-usage/",
      "published_at": "2021-10-24T20:32:07Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this doc explains how New Relic calculates billable usage for APM accounts that have host-based pricing (not CU-based pricing). This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, an APM account will generate an NrDailyUsage event for: Every application instance that existed during the last 24 hours Every unique host on which an application instance ran during the last 24 hours These two types of events allow your usage data to be queried and analyzed in many different ways. To query the application events, use a usageType attribute value of Application. To query the host events, use a usageType attribute value of Host. All APM events use a productLine attribute value of APM. For more information, see APM query examples. Usage calculations For host-based APM pricing, monthly billable usage is determined by the number of equivalent hosts used during that month. An equivalent host is defined as: 750 hours (standardized number of monthly hours) of connection to New Relic by a host or multiple hosts. For more on this calculation, see host-based pricing. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To get an estimate of the current month's billable usage: Go to the usage UI. On the APM usage page, set the time picker to Current month. See the Avg daily equivalent hosts for an account or grouping of accounts. The UI is meant to estimate your host usage but, especially for cloud environments, your usage may go up or down over time. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers in the UI table and CSV files. The columns you see depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Host ID The unique identifier for that host. If the host is in AWS, we use the AWS-provided instance ID. For other hosts, New Relic assigns a host ID. For more about how this value is created, see hostID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily equivalent hosts Average equivalent hosts for that day. Calculated as the total number of hours reported for all unique hosts in a day, divided by 24. For more on how this is calculated, see Host-based pricing. % of total usage The percentage of the total usage used. General attributes The following are general (not APM-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. APM attributes (host-based) The following are usage-related attributes generated by host-based APM accounts (not CU-based APM). To query APM-specific data, use a productLine attribute value of APM. Attribute Description agentHostname ID reported by the agent to uniquely identify the host for which this usage event is reported. This value can come from several sources in the application’s environment, but commonly is the value returned by the gethostname Linux syscall. In Docker environments, this attribute can take on the value (sometimes truncated) of the Docker container ID. agentHostname is one of three possible providers for the hostId value. apmAgentVersion Version of the New Relic APM agent running in the application instance reporting this usage. Present only for events where usageType equals Application. To update your agent version, see Update the New Relic agent. apmAppId ID uniquely identifying the application that is reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmAppName Name of the application reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmHoursUsed Number of hours for which usage was recorded for the given entity. When an entity is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. When calculating monthly APM host usage, the calculation for equivalent hosts for a month assumes that a standard month has 750 hours: ` apmHoursUsed / 750 ` . apmLanguage Name of the language that the usage-reporting application is written in, as reported by the New Relic agent. Examples: ruby, java, python. Present only for events where usageType equals Application. bootId Linux boot ID of host for which this usage is reported, which is unique for each boot lifetime of each Linux operating system instance. Will only be present when the New Relic agent is one of the following versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher bootId is one of three possible providers for the hostId value. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This is used to uniquely identify the host if the apmComputeUnitRule is cloud_provider_data. This will not be present if no cloud provider was detected by the agent. Agents with these versions will detect cloud provider data for AWS: Go: 1.11 or higher Java: 3.18.0 or higher .NET: 5.1.72.0 or higher Node.js: 1.21.0 or higher PHP: 5.5.0 or higher Python: 2.54.0.41 or higher Ruby: 3.12.1.298 or higher cloudInstanceId is one of three possible providers for the hostId value. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. containerId ID of the Docker or other Linux container in which the application instance is running. This will not be present if a container was not detected by the agent. Present only for events where usageType equals Application. This attribute is not used to uniquely identify hosts for billing purposes. hostId ID used to uniquely identify the host for which this usage is reported. Any given hour of APM usage for this host will be counted only once when calculating apmHoursUsed. There are several possible host identifiers reported by the New Relic agent. The attributes, if present, will be chosen to use in this order of precedence: cloudInstanceId, bootId, agentHostname. productLine The New Relic product the usage data is from. Always use the value APM when querying for APM CU usage data. usageType For APM, this value can be either Application or Host, depending on the type of entity this event records usage for (other New Relic products will have different values for usageType). Events with both values are recorded so that usage data can be analyzed in several ways. For Application: the event represents usage for a single unique application instance for that day. For Host: the event represents usage for a single unique host for that day. Only Host entities are used to calculate billable usage. Application entities are useful for comparing usage between applications, but are not used for billing or contract purposes. Query examples Here are some examples of NRQL queries you can use with your account usage data. You can run NRQL queries and use the resulting charts in dashboards. Usage for last month This query uses New Relic’s standard number of hours per month (750) for the purpose of calculating APM equivalent hosts over the last month. SELECT sum(apmHoursUsed)/750 AS 'Equivalent hosts' FROM NrDailyUsage WHERE usageType='Host' AND productLine='APM' SINCE last month UNTIL this month Copy Usage per host per application New Relic records usage per application instance, not strictly per application. This query gives an approximation of the usage for a given application on a given host. If unique application instances run sequentially on a host within a given day, this query could return an underestimate (this would be likely, for example, in a container environment). SELECT max(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName,hostId SINCE 1 day ago LIMIT 2000 Copy Instance-hours per application This query measures the total number of hours used by all instances (processes) of an application in the last 24 hours. It's useful for determining which applications are responsible for APM usage, but does not return results that match precisely how New Relic prices APM usage. Each application instance is counted separately in this query, even if it runs concurrently with another application instance on the same host, so the number of application instance-hours is likely to be greater than the number of host-hours (the billable quantity). SELECT sum(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName SINCE 1 day ago LIMIT 2000 Copy Agent version information Use this query to see which agent versions are running on your applications in the last 24 hours. This information can be useful in determining whether the agent needs to be upgraded to report a more accurate host name in a Docker container environment (either a Linux boot ID or a cloud provider instance ID). FROM NrDailyUsage SELECT count(*) WHERE productLine='APM' AND usageType='Application' FACET consumingAccountId, consumingAccountName, apmAppName, apmAgentVersion, apmLanguage SINCE 1 day ago LIMIT 2000 Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 2000 SINCE 1 day ago Copy Legacy per-host usage report This query produces a close approximation of the CSV report you would have seen in the deprecated UI system: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID', hostId, cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type', apmBillingInstanceSize AS 'Instance size', apmHoursUsed AS 'Hours used', apmComputeUnits AS 'Usage (CU)', apmMemoryBytes/(1024*1024*1024) AS 'Total RAM', apmProcessorCount AS 'Logical processors', apmContainerCount AS 'Container count', apmComputeUnitRule AS 'Business rule', missingCpuData, missingRamData, instanceSizeCapped, cloudZone, cloudInstanceId WHERE productLine='APM' AND usageType='Host' SINCE 1 day ago LIMIT 2000 Copy This NRQL query is different than the legacy usage report: Per-host query Comments Time period This query includes only the last 24 hours of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to a maximum number of rows NRQL limits the number of rows returned. If you have more hosts than the maximum number of rows returned and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example WHERE cloudInstanceId LIKE “%0”) to divide the data into up to 16 groups, modulo the last character in the AWS instance ID. Docker container IDs A single Docker container ID does not appear in this report. A Docker container ID is reported only at the application instance level of granularity (usageType='Application'). For the host (usageType='Host'), a count of unique containers is reported, since there are often very many. While choosing just one container ID to report for a host had been informative, now there is more data reported at the appropriate level of granularity. Business rule Business rule has been replaced with other attributes. It no longer is used to describe whether the agent needs to be updated. Legacy host usage report (application listing) This query returns data once provided in the \"host usage report\": a listing of applications running on each host. Note that while APM usage is counted on an hour-by-hour basis, per-hour usage data is no longer available via the API or UI. FROM NrDailyUsage SELECT min(timestamp) AS 'Earliest reporting day',max(timestamp) AS 'Latest reporting day' FACET apmAppName,hostId,agentHostname,consumingAccountName,consumingAccountId WHERE usageType='Application' AND productLine='APM' SINCE 1 month ago LIMIT 2000 Copy Use of Docker and other containers Some previous New Relic APM agents may miscount containers as hosts, which may lead to over-reporting of host-based usage. To fix this calculation for Linux-based containers (including Docker), upgrade your APM agent to these versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM (host-based) subscription <em>usage</em>",
        "sections": "APM (host-based) subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this doc explains how New Relic calculates billable"
      },
      "id": "603e834128ccbc66fdeba78b"
    },
    {
      "sections": [
        "Browser subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "Browser attributes",
        "Query examples",
        "Page views for the last complete month",
        "Page views for the last week by account",
        "Page views for the past month, by application:",
        "Account hierarchy",
        "SPA usage",
        "Notes on Insights subscription"
      ],
      "title": "Browser subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "1accc55c1dd4a3a35550f8d209f40a602b06a330",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-pricing-plan-usage/browser-subscription-usage/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-07-01T15:31:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Browser subscription usage. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. For details about single-page app (SPA) monitoring usage, see SPA usage. Data generation Once per hour, for every monitored application, a New Relic Browser account will generate a NrUsage event. Each event will summarize the usage for the last hour. When querying Browser usage data, use a productLine attribute value of Browser. For more information, see the Browser query examples. Usage calculations Monthly subscription usage equals the total number of page views that month across all end-user browsers. AJAX traffic does not count against your daily usage. If your page views are fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrUsage event. To view usage information in the UI: Go to: account dropdown > View your usage. On the Browser usage page, set the time picker to Last 30 days. Multiply the Avg daily page views by the number of days in the current month. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns visible depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account, or a customer partnership. Account ID New Relic account ID. Average daily page views The average daily page views for that account or application. % of total usage The percentage of the total usage used. General attributes The following are general (not Browser-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Browser attributes The following are usage-related attributes generated by New Relic Browser. To query Browser data, use a productLine attribute value of Browser. Attribute Description browserPageViewCount Number of page views for an application for that 24-hour period. For more on how events are generated, see Data generation.Page views for both Pro and Lite Browser agents are counted. productLine The New Relic product the usage data is from. For Browser data, this value is Browser. usageType The type of entity this event records values for. For Browser, this value is Application. browserAppId ID uniquely identifying the application reporting this usage, as it appears in the Browser product. isPrimaryApp Deprecated April 2, 2020. Boolean. true means the application is the primary app. false means the app is one of several apps that an agent reports data for. For more on multiple app names in APM and Browser, see Use multiple app names. The sum of events where this attribute is true will give an accurate total of page views when you are using the multiple app names feature. Counting events where this attribute is false will result in over-counting of usage. Query examples Here are some examples of NRQL queries you can use with your subscription usage data. You can run NRQL queries and use the resulting charts in dashboards. Page views for the last complete month This query shows a count of page views from the last complete month: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE last month UNTIL this month Copy Page views for the last week by account This query shows a count of page views from the last week by account: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 7 days ago FACET consumingAccountName Copy Page views for the past month, by application: This query shows a count of page views from the past month by application SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 30 days ago FACET browserAppID Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts): SELECT count(*) FROM NrUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy SPA usage Page views are used by New Relic Browser to determine customer data usage and product pricing. This document defines a page view in the context of New Relic Browser's SPA monitoring and explains why: SPA monitoring does not affect Browser data usage SPA monitoring will increase Insights data usage In New Relic Browser, a page view is defined as a complete load or reload of a page, signaled by the firing of the window.onload event. New Relic's SPA monitoring tracks traditional page views, but it also tracks changes in the browser that do not require a page load, such as: Route and hash changes Synchronous and asynchronous JavaScript Dynamic server-side updates to a page Route changes are tracked automatically, and by setting up custom instrumentation you can capture almost any type of browser interaction. With New Relic Browser Pro, pricing is based on an account's number of page views per month. If SPA monitoring is enabled, browser interactions that do not require a page load are not counted as page views for billing purposes. With SPA monitoring, you can track an unlimited number of route changes and other custom browser interactions that don't involve page loads. Notes on Insights subscription If you switch from standard Browser monitoring to SPA monitoring, and you also pay for Insights (and don't use only your complementary Insights subscription), your Insights data usage will increase. Because SPA monitoring is a more advanced way to monitor your application, it creates more Insights events than standard monitoring for the following reasons: Page views create not only PageView events, but also BrowserInteraction, AjaxRequest, and BrowserTiming events. For the typical SPA-architecture app, there are more route changes than there are standard page loads. If you pay for Insights and your current Insights license is not sufficient for the amount of events generated with SPA monitoring, we will notify you when you have exceeded your data usage plan. To remedy this, the following options are available: Upgrade your Insights plan. Turn off the reporting of some event types. Use the Browser API to manually turn off collection of some events Switch from Browser SPA monitoring back to standard monitoring",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.27458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser subscription <em>usage</em>",
        "sections": "Browser subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e8774e7b9d28a042a07d2"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-pricing-plan-usage/mobile-subscription-usage": [
    {
      "sections": [
        "Infrastructure subscription usage",
        "Important",
        "Data generation",
        "Usage calculation",
        "Tip",
        "Table definitions",
        "General attributes",
        "Infrastructure attributes",
        "Query examples",
        "Compute units for last month",
        "Detailed host report (reproducing old usage report)",
        "Account hierarchy"
      ],
      "title": "Infrastructure subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "036858ab7d7fb54da536202e11788d0fc1029460",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/infrastructure-subscription-usage/",
      "published_at": "2021-10-24T19:09:48Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Infrastructure accounts. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, a New Relic Infrastructure account will generate an NrDailyUsage event for every unique host on which an application instance existed over the last 24 hours. All Infrastructure events have a productLine attribute value of Infrastructure. For more information, see query examples. Usage calculation Monthly billable CUs for a host are calculated by the size of the host running Infrastructure (number of CPUs + GBs of RAM) multiplied by the number of hours the host is connected to New Relic during that month. For more on how this is calculated, see CU-based pricing. If your usage is fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To view usage information in the UI: Go to the usage UI. On the Infrastructure usage page, set the time picker to Last 30 days. Multiply the Avg daily compute units by the number of days in the current month. For more information about the usage UI, see Introduction to subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns displayed depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily compute units The average daily compute units used. % of total usage The percentage of the total usage used. General attributes The following are general (not Infrastructure-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Infrastructure attributes The following are usage-related attributes generated by Infrastructure. To query this data, use a productLine attribute value of Infrastructure. Attribute Description agentHostname ID used to uniquely identify the host for which this usage is reported. Any given hour of usage for this host will be counted only once when calculating infrastructureHoursUsed. There are several possible host identifiers reported by the New Relic agent. The usage reporting system will always use the agent-reported hostname to uniquely identify the host for the Infrastructure product, but will also record the cloudInstanceId, if present, for informational purposes. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This will not be present if no cloud provider was detected by the agent. cloudInstanceSize Size of the cloud instance for this host for CU billing purposes, as calculated according to the formula for infrastructureBillingInstanceSize, using the CPU and memory sizes associated with the instance type defined by the cloud provider. Will not be present if no cloud provider was detected by the agent. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. infrastructureAgentVersion Version of the Infrastructure agent running on the host reporting this usage. If multiple agents are reporting from the same host, the version from the first agent seen in a given hour will be used. infrastructureAgentMemoryBytes Bytes of RAM available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureAgentProcessorCount Number of logical CPU cores available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedMemoryBytes Bytes of RAM available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedProcessorCount Number of logical CPU cores available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureBillingInstanceSize Size of the host, for CU billing purposes. Calculated as: number of processors multiplied by memory in GiB. infrastructureHoursUsed Number of hours for which usage was recorded for the given host. When a host is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. infrastructureComputeUnits Number of compute units (CUs) recorded for the given host. CUs are calculated as: infrastructureHoursUsed multiplied by infrastructureBillingInstanceSize. For more about compute unit calculation, see CU pricing. infrastructureComputeUnitRule Describes the algorithm used to calculate the host size for CU usage. Values include: agent_collected_calculated_data: Use the host size data collected by the agent from the OS environment. cloud_provider_data: Use the host size data from the cloud provider. missing_data: Some host size data was missing. This could be due to an agent and operating system combination for which CPU and memory sizes are not supported. This will result in the default host size (16) being applied. instanceSizeCapped This is True if the calculated host size was greater than 16 and therefore capped. missingCpuData True if the Infrastructure agent reports no CPU count. missingRamData True if the Infrastructure agent reports no memory count. productLine The New Relic product the usage data is from. Always use the value Infrastructure when querying for Infrastructure usage data. usageType The type of entity this event records values for. This value is Host for Infrastructure. Query examples Here are some examples of NRQL queries you can use with your Infrastructure subscription usage data. You can run NRQL queries, and use the resulting charts in dashboards. For general information about how to use NRQL queries to get focused usage data, see Intro to usage data. Compute units for last month This query produces a count of the CUs used over the last month: SELECT sum(infrastructureComputeUnits) FROM NrDailyUsage WHERE productLine='Infrastructure' AND usageType='Host' SINCE last month UNTIL this month Copy Detailed host report (reproducing old usage report) This query reproduces as closely as possible the report you would have gotten by downloading the CSV from the previously available Infrastructure subscription usage UI: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID',agentHostname,cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type',infrastructureBillingInstanceSize AS 'Instance size',infrastructureHoursUsed AS 'Hours used',infrastructureComputeUnits AS 'Usage (CU)', infrastructureCloudDerivedMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureCloudDerivedProcessorCount AS 'Logical processors',infrastructureAgentMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureAgentProcessorCount AS 'Logical processors',infrastructureComputeUnitRule AS 'Business rule',missingCpuData, missingRamData, instanceSizeCapped,cloudZone,cloudInstanceId WHERE productLine='Infrastructure' AND usageType='Host' SINCE 1 day ago LIMIT 1000 Copy This NRQL query is different than the legacy usage report: Detailed host query Comments Time period This query includes only the last day of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to 1000 NRQL limits the results to 1000. If you have more than 1000 hosts and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example, WHERE agentHostname LIKE ... to divide the data into groups). Business rule Business rule has been replaced with two attributes: infrastructureComputeUnitRule defines how the size of the host was calculated, depending on what data was available from the agent. It no longer describes whether the agent needs to be updated to provide more accurate host naming in a container environment (update_agent_for_container_environment). missingCpuData, missingRamData, and instanceSizeCapped are now boolean flags describing what the value missing_data means when it is present in the infrastructureComputeUnitRule attribute. Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure subscription <em>usage</em>",
        "sections": "Infrastructure subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e87a7196a676ed2a83db4"
    },
    {
      "sections": [
        "APM (host-based) subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "APM attributes (host-based)",
        "Query examples",
        "Usage for last month",
        "Usage per host per application",
        "Instance-hours per application",
        "Agent version information",
        "Account hierarchy",
        "Legacy per-host usage report",
        "Legacy host usage report (application listing)",
        "Use of Docker and other containers"
      ],
      "title": "APM (host-based) subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "afaa1272f61e4c003e687d26e904438c0391cda1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/apm-host-based-subscription-usage/",
      "published_at": "2021-10-24T20:32:07Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this doc explains how New Relic calculates billable usage for APM accounts that have host-based pricing (not CU-based pricing). This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, an APM account will generate an NrDailyUsage event for: Every application instance that existed during the last 24 hours Every unique host on which an application instance ran during the last 24 hours These two types of events allow your usage data to be queried and analyzed in many different ways. To query the application events, use a usageType attribute value of Application. To query the host events, use a usageType attribute value of Host. All APM events use a productLine attribute value of APM. For more information, see APM query examples. Usage calculations For host-based APM pricing, monthly billable usage is determined by the number of equivalent hosts used during that month. An equivalent host is defined as: 750 hours (standardized number of monthly hours) of connection to New Relic by a host or multiple hosts. For more on this calculation, see host-based pricing. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To get an estimate of the current month's billable usage: Go to the usage UI. On the APM usage page, set the time picker to Current month. See the Avg daily equivalent hosts for an account or grouping of accounts. The UI is meant to estimate your host usage but, especially for cloud environments, your usage may go up or down over time. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers in the UI table and CSV files. The columns you see depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Host ID The unique identifier for that host. If the host is in AWS, we use the AWS-provided instance ID. For other hosts, New Relic assigns a host ID. For more about how this value is created, see hostID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily equivalent hosts Average equivalent hosts for that day. Calculated as the total number of hours reported for all unique hosts in a day, divided by 24. For more on how this is calculated, see Host-based pricing. % of total usage The percentage of the total usage used. General attributes The following are general (not APM-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. APM attributes (host-based) The following are usage-related attributes generated by host-based APM accounts (not CU-based APM). To query APM-specific data, use a productLine attribute value of APM. Attribute Description agentHostname ID reported by the agent to uniquely identify the host for which this usage event is reported. This value can come from several sources in the application’s environment, but commonly is the value returned by the gethostname Linux syscall. In Docker environments, this attribute can take on the value (sometimes truncated) of the Docker container ID. agentHostname is one of three possible providers for the hostId value. apmAgentVersion Version of the New Relic APM agent running in the application instance reporting this usage. Present only for events where usageType equals Application. To update your agent version, see Update the New Relic agent. apmAppId ID uniquely identifying the application that is reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmAppName Name of the application reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmHoursUsed Number of hours for which usage was recorded for the given entity. When an entity is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. When calculating monthly APM host usage, the calculation for equivalent hosts for a month assumes that a standard month has 750 hours: ` apmHoursUsed / 750 ` . apmLanguage Name of the language that the usage-reporting application is written in, as reported by the New Relic agent. Examples: ruby, java, python. Present only for events where usageType equals Application. bootId Linux boot ID of host for which this usage is reported, which is unique for each boot lifetime of each Linux operating system instance. Will only be present when the New Relic agent is one of the following versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher bootId is one of three possible providers for the hostId value. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This is used to uniquely identify the host if the apmComputeUnitRule is cloud_provider_data. This will not be present if no cloud provider was detected by the agent. Agents with these versions will detect cloud provider data for AWS: Go: 1.11 or higher Java: 3.18.0 or higher .NET: 5.1.72.0 or higher Node.js: 1.21.0 or higher PHP: 5.5.0 or higher Python: 2.54.0.41 or higher Ruby: 3.12.1.298 or higher cloudInstanceId is one of three possible providers for the hostId value. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. containerId ID of the Docker or other Linux container in which the application instance is running. This will not be present if a container was not detected by the agent. Present only for events where usageType equals Application. This attribute is not used to uniquely identify hosts for billing purposes. hostId ID used to uniquely identify the host for which this usage is reported. Any given hour of APM usage for this host will be counted only once when calculating apmHoursUsed. There are several possible host identifiers reported by the New Relic agent. The attributes, if present, will be chosen to use in this order of precedence: cloudInstanceId, bootId, agentHostname. productLine The New Relic product the usage data is from. Always use the value APM when querying for APM CU usage data. usageType For APM, this value can be either Application or Host, depending on the type of entity this event records usage for (other New Relic products will have different values for usageType). Events with both values are recorded so that usage data can be analyzed in several ways. For Application: the event represents usage for a single unique application instance for that day. For Host: the event represents usage for a single unique host for that day. Only Host entities are used to calculate billable usage. Application entities are useful for comparing usage between applications, but are not used for billing or contract purposes. Query examples Here are some examples of NRQL queries you can use with your account usage data. You can run NRQL queries and use the resulting charts in dashboards. Usage for last month This query uses New Relic’s standard number of hours per month (750) for the purpose of calculating APM equivalent hosts over the last month. SELECT sum(apmHoursUsed)/750 AS 'Equivalent hosts' FROM NrDailyUsage WHERE usageType='Host' AND productLine='APM' SINCE last month UNTIL this month Copy Usage per host per application New Relic records usage per application instance, not strictly per application. This query gives an approximation of the usage for a given application on a given host. If unique application instances run sequentially on a host within a given day, this query could return an underestimate (this would be likely, for example, in a container environment). SELECT max(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName,hostId SINCE 1 day ago LIMIT 2000 Copy Instance-hours per application This query measures the total number of hours used by all instances (processes) of an application in the last 24 hours. It's useful for determining which applications are responsible for APM usage, but does not return results that match precisely how New Relic prices APM usage. Each application instance is counted separately in this query, even if it runs concurrently with another application instance on the same host, so the number of application instance-hours is likely to be greater than the number of host-hours (the billable quantity). SELECT sum(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName SINCE 1 day ago LIMIT 2000 Copy Agent version information Use this query to see which agent versions are running on your applications in the last 24 hours. This information can be useful in determining whether the agent needs to be upgraded to report a more accurate host name in a Docker container environment (either a Linux boot ID or a cloud provider instance ID). FROM NrDailyUsage SELECT count(*) WHERE productLine='APM' AND usageType='Application' FACET consumingAccountId, consumingAccountName, apmAppName, apmAgentVersion, apmLanguage SINCE 1 day ago LIMIT 2000 Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 2000 SINCE 1 day ago Copy Legacy per-host usage report This query produces a close approximation of the CSV report you would have seen in the deprecated UI system: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID', hostId, cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type', apmBillingInstanceSize AS 'Instance size', apmHoursUsed AS 'Hours used', apmComputeUnits AS 'Usage (CU)', apmMemoryBytes/(1024*1024*1024) AS 'Total RAM', apmProcessorCount AS 'Logical processors', apmContainerCount AS 'Container count', apmComputeUnitRule AS 'Business rule', missingCpuData, missingRamData, instanceSizeCapped, cloudZone, cloudInstanceId WHERE productLine='APM' AND usageType='Host' SINCE 1 day ago LIMIT 2000 Copy This NRQL query is different than the legacy usage report: Per-host query Comments Time period This query includes only the last 24 hours of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to a maximum number of rows NRQL limits the number of rows returned. If you have more hosts than the maximum number of rows returned and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example WHERE cloudInstanceId LIKE “%0”) to divide the data into up to 16 groups, modulo the last character in the AWS instance ID. Docker container IDs A single Docker container ID does not appear in this report. A Docker container ID is reported only at the application instance level of granularity (usageType='Application'). For the host (usageType='Host'), a count of unique containers is reported, since there are often very many. While choosing just one container ID to report for a host had been informative, now there is more data reported at the appropriate level of granularity. Business rule Business rule has been replaced with other attributes. It no longer is used to describe whether the agent needs to be updated. Legacy host usage report (application listing) This query returns data once provided in the \"host usage report\": a listing of applications running on each host. Note that while APM usage is counted on an hour-by-hour basis, per-hour usage data is no longer available via the API or UI. FROM NrDailyUsage SELECT min(timestamp) AS 'Earliest reporting day',max(timestamp) AS 'Latest reporting day' FACET apmAppName,hostId,agentHostname,consumingAccountName,consumingAccountId WHERE usageType='Application' AND productLine='APM' SINCE 1 month ago LIMIT 2000 Copy Use of Docker and other containers Some previous New Relic APM agents may miscount containers as hosts, which may lead to over-reporting of host-based usage. To fix this calculation for Linux-based containers (including Docker), upgrade your APM agent to these versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM (host-based) subscription <em>usage</em>",
        "sections": "APM (host-based) subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this doc explains how New Relic calculates billable"
      },
      "id": "603e834128ccbc66fdeba78b"
    },
    {
      "sections": [
        "Browser subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "Browser attributes",
        "Query examples",
        "Page views for the last complete month",
        "Page views for the last week by account",
        "Page views for the past month, by application:",
        "Account hierarchy",
        "SPA usage",
        "Notes on Insights subscription"
      ],
      "title": "Browser subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "1accc55c1dd4a3a35550f8d209f40a602b06a330",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-pricing-plan-usage/browser-subscription-usage/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-07-01T15:31:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Browser subscription usage. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. For details about single-page app (SPA) monitoring usage, see SPA usage. Data generation Once per hour, for every monitored application, a New Relic Browser account will generate a NrUsage event. Each event will summarize the usage for the last hour. When querying Browser usage data, use a productLine attribute value of Browser. For more information, see the Browser query examples. Usage calculations Monthly subscription usage equals the total number of page views that month across all end-user browsers. AJAX traffic does not count against your daily usage. If your page views are fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrUsage event. To view usage information in the UI: Go to: account dropdown > View your usage. On the Browser usage page, set the time picker to Last 30 days. Multiply the Avg daily page views by the number of days in the current month. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns visible depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account, or a customer partnership. Account ID New Relic account ID. Average daily page views The average daily page views for that account or application. % of total usage The percentage of the total usage used. General attributes The following are general (not Browser-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Browser attributes The following are usage-related attributes generated by New Relic Browser. To query Browser data, use a productLine attribute value of Browser. Attribute Description browserPageViewCount Number of page views for an application for that 24-hour period. For more on how events are generated, see Data generation.Page views for both Pro and Lite Browser agents are counted. productLine The New Relic product the usage data is from. For Browser data, this value is Browser. usageType The type of entity this event records values for. For Browser, this value is Application. browserAppId ID uniquely identifying the application reporting this usage, as it appears in the Browser product. isPrimaryApp Deprecated April 2, 2020. Boolean. true means the application is the primary app. false means the app is one of several apps that an agent reports data for. For more on multiple app names in APM and Browser, see Use multiple app names. The sum of events where this attribute is true will give an accurate total of page views when you are using the multiple app names feature. Counting events where this attribute is false will result in over-counting of usage. Query examples Here are some examples of NRQL queries you can use with your subscription usage data. You can run NRQL queries and use the resulting charts in dashboards. Page views for the last complete month This query shows a count of page views from the last complete month: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE last month UNTIL this month Copy Page views for the last week by account This query shows a count of page views from the last week by account: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 7 days ago FACET consumingAccountName Copy Page views for the past month, by application: This query shows a count of page views from the past month by application SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 30 days ago FACET browserAppID Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts): SELECT count(*) FROM NrUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy SPA usage Page views are used by New Relic Browser to determine customer data usage and product pricing. This document defines a page view in the context of New Relic Browser's SPA monitoring and explains why: SPA monitoring does not affect Browser data usage SPA monitoring will increase Insights data usage In New Relic Browser, a page view is defined as a complete load or reload of a page, signaled by the firing of the window.onload event. New Relic's SPA monitoring tracks traditional page views, but it also tracks changes in the browser that do not require a page load, such as: Route and hash changes Synchronous and asynchronous JavaScript Dynamic server-side updates to a page Route changes are tracked automatically, and by setting up custom instrumentation you can capture almost any type of browser interaction. With New Relic Browser Pro, pricing is based on an account's number of page views per month. If SPA monitoring is enabled, browser interactions that do not require a page load are not counted as page views for billing purposes. With SPA monitoring, you can track an unlimited number of route changes and other custom browser interactions that don't involve page loads. Notes on Insights subscription If you switch from standard Browser monitoring to SPA monitoring, and you also pay for Insights (and don't use only your complementary Insights subscription), your Insights data usage will increase. Because SPA monitoring is a more advanced way to monitor your application, it creates more Insights events than standard monitoring for the following reasons: Page views create not only PageView events, but also BrowserInteraction, AjaxRequest, and BrowserTiming events. For the typical SPA-architecture app, there are more route changes than there are standard page loads. If you pay for Insights and your current Insights license is not sufficient for the amount of events generated with SPA monitoring, we will notify you when you have exceeded your data usage plan. To remedy this, the following options are available: Upgrade your Insights plan. Turn off the reporting of some event types. Use the Browser API to manually turn off collection of some events Switch from Browser SPA monitoring back to standard monitoring",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.27458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser subscription <em>usage</em>",
        "sections": "Browser subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e8774e7b9d28a042a07d2"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-pricing-plan-usage/synthetics-subscription-usage": [
    {
      "sections": [
        "Infrastructure subscription usage",
        "Important",
        "Data generation",
        "Usage calculation",
        "Tip",
        "Table definitions",
        "General attributes",
        "Infrastructure attributes",
        "Query examples",
        "Compute units for last month",
        "Detailed host report (reproducing old usage report)",
        "Account hierarchy"
      ],
      "title": "Infrastructure subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "036858ab7d7fb54da536202e11788d0fc1029460",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/infrastructure-subscription-usage/",
      "published_at": "2021-10-24T19:09:48Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Infrastructure accounts. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, a New Relic Infrastructure account will generate an NrDailyUsage event for every unique host on which an application instance existed over the last 24 hours. All Infrastructure events have a productLine attribute value of Infrastructure. For more information, see query examples. Usage calculation Monthly billable CUs for a host are calculated by the size of the host running Infrastructure (number of CPUs + GBs of RAM) multiplied by the number of hours the host is connected to New Relic during that month. For more on how this is calculated, see CU-based pricing. If your usage is fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To view usage information in the UI: Go to the usage UI. On the Infrastructure usage page, set the time picker to Last 30 days. Multiply the Avg daily compute units by the number of days in the current month. For more information about the usage UI, see Introduction to subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns displayed depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily compute units The average daily compute units used. % of total usage The percentage of the total usage used. General attributes The following are general (not Infrastructure-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Infrastructure attributes The following are usage-related attributes generated by Infrastructure. To query this data, use a productLine attribute value of Infrastructure. Attribute Description agentHostname ID used to uniquely identify the host for which this usage is reported. Any given hour of usage for this host will be counted only once when calculating infrastructureHoursUsed. There are several possible host identifiers reported by the New Relic agent. The usage reporting system will always use the agent-reported hostname to uniquely identify the host for the Infrastructure product, but will also record the cloudInstanceId, if present, for informational purposes. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This will not be present if no cloud provider was detected by the agent. cloudInstanceSize Size of the cloud instance for this host for CU billing purposes, as calculated according to the formula for infrastructureBillingInstanceSize, using the CPU and memory sizes associated with the instance type defined by the cloud provider. Will not be present if no cloud provider was detected by the agent. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. infrastructureAgentVersion Version of the Infrastructure agent running on the host reporting this usage. If multiple agents are reporting from the same host, the version from the first agent seen in a given hour will be used. infrastructureAgentMemoryBytes Bytes of RAM available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureAgentProcessorCount Number of logical CPU cores available to the host, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedMemoryBytes Bytes of RAM available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureCloudDerivedProcessorCount Number of logical CPU cores available to the host, as reported by the cloud provider, used to calculate infrastructureBillingInstanceSize. infrastructureBillingInstanceSize Size of the host, for CU billing purposes. Calculated as: number of processors multiplied by memory in GiB. infrastructureHoursUsed Number of hours for which usage was recorded for the given host. When a host is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. infrastructureComputeUnits Number of compute units (CUs) recorded for the given host. CUs are calculated as: infrastructureHoursUsed multiplied by infrastructureBillingInstanceSize. For more about compute unit calculation, see CU pricing. infrastructureComputeUnitRule Describes the algorithm used to calculate the host size for CU usage. Values include: agent_collected_calculated_data: Use the host size data collected by the agent from the OS environment. cloud_provider_data: Use the host size data from the cloud provider. missing_data: Some host size data was missing. This could be due to an agent and operating system combination for which CPU and memory sizes are not supported. This will result in the default host size (16) being applied. instanceSizeCapped This is True if the calculated host size was greater than 16 and therefore capped. missingCpuData True if the Infrastructure agent reports no CPU count. missingRamData True if the Infrastructure agent reports no memory count. productLine The New Relic product the usage data is from. Always use the value Infrastructure when querying for Infrastructure usage data. usageType The type of entity this event records values for. This value is Host for Infrastructure. Query examples Here are some examples of NRQL queries you can use with your Infrastructure subscription usage data. You can run NRQL queries, and use the resulting charts in dashboards. For general information about how to use NRQL queries to get focused usage data, see Intro to usage data. Compute units for last month This query produces a count of the CUs used over the last month: SELECT sum(infrastructureComputeUnits) FROM NrDailyUsage WHERE productLine='Infrastructure' AND usageType='Host' SINCE last month UNTIL this month Copy Detailed host report (reproducing old usage report) This query reproduces as closely as possible the report you would have gotten by downloading the CSV from the previously available Infrastructure subscription usage UI: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID',agentHostname,cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type',infrastructureBillingInstanceSize AS 'Instance size',infrastructureHoursUsed AS 'Hours used',infrastructureComputeUnits AS 'Usage (CU)', infrastructureCloudDerivedMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureCloudDerivedProcessorCount AS 'Logical processors',infrastructureAgentMemoryBytes/(1024*1024*1024) AS 'Total RAM',infrastructureAgentProcessorCount AS 'Logical processors',infrastructureComputeUnitRule AS 'Business rule',missingCpuData, missingRamData, instanceSizeCapped,cloudZone,cloudInstanceId WHERE productLine='Infrastructure' AND usageType='Host' SINCE 1 day ago LIMIT 1000 Copy This NRQL query is different than the legacy usage report: Detailed host query Comments Time period This query includes only the last day of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to 1000 NRQL limits the results to 1000. If you have more than 1000 hosts and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example, WHERE agentHostname LIKE ... to divide the data into groups). Business rule Business rule has been replaced with two attributes: infrastructureComputeUnitRule defines how the size of the host was calculated, depending on what data was available from the agent. It no longer describes whether the agent needs to be updated to provide more accurate host naming in a container environment (update_agent_for_container_environment). missingCpuData, missingRamData, and instanceSizeCapped are now boolean flags describing what the value missing_data means when it is present in the infrastructureComputeUnitRule attribute. Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure subscription <em>usage</em>",
        "sections": "Infrastructure subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e87a7196a676ed2a83db4"
    },
    {
      "sections": [
        "APM (host-based) subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "APM attributes (host-based)",
        "Query examples",
        "Usage for last month",
        "Usage per host per application",
        "Instance-hours per application",
        "Agent version information",
        "Account hierarchy",
        "Legacy per-host usage report",
        "Legacy host usage report (application listing)",
        "Use of Docker and other containers"
      ],
      "title": "APM (host-based) subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "afaa1272f61e4c003e687d26e904438c0391cda1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/new-relic-account-usage/getting-started-usage/apm-host-based-subscription-usage/",
      "published_at": "2021-10-24T20:32:07Z",
      "updated_at": "2021-08-08T22:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this doc explains how New Relic calculates billable usage for APM accounts that have host-based pricing (not CU-based pricing). This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. Data generation Once per day, an APM account will generate an NrDailyUsage event for: Every application instance that existed during the last 24 hours Every unique host on which an application instance ran during the last 24 hours These two types of events allow your usage data to be queried and analyzed in many different ways. To query the application events, use a usageType attribute value of Application. To query the host events, use a usageType attribute value of Host. All APM events use a productLine attribute value of APM. For more information, see APM query examples. Usage calculations For host-based APM pricing, monthly billable usage is determined by the number of equivalent hosts used during that month. An equivalent host is defined as: 750 hours (standardized number of monthly hours) of connection to New Relic by a host or multiple hosts. For more on this calculation, see host-based pricing. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrDailyUsage event. To get an estimate of the current month's billable usage: Go to the usage UI. On the APM usage page, set the time picker to Current month. See the Avg daily equivalent hosts for an account or grouping of accounts. The UI is meant to estimate your host usage but, especially for cloud environments, your usage may go up or down over time. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers in the UI table and CSV files. The columns you see depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account or a customer partnership. Account ID New Relic account ID. Host ID The unique identifier for that host. If the host is in AWS, we use the AWS-provided instance ID. For other hosts, New Relic assigns a host ID. For more about how this value is created, see hostID. Agent hostname The name of the host, as reported by the agent. For more about this value, see agentHostname. Average daily equivalent hosts Average equivalent hosts for that day. Calculated as the total number of hours reported for all unique hosts in a day, divided by 24. For more on how this is calculated, see Host-based pricing. % of total usage The percentage of the total usage used. General attributes The following are general (not APM-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. APM attributes (host-based) The following are usage-related attributes generated by host-based APM accounts (not CU-based APM). To query APM-specific data, use a productLine attribute value of APM. Attribute Description agentHostname ID reported by the agent to uniquely identify the host for which this usage event is reported. This value can come from several sources in the application’s environment, but commonly is the value returned by the gethostname Linux syscall. In Docker environments, this attribute can take on the value (sometimes truncated) of the Docker container ID. agentHostname is one of three possible providers for the hostId value. apmAgentVersion Version of the New Relic APM agent running in the application instance reporting this usage. Present only for events where usageType equals Application. To update your agent version, see Update the New Relic agent. apmAppId ID uniquely identifying the application that is reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmAppName Name of the application reporting this usage, as it appears in the APM product. Present only for events where usageType equals Application. apmHoursUsed Number of hours for which usage was recorded for the given entity. When an entity is connected to New Relic for any amount of time within a given hour, that hour is counted toward usage. When calculating monthly APM host usage, the calculation for equivalent hosts for a month assumes that a standard month has 750 hours: ` apmHoursUsed / 750 ` . apmLanguage Name of the language that the usage-reporting application is written in, as reported by the New Relic agent. Examples: ruby, java, python. Present only for events where usageType equals Application. bootId Linux boot ID of host for which this usage is reported, which is unique for each boot lifetime of each Linux operating system instance. Will only be present when the New Relic agent is one of the following versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher bootId is one of three possible providers for the hostId value. cloudInstanceId ID uniquely identifying the cloud host instance (example: an AWS EC2 instance) for which this usage is reported. (For example, for an AWS EC2 instance, the value would look like i-1234abcd5678ef900.) This is used to uniquely identify the host if the apmComputeUnitRule is cloud_provider_data. This will not be present if no cloud provider was detected by the agent. Agents with these versions will detect cloud provider data for AWS: Go: 1.11 or higher Java: 3.18.0 or higher .NET: 5.1.72.0 or higher Node.js: 1.21.0 or higher PHP: 5.5.0 or higher Python: 2.54.0.41 or higher Ruby: 3.12.1.298 or higher cloudInstanceId is one of three possible providers for the hostId value. cloudInstanceType Instance type of the host as defined by the cloud provider and detected by the agent. For example: c4.2xlarge. This will not be present if no cloud provider was detected by the agent. cloudProvider Name of the cloud provider for this host. Example values: aws, azure. This will not be present if no cloud provider was detected by the agent. cloudZone Name of the zone that a cloud provider host is located in. For example: eu-central-1b. This will not be present if no cloud provider was detected by the agent. containerId ID of the Docker or other Linux container in which the application instance is running. This will not be present if a container was not detected by the agent. Present only for events where usageType equals Application. This attribute is not used to uniquely identify hosts for billing purposes. hostId ID used to uniquely identify the host for which this usage is reported. Any given hour of APM usage for this host will be counted only once when calculating apmHoursUsed. There are several possible host identifiers reported by the New Relic agent. The attributes, if present, will be chosen to use in this order of precedence: cloudInstanceId, bootId, agentHostname. productLine The New Relic product the usage data is from. Always use the value APM when querying for APM CU usage data. usageType For APM, this value can be either Application or Host, depending on the type of entity this event records usage for (other New Relic products will have different values for usageType). Events with both values are recorded so that usage data can be analyzed in several ways. For Application: the event represents usage for a single unique application instance for that day. For Host: the event represents usage for a single unique host for that day. Only Host entities are used to calculate billable usage. Application entities are useful for comparing usage between applications, but are not used for billing or contract purposes. Query examples Here are some examples of NRQL queries you can use with your account usage data. You can run NRQL queries and use the resulting charts in dashboards. Usage for last month This query uses New Relic’s standard number of hours per month (750) for the purpose of calculating APM equivalent hosts over the last month. SELECT sum(apmHoursUsed)/750 AS 'Equivalent hosts' FROM NrDailyUsage WHERE usageType='Host' AND productLine='APM' SINCE last month UNTIL this month Copy Usage per host per application New Relic records usage per application instance, not strictly per application. This query gives an approximation of the usage for a given application on a given host. If unique application instances run sequentially on a host within a given day, this query could return an underestimate (this would be likely, for example, in a container environment). SELECT max(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName,hostId SINCE 1 day ago LIMIT 2000 Copy Instance-hours per application This query measures the total number of hours used by all instances (processes) of an application in the last 24 hours. It's useful for determining which applications are responsible for APM usage, but does not return results that match precisely how New Relic prices APM usage. Each application instance is counted separately in this query, even if it runs concurrently with another application instance on the same host, so the number of application instance-hours is likely to be greater than the number of host-hours (the billable quantity). SELECT sum(apmHoursUsed) FROM NrDailyUsage WHERE usageType='Application' AND productLine='APM' FACET consumingAccountName,consumingAccountId,apmAppName SINCE 1 day ago LIMIT 2000 Copy Agent version information Use this query to see which agent versions are running on your applications in the last 24 hours. This information can be useful in determining whether the agent needs to be upgraded to report a more accurate host name in a Docker container environment (either a Linux boot ID or a cloud provider instance ID). FROM NrDailyUsage SELECT count(*) WHERE productLine='APM' AND usageType='Application' FACET consumingAccountId, consumingAccountName, apmAppName, apmAgentVersion, apmLanguage SINCE 1 day ago LIMIT 2000 Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts). SELECT count(*) FROM NrDailyUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 2000 SINCE 1 day ago Copy Legacy per-host usage report This query produces a close approximation of the CSV report you would have seen in the deprecated UI system: FROM NrDailyUsage SELECT consumingAccountId AS 'Account ID', hostId, cloudProvider AS 'Host provider', cloudInstanceType AS 'Instance type', apmBillingInstanceSize AS 'Instance size', apmHoursUsed AS 'Hours used', apmComputeUnits AS 'Usage (CU)', apmMemoryBytes/(1024*1024*1024) AS 'Total RAM', apmProcessorCount AS 'Logical processors', apmContainerCount AS 'Container count', apmComputeUnitRule AS 'Business rule', missingCpuData, missingRamData, instanceSizeCapped, cloudZone, cloudInstanceId WHERE productLine='APM' AND usageType='Host' SINCE 1 day ago LIMIT 2000 Copy This NRQL query is different than the legacy usage report: Per-host query Comments Time period This query includes only the last 24 hours of usage. To see the usage aggregated over a longer time period, change the SINCE clause. Results limited to a maximum number of rows NRQL limits the number of rows returned. If you have more hosts than the maximum number of rows returned and want to get the complete set of hosts, you can narrow your query with more WHERE clauses to return subsets of the data (for example WHERE cloudInstanceId LIKE “%0”) to divide the data into up to 16 groups, modulo the last character in the AWS instance ID. Docker container IDs A single Docker container ID does not appear in this report. A Docker container ID is reported only at the application instance level of granularity (usageType='Application'). For the host (usageType='Host'), a count of unique containers is reported, since there are often very many. While choosing just one container ID to report for a host had been informative, now there is more data reported at the appropriate level of granularity. Business rule Business rule has been replaced with other attributes. It no longer is used to describe whether the agent needs to be updated. Legacy host usage report (application listing) This query returns data once provided in the \"host usage report\": a listing of applications running on each host. Note that while APM usage is counted on an hour-by-hour basis, per-hour usage data is no longer available via the API or UI. FROM NrDailyUsage SELECT min(timestamp) AS 'Earliest reporting day',max(timestamp) AS 'Latest reporting day' FACET apmAppName,hostId,agentHostname,consumingAccountName,consumingAccountId WHERE usageType='Application' AND productLine='APM' SINCE 1 month ago LIMIT 2000 Copy Use of Docker and other containers Some previous New Relic APM agents may miscount containers as hosts, which may lead to over-reporting of host-based usage. To fix this calculation for Linux-based containers (including Docker), upgrade your APM agent to these versions: Go: 1.11 or higher Java: 3.42.0 or higher .NET: 6.19.330.0 or higher Node.js: 2.1.0 or higher PHP: 7.5.0.199 or higher Python: 2.90.0.75 or higher Ruby: 4.4.0.336 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.49261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM (host-based) subscription <em>usage</em>",
        "sections": "APM (host-based) subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this doc explains how New Relic calculates billable"
      },
      "id": "603e834128ccbc66fdeba78b"
    },
    {
      "sections": [
        "Browser subscription usage",
        "Important",
        "Data generation",
        "Usage calculations",
        "Tip",
        "Table definitions",
        "General attributes",
        "Browser attributes",
        "Query examples",
        "Page views for the last complete month",
        "Page views for the last week by account",
        "Page views for the past month, by application:",
        "Account hierarchy",
        "SPA usage",
        "Notes on Insights subscription"
      ],
      "title": "Browser subscription usage",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original pricing plan usage"
      ],
      "external_id": "1accc55c1dd4a3a35550f8d209f40a602b06a330",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-pricing-plan-usage/browser-subscription-usage/",
      "published_at": "2021-10-24T23:51:39Z",
      "updated_at": "2021-07-01T15:31:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on the newer pricing plan, see New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For accounts on our original pricing plan, this document explains how we calculate billable usage for Browser subscription usage. This document also provides available subscription usage attributes and example NRQL queries to use in the New Relic UI or with API calls. For details about single-page app (SPA) monitoring usage, see SPA usage. Data generation Once per hour, for every monitored application, a New Relic Browser account will generate a NrUsage event. Each event will summarize the usage for the last hour. When querying Browser usage data, use a productLine attribute value of Browser. For more information, see the Browser query examples. Usage calculations Monthly subscription usage equals the total number of page views that month across all end-user browsers. AJAX traffic does not count against your daily usage. If your page views are fairly steady over time, you can estimate usage for the current month. Tip Only the account Owner and Admins can view the usage UI. However, anyone in your account can query usage data using the NrUsage event. To view usage information in the UI: Go to: account dropdown > View your usage. On the Browser usage page, set the time picker to Last 30 days. Multiply the Avg daily page views by the number of days in the current month. For more information about the usage UI, see Introduction to New Relic subscription usage data. Table definitions Here are definitions of the column headers displayed in the UI table and CSV files. The columns visible depend on the Group by option selected at the top of the page. Header Definition Account name The name of the account. This can be a standalone account, a parent account, or a customer partnership. Account ID New Relic account ID. Average daily page views The average daily page views for that account or application. % of total usage The percentage of the total usage used. General attributes The following are general (not Browser-specific) account-related attributes. These attributes can help you understand how your accounts are using New Relic products. Attribute Description consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. consumingAccountName Name of the New Relic account that is directly responsible for the stored events, as determined from the license key used. masterAccountId The ID of the parent account that is either responsible for stored events or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountId is the consumingAccountId. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. masterAccountName Name of the parent account that is either responsible for stored events, or that is the parent of the consuming account. When a parent account is the consuming account, masterAccountName is the consumingAccountName. This attribute is present even for accounts that do not have a parent account. This is to ensure continued reporting if the account is later made a parent account. partnershipId Partner ID of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a New Relic customer partnership. partnershipName Name of the New Relic customer partnership associated with the account responsible for the stored events. This attribute is only present if the consuming account is associated with a customer partnership. subAccountId ID of the child account that is responsible for the stored event. When this attribute is present, subAccountId is the consumingAccountId. This attribute is only present if the consuming account is a child account (not a parent account). subAccountName Name of the child account responsible for stored events. When present, this attribute is the same as the consumingAccountName. This attribute is only present if the consuming account is a child account (not a parent account). timestamp UNIX timestamp (seconds since epoch) of the day and time when event generation was initiated. Browser attributes The following are usage-related attributes generated by New Relic Browser. To query Browser data, use a productLine attribute value of Browser. Attribute Description browserPageViewCount Number of page views for an application for that 24-hour period. For more on how events are generated, see Data generation.Page views for both Pro and Lite Browser agents are counted. productLine The New Relic product the usage data is from. For Browser data, this value is Browser. usageType The type of entity this event records values for. For Browser, this value is Application. browserAppId ID uniquely identifying the application reporting this usage, as it appears in the Browser product. isPrimaryApp Deprecated April 2, 2020. Boolean. true means the application is the primary app. false means the app is one of several apps that an agent reports data for. For more on multiple app names in APM and Browser, see Use multiple app names. The sum of events where this attribute is true will give an accurate total of page views when you are using the multiple app names feature. Counting events where this attribute is false will result in over-counting of usage. Query examples Here are some examples of NRQL queries you can use with your subscription usage data. You can run NRQL queries and use the resulting charts in dashboards. Page views for the last complete month This query shows a count of page views from the last complete month: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE last month UNTIL this month Copy Page views for the last week by account This query shows a count of page views from the last week by account: SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 7 days ago FACET consumingAccountName Copy Page views for the past month, by application: This query shows a count of page views from the past month by application SELECT sum(usage) FROM NrUsage WHERE productLine='Browser' SINCE 30 days ago FACET browserAppID Copy Account hierarchy This query is useful for seeing the account hierarchy (partnership, parent accounts, child accounts): SELECT count(*) FROM NrUsage FACET partnershipName,masterAccountName,masterAccountId,consumingAccountName,consumingAccountId LIMIT 1000 SINCE 1 day ago Copy SPA usage Page views are used by New Relic Browser to determine customer data usage and product pricing. This document defines a page view in the context of New Relic Browser's SPA monitoring and explains why: SPA monitoring does not affect Browser data usage SPA monitoring will increase Insights data usage In New Relic Browser, a page view is defined as a complete load or reload of a page, signaled by the firing of the window.onload event. New Relic's SPA monitoring tracks traditional page views, but it also tracks changes in the browser that do not require a page load, such as: Route and hash changes Synchronous and asynchronous JavaScript Dynamic server-side updates to a page Route changes are tracked automatically, and by setting up custom instrumentation you can capture almost any type of browser interaction. With New Relic Browser Pro, pricing is based on an account's number of page views per month. If SPA monitoring is enabled, browser interactions that do not require a page load are not counted as page views for billing purposes. With SPA monitoring, you can track an unlimited number of route changes and other custom browser interactions that don't involve page loads. Notes on Insights subscription If you switch from standard Browser monitoring to SPA monitoring, and you also pay for Insights (and don't use only your complementary Insights subscription), your Insights data usage will increase. Because SPA monitoring is a more advanced way to monitor your application, it creates more Insights events than standard monitoring for the following reasons: Page views create not only PageView events, but also BrowserInteraction, AjaxRequest, and BrowserTiming events. For the typical SPA-architecture app, there are more route changes than there are standard page loads. If you pay for Insights and your current Insights license is not sufficient for the amount of events generated with SPA monitoring, we will notify you when you have exceeded your data usage plan. To remedy this, the following options are available: Upgrade your Insights plan. Turn off the reporting of some event types. Use the Browser API to manually turn off collection of some events Switch from Browser SPA monitoring back to standard monitoring",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.27458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser subscription <em>usage</em>",
        "sections": "Browser subscription <em>usage</em>",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> Product-based <em>pricing</em>. If you&#x27;re on the newer <em>pricing</em> <em>plan</em>, see New Relic One <em>pricing</em> <em>plan</em>. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. For <em>accounts</em> on our <em>original</em> <em>pricing</em> <em>plan</em>, this document explains how we calculate billable <em>usage</em>"
      },
      "id": "603e8774e7b9d28a042a07d2"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-product-based-pricing/overview-changes-pricing-user-model": [
    {
      "sections": [
        "Original product-based pricing and billing",
        "Important",
        "Overview of original pricing",
        "Annual vs monthly pricing plans",
        "APM and infrastructure: Compute-unit vs host-based pricing",
        "Compute unit pricing",
        "Host-based pricing",
        "Tip",
        "How is a \"host\" defined?",
        "Prorated billing",
        "Manage subscription and billing settings",
        "View summary information",
        "View or change current subscription",
        "View usage",
        "View or update billing information"
      ],
      "title": "Original product-based pricing and billing",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "92a9a2aaacf80af45767d6f8f15283c541b2bf08",
      "image": "https://docs.newrelic.com/static/a5a6fd548a3c62e03183f13e6be6688a/77a9e/Accounts_CU-calculation_0.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-pricing/product-based-pricing/",
      "published_at": "2021-10-24T19:44:57Z",
      "updated_at": "2021-09-14T14:48:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more on pricing and user-related changes, see Overview of changes. Overview of original pricing New Relic has two pricing plans: a newer one called New Relic One pricing, and our original pricing plan. Our original pricing plan was based on subscriptions to specific products, like APM, Mobile, and Infrastructure. If you are on this pricing plan, your users are likely on our original user model and use these original user docs. To understand more about the new pricing and user changes, see Overview of changes. For accounts on original pricing, this doc includes: Explanation of how our original pricing plan works How to manage subscription and billing settings Annual vs monthly pricing plans Here are the differences between billed-annually and billed-monthly plans: Pricing plans Details Annual (best price) New Relic charges your credit card each month for a year for a committed number of hosts or compute units. You can increase this amount at any time, and charges will adjust with the next monthly bill. Your account will automatically renew at the end of the year unless you change your subscription. Early termination, downgrade, or decrease in service: Unless your order form states otherwise, you will be charged at the level and quantity of service ordered until the end of the then-current term if you cancel or downgrade to a lower level of service or fewer hosts during your commitment year. Monthly (no commitment) New Relic charges your credit card each month for a specified number of hosts or compute units. The account Owner can change the credit card number. To edit billing settings, use the Billing UI. Adjustments to billing settings will take effect for the next billing period. Your account automatically renews each month unless you change your subscription. You can cancel service or downgrade to a lower level of service without penalty. APM and infrastructure: Compute-unit vs host-based pricing APM offers a choice between two pricing models: compute unit (CU) based pricing and host-based pricing. New Relic Infrastructure offers only CU-based pricing. This section shows how both options are calculated, and explains what \"host\" means in these pricing contexts: Compute unit pricing CU-based pricing is available for these New Relic products: APM (choice of either CU-based pricing or host-based pricing) Infrastructure: only CU-based pricing With CU-based pricing, your monthly price is determined by the size of the host (computing power and memory) running New Relic and the number of hours it connects to New Relic during the month. If a host is connected to New Relic at any time during an hour, that hour counts towards the CU calculation. Each host is counted separately for each New Relic account the host reports data to. For example, if you have a parent account with two children accounts, each running applications on the same host for 3,000 CUs in a given month, the usage for the parent account will be 6,000 CUs. For APM, CU-based pricing is the best choice if you have many cloud-based dynamic computing resources. For this reason, CU-based pricing is sometimes referred to as cloud pricing. CUs are calculated as follows: The maximum size of a given host (CPUs + GB RAM) is capped at 16. Examples: If a host has 2 CPU cores, 2GB RAM, and connects to New Relic for one hour (or less than one hour), it consumes 4 CUs. If a host has 2 CPU cores, 2GB RAM, and connects to New Relic for an entire month (750 hours used as standard month size), it consumes 3,000 CUs. You can purchase blocks of CUs to be consumed on a monthly basis. The total number of CUs purchased monthly is calculated by adding up the estimated CU consumption for all hosts for the month. There is no month-to-month rollover of unused CUs. Also, New Relic does not charge by JVMs, containers (such as Docker or Cloud Foundry), or application instances--it charges by the hosts running those containers or application instances. Price points vary, depending on the New Relic product and subscription level. You can view CU-based account usage from the New Relic UI. Host-based pricing Tip Pricing for your APM account can be either CU-based or host-based. New Relic Infrastructure uses only CU-based pricing. With host-based pricing, New Relic charges based on the number of equivalent hosts used in a month. One equivalent host is defined as: a host connected to New Relic for 750 hours (750 hours used as standard month size). If a host is connected to New Relic at any time during an hour, that hour counts towards the host calculation. These hours can be divided across multiple hosts. For example, you might have three hosts that are each connected to New Relic for 250 hours during one month: these hours would add up to equal one equivalent host. Each host is counted separately for each New Relic account the host reports data to. For example, if you have a parent account with two child accounts, each running applications on the same single host for 750 hours in a given month, the usage for the parent account will be 2 equivalent hosts. Once connected to New Relic, hosts are distinguished by their unique hostnames. A host is connected to New Relic when the language agent is active and is deployed on the host. New Relic does not charge by containers (such as Docker or Cloud Foundry), JVMs, or application instances; it charges by the hosts running those containers or application instances. New Relic APM gives you a choice between host-based pricing and CU-based pricing. Host-based pricing is ideal if you have mainly static environments, consisting of hosts you manage in your own data center. For specifics on pricing amounts, see the New Relic APM pricing page. How is a \"host\" defined? To understand how New Relic computes both host-based pricing and CU-based pricing, it's important to understand how the word host is used. A host can be one of the following: A physical machine is a hardware-based device with dedicated physical resources, including memory, processing, and storage. Each machine has its own OS which applications run on. A virtual machine (VM) is the software implementation of a physical machine that executes programs like a physical machine. One or more virtual machines can run on a physical machine. Each virtual machine has its own OS and allocated virtual machine resources such as RAM and CPU. A cloud instance is a type of virtual machine that is run in the public cloud. In this context, virtual machines and cloud instances are different from Java Virtual Machines (JVMs) and containers. For New Relic's pricing calculation purposes, a month is defined as 750 hours. Prorated billing If you upgrade your subscription partway through your billing period, you will be subject to a prorated charge for the higher level of service over the remainder of your billing period. This will be invoiced or charged to your credit card when the upgrade is submitted. You will be notified about this charge as part of the subscription change process. If you have questions, contact your New Relic account representative. If you need to report billing issues, contact New Relic's Billing Department. Manage subscription and billing settings Important Note that as of July 30 2020, we have a newer pricing plan. To learn more, see Overview of pricing. The account Owner can perform many subscription self-service functions directly from the user interface: From one.newrelic.com, select the account dropdown. Select your choice of self-service options. When making subscription changes, be sure to save any changes, agree to New Relic's Terms of Service and Supplemental Payment Terms as appropriate, and select Pay now. Optional: If you downgrade your subscription, complete New Relic's survey. Here is a summary of the available options from your account dropdown in the New Relic user interface: View summary information To view summary information about your subscription, go to the billing UI. View or change current subscription To adjust your subscription settings, use the Billing UI. If you need more help, contact your New Relic account representative, or contact New Relic's Billing Department. View usage To view your usage, use the usage UI. View or update billing information To view or update your New Relic account's billing information, see the billing UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.85196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "sections": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": ". For <em>accounts</em> on <em>original</em> <em>pricing</em>, this doc includes: Explanation of how our <em>original</em> <em>pricing</em> plan works How to manage subscription and <em>billing</em> settings Annual vs monthly <em>pricing</em> plans Here are the differences between billed-annually and billed-monthly plans: <em>Pricing</em> plans Details Annual (best <em>price</em>) New Relic"
      },
      "id": "6043f753e7b9d212085799da"
    },
    {
      "sections": [
        "Set session timeouts",
        "Original pricing plan",
        "Requirements",
        "Overview",
        "Features",
        "Tip",
        "Select the session timeout value",
        "Select SAML SSO browser re-authentication",
        "Redirect after SAML timeout"
      ],
      "title": "Set session timeouts",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "a61d4c61f52ee18be0763a9cd526634d9d2f50f5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/set-session-timeouts/",
      "published_at": "2021-10-24T22:52:07Z",
      "updated_at": "2021-09-14T10:20:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. New Relic's session configuration feature allows you to set limits on idle time before your users' browser sessions automatically expire. Requirements If you're on the New Relic One user model, see Session settings. Overview Session configuration allows you to set limits on idle time before your users' browser sessions automatically expire. A message appears three minutes before the system logs them out. Users then need to sign back in to continue. For accounts configured with SAML Single Sign On (SSO), an additional option is available to set how often the users' browser sessions are re-authenticated. Users and Restricted Users can view the time period for automatic timeout, but they cannot change it. To view the timeout value: Go to account dropdown > Account settings > Authentication > Session configuration. Features Tip Owner or Admins The session configuration options provide an additional level of security to ensure that unattended browsers will automatically time out. Session values are automatically stored in the session cookie. Additional features include: Feature Notes Easy setup Admins use the slide bar in New Relic's user interface to select predefined time periods. Default is two weeks. Separate options available by role Admins can choose for Restricted User sessions to never time out even if they select a session timeout setting. This is useful, for example, when you use a Restricted User login for demos. Automatic inheritance for child accounts By default, child accounts inherit the same session configuration as their parent account. Most restrictive by default If users have multiple accounts, the most restrictive setting applies, regardless of which account the user currently is using. Integration with SAML SSO logout URL If the account's SAML SSO configuration does not include a logout URL, New Relic includes a link from Session configuration for the Owner to set it up. If the Admin is not also the Owner, a message about the SAML SSO logout URL requirement appears. Additional re-authentication setting for SAML SSO In addition to the session timeout option, Admins can select the time (15 minutes to 2 weeks, or never) for how often a SAML-authenticated browser session must be re-authenticated. Select the session timeout value The process to select the session timeout value is the same for both SAML and non-SAML configurations. For additional SAML configuration options, see SAML SSO browser reauthentication. To select a predefined period for session timeouts with SAML SSO accounts, the account Owner must have previously identified the logout URL in the SAML SSO configuration settings. If this has not been set up, the account Admin can view the session timeout slide bar but not change it. If the Admin is also the account Owner, the Session configuration includes a link to go directly to New Relic's SAML SSO Configuration and identify the logout URL. For more information, see Setting up SSO. To select a predefined period for session timeouts for users on our original user model: Go to: account dropdown > Account settings > Authentication > Session configuration. Use the slide bar to select a time period for idle sessions to expire and log out automatically. Optional: Select the checkbox option if you do not want restricted users' browser sessions to expire. Select Save my changes. Changes take effect immediately. Select SAML SSO browser re-authentication To select a predefined period for SAML SSO-authenticated browser sessions to be re-authenticated: Go to: account dropdown > Account settings > Authentication > Session configuration. Use the SAML re-authentication time slide bar to select a time period for New Relic to check the browser session. Select Save my changes. Redirect after SAML timeout If you are logged out due to a session idle timeout on an account configured for SAML, you will be sent to the New Relic login page. Because your account is configured for SAML, you do not have a direct New Relic login. To be redirected to your SAML provider for authentication: Enter your email address in the Email field. Leave the Password field blank. Click the Sign In button. You will then be redirected to your SAML provider. Once reauthorized, you will then be returned to the New Relic website.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.6859,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Original</em> <em>pricing</em> plan",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": "<em>Original</em> <em>pricing</em> plan This doc is for users on our <em>original</em> user model. New Relic&#x27;s session configuration feature allows you to set limits on idle time before your users&#x27; browser sessions automatically expire. Requirements If you&#x27;re on the New Relic One user model, see Session settings. Overview"
      },
      "id": "603e8914196a678f45a83de3"
    },
    {
      "sections": [
        "Overview of data retention (original pricing plan)",
        "Important",
        "Limits on editing and deleting data",
        "Product and API data retention policies",
        "APM",
        "APM data retention policies",
        "Legacy APM data retention policies",
        "Browser",
        "Infrastructure",
        "Tip",
        "Infrastructure downsampling and data retention",
        "Integration compute unit event limits",
        "Insights",
        "Logs",
        "Logs in context data retention",
        "Mobile",
        "Mobile data retention policies",
        "Standard Mobile (legacy) data retention policies",
        "Plugins",
        "Plugins data retention",
        "Legacy Plugins data retention",
        "Synthetics",
        "Synthetics data retention policies",
        "Metric API",
        "Trace API",
        "Data components",
        "Event data: reported by most products",
        "Metric timeslice data: reported by APM, Browser, and Mobile",
        "Aggregate metric timeslice data: reported by APM, Browser, and Mobile",
        "Key metrics: reported by APM, Browser, and Mobile",
        "Trace data: reported by APM, Browser, and Mobile"
      ],
      "title": "Overview of data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "22d5ab9f4d623ead28ee7bb82c118d91804dee22",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-based-pricing/overview-data-retention-components/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-09-14T14:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on our New Relic One pricing plan, see Manage your data. Not sure which you're on? See Overview of pricing plans. If you're on the original product-based pricing plan, you retain your existing subscriptions and data retention values. You manage these existing retention settings from the Data management hub in New Relic One. To manage your retention settings, go to the Data management UI. You'll see your existing retention settings. Adjust retention values by clicking Edit retention. New Relic stores different types of data for different periods of time. The retention period for a type of data will vary depending on the product, the subscription level, and the feature. Limits on editing and deleting data Once telemetry data (events, metrics, logs, traces) is reported to New Relic and available for querying, that data cannot be edited or deleted. This is a purposeful design decision that optimizes New Relic's speed and performance. Data will expire after its data retention ends. If you sent unwanted data or sensitive data to New Relic that must be removed, contact your account representative at New Relic, or get support at support.newrelic.com. Product and API data retention policies Select a New Relic product to see details about its data retention: APM Specific retention policies apply to each APM subscription level, including Lite, Essentials, Pro, and Enterprise. This includes metric timeslice data, key metrics, trace data, and event data. In addition to retention limits, your data is subject to aggregation (averaging) after certain elapsed time periods. For more information, see the aggregate metric data description. APM data retention policies For accounts on our original product-based pricing, APM data retention policies depend on your APM product subscription level. Component Lite Essentials Pro Metric timeslice data 24 hours 3 days 90 days Key metrics none forever forever Distributed tracing and logs in context none none 8 days Other trace data * 1 day 3 days 7 days Event data * * 1 day 3 days 8 days * If you view a transaction trace in the New Relic UI, New Relic stores that trace data for up to one year. * * Learn about how to extend the retention of event data. Legacy APM data retention policies Component Standard Startup Small Business Enterprise Metric timeslice data 7 days 14 days 30 days 90 days Key metrics none none none forever Trace data 7 days 7 days 7 days 7 days Event data none 8 days 8 days 8 days Browser For accounts on our original product-based pricing, Browser data is stored depending on your subscription level: Component Lite Pro Metric data 24 hours 90 days Key metrics 24 hours forever Trace data 7 days 7 days Event data * 1 day 8 days SPA data Unavailable 8 days * Learn about how to extend the retention of event data. Infrastructure For accounts on our original product-based pricing, Infrastructure data retention policies depend on your Infrastructure subscription level and your New Relic Infrastructure compute units pricing model. Data retention rules apply the same whether that data is displayed in the UI or queried. Tip Infrastructure data retention is not governed by your Insights subscription. Infrastructure downsampling and data retention Types of data are stored depending on your subscription level: Component Essentials Pro Infrastructure data 3 months 13 months Host count Host count will stop reflecting a host whose agent is no longer reporting after three minutes. However, host data will be available, subject to other retention criteria. 3 minutes 3 minutes Inventory attributes removed Inventory attributes for a host are retained for 24 hours after the agent stops reporting. 24 hours 24 hours Integration data Not available with Essentials Limit of 2275 integration events per compute unit per month In addition, Infrastructure downsamples your data on the fly, as it's generated. All Infrastructure metric data types (including On-Host Integrations metrics) will display different granularity depending on the age of the data and the size of the time window. The following table illustrates when different downsampled buckets will be used, both in the Infrastructure UI and for queries: Bucket Size Used For Time Windows Covering... Data Retained For... Raw (5, 10 or 15 second) 0 to 59 minutes 7 days 1 minute 60 minutes to 6 hours 30 days 10 minutes 6 hours to 3 days Full account retention period 1 hour 3 days to 14 days Full account retention period 3 hours 14+ days Full account retention period Integration compute unit event limits The 2275 limit on integration events per compute unit per month is a limit on total Infrastructure integration events. It's not a limit of 2275 for each integration's events. Additional details and clarifications about this limit: This limit applies to all events from all integrations (cloud integrations and on-host integrations). The events are all handled the same. Default data received by the Infrastructure agent does not count against the 2275 event per compute unit limit. If you exceed your limit, we do not enforce this limit. If you exceed your limit, we'll review pricing options with you to ensure you get the most cost-effective pricing for your organization's integrations. Insights For accounts on our original product-based pricing, an Insights subscription extends your event data retention. An Insights Pro subscription allows you to customize the length of your event data retention. Logs For accounts on our original product-based pricing, log data can be retained for up to 30 days by New Relic. Shorter retention periods of 8 or 15 days are also available. Logs in context data retention New Relic Logs logs in context data retention policy is based on your current APM product subscription level. For more information, see APM data retention. Mobile For accounts on our original product-based pricing, Mobile data retention policies depend on your New Relic Mobile product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and event data. For information about your subscription-related data usage, see Mobile subscription usage. Mobile data retention policies Component Lite Enterprise Overview page data 24 hours 90 days Crash data and stack traces 24 hours 90 days HTTP requests (except errors) as metric data Unavailable 90 days HTTP request errors as metric data Unavailable 3 days Interaction traces Unavailable 90 days Custom events * Unavailable 1 day Mobile events * 1 day 8 days MobileBreadcrumb events * Unavailable 3 days MobileCrash events * 1 day 90 days MobileHandledException events * Unavailable 3 days MobileJSError events (React Native beta) * Unavailable 3 days MobileRequest events * Unavailable 3 days MobileRequestError events * Unavailable 3 days MobileSession events * 1 day 90 days * Learn how to extend retention of event data. Standard Mobile (legacy) data retention policies Unless otherwise noted, Insights event data is unavailable for Standard subscriptions. Component Standard Overview page data 7 days Crash data and stack traces 7 days HTTP requests (except errors) as metric data 7 days HTTP request errors as metric data 3 days Interaction traces Unavailable MobileCrash events 8 days MobileSession events 8 days Plugins The retention period for historical data depends on the product and subscription level. The following data retention periods exist for New Relic Plugins. Important Plugins is not supported with accounts that host data in the EU region data center. Plugins data retention Component Lite Essentials Pro Enterprise Metric data 24 hours 3 days 90 days 90 days Legacy Plugins data retention Component Standard Startup Small Business Metric data 7 days 14 days 30 days Synthetics For accounts on our original product-based pricing, Synthetics data retention policies depend on your Synthetics product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and Insights events. Tip Synthetics events do not count against an Insights Pro subscription. Your current subscription level appears in the right column of the Account summary page: Go to synthetics.newrelic.com > (account dropdown) > Account settings > Account > Summary. Synthetics data retention policies Component Lite Pro Synthetics monitor data 2 weeks 13 months Event data 2 weeks 13 months Also see the data retention details for APIs, including: Metric API All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Trace API See Trace API general requirements and limits. Data components For accounts on our original product-based pricing, the section below provides an explanation of some types of data components governed by the data retention rules of specific products: Event data: reported by most products See Event data retention for information on the event data type. Metric timeslice data: reported by APM, Browser, and Mobile Metric timeslice data is a specific type of data that is used for most metric charts and reports in APM, mobile, and browser. Important Note that metric timeslice data differs from other metric data types. All metric timeslice data is aggregated, but New Relic deals with fresh data and old data in different ways. Fresh data has specific policies applied to the data to keep granular views of performance as aggregate metrics. As data ages and becomes less useful in a granular state, we summarize that data and only keep key metrics. Aggregate metric timeslice data: reported by APM, Browser, and Mobile Aggregate metric timeslice data summarizes calls to specific methods in your application: how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on your subscription level. Subscription Level Aggregate retention Enterprise Aggregates (averages) to 1-hour periods after 8 days. After 90 days, the permanent metric data continues to be stored in 1-hour periods. This means you cannot obtain data granularity of less than 1 hour after 8 days, and only a subset of metrics are available after 90 days. Pro After 8 days Essentials After 3 days. Legacy Small Business, Startup, and Standard After 3 days. Lite After 2 hours. We retain your most recent data in one-minute increments. We also aggregate permanent metric data to day-size increments after 90 days. When looking at older data in small time windows, you may notice that charts show less detail. As data ages, it is aggregated into larger segments. Key metrics: reported by APM, Browser, and Mobile New Relic retains certain \"key\" metric timeslice data aggregations forever for Enterprise and Pro customers, for any number of applications. New Relic aggregates permanent key metric data to hour-size increments after 90 days. Product Key metrics APM Apdex, for app server Throughput and page views Response time, plus breakdown into tiers or categories on your app's main Overview chart Page load time, plus breakdown into segments Error rate CPU usage Memory usage Browser Apdex, for browser Browser page load time Throughput total. After 90 days, there is no breakout by browser type, and only the combined average value is available for the time range requested. Mobile Crash rate: For iOS and for Android Network throughput Network response time Network error rates Interaction traces Trace data: reported by APM, Browser, and Mobile Depending on the product, New Relic retains different types of trace data: Product Trace data APM Types of trace data: Transaction traces Distributed tracing Slow query samples Error details See APM data retention details. Browser Types of trace data: Session traces Browser traces JavaScript errors* See Browser data retention details. Mobile Types of trace data: App crash stack traces Interaction traces See Mobile data retention details. * JavaScript errors in the stack trace UI are saved as trace data. JS errors are also saved as events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.07425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of data retention (<em>original</em> <em>pricing</em> plan)",
        "sections": "Overview of data retention (<em>original</em> <em>pricing</em> plan)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> <em>Product</em>-<em>based</em> <em>pricing</em>. If you&#x27;re on our New Relic One <em>pricing</em> plan, see Manage your data. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. If you&#x27;re on the <em>original</em> <em>product</em>-<em>based</em> <em>pricing</em> plan, you retain your existing subscriptions and data"
      },
      "id": "6043f75364441f6967378ec6"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-product-based-pricing/switch-new-models": [
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.65016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access <em>to</em> features <em>and</em> data",
        "sections": "<em>Pricing</em> <em>plan</em> or edition",
        "tags": "Accounts <em>and</em> billing",
        "body": " on the products you pay for. Our <em>New</em> Relic One <em>pricing</em> <em>plan</em>: This newer <em>pricing</em> <em>plan</em> gives more cross-platform access. The main factors affecting access are your edition and your <em>user</em> type. We also have several <em>pricing</em> editions: Standard, Pro, and Enterprise. Learn more about our <em>pricing</em> plans"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, who have access to our more curated UI experiences. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.36761,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> Relic One <em>pricing</em> <em>and</em> billing ",
        "sections": "How the <em>New</em> Relic One <em>pricing</em> <em>plan</em> works",
        "tags": "<em>New</em> Relic One <em>pricing</em> <em>and</em> billing",
        "body": " original <em>user</em> <em>model</em> that have a parent&#x2F;child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see <em>User</em> count discrepancy. The Standard edition of the <em>New</em> Relic One <em>pricing</em> <em>plan</em> includes one free full <em>user</em>. For organizations on our original"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Overview of changes to pricing and user model",
        "Overview of how pricing plan and user model relate",
        "Pricing plans explained",
        "Determine pricing plan",
        "Convert to new pricing",
        "User models explained",
        "Requirements for new user model",
        "Determine which user model you're on",
        "Feature impacts of user model",
        "Transition to new models"
      ],
      "title": "Overview of changes to pricing and user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "b19d61b5a0c65ca352e2ce0e260e2b53391b94fc",
      "image": "https://docs.newrelic.com/static/1461470cc1ef0be91120c84d76a7ccdd/c1b63/new-relic-one-pricing-plan-billing-ui.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-product-based-pricing/overview-changes-pricing-user-model/",
      "published_at": "2021-10-24T19:44:08Z",
      "updated_at": "2021-09-13T20:48:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In 2020, New Relic released both a newer pricing plan and a newer user model. Keep reading to learn about: How the pricing plan and the user model relate to each other Pricing plans explained User models explained How to switch to the new models Overview of how pricing plan and user model relate In 2020, we released both a new, improved pricing plan and a new, improved user model. These models represent the future. All new sign-ups are on these new models and eventually all organizations will be on these models. But currently, our customers from before July 2020 may have one of several combinations of these as they either switch to the new pricing or migrate their users to the new user model. This table shows how pricing and user model relate to each other: Pricing plan factors User model factors Original pricing If your organization was created before July 30 2020, you remain on our original pricing plan until you transition to New Relic One pricing. For original pricing accounts, you have users on the original user model unless you've migrated your users to the new model. Note that if you've added users via automated user management, they're on the new model. This means it's possible to have some users on both models. New Relic One pricing An organization is on the New Relic One pricing plan: If it was created on or after July 30 2020, or If it's an older organization but has switched to New Relic One pricing. If your organization was created on or after July 30 2020, your users are on the New Relic One user model. If you have an older organization, you have users on the original user model unless you've migrated your users to the new model. Pricing plans explained New Relic organizations are on one of two pricing plans: New Relic One pricing: Our new pricing plan is simpler. It bills on a) which edition you're on (Standard, Pro, or Enterprise), b) the GBs of data ingested, and c) how many billable full users you have. All organizations created on or after July 30 2020 are on this pricing plan, as are older organizations that have switched to this pricing. There are two versions of this pricing plan. Our original product-based pricing plan: this is based on subscriptions to specific products (for example, APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer pricing plan: in that case, their users remain on our original user model. Determine pricing plan To determine which pricing plan you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see billing information about data ingested and the number of billable users, you’re on the new pricing plan. If you're on New Relic One pricing, you'll see a billing UI like this. Convert to new pricing Some organizations are able to switch to new pricing. Learn more about switching your pricing plan. User models explained In this context, the term \"user model\" refers to the structure of a New Relic user record and how it interacts with the broader New Relic organization that it's in. Our two user models are: New Relic One user model: this newer, improved user model has these major differences from the original user model: All your accounts and users are contained under a top-level organization. This gives an organization stronger control over managing users and what they can access. One impact of this is that users who work with multiple New Relic organizations may have an email address associated with multiple logins. Users on this model have a different system for managing permissions and account access. Using access grants, you assign users access to specific roles on specific accounts. Original user model: some aspects of this older model that are different from our newer model: There wasn't as much organization-level control over users. For example, a New Relic user had the ability to access multiple accounts they'd been granted access to using a single login. Users on the original user model have a different user management system. To learn more about benefits of the new model, see our blog post about user model changes and an explanation of the new account structure. For impacts and limitations, see Feature impacts. Requirements for new user model Here's a synopsis of the factors governing what organizations use the new model: All New Relic organizations that signed up after July 30 2020 have users on this model, and also have the new pricing plan. Some older New Relic organizations have had their users migrated to the new model by New Relic or by using the user migration procedure. Note that switching to the new pricing plan is independent from migrating users. Partner accounts (resellers, managed service providers), and organizations using the partnership account structure, cannot yet migrate their users to the new model. Determine which user model you're on To determine what user model you're on, from the account dropdown select User preferences. If you see the UI below, you're on the New Relic One user model. If you see a different UI with more content displayed, you're on the original user model (see original user docs). To determine if you can manage users on the New Relic One user model, see Manage users. The user model is independent of your pricing plan. For how user model relates to pricing, see the Pricing and user model table. Feature impacts of user model The new user model offers many benefits. Here are some feature impacts of being on the New Relic One user model that may be not obvious to users accustomed to our previous user model: More separation of organizations/accounts: If you have an email address associated with multiple New Relic accounts, this may mean you need to log out and log back in. Learn more about account access. Adding accounts: Pro and Enterprise edition can have more than one account in their organization. Currently users in these organizations cannot, on their own, add accounts. They must get help from their New Relic account representative. To learn about adding users to accounts, see Manage users. Alerts-related impacts: Policy actions: For alert policies and conditions, some UI locations display the user that made the last modification. For users on the new model, it will display their user ID and not their user name. For example, a policy might read Last modified Sep 7, '20 4:26 pm by user 1234567 instead of by John Doe. If you have user management permissions, you can determine what user this is by going to the User management UI. Notifications: Users on the new model won’t show up as an option when choosing users to receive alert notifications. The result of this is that these users will not get New Relic mobile app push notifications. As a workaround, you can instead use their email address as the notification channel. You can't use the REST API to generate a list of users (only original model users). Instead you'd use the user management UI. Changing account name: These users cannot change the name of their organization after it has been created. Transition to new models Some New Relic organizations on the old models are able to transition to the new models. To learn more about this, see Transition to new models.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.58281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of changes <em>to</em> <em>pricing</em> <em>and</em> <em>user</em> <em>model</em>",
        "sections": "Overview of changes <em>to</em> <em>pricing</em> <em>and</em> <em>user</em> <em>model</em>",
        "tags": "Original product-based <em>pricing</em>",
        "body": "In 2020, <em>New</em> Relic released both a newer <em>pricing</em> <em>plan</em> and a newer <em>user</em> <em>model</em>. Keep reading to learn about: How the <em>pricing</em> <em>plan</em> and the <em>user</em> <em>model</em> relate to each other <em>Pricing</em> plans explained <em>User</em> models explained How to <em>switch</em> to the <em>new</em> models Overview of how <em>pricing</em> <em>plan</em> and <em>user</em> <em>model</em> relate"
      },
      "id": "603e97fa28ccbcb7c2eba754"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-users-roles/original-account-structure": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/new-relic-account-structure/",
      "sections": [
        "Organization and account structure",
        "Important",
        "New Relic One user model",
        "How users access accounts",
        "Original user model"
      ],
      "published_at": "2021-10-24T23:49:09Z",
      "title": "Organization and account structure",
      "updated_at": "2021-10-24T23:49:08Z",
      "type": "docs",
      "external_id": "4f5a4cde293d0b599f489eff010f69c021ccb539",
      "document_type": "page",
      "popularity": 1,
      "body": "Depending on your user model, you have different options for adding and managing accounts and assigning users to them. We have two models: New Relic One user model Original user model Important Note that the user model is not directly related to our two pricing plans. New Relic One user model Important This section is about organizations on the New Relic One user model, not the original model. Learn more about the difference. At New Relic, an \"organization\" represents a New Relic customer. The organization contains everything relevant to a New Relic customer: its accounts, its users, and its data. A New Relic \"account\" can be considered a workspace. For example, you might have an account for a specific app, or a set of related hosts and services for a specific initiative or project, or you might have an account for a specific team. Each account has its own account ID, and that ID is used for some account-specific tasks, like making API calls. Our Standard edition allows for a single account per organization. Pro and Enterprise editions allow for multiple accounts per organization. Currently you can't add accounts to your organization on your own. To add accounts, talk to your New Relic account representative. How users access accounts In your organization, your New Relic users are granted access to specific accounts that are relevant to their duties and responsibilities. To manage users’ access to accounts, you create access grants, which assign a group of users to a specific role on a specific account. For example, you may assign a user group the ability to manage billing on some accounts with the Billing manager role, and assign some users as non-admin full users on some accounts, and assign some users as basic users on some accounts. Our user management system allows you to create the user access you need, whether that’s a relatively simple setup with just a few roles across a few accounts, or a complex one with many roles across many accounts. Learn more about user management. Note that some features, like dashboards and workloads, can display data from across different accounts in an organization. This means that if a user isn’t granted access to all relevant accounts, they may experience missing data. To learn more about access issues, see Factors affecting access. Original user model See Original user model structure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 349.3015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Organization</em> <em>and</em> <em>account</em> <em>structure</em>",
        "sections": "<em>Organization</em> <em>and</em> <em>account</em> <em>structure</em>",
        "body": " across different accounts in an <em>organization</em>. This means that if a <em>user</em> isn’t granted access to all relevant accounts, they may experience missing data. To learn more about access issues, see Factors affecting access. <em>Original</em> <em>user</em> <em>model</em> See <em>Original</em> <em>user</em> <em>model</em> <em>structure</em>."
      },
      "id": "60bee5c028ccbc2413e667e4"
    },
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.664,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Factors affecting access to features <em>and</em> data",
        "sections": "<em>User</em> permissions",
        "tags": "<em>Account</em> <em>structure</em>",
        "body": " in, select Remember me when logging in. If one of your login options reads &quot;<em>Original</em> <em>account</em>&quot;, that means it&#x27;s a <em>user</em> record on our <em>original</em> <em>user</em> <em>model</em>. For more information, see this Explorers Hub post about multiple accounts. Related docs: <em>User</em> permission factors <em>Account</em> <em>structure</em> Login and password"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "image": "https://docs.newrelic.com/static/565d4ebddf52a4592c594032696516b9/c1b63/New-Relic-capabilities-UI-screenshot.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/new-relic-one-user-model-understand-user-structure/",
      "sections": [
        "Users, roles, permissions (New Relic One user model)",
        "Important",
        "Overview",
        "User type: basic and full",
        "Compare full vs basic capabilities",
        "Tips on choosing user type",
        "Understand user-related billing",
        "Have questions about why you can't access something?",
        "Default groups: Admin and User",
        "How do user type, roles, and groups relate to each other?",
        "Roles and capabilities",
        "Standard (default) roles",
        "Capabilities",
        "Manage users",
        "2020 user model changes"
      ],
      "published_at": "2021-10-24T20:31:19Z",
      "title": "Users, roles, permissions (New Relic One user model)",
      "updated_at": "2021-10-24T20:31:18Z",
      "type": "docs",
      "external_id": "169383c2678ce973404db07195b2dee6eda9163d",
      "document_type": "page",
      "popularity": 1,
      "body": "Your New Relic users can be on one of two user models: this doc explains the New Relic One user model. Important If your New Relic organization was created before July 30 2020 and you haven't gone through a user migration process, your users are likely on our original user model. For more on this, see User model changes. Overview This doc will explain the structure of the New Relic One user model, including: User type (basic user versus full user) Default user groups, including Admin and User Roles and capabilities For how to add and manage users in the UI, see User management. User type: basic and full Important This section is for users on our New Relic One user model. If you're on our original user model, see Original users. A user's user type determines if they have access to our basic features (basic user) or can access all of our curated observability UI features (full user). The user type is something meant to be set long-term based on that user's expected New Relic responsibilities. Below are details on the two user types. Note that full users are billable only if you're on New Relic One pricing. Basic user. Details: These users are free and have access to a wide range of features, including setting up and configuring any New Relic data-reporting tool, running queries of your data, using our logs UI, making custom charts and dashboards, and setting up alerts. Unlike full users, they do not have access to our more curated observability UI experiences or some Applied Intelligence features (for a detailed comparison, see Capabilities). Basic users will see prompts to become a full user when they attempt to access unavailable features. For details, see Upgrade. Full user. Details: Full users have access to everything (depending on any role restrictions), including all our observability UI experiences, such as APM, infrastructure monitoring, browser monitoring, mobile monitoring, synthetic monitors, access to New Relic One apps, and more. For details, see Capabilities. Standard edition includes one free full user and up to five total full users. A full user can downgrade to a basic user twice in a 12-month period. To view and edit the user type of your users, use the User management UI. Learn more about basic user versus full user differences: Compare full vs basic capabilities Below is a table comparing what basic users and full users can do. A simple way to think about it is that full users have theoretical access (dependent on any chosen role restrictions) to all of our curated UI experiences, while basic users are restricted to fairly basic capabilities. Features Full user Basic user Observability UI experiences Application performance monitoring (APM) UI Infrastructure monitoring UI Digital Experience Monitoring UI, which includes: Browser monitoring UI Mobile monitoring UI Synthetic monitoring UI Synthetics checks Serverless monitoring UI Logs in context Distributed tracing Infinite Tracing (Pro and Enterprise edition) Assorted UI experiences, including: Kubernetes cluster explorer UI Key transaction UI Workloads UI Manage other users Access to New Relic One apps Can build apps but can't access other apps Applied Intelligence Automatic anomaly detection Correlated alerts and events Anomaly/alert analysis Root cause details in issues Basic platform capabilities Data ingest from any source (agents, integrations, APIs) Query your data Create custom charts and dashboards Alerts and notifications Our APIs, including NerdGraph (GraphQL) (with some restrictions) Query and chart log data Build New Relic One apps (but cannot access other apps) Encryption at rest Standard data retention Security and compliance Data management Note that the pricing edition (Standard, Pro, or Enterprise) will also affect what features you have access to. For organizations with New Relic One pricing, learn more about how full users impact billing. Tips on choosing user type A user's type (basic user vs full user) is meant to be a long-term assignment, based on the New Relic responsibilities that user is expected to perform. A full user can be downgraded to a basic user only twice in one year. Below are tips for why you'd choose full user versus basic user. Reasons to make someone a full user: They play a key role in the development, testing, deployment, and maintenance phases of the application development lifecycle. They break/fix code regularly; they are responsible for triaging workflows, troubleshooting, or managing users and roles for their team. They have DevOps practices (i.e. version control systems and implement CI/CD). They need to use New Relic's curated dashboards and experiences (not just the ability to create their own custom queries and charts); in other words, they need full access to our platform. They need to be able to manage users and/or billing. Reasons to make someone a basic user: They play a key role in the planning phase of the application development lifecycle. They use and configure New Relic agents, APIs, and integrations to send us data, and access, configure, and use alerts on such data (not necessarily responsible for triaging workflows, troubleshooting, or managing users and roles for their team). They want to see high-level analytics and business metrics for future planning (such as C-Suite executives). They do not need to use our curated experiences and dashboards, but would benefit from the ability to create their own custom queries and charts of data; in other words, they don't need full access to the platform. They don't manage users. For accounts on New Relic One pricing, learn more about user-related billing calculations. Understand user-related billing If you're on the New Relic One pricing plan, full users are billable, and there are restrictions around how often a full user can downgrade to a basic user. For details, see User count billing details. For how to query and alert on usage data, see Query usage data. Have questions about why you can't access something? See Factors affecting access. Default groups: Admin and User For users on our New Relic One user model, a \"group\" is what allows the grouping together and managing of multiple users at the same time. Your New Relic users are assigned to a group, and that group is granted access to specific roles on specific accounts. We have two default groups: User: This group allows a user to use and configure monitoring/analysis features but not perform account-related tasks like managing billing or users. It has access to the All product admin role, which gives access to our observability platform tools but not to the organization and user management capabilities governed by the Organization manager and Authentication manager roles. Admin: has full access and capabilities, including the organization-level admin abilities. This is the equivalent of having the All product admin, the Billing user, the Organization manager and the Authentication domain manager roles. These groups are added inside your default authentication domain, which includes the default settings of users a) being managed via New Relic and b) logging in via standard email and password. If you add other authentication domains (for SAML SSO and/or SCIM provisioning of users), you'd have new custom groups in those new domains to govern those users. Note that groups, whether default or custom, are not what limit a user's capabilities: it is the role that is assigned to that group (with any basic user restrictions on top of that). If your organization is Pro or Enterprise edition and you want to understand how users are granted access to specific roles and accounts, see Access grants. To change the group a user is in, use the User management UI. How do user type, roles, and groups relate to each other? For users on the New Relic One user model, here's a table explaining how user type (basic vs full user), roles, and groups relate to each other: Full user Basic user Group Full users can be assigned to default groups (User and Admin) or custom groups. When basic users are added to a group, that group's role-related restrictions apply. A basic user's capabilities can be restricted in that way, but a basic user can never be granted more capabilities than they start with. For Standard edition, basic users can't be assigned to groups. For Pro and Enterprise edition, they can. Role For an explanation of the roles our default groups have, see Default groups. Custom groups can have either our default standard roles, or custom roles. A basic user's abilities aren't directly defined by a specific role. A basic user can best be described as having the All product admin role but without access to our more curated UI experiences (learn more about user type). When basic users are added to a group, that group's role-related restrictions apply, but a basic user can never be granted more capabilities than they start with. Roles and capabilities For users on the New Relic One user model, a \"role\" can be defined as \"a set of capabilities.\" A capability is defined as the ability to do a specific New Relic task, like 'Delete alert conditions' (learn more about capabilities). Roles are assigned to user groups. Our default groups Admin and User already have our standard roles (defined below) assigned. Organizations on Pro or Enterprise edition can also create custom roles. Standard (default) roles Roles are sets of capabilities. We have several \"standard roles,\" which are roles that satisfy some commonly needed use cases. To view roles and their associated capabilities, use the Organization and access UI. Important Note that some of our standard roles have hidden, non-exposed capabilities that are not available for selection when creating a custom role. The only standard roles that can be replicated with a custom role are Standard user and Read only; all others have some hidden capabilities. Our standard roles include: Standard roles Scope Description All product admin Account Provides admin-level access to observability platform features but not organization-level and user management features. In other words, this role includes all New Relic capabilities with the exception of managing users (Authentication domain manager role), managing organization/account-structure settings (Organization manager role), and managing billing (Billing user role). Note: the Standard user role is essentially the All product admin role minus observability feature configuration capabilities. Standard user Account Provides access to observability platform features, but lacks permissions for configuring those features (for example, ability to configure synthetic monitor secure credentials) and lacks organization-level and user management permissions. Note: the Standard user role is essentially the All product admin role without that role's ability to configure platform features. Billing user Account Provides ability to manage subscriptions and billing setup, and read-only access to the rest of the platform. For organizations with multiple accounts, billing is aggregated in the primary (first-created) account, which is why assigning this role to that primary account grants billing permissions for the entire organization. Organization manager Organization Provides the ability to manage organization settings, including organization structure, name, and preferences. Due to our recent switch to the New Relic One user model, this role currently has few abilities but more will be added over time. For how to grant this role, see Add user management capability. Organization read only Organization Provides the ability to view organization-level settings. For how to grant this role, see Add user management capability. Authentication domain manager Organization Provides ability to add and manage users, and configure authentication domains for users on the New Relic One user model. For how to grant this role, see Add user management capability. Authentication domain read only Organization Provides the ability to view users in your organization and view the configuration of authentication domains. For how to grant this role, see Add user management capability. Read only Account Provides read-only access to the New Relic platform (except for synthetic monitor secure credentials). Manage v1 users Account For New Relic organizations that existed before July 30 2020 and have users on our original user model, this role lets you manage those \"v1\" users. For more about how you'd assign roles to groups and create custom roles, see the user management tutorial. Capabilities A role, whether one of our standard roles or a custom role, is defined as a set of capabilities. To view roles and their associated capabilities, use the Organization and access UI. Important Some of our standard roles have hidden capabilities that aren't available for selection when creating a custom role. For details, see Standard roles. A view of the capabilities associated with the All product admin role. When creating a custom role, you select a custom set of capabilities. Note that the capabilities we expose may change over time: this screenshot was taken in April of 2021. For how to set up roles with custom capabilities, see the user management tutorial. Manage users To learn how to add users, assign them to groups, and create custom groups and roles, see Manage users. 2020 user model changes If you'd like to understand how our user model changed in 2020 and what the impacts of that change were, see User model changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.5906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Users</em>, roles, permissions (New Relic One <em>user</em> <em>model</em>)",
        "sections": "<em>Users</em>, roles, permissions (New Relic One <em>user</em> <em>model</em>)",
        "body": "Your New Relic users can be on one of two <em>user</em> models: this doc explains the New Relic One <em>user</em> <em>model</em>. Important If your New Relic <em>organization</em> was created before July 30 2020 and you haven&#x27;t gone through a <em>user</em> migration process, your users are likely on our <em>original</em> <em>user</em> <em>model</em>. For more"
      },
      "id": "603e88e328ccbcfcbaeba7a8"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-users-roles/parent-child-account-structure": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "21a79b6a8acf57efc16c3fae83e5167367b82452",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/rules-limits-alerts/",
      "published_at": "2021-10-24T19:44:57Z",
      "updated_at": "2021-08-26T05:49:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, mobile monitoring, synthetic monitoring, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 769.01276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " acknowledge an incident or close a violation. Limits If your organization has a <em>parent</em>&#x2F;<em>child</em> <em>account</em> <em>structure</em>, <em>child</em> accounts do not inherit a <em>parent</em> <em>account</em>&#x27;s alert policies: You must create policies separately for all <em>child</em> accounts. The following rules apply both to the New Relic One user"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, who have access to our more curated UI experiences. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 697.25916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Accounts</em>",
        "body": " original user model that have a <em>parent</em>&#x2F;<em>child</em> <em>account</em> <em>structure</em>, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "image": "https://docs.newrelic.com/static/49612c40721bfa27afa90fafcba0e95c/c1b63/login-multiple-accounts-found.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-users-roles/users-roles-original-user-model/",
      "sections": [
        "Users, roles, permissions (original user model)",
        "Requirements",
        "Updates about our new user model",
        "View and manage users in UI",
        "Tip",
        "Add a new user",
        "Important",
        "Manage user type (basic vs full) and full user upgrades",
        "Determine full user count",
        "Enable SAML SSO and/or SCIM",
        "View pending SAML SSO users",
        "Update account roles",
        "Delete a user",
        "Update the account Owner",
        "User types: basic user and full user",
        "Account roles",
        "Add-on roles",
        "View roles",
        "Assign a managed role",
        "Create a custom role",
        "Assign a custom role",
        "Edit or delete a custom role",
        "Account permissions",
        "Alert permissions",
        "APM permissions",
        "Browser permissions",
        "Infrastructure permissions",
        "Insights permissions",
        "Mobile permissions",
        "Synthetics permissions",
        "Workloads permissions"
      ],
      "published_at": "2021-10-24T23:52:40Z",
      "title": "Users, roles, permissions (original user model)",
      "updated_at": "2021-10-24T23:52:40Z",
      "type": "docs",
      "external_id": "95ae42f3474b43dec394245cfc3e23628449a1ed",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our original user model, an introduction to how the user model works, including user roles and permissions, and how to add and manage users. Requirements This doc and the surrounding section of docs shows you how to manage users on our original user model. If you were a New Relic customer before July 30 2020 and haven't migrated your users to the new model, your users are on our original user model (and not the New Relic One model). If you're an admin and want to see if you have users on the original model: If you can see users in the Users and roles UI, those users are on our original user model. Updates about our new user model In July of 2020, we released a new user model called the New Relic One user model, which offers many benefits in terms of how you manage your organization and users. At first this was only available to new sign-ups but over time we've been migrating more older customers to the new model. Some older customers are able to migrate their users on their own. We'll continue working on migrating users to the new model until the original model is fully deprecated. One impact of the new user model is that it's possible now for users to have multiple logins associated with the same email. For example, a user with access to multiple organizations (like a contractor) may have their user record updated to the new user model in one organization, resulting in them having their original login method and records and a New Relic One user model record. This may result in the user being logged in to New Relic and not being able to find an account they're looking for. For more on that, see Factors affecting access. If a user's email is associated with more than one login, they'll see a \"multiple accounts found\" note when logging in. View and manage users in UI If your New Relic account has users on our original user model, you can use the Users and roles UI. To access this: Click the account dropdown, click Account settings, and then click Users and roles. Some features in the UI are visible only to account Owners and Admins. Tip You can also use the New Relic REST API to obtain a list of everyone and their roles in your New Relic account. Here are some instructions and tips for adding and managing users via the UI: Add a new user Tip Owner or Admins To add a new user to your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. In the upper right corner, click New user. Enter the appropriate name and email address. Select their base role as either Admin, User, or Restricted. Select Add user. The new user will receive an email notification automatically from New Relic. Important New Relic recommends a maximum of 1,000 accounts per user. Additional accounts may result in limited access to some New Relic features. Manage user type (basic vs full) and full user upgrades Note that billing-related aspects of your count of full users only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. To update a user's type (basic user versus full user): Go to: account dropdown > Account settings > Users and roles > Users. Either select a user and edit their type or bulk update the type for multiple useres. To control how basic users upgrade to become full users, from the Users and roles UI you can select Access requests. You have two options: Automatic approval: With this option, basic users can automatically upgrade to be full users. This option allows your users to more easily troubleshoot problems. Require review: With this option, your admins get a notification when basic users request an upgrade and must upgrade them first. You can approve them either from the notification email or from the user's entry in the Users and roles UI. For more about user type, see User type. Determine full user count If you're on New Relic One pricing plan, your count of full users is a factor in your billing. To see your count of full users, click the account dropdown and then click View your usage. If you have a parent/child account structure (including a customer partnership), your count of full users may not match what you see when you go to Account settings > Users and roles. To examine users on a parent account's children accounts, go to a parent account's Account settings UI page, click on a child account, and go to that account's Users and roles UI page. Enable SAML SSO and/or SCIM For an introduction to using SAML SSO and/or SCIM provisioning, see Get started with SAML SSO or SCIM. View pending SAML SSO users New Relic accounts with SAML Single Sign On (SSO) may have a list of Pending users. These are individuals who have been added to the SAML-enabled account but have not yet confirmed. Update account roles Tip Owner or Admins To update a person's role and capabilities: Go to: account dropdown > Account settings > Users and roles > Users. Select the person's name. Under Roles and capabilities, select their base role as Admin, User, or Restricted. The account Owner must update the Owner role. Delete a user Tip Owner or Admins To remove a user from your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. Click on the name of the person you would like to update. Click Delete User. Tip You can also add, update, or delete users in bulk via CSV file. Update the account Owner A New Relic account can have only one Owner role at any time. You must be the current account Owner to change your role to someone who currently has an Admin role for the account. If the current Owner is unavailable, contact your account representative at New Relic, or get support at support.newrelic.com. You cannot delete or remove your assigned Owner role. However, if the account has one or more Admin role, you can change an Owner to an Admin. Go to: account dropdown > Account settings > Account > Users and roles. Above the Active users list, select Change owner. If an account has no Admins, this button won't be available. Select someone who currently has an Admin role for the account. Refresh the page for changes to take effect. Your previous Owner role automatically changes to an Admin role. To find out who is the current assigned Owner: Go to: account dropdown > Account settings > Account > Users and roles. View the Base role column to locate your account Owner. The Change owner button is only visible to the current account Owner. If the current Owner is unable to change the role (for example, that person no longer is with your organization), contact your account representative at New Relic, or get support at support.newrelic.com. User types: basic user and full user Important This section is for users on our original user model. If you're on our New Relic One user model, see our New Relic One user docs. Starting March 2021, we ended the preview period for basic users on our original user model. The preview period gave these basic users the same permissions as full users. For more on this, see our Explorers Hub post on user type changes. The user type (basic user or full user) determines what features a user has access to. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. Basic user. Details: These users have access to basic features like setting up reporting of data, running queries of data, making custom charts and dashboards, and setting up alerts. They do not have access to our more curated observability UI experiences (for more details on feature access, see Capabilities). Depending on access request settings, basic users can either upgrade themselves to be full users or request upgrade access from admins. Full user. Details: Full users have access to everything (dependent on role restrictions), which includes our curated observability UI experiences, such as APM, infrastructure monitoring, browser monitoring, mobile monitoring, and synthetic monitors. For details, see Capabilities. For organizations on New Relic One pricing: these users are billable. The Standard edition includes one free full user and up to five total. If a user in your organization is set as a basic user in one account and a full user in another, the user is considered a full user and has full user access on all accounts in that organization. For how to edit a user's type, see Manage users. Account roles A New Relic account can have only one Owner. To share an account with other users in your organization, create Admins, Users, or Restricted Users. Account role Description Owner The person who initially creates the New Relic account and receives all billing queries. The Owner has complete access to all of the account information. Admin Can add, edit, and delete users, and can enable or set up features. User Can use (and optionally set up) New Relic features. In general, Admins take responsibility for setting up features, and Users and Restricted Users can use them. Restricted User One or more individuals who can view (but not set up or change) any New Relic features. The Restricted User role is useful, for example, for demos. You can change your New Relic session settings so that Restricted User logins do not time out, and then set the user interface to Kiosk mode. Add-on roles With add-on roles, you can grant variable levels of access to all users in your account, across the entire platform of New Relic products. This allows you to tailor your account permissions levels to suit the needs of Users and Restricted Users within your account. Giving a User or Restricted User add-on manager access to a product grants them the equivalent of Admin capabilities within the product. They will continue to have User or Restricted User capabilities for all other New Relic products. For example, you could make a software engineer in your company a User in most products, but assign Admin-level access to APM. For another example, you might assign the Nerdpack manager role to a user, and that gives them the ability to subscribe and unsubscribe New Relic One applications to an account. There are two types of add-on roles: Add-on Manager roles are available to grant permissions on a per-product basis. Giving a User or Restricted User managed add-on access to a product grants them the equivalent of Admin capabilities within the product. Custom add-on roles can grant feature-specific permissions across different New Relic products. For example, a group of Users could have the ability to acknowledge incidents and close violations in New Relic Alerts, but not have the ability to modify your existing alert preferences. Individuals on a parent account automatically have the same level of access for all the child accounts of the parent account. Below are options for managing both managed add-on roles and custom add-on roles: View roles To view the list of individuals assigned to your account and their current roles: Go to account dropdown > Account settings > Users and roles. Assign a managed role Tip Owner and Admins Managed add-on roles are available by default for each New Relic product. Adding a managed role for a user grants them Admin-level permissions for the assigned product. They cannot be edited or deleted. To assign a managed add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles. From the list of users associated with your account, select their name. Under Add-on roles, select the type of manager role for the user. To understand which capabilities may be added, use the Capabilities preview chart. Features in the Capabilities preview chart may not exactly match what features are available for your subscription level. Tip You can also add, update, or delete users in bulk by using a CSV file. Create a custom role To create a custom add-on role for your account: Go to account dropdown > Account settings > Users and roles > Roles. Select New custom add-on role. Select the capabilities necessary for the new custom role, then Create role. Assign a custom role Tip Owners and Admins You must create a custom role before assigning it to a user. To assign a custom add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles > Users. From the list of users associated with your account, select their name ]. Under Add-on roles, select a custom role for the user. Click Update user. Edit or delete a custom role Tip Owners and Admins You cannot edit or delete New Relic's default roles. However, you can edit or delete custom add-on roles for your account: Go to account dropdown > Account settings > Users and roles > Roles. From the Add-on roles list, select the custom add-on role, then select Edit role or Delete role as appropriate. Account permissions Here is a summary of user permissions. Individuals on a parent account automatically have the same level of access for all the child accounts of that parent account. However, they won't receive email notifications for alerts or weekly reports for child accounts unless they are explicitly granted permission on those accounts. Function Owner Admin User Restricted Maintain billing information. Change the account Owner. Add, update, and delete account Admins, Users, and Restricted Users. When the account Owner and Admins add individuals to the account, New Relic automatically sends them an email message. Update users' job titles and roles from Account settings in the New Relic UI. Create, modify and delete child accounts from Account settings in the New Relic UI. Update your own account information (name, password change or password reset request, default account, email preferences, etc.) from User preferences in the New Relic UI. Change someone else's password. You cannot reset passwords for anyone else on the account, even if you are an Owner or Admin. Instead, follow standard procedures to request a password reset from New Relic. View the list of individuals on the account from (account dropdown) > Account settings > Account > Summary in the New Relic UI. Manage flexible data retention. Subscribe and unsubscribe applications to New Relic One Add, update, and delete Proactive Detection configurations. Alert permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Alerts. To allow a User or Restricted User to execute any of these functions in New Relic Alerts, assign an Alerts add-on manager role. Admin and manager capabilities for Alerts include: Create or name alert policies. Specify incident preferences. Disable or define alert conditions. Provide runbook instructions. Select product targets. Alter alert condition thresholds. Create, modify, or delete notification channels. APM permissions Here is a summary of Admin and Add-on manager capabilities with APM. To allow a User or Restricted User to execute any of these functions in APM, assign an APM add-on manager role. Admin and manager capabilities for APM include: Remove applications from the New Relic UI. Delete app traces and error traces. Browser permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Browser. To allow a User or Restricted User to execute any of these functions in New Relic Browser, assign a Browser add-on manager role. Admin and manager capabilities for Browser include: Add, rename, or delete applications. Manage whitelists. Manage domain conditions. Infrastructure permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Infrastructure. To allow a User or Restricted User to execute any of these functions in New Relic Infrastructure, assign an Infrastructure manager role. Admin and manager capabilities for Infrastructure include: Create alert conditions in New Relic Infrastructure, including conditions for host not reporting. Add or modify integrations. Insights permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Insights. To allow a User or Restricted User to execute any of these functions, assign an Insights manager role. These functions include: Create, view, modify, or delete Query API keys or Insert API keys. Tip New Relic Insights includes permission levels to share your Insights dashboards with others. Mobile permissions To give permission to delete a mobile app from New Relic, you can assign an Admin or Mobile manager role. Synthetics permissions Here's a summary of Admin and Add-on manager capabilities with New Relic Synthetics. To allow a User or Restricted User to execute any of these functions in New Relic Synthetics, assign a Synthetics add-on manager role. Admin and manager capabilities for Synthetics include: Create, edit, or delete monitors. Edit monitor scripts. Create, edit, or delete private locations. Create, edit, or delete monitor downtimes. Create, view, edit, or delete secure credentials. For more information, see User roles in Synthetics. Workloads permissions Here's a summary of Admin and Add-on manager capabilities with New Relic One workloads: Create, duplicate, modify, or delete workloads. Link dashboards to workloads and save filters. To allow a User or Restricted User to execute these functions, assign the workloads manager add-on role.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 533.81067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Update <em>account</em> roles",
        "body": " pricing plan, your count of full users is a factor in your billing. To see your count of full users, click the <em>account</em> dropdown and then click View your usage. If you have a <em>parent</em>&#x2F;<em>child</em> <em>account</em> <em>structure</em> (including a customer partnership), your count of full users may not match what you see when you go"
      },
      "id": "603e88b2e7b9d2a3f12a07d5"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-users-roles/user-migration": [
    {
      "sections": [
        "Introduction to New Relic One",
        "Tip",
        "Quickly understand context",
        "Query your data more easily",
        "Enhanced dashboards",
        "Build on New Relic One",
        "What’s next?"
      ],
      "title": "Introduction to New Relic One",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Get started"
      ],
      "external_id": "c9ba93c83a579625a4ba3364c6046f3c475cba3a",
      "image": "https://docs.newrelic.com/static/2bc08b6d64c16b39697bb43d8e66870e/c1b63/nrone20210722.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/get-started/introduction-new-relic-one/",
      "published_at": "2021-10-24T17:36:54Z",
      "updated_at": "2021-10-24T17:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One is the platform that gives you access to core platform capabilities like querying data and building charts, our more curated observability UI experiences features, and our alerting and Applied Intelligence tools. With New Relic One, you can see and act on all the data throughout your entire system. To access New Relic One: Go to one.newrelic.com. Or, if you report data to the EU data center go to one.eu.newrelic.com. Tip Learn more about New Relic One’s basic UI features. Quickly understand context We provide multiple ways to understand your system's dependencies, so you can easily see how everything fits together and troubleshoot problems. New Relic One gives you and your teams a connected view that cuts through complexity! If you want to... Use this Have an overall view of your system, and drill down to get performance details. Use the New Relic Explorer as the front door to New Relic One: observe, group, and filter the performance data from all the entities (that is, all applications, services, hosts, or containers) in your system. Gain extensive visibility into each entity in your solution, its alert status, and how the entities are connected. Use the New Relic Navigator to give you a high density overview of all your entities so you can detect any issues at a glance. And use the New Relic Lookout to spot entities recently experiencing behavior deviations. Provide context for your entities. Add tags to all your entities. Or create tags for teams and all the services they monitor. Use tags to illustrate relationships and contextual information for what you monitor. By thoughtfully tagging your entities, you can connect all the data your teams need to understand their increasingly complex and interdependent systems. See how each part of your system is connected. Service maps illustrate your upstream and downstream dependencies. Visualize the aggregated health and activity data from all you monitor. Group and monitor any entities together into functional team-focused, project-focused groupings, or any other attribute, with workloads. Fetch and analyze specific data. Get more context while you query with the query builder, which surfaces data definitions as you craft and edit queries. Create visuals that showcase your business needs at a glance. Tailor custom dashboards for your unique needs. Find a service or dashboard in a complex environment. Search by name across all accounts in the unified search, or filter the explorer by tags or text. View everything you’re monitoring in one place, like entities or dashboards across your organization. View a list of all the dependencies for a service. The dependencies view tab in an entity summary shows all the dependencies of the entity you’re viewing. Track activity as it moves across your distributed system. Distributed tracing helps you analyze your modern environment. Understand how everything is connected via API. The NerdGraph GraphiQL explorer manages all your entities, tags, and relationships. Query your data more easily On the Browse data menu on the top navigation menu you can easily access your basic telemetry data (metrics, events, logs, and traces). Wherever you go in the UI, Query your data is available. No matter your level of proficiency with our query language, you can create custom queries and charts: Browse your data in a query-less experience with our data explorer. Use your NRQL (our query language) expertise to build custom charts in the query builder. Run PromQL-style queries in the query builder. one.newrelic.com > Query your data: Build NRQL and PROMQL-like queries. Enhanced dashboards one.newrelic.com > Dashboards: Quickly create information dense custom views into the data that matters most to you with dashboards in New Relic One. New Relic One dashboards let you build better visualizations more easily, with more options to customize. Dashboard features include: Perform NRQL queries and create charts and dashboards everywhere in the platform using the query builder. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our agents, integrations, and APIs. Share dashboards or charts as a .pdf, or embed a chart in an external site. Tip If you previously used New Relic Insights to create dashboards, these are available as New Relic One dashboards. Build on New Relic One If custom charts and dashboards don't solve your current challenge, we give you a framework for building React JavaScript applications that: Live on New Relic One, alongside your other New Relic-monitored data. Feature highly tailored visualizations. Display data from any source you want, whether from a New Relic-monitored entity or data from any service or API. And you can use open source apps built by the community, and contribute your own open source apps. To learn more, see New Relic One applications. What’s next? To get started understanding how to get around in New Relic One: See what data you have available with the data explorer. Browse your monitored entities with the New Relic Explorer. Use our NerdGraph API to add tags to your data. Learn about dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.12848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction <em>to</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "sections": "Introduction <em>to</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em>",
        "body": "<em>New</em> <em>Relic</em> <em>One</em> is the platform that gives you access to core platform capabilities like querying data and building charts, our more curated observability UI experiences features, and our alerting and Applied Intelligence tools. With <em>New</em> <em>Relic</em> <em>One</em>, you can see and act on all the data throughout <em>your</em>"
      },
      "id": "603ec19164441f9e704e8896"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.78003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> <em>One</em>",
        "sections": "Preview access for <em>New</em> <em>Relic</em> <em>One</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> <em>One</em> platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING <em>YOUR</em> AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, who have access to our more curated UI experiences. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.25726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>One</em> pricing and billing ",
        "sections": "<em>New</em> <em>Relic</em> <em>One</em> pricing and billing",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em> pricing and billing",
        "body": " want. If all sources are removed, no data is sent to Incident Intelligence. Full <em>user</em> count billing details For accounts with <em>New</em> <em>Relic</em> <em>One</em> pricing, the monthly count of provisioned full <em>users</em> is <em>one</em> billing factor. To give an example: if you&#x27;re on the Pro pricing edition and <em>your</em> organization has"
      },
      "id": "6043f69a64441f7b26378eda"
    }
  ],
  "/docs/accounts/original-accounts-billing/original-users-roles/users-roles-original-user-model": [
    {
      "sections": [
        "Factors affecting access to features and data",
        "User permissions",
        "Account access",
        "Pricing plan or edition",
        "The entities being monitored",
        "Data retention"
      ],
      "title": "Factors affecting access to features and data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Account structure"
      ],
      "external_id": "98bf366604050b491ee35c8422414c70bda452b4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/",
      "published_at": "2021-10-24T23:49:09Z",
      "updated_at": "2021-10-24T23:49:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several factors that can affect your access to a New Relic feature, or New Relic data. User permissions User-related settings can impact what features or data you have access to. Potential impacts include: Your user type (basic user or full user). Your assigned roles. How your user roles and permissions work depends on which user model you're on: Original user model roles New Relic One user model roles If you think your permissions are preventing you from accessing something, talk to your New Relic administrators. Account access If you're having trouble finding an account, here are some causes and solutions: If your organization has multiple accounts and you have access to those accounts, you will see an account switcher at the top left of most New Relic UI pages that will let you switch between accounts. If you're logged into New Relic but can't find an account or its data, it may be for one of these reasons: You may need to be added to that account. How you do this will depend on your user model: Original use model | New Relic One user model. You may have more than one New Relic login associated with the same email address. If you think this may be the case, log out and log back in. When you input your email address, the login UI notes if you have multiple user records and gives you an option for verifying your email to see all available accounts when you log in. Other details about multiple logins: To see all your available login options the next time you log in, select Remember me when logging in. If one of your login options reads \"Original account\", that means it's a user record on our original user model. For more information, see this Explorers Hub post about multiple accounts. Related docs: User permission factors Account structure Login and password troubleshooting Delete accounts Pricing plan or edition We have two pricing plans available, and this can impact feature availability. Pricing plans: Our original product-based pricing plan: This plan separates our offerings by product. If you’re on this plan, access to some features may depend on the products you pay for. Our New Relic One pricing plan: This newer pricing plan gives more cross-platform access. The main factors affecting access are your edition and your user type. We also have several pricing editions: Standard, Pro, and Enterprise. Learn more about our pricing plans. The entities being monitored Some of our solutions enable functionality that isn’t available to all users, like: Additional UI components, and Data available for querying For example, enabling distributed tracing results in you seeing trace data in the UI and in having trace data available for querying. If you are missing data that you expect to see, see Missing data. Data retention Different types of New Relic data have different data retention periods. Once data has passed a given data retention point, it may be deleted or be aggregated for longer term storage. For details, see Data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 352.5393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>User</em> <em>permissions</em>",
        "body": " and <em>permissions</em> work depends on which <em>user</em> <em>model</em> you&#x27;re on: <em>Original</em> <em>user</em> <em>model</em> <em>roles</em> New Relic One <em>user</em> <em>model</em> <em>roles</em> If you think your <em>permissions</em> are preventing you from accessing something, talk to your New Relic administrators. Account access If you&#x27;re having trouble finding an account, here"
      },
      "id": "60bee5c064441f0505d543bb"
    },
    {
      "image": "https://docs.newrelic.com/static/565d4ebddf52a4592c594032696516b9/c1b63/New-Relic-capabilities-UI-screenshot.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/new-relic-one-user-model-understand-user-structure/",
      "sections": [
        "Users, roles, permissions (New Relic One user model)",
        "Important",
        "Overview",
        "User type: basic and full",
        "Compare full vs basic capabilities",
        "Tips on choosing user type",
        "Understand user-related billing",
        "Have questions about why you can't access something?",
        "Default groups: Admin and User",
        "How do user type, roles, and groups relate to each other?",
        "Roles and capabilities",
        "Standard (default) roles",
        "Capabilities",
        "Manage users",
        "2020 user model changes"
      ],
      "published_at": "2021-10-24T20:31:19Z",
      "title": "Users, roles, permissions (New Relic One user model)",
      "updated_at": "2021-10-24T20:31:18Z",
      "type": "docs",
      "external_id": "169383c2678ce973404db07195b2dee6eda9163d",
      "document_type": "page",
      "popularity": 1,
      "body": "Your New Relic users can be on one of two user models: this doc explains the New Relic One user model. Important If your New Relic organization was created before July 30 2020 and you haven't gone through a user migration process, your users are likely on our original user model. For more on this, see User model changes. Overview This doc will explain the structure of the New Relic One user model, including: User type (basic user versus full user) Default user groups, including Admin and User Roles and capabilities For how to add and manage users in the UI, see User management. User type: basic and full Important This section is for users on our New Relic One user model. If you're on our original user model, see Original users. A user's user type determines if they have access to our basic features (basic user) or can access all of our curated observability UI features (full user). The user type is something meant to be set long-term based on that user's expected New Relic responsibilities. Below are details on the two user types. Note that full users are billable only if you're on New Relic One pricing. Basic user. Details: These users are free and have access to a wide range of features, including setting up and configuring any New Relic data-reporting tool, running queries of your data, using our logs UI, making custom charts and dashboards, and setting up alerts. Unlike full users, they do not have access to our more curated observability UI experiences or some Applied Intelligence features (for a detailed comparison, see Capabilities). Basic users will see prompts to become a full user when they attempt to access unavailable features. For details, see Upgrade. Full user. Details: Full users have access to everything (depending on any role restrictions), including all our observability UI experiences, such as APM, infrastructure monitoring, browser monitoring, mobile monitoring, synthetic monitors, access to New Relic One apps, and more. For details, see Capabilities. Standard edition includes one free full user and up to five total full users. A full user can downgrade to a basic user twice in a 12-month period. To view and edit the user type of your users, use the User management UI. Learn more about basic user versus full user differences: Compare full vs basic capabilities Below is a table comparing what basic users and full users can do. A simple way to think about it is that full users have theoretical access (dependent on any chosen role restrictions) to all of our curated UI experiences, while basic users are restricted to fairly basic capabilities. Features Full user Basic user Observability UI experiences Application performance monitoring (APM) UI Infrastructure monitoring UI Digital Experience Monitoring UI, which includes: Browser monitoring UI Mobile monitoring UI Synthetic monitoring UI Synthetics checks Serverless monitoring UI Logs in context Distributed tracing Infinite Tracing (Pro and Enterprise edition) Assorted UI experiences, including: Kubernetes cluster explorer UI Key transaction UI Workloads UI Manage other users Access to New Relic One apps Can build apps but can't access other apps Applied Intelligence Automatic anomaly detection Correlated alerts and events Anomaly/alert analysis Root cause details in issues Basic platform capabilities Data ingest from any source (agents, integrations, APIs) Query your data Create custom charts and dashboards Alerts and notifications Our APIs, including NerdGraph (GraphQL) (with some restrictions) Query and chart log data Build New Relic One apps (but cannot access other apps) Encryption at rest Standard data retention Security and compliance Data management Note that the pricing edition (Standard, Pro, or Enterprise) will also affect what features you have access to. For organizations with New Relic One pricing, learn more about how full users impact billing. Tips on choosing user type A user's type (basic user vs full user) is meant to be a long-term assignment, based on the New Relic responsibilities that user is expected to perform. A full user can be downgraded to a basic user only twice in one year. Below are tips for why you'd choose full user versus basic user. Reasons to make someone a full user: They play a key role in the development, testing, deployment, and maintenance phases of the application development lifecycle. They break/fix code regularly; they are responsible for triaging workflows, troubleshooting, or managing users and roles for their team. They have DevOps practices (i.e. version control systems and implement CI/CD). They need to use New Relic's curated dashboards and experiences (not just the ability to create their own custom queries and charts); in other words, they need full access to our platform. They need to be able to manage users and/or billing. Reasons to make someone a basic user: They play a key role in the planning phase of the application development lifecycle. They use and configure New Relic agents, APIs, and integrations to send us data, and access, configure, and use alerts on such data (not necessarily responsible for triaging workflows, troubleshooting, or managing users and roles for their team). They want to see high-level analytics and business metrics for future planning (such as C-Suite executives). They do not need to use our curated experiences and dashboards, but would benefit from the ability to create their own custom queries and charts of data; in other words, they don't need full access to the platform. They don't manage users. For accounts on New Relic One pricing, learn more about user-related billing calculations. Understand user-related billing If you're on the New Relic One pricing plan, full users are billable, and there are restrictions around how often a full user can downgrade to a basic user. For details, see User count billing details. For how to query and alert on usage data, see Query usage data. Have questions about why you can't access something? See Factors affecting access. Default groups: Admin and User For users on our New Relic One user model, a \"group\" is what allows the grouping together and managing of multiple users at the same time. Your New Relic users are assigned to a group, and that group is granted access to specific roles on specific accounts. We have two default groups: User: This group allows a user to use and configure monitoring/analysis features but not perform account-related tasks like managing billing or users. It has access to the All product admin role, which gives access to our observability platform tools but not to the organization and user management capabilities governed by the Organization manager and Authentication manager roles. Admin: has full access and capabilities, including the organization-level admin abilities. This is the equivalent of having the All product admin, the Billing user, the Organization manager and the Authentication domain manager roles. These groups are added inside your default authentication domain, which includes the default settings of users a) being managed via New Relic and b) logging in via standard email and password. If you add other authentication domains (for SAML SSO and/or SCIM provisioning of users), you'd have new custom groups in those new domains to govern those users. Note that groups, whether default or custom, are not what limit a user's capabilities: it is the role that is assigned to that group (with any basic user restrictions on top of that). If your organization is Pro or Enterprise edition and you want to understand how users are granted access to specific roles and accounts, see Access grants. To change the group a user is in, use the User management UI. How do user type, roles, and groups relate to each other? For users on the New Relic One user model, here's a table explaining how user type (basic vs full user), roles, and groups relate to each other: Full user Basic user Group Full users can be assigned to default groups (User and Admin) or custom groups. When basic users are added to a group, that group's role-related restrictions apply. A basic user's capabilities can be restricted in that way, but a basic user can never be granted more capabilities than they start with. For Standard edition, basic users can't be assigned to groups. For Pro and Enterprise edition, they can. Role For an explanation of the roles our default groups have, see Default groups. Custom groups can have either our default standard roles, or custom roles. A basic user's abilities aren't directly defined by a specific role. A basic user can best be described as having the All product admin role but without access to our more curated UI experiences (learn more about user type). When basic users are added to a group, that group's role-related restrictions apply, but a basic user can never be granted more capabilities than they start with. Roles and capabilities For users on the New Relic One user model, a \"role\" can be defined as \"a set of capabilities.\" A capability is defined as the ability to do a specific New Relic task, like 'Delete alert conditions' (learn more about capabilities). Roles are assigned to user groups. Our default groups Admin and User already have our standard roles (defined below) assigned. Organizations on Pro or Enterprise edition can also create custom roles. Standard (default) roles Roles are sets of capabilities. We have several \"standard roles,\" which are roles that satisfy some commonly needed use cases. To view roles and their associated capabilities, use the Organization and access UI. Important Note that some of our standard roles have hidden, non-exposed capabilities that are not available for selection when creating a custom role. The only standard roles that can be replicated with a custom role are Standard user and Read only; all others have some hidden capabilities. Our standard roles include: Standard roles Scope Description All product admin Account Provides admin-level access to observability platform features but not organization-level and user management features. In other words, this role includes all New Relic capabilities with the exception of managing users (Authentication domain manager role), managing organization/account-structure settings (Organization manager role), and managing billing (Billing user role). Note: the Standard user role is essentially the All product admin role minus observability feature configuration capabilities. Standard user Account Provides access to observability platform features, but lacks permissions for configuring those features (for example, ability to configure synthetic monitor secure credentials) and lacks organization-level and user management permissions. Note: the Standard user role is essentially the All product admin role without that role's ability to configure platform features. Billing user Account Provides ability to manage subscriptions and billing setup, and read-only access to the rest of the platform. For organizations with multiple accounts, billing is aggregated in the primary (first-created) account, which is why assigning this role to that primary account grants billing permissions for the entire organization. Organization manager Organization Provides the ability to manage organization settings, including organization structure, name, and preferences. Due to our recent switch to the New Relic One user model, this role currently has few abilities but more will be added over time. For how to grant this role, see Add user management capability. Organization read only Organization Provides the ability to view organization-level settings. For how to grant this role, see Add user management capability. Authentication domain manager Organization Provides ability to add and manage users, and configure authentication domains for users on the New Relic One user model. For how to grant this role, see Add user management capability. Authentication domain read only Organization Provides the ability to view users in your organization and view the configuration of authentication domains. For how to grant this role, see Add user management capability. Read only Account Provides read-only access to the New Relic platform (except for synthetic monitor secure credentials). Manage v1 users Account For New Relic organizations that existed before July 30 2020 and have users on our original user model, this role lets you manage those \"v1\" users. For more about how you'd assign roles to groups and create custom roles, see the user management tutorial. Capabilities A role, whether one of our standard roles or a custom role, is defined as a set of capabilities. To view roles and their associated capabilities, use the Organization and access UI. Important Some of our standard roles have hidden capabilities that aren't available for selection when creating a custom role. For details, see Standard roles. A view of the capabilities associated with the All product admin role. When creating a custom role, you select a custom set of capabilities. Note that the capabilities we expose may change over time: this screenshot was taken in April of 2021. For how to set up roles with custom capabilities, see the user management tutorial. Manage users To learn how to add users, assign them to groups, and create custom groups and roles, see Manage users. 2020 user model changes If you'd like to understand how our user model changed in 2020 and what the impacts of that change were, see User model changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.4961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Users</em>, <em>roles</em>, <em>permissions</em> (New Relic One <em>user</em> <em>model</em>)",
        "sections": "<em>Users</em>, <em>roles</em>, <em>permissions</em> (New Relic One <em>user</em> <em>model</em>)",
        "body": " Account For New Relic organizations that existed before July 30 2020 and have <em>users</em> on our <em>original</em> <em>user</em> <em>model</em>, this <em>role</em> lets you manage those &quot;v1&quot; <em>users</em>. For more about how you&#x27;d assign <em>roles</em> to groups and create custom <em>roles</em>, see the <em>user</em> management tutorial. Capabilities A <em>role</em>, whether one"
      },
      "id": "603e88e328ccbcfcbaeba7a8"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/new-relic-account-structure/",
      "sections": [
        "Organization and account structure",
        "Important",
        "New Relic One user model",
        "How users access accounts",
        "Original user model"
      ],
      "published_at": "2021-10-24T23:49:09Z",
      "title": "Organization and account structure",
      "updated_at": "2021-10-24T23:49:08Z",
      "type": "docs",
      "external_id": "4f5a4cde293d0b599f489eff010f69c021ccb539",
      "document_type": "page",
      "popularity": 1,
      "body": "Depending on your user model, you have different options for adding and managing accounts and assigning users to them. We have two models: New Relic One user model Original user model Important Note that the user model is not directly related to our two pricing plans. New Relic One user model Important This section is about organizations on the New Relic One user model, not the original model. Learn more about the difference. At New Relic, an \"organization\" represents a New Relic customer. The organization contains everything relevant to a New Relic customer: its accounts, its users, and its data. A New Relic \"account\" can be considered a workspace. For example, you might have an account for a specific app, or a set of related hosts and services for a specific initiative or project, or you might have an account for a specific team. Each account has its own account ID, and that ID is used for some account-specific tasks, like making API calls. Our Standard edition allows for a single account per organization. Pro and Enterprise editions allow for multiple accounts per organization. Currently you can't add accounts to your organization on your own. To add accounts, talk to your New Relic account representative. How users access accounts In your organization, your New Relic users are granted access to specific accounts that are relevant to their duties and responsibilities. To manage users’ access to accounts, you create access grants, which assign a group of users to a specific role on a specific account. For example, you may assign a user group the ability to manage billing on some accounts with the Billing manager role, and assign some users as non-admin full users on some accounts, and assign some users as basic users on some accounts. Our user management system allows you to create the user access you need, whether that’s a relatively simple setup with just a few roles across a few accounts, or a complex one with many roles across many accounts. Learn more about user management. Note that some features, like dashboards and workloads, can display data from across different accounts in an organization. This means that if a user isn’t granted access to all relevant accounts, they may experience missing data. To learn more about access issues, see Factors affecting access. Original user model See Original user model structure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Original</em> <em>user</em> <em>model</em>",
        "body": "Depending on your <em>user</em> <em>model</em>, you have different options for adding and managing accounts and assigning <em>users</em> to them. We have two models: New Relic One <em>user</em> <em>model</em> <em>Original</em> <em>user</em> <em>model</em> Important Note that the <em>user</em> <em>model</em> is not directly related to our two pricing plans. New Relic One <em>user</em> <em>model</em>"
      },
      "id": "60bee5c028ccbc2413e667e4"
    }
  ],
  "/docs/accounts/original-accounts-billing/product-based-pricing/overview-data-retention-components": [
    {
      "sections": [
        "Event data retention (original pricing plan)",
        "Important",
        "Data retention UI",
        "Overview of event data retention",
        "Extend your event retention",
        "Insights Pro",
        "How number of events stored is calculated",
        "Insights Pro event overage example",
        "Disable/enable Transaction and Pageview event reporting",
        "Tip",
        "Flexible data retention",
        "How it works",
        "Manage retention via UI",
        "Glossary",
        "For more help"
      ],
      "title": "Event data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "76d1289aad7de08b355bb8c313f9e7a42a5779d8",
      "image": "https://docs.newrelic.com/static/e53a1e416eb6116545627d3ec880d08e/e9c9b/flex-2.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-data-retention/event-data-retention-original-pricing-plan/",
      "published_at": "2021-10-24T19:51:24Z",
      "updated_at": "2021-08-27T08:49:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original pricing plan, not our New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For organizations on New Relic One pricing, our various New Relic products report a wide range of event data. Different products have different data retention periods, and different ways to extend event data retention. You can customize the length of your event data retention through flexible event retention. Data retention UI For how to find the data retention UI, see Manage data. Overview of event data retention All New Relic product subscriptions come with a certain level of data retention that governs how long different types of data are retained. One type of data governed by data retention rules is event data. Event data is available in some UI charts and tables, and also available for querying via NRQL, our querying language. There are events reported from products by default, and there are custom events: each have their own retention rules, depending on the product and subscription level. Here are some examples of how different product subscriptions can affect event data retention: Free/Lite APM subscription: default-reported events available for 1 day. No custom events available. Pro APM subscription: default-reported events available for 8 days. Custom events available for 1 day (and able to be extended with Insight Pro). To see your subscriptions, go to the Account summary page. Extend your event retention Product Method APM, Browser, and Mobile Event data retention can be extended with a paid subscription to these products (see product data retention). To extend retention of both default-reported events and custom events further, you need an Insights Pro subscription. Infrastructure Event data retention can be extended with a paid Infrastructure subscription. See Infrastructure data retention rules. Synthetics Event data retention can be extended with a paid Synthetics subscription. See Synthetics data retention rules. Custom events Custom events reported by agent APIs or the Event API: Extension requires an Insights Pro subscription. Insights Pro Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. A paid Insights subscription is what governs the extension of event data retention for: Our APM, Browser, Mobile, and Serverless products Custom events that come from an agent API or from the Event API Important Note that having an Insights Pro subscription doesn't require use of the Insights UI (insights.newrelic.com) to query your data: there are other querying options available. To see the data retention governed by your Insights subscription: go to the usage UI and select Insights usage. With an Insights Pro subscription, you can use flexible retention to customize how your event data is retained. This lets you keep only the data you need, for as long as you need it. How number of events stored is calculated This is an explanation of how the number of stored events are calculated by default for an Insights Pro subscription. (Note that with flexible retention, you have more fine-grained control over the retention period.) The events stored is calculated based on 1) total events stored over time (calculated based on the events generated per week) and 2) the weeks of data retention available. This equation can be represented like this: events stored = (events generated per week) * (weeks of retention) Copy An Insights Pro subscription provides a given number of weeks of data retention as well as a given number of events over that retention period. For example: (200M transactions per week) * (4 weeks of retention) = 800M events stored in Insights (16M transactions per week) * (50 weeks of retention) = 800M events stored in Insights For Insights Pro subscriptions, data is purged based on retention window, not volume. It is deleted from the system once it's past the retention window. For example: If your Insights license is for 800 million events with a 4 week retention period, your data would start being purged after it is older than four weeks. Temporary spikes in data exceeding your subscription level will still be recorded, but consistent overage should be solved by upgrading your subscription level or decreasing data collected. For customers without an Insights Pro subscription, New Relic may throttle or downsample events to a limit of not more than than 4,000 events per host per minute. Insights Pro event overage example In this example, you have an Insights Pro subscription with a license for 800 million events over 4 weeks, a rate of 200 million events per week. You have APM Pro, Browser Pro, and Mobile Enterprise. A fifth week of data is added via your subscriptions, bumping you to a total of 1 billion events stored within your plan: If you are using 975 million events, you are not over your retention. If you are using 1.25 billion events, you are over your retention. Disable/enable Transaction and Pageview event reporting Tip Owners or Admins The Insights Data summary UI page is used to see the types of events being reported. You can also use this page to enable and disable the reporting of PageView and Transaction events. To view Data summary: Go to insights.newrelic.com > Manage data. Select the Summary tab. Note: if you disable PageView or Transaction event reporting, this can affect some New Relic UI elements. You may see some empty charts on some UI pages that rely on this data. Go to insights.newrelic.com > Manage data > Summary. From the Summary tab, select Configure data sources. Toggle the appropriate switch on or off, then save. Toggling Transaction on or off will cause reporting agents to restart themselves. For more about configuring event reporting, see Event data retention. Flexible data retention With an Insights Pro subscription, you get access to flexible retention, which lets you define how some types of event data are retained. This lets you keep only the event data you need, for as long as you need it. You can manage your flexible retention through the UI or through our GraphQL API. Requirements to use this feature: An Insights Pro subscription or equivalent trial. Applies only for events governed by an Insights Pro subscription. To use this feature, you must be an account Owner or data retention add-on manager for your account. How it works To understand how standard event data retention works, first read Event data retention. With flexible retention, you specify the data retention for applicable event namespaces across your accounts. This gives you per-event namespace control of your data. The retention that you specify for an event namespace will be shared by all the event types under that namespace. If some namespaces are not relevant to you, you can avoid collecting their event data entirely. Your retention value can’t be lower than the included retention or higher than the default retention. You can control data retention either in our UI or by API. Manage retention via UI You can control data retention either using our GraphQL API or in the UI. To do this with the UI, go to the data retention UI. Your retention changes take effect within 24 hours after updating. Glossary To understand the terms used with flexible retention, see the following: Term Description Event namespace An event's namespace corresponds to one or more event types that share a single data retention value. For more information, see Event namespaces (types). You can also use NerdGraph to get the list of customizable event namespaces. Retention value The number (in days) that specifies how long your event data is stored. Retention rule The event namespace and retention value pair that you specify to override the current retention. Licensed retention Retention period that’s determined in weeks by your Insights Pro subscription contract. Included retention Retention period for which your data is stored but not charged under the Insights Pro subscription. For details, see the data retention details for a specific product. Paid retention Retention period for which your data is stored and is charged under the Insights Pro subscription. By default, your licensed retention determines this value but Flexible retention lets you override it. Default retention Retention period that comes out of the box. This is based on the total of included retention plus licensed retention. For information on managing retention settings with APIs, see the Manage data retention documentation. For more help For details about the data retention of other products or integrations, see that specific documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.2075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Event <em>data</em> <em>retention</em> (<em>original</em> pricing plan)",
        "sections": "Event <em>data</em> <em>retention</em> (<em>original</em> pricing plan)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " <em>account</em>. How it works To understand how standard event <em>data</em> <em>retention</em> works, first read Event <em>data</em> <em>retention</em>. With flexible <em>retention</em>, you specify the <em>data</em> <em>retention</em> for applicable event namespaces across your <em>accounts</em>. This gives you per-event namespace control of your <em>data</em>. The <em>retention</em> that you"
      },
      "id": "6043f713e7b9d2ccee579a1d"
    },
    {
      "sections": [
        "Configure SAML with multiple accounts (original user model)",
        "Important",
        "Requirements",
        "Select custom entity IDs"
      ],
      "title": "Configure SAML with multiple accounts (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "SAML SSO (original users)"
      ],
      "external_id": "1b250bac5bec9013089261125b051fbe7b473c48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/saml-single-sign/configure-saml-multiple-accounts/",
      "published_at": "2021-10-24T19:09:50Z",
      "updated_at": "2021-10-22T22:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important These docs are for setting up SSO for users on our original user model. For SSO for users on New Relic One user model, see Authentication domains. In the SAML protocol, the entity ID uniquely identifies the service provider (New Relic) to your SAML provider. New Relic's default entity ID is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled account. When you configure multiple New Relic accounts with SAML, your SAML provider typically requires each account to have a unique entity ID. If you need to configure multiple accounts with separate SAML identities, use New Relic's custom entity ID feature. Requirements For requirements, including which New Relic users this feature applies to, see Requirements. Select custom entity IDs New Relic's custom entity ID feature allows you to enable a unique entity ID for each of your accounts. You can then configure SAML SSO for them as a distinct application with your SAML provider. This allows you to centrally control user authentication to each of your accounts independently. To select custom entity IDs: Follow standard procedures to set up SSO. In addition, from the Entity ID row on the Step 1. Configure page, select Use custom entity ID. Important You must use the same entity ID to configure the application's setting with your SAML provider. Some SAML providers require you to create a new application configuration when changing the entity ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.55688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "sections": "Configure SAML with multiple <em>accounts</em> (<em>original</em> user model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " is rpm.newrelic.com. This is sufficient if you have only a single SAML-enabled <em>account</em>. When you configure multiple New Relic <em>accounts</em> with SAML, your SAML provider typically requires each <em>account</em> to have a unique entity ID. If you need to configure multiple <em>accounts</em> with separate SAML identities"
      },
      "id": "6043f753e7b9d2156e5799d8"
    },
    {
      "sections": [
        "Bulk user actions (original user model)",
        "Important",
        "Update users in bulk",
        "Example CSV file",
        "Troubleshooting",
        "If you have a backup CSV file",
        "If no backup file exists"
      ],
      "title": "Bulk user actions (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original users and roles"
      ],
      "external_id": "ebfb52863fb5b57a14a2c298a2518c42f23c0908",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/roles-permissions/bulk-user-actions-add-delete-or-update-batches-users/",
      "published_at": "2021-10-24T22:50:46Z",
      "updated_at": "2021-08-09T00:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains how to manage users on our original user model. Not sure which model you're on? See Overview of user models. With the Bulk user actions feature, you can add, update, or delete multiple users at once. This can be helpful for: adding roles when multiple new employees start deleting roles when multiple employees leave giving multiple employees Admin roles Update users in bulk Some important rules and recommendations for making bulk user actions: You cannot make updates to your own role or an Owner role. You cannot edit an existing user's email address or name. You should avoid editing an existing user by deleting and re-adding them because this can have unintended consequences (for example, API keys associated with the original user will be lost). To add new user roles, update existing user roles, or delete user roles for users on the original user model: Go to: account dropdown > Account settings > Users and roles, and add /bulk_actions at the end of the URL. Example URL: https://account.newrelic.com/accounts/123456789/users/bulk_actions Copy Download a Backup CSV file. Downloading a backup file keeps a record of the users in your account prior to changes being made, and allows you to easily re-add any users that may be removed accidentally. Download a CSV of users or a CSV template. Each bulk action (add, update, or delete) will require its own CSV file. New Relic recommends saving your files with an account number, date, and the bulk action being performed. For example: account_123456789_delete_users_2018-06-29 Populate that sheet with only the users whose roles you'll be applying the chosen bulk action for. Remove users from the spreadsheet whose roles you do not want to change. Bulk action Fields Add Required fields: user email, name, type, base role Optional field: add-on role Update Required fields: user email (do not edit), name (do not edit), base role Optional field: add-on role Delete Required fields: only user email Example CSV file The following is an example downloaded CSV of users that lists four users on the New Relic account. In this example, we want to delete the user Alex Datanerd. All other users must be removed before uploading the CSV. Email Name Type Base role Add-on roles Last active User1 @Company.com Jane Datanerd full Owner 2/6/20 User2 @Company.com Jamie Datanerd full Admin 6/6/20 User3 @Company.com Alex Datanerd full User apm_admin, browser_admin 7/25/20 User4 @Company.com Pat Datanerd basic User alerts_admin, insights_admin, apm_admin 4/6/20 The other three users, whose roles will remain unchanged, are removed. The final CSV only shows Alex's name. This file would then be uploaded using the Delete users in CSV option in the UI. Email Name Type Base role Add-on roles Last active User3 @Company.com Alex Datanerd full User apm_admin, browser_admin In the UI, select a CSV action: Add, Update, or Delete the users listed within the CSV file. Upload the new CSV, and select Save changes. Troubleshooting If a user is removed or changed during your CSV file upload by mistake, you can add them back through another CSV file upload. Important Be aware that associated permissions may be lost when a user is deleted and re-added. For example, associated API keys will need to be re-added. If you have a backup CSV file If you have a backup CSV file saved: Open the backup CSV file. Populate the backup CSV file with the users whose roles will be modified. Select a CSV action for the new CSV file: add, update, or delete Upload the new CSV, and select Save changes. If no backup file exists If no backup CSV file has been previously downloaded: Download the CSV file template. Populate the spreadsheet with the information required for the user to be restored. Action Required fields Add User email, name, type, base role. Optional: Add-on role Update User email, name, type, base role. Optional: Add-on role Delete User email Select a CSV action for the new CSV file: Add, Update, or Delete. Upload the new CSV, and select Save changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.73083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bulk user actions (<em>original</em> user model)",
        "sections": "Bulk user actions (<em>original</em> user model)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": " to: <em>account</em> dropdown &gt; <em>Account</em> settings &gt; Users and roles, and add &#x2F;bulk_actions at the end of the URL. Example URL: https:&#x2F;&#x2F;<em>account</em>.newrelic.com&#x2F;<em>accounts</em>&#x2F;123456789&#x2F;users&#x2F;bulk_actions Copy Download a Backup CSV file. Downloading a backup file keeps a record of the users in your <em>account</em> prior to changes"
      },
      "id": "6043f605e7b9d264815799e1"
    }
  ],
  "/docs/accounts/original-accounts-billing/product-based-pricing/trial-lite-accounts-deprecated": [
    {
      "sections": [
        "Original product-based pricing and billing",
        "Important",
        "Overview of original pricing",
        "Annual vs monthly pricing plans",
        "APM and infrastructure: Compute-unit vs host-based pricing",
        "Compute unit pricing",
        "Host-based pricing",
        "Tip",
        "How is a \"host\" defined?",
        "Prorated billing",
        "Manage subscription and billing settings",
        "View summary information",
        "View or change current subscription",
        "View usage",
        "View or update billing information"
      ],
      "title": "Original product-based pricing and billing",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "92a9a2aaacf80af45767d6f8f15283c541b2bf08",
      "image": "https://docs.newrelic.com/static/a5a6fd548a3c62e03183f13e6be6688a/77a9e/Accounts_CU-calculation_0.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-pricing/product-based-pricing/",
      "published_at": "2021-10-24T19:44:57Z",
      "updated_at": "2021-09-14T14:48:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more on pricing and user-related changes, see Overview of changes. Overview of original pricing New Relic has two pricing plans: a newer one called New Relic One pricing, and our original pricing plan. Our original pricing plan was based on subscriptions to specific products, like APM, Mobile, and Infrastructure. If you are on this pricing plan, your users are likely on our original user model and use these original user docs. To understand more about the new pricing and user changes, see Overview of changes. For accounts on original pricing, this doc includes: Explanation of how our original pricing plan works How to manage subscription and billing settings Annual vs monthly pricing plans Here are the differences between billed-annually and billed-monthly plans: Pricing plans Details Annual (best price) New Relic charges your credit card each month for a year for a committed number of hosts or compute units. You can increase this amount at any time, and charges will adjust with the next monthly bill. Your account will automatically renew at the end of the year unless you change your subscription. Early termination, downgrade, or decrease in service: Unless your order form states otherwise, you will be charged at the level and quantity of service ordered until the end of the then-current term if you cancel or downgrade to a lower level of service or fewer hosts during your commitment year. Monthly (no commitment) New Relic charges your credit card each month for a specified number of hosts or compute units. The account Owner can change the credit card number. To edit billing settings, use the Billing UI. Adjustments to billing settings will take effect for the next billing period. Your account automatically renews each month unless you change your subscription. You can cancel service or downgrade to a lower level of service without penalty. APM and infrastructure: Compute-unit vs host-based pricing APM offers a choice between two pricing models: compute unit (CU) based pricing and host-based pricing. New Relic Infrastructure offers only CU-based pricing. This section shows how both options are calculated, and explains what \"host\" means in these pricing contexts: Compute unit pricing CU-based pricing is available for these New Relic products: APM (choice of either CU-based pricing or host-based pricing) Infrastructure: only CU-based pricing With CU-based pricing, your monthly price is determined by the size of the host (computing power and memory) running New Relic and the number of hours it connects to New Relic during the month. If a host is connected to New Relic at any time during an hour, that hour counts towards the CU calculation. Each host is counted separately for each New Relic account the host reports data to. For example, if you have a parent account with two children accounts, each running applications on the same host for 3,000 CUs in a given month, the usage for the parent account will be 6,000 CUs. For APM, CU-based pricing is the best choice if you have many cloud-based dynamic computing resources. For this reason, CU-based pricing is sometimes referred to as cloud pricing. CUs are calculated as follows: The maximum size of a given host (CPUs + GB RAM) is capped at 16. Examples: If a host has 2 CPU cores, 2GB RAM, and connects to New Relic for one hour (or less than one hour), it consumes 4 CUs. If a host has 2 CPU cores, 2GB RAM, and connects to New Relic for an entire month (750 hours used as standard month size), it consumes 3,000 CUs. You can purchase blocks of CUs to be consumed on a monthly basis. The total number of CUs purchased monthly is calculated by adding up the estimated CU consumption for all hosts for the month. There is no month-to-month rollover of unused CUs. Also, New Relic does not charge by JVMs, containers (such as Docker or Cloud Foundry), or application instances--it charges by the hosts running those containers or application instances. Price points vary, depending on the New Relic product and subscription level. You can view CU-based account usage from the New Relic UI. Host-based pricing Tip Pricing for your APM account can be either CU-based or host-based. New Relic Infrastructure uses only CU-based pricing. With host-based pricing, New Relic charges based on the number of equivalent hosts used in a month. One equivalent host is defined as: a host connected to New Relic for 750 hours (750 hours used as standard month size). If a host is connected to New Relic at any time during an hour, that hour counts towards the host calculation. These hours can be divided across multiple hosts. For example, you might have three hosts that are each connected to New Relic for 250 hours during one month: these hours would add up to equal one equivalent host. Each host is counted separately for each New Relic account the host reports data to. For example, if you have a parent account with two child accounts, each running applications on the same single host for 750 hours in a given month, the usage for the parent account will be 2 equivalent hosts. Once connected to New Relic, hosts are distinguished by their unique hostnames. A host is connected to New Relic when the language agent is active and is deployed on the host. New Relic does not charge by containers (such as Docker or Cloud Foundry), JVMs, or application instances; it charges by the hosts running those containers or application instances. New Relic APM gives you a choice between host-based pricing and CU-based pricing. Host-based pricing is ideal if you have mainly static environments, consisting of hosts you manage in your own data center. For specifics on pricing amounts, see the New Relic APM pricing page. How is a \"host\" defined? To understand how New Relic computes both host-based pricing and CU-based pricing, it's important to understand how the word host is used. A host can be one of the following: A physical machine is a hardware-based device with dedicated physical resources, including memory, processing, and storage. Each machine has its own OS which applications run on. A virtual machine (VM) is the software implementation of a physical machine that executes programs like a physical machine. One or more virtual machines can run on a physical machine. Each virtual machine has its own OS and allocated virtual machine resources such as RAM and CPU. A cloud instance is a type of virtual machine that is run in the public cloud. In this context, virtual machines and cloud instances are different from Java Virtual Machines (JVMs) and containers. For New Relic's pricing calculation purposes, a month is defined as 750 hours. Prorated billing If you upgrade your subscription partway through your billing period, you will be subject to a prorated charge for the higher level of service over the remainder of your billing period. This will be invoiced or charged to your credit card when the upgrade is submitted. You will be notified about this charge as part of the subscription change process. If you have questions, contact your New Relic account representative. If you need to report billing issues, contact New Relic's Billing Department. Manage subscription and billing settings Important Note that as of July 30 2020, we have a newer pricing plan. To learn more, see Overview of pricing. The account Owner can perform many subscription self-service functions directly from the user interface: From one.newrelic.com, select the account dropdown. Select your choice of self-service options. When making subscription changes, be sure to save any changes, agree to New Relic's Terms of Service and Supplemental Payment Terms as appropriate, and select Pay now. Optional: If you downgrade your subscription, complete New Relic's survey. Here is a summary of the available options from your account dropdown in the New Relic user interface: View summary information To view summary information about your subscription, go to the billing UI. View or change current subscription To adjust your subscription settings, use the Billing UI. If you need more help, contact your New Relic account representative, or contact New Relic's Billing Department. View usage To view your usage, use the usage UI. View or update billing information To view or update your New Relic account's billing information, see the billing UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.85193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "sections": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em> <em>and</em> <em>billing</em>",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": ". For <em>accounts</em> on <em>original</em> <em>pricing</em>, this doc includes: Explanation of how our <em>original</em> <em>pricing</em> plan works How to manage subscription and <em>billing</em> settings Annual vs monthly <em>pricing</em> plans Here are the differences between billed-annually and billed-monthly plans: <em>Pricing</em> plans Details Annual (best <em>price</em>) New Relic"
      },
      "id": "6043f753e7b9d212085799da"
    },
    {
      "sections": [
        "Set session timeouts",
        "Original pricing plan",
        "Requirements",
        "Overview",
        "Features",
        "Tip",
        "Select the session timeout value",
        "Select SAML SSO browser re-authentication",
        "Redirect after SAML timeout"
      ],
      "title": "Set session timeouts",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "a61d4c61f52ee18be0763a9cd526634d9d2f50f5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/set-session-timeouts/",
      "published_at": "2021-10-24T22:52:07Z",
      "updated_at": "2021-09-14T10:20:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. New Relic's session configuration feature allows you to set limits on idle time before your users' browser sessions automatically expire. Requirements If you're on the New Relic One user model, see Session settings. Overview Session configuration allows you to set limits on idle time before your users' browser sessions automatically expire. A message appears three minutes before the system logs them out. Users then need to sign back in to continue. For accounts configured with SAML Single Sign On (SSO), an additional option is available to set how often the users' browser sessions are re-authenticated. Users and Restricted Users can view the time period for automatic timeout, but they cannot change it. To view the timeout value: Go to account dropdown > Account settings > Authentication > Session configuration. Features Tip Owner or Admins The session configuration options provide an additional level of security to ensure that unattended browsers will automatically time out. Session values are automatically stored in the session cookie. Additional features include: Feature Notes Easy setup Admins use the slide bar in New Relic's user interface to select predefined time periods. Default is two weeks. Separate options available by role Admins can choose for Restricted User sessions to never time out even if they select a session timeout setting. This is useful, for example, when you use a Restricted User login for demos. Automatic inheritance for child accounts By default, child accounts inherit the same session configuration as their parent account. Most restrictive by default If users have multiple accounts, the most restrictive setting applies, regardless of which account the user currently is using. Integration with SAML SSO logout URL If the account's SAML SSO configuration does not include a logout URL, New Relic includes a link from Session configuration for the Owner to set it up. If the Admin is not also the Owner, a message about the SAML SSO logout URL requirement appears. Additional re-authentication setting for SAML SSO In addition to the session timeout option, Admins can select the time (15 minutes to 2 weeks, or never) for how often a SAML-authenticated browser session must be re-authenticated. Select the session timeout value The process to select the session timeout value is the same for both SAML and non-SAML configurations. For additional SAML configuration options, see SAML SSO browser reauthentication. To select a predefined period for session timeouts with SAML SSO accounts, the account Owner must have previously identified the logout URL in the SAML SSO configuration settings. If this has not been set up, the account Admin can view the session timeout slide bar but not change it. If the Admin is also the account Owner, the Session configuration includes a link to go directly to New Relic's SAML SSO Configuration and identify the logout URL. For more information, see Setting up SSO. To select a predefined period for session timeouts for users on our original user model: Go to: account dropdown > Account settings > Authentication > Session configuration. Use the slide bar to select a time period for idle sessions to expire and log out automatically. Optional: Select the checkbox option if you do not want restricted users' browser sessions to expire. Select Save my changes. Changes take effect immediately. Select SAML SSO browser re-authentication To select a predefined period for SAML SSO-authenticated browser sessions to be re-authenticated: Go to: account dropdown > Account settings > Authentication > Session configuration. Use the SAML re-authentication time slide bar to select a time period for New Relic to check the browser session. Select Save my changes. Redirect after SAML timeout If you are logged out due to a session idle timeout on an account configured for SAML, you will be sent to the New Relic login page. Because your account is configured for SAML, you do not have a direct New Relic login. To be redirected to your SAML provider for authentication: Enter your email address in the Email field. Leave the Password field blank. Click the Sign In button. You will then be redirected to your SAML provider. Once reauthorized, you will then be returned to the New Relic website.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.68587,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Original</em> <em>pricing</em> plan",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": "<em>Original</em> <em>pricing</em> plan This doc is for users on our <em>original</em> user model. New Relic&#x27;s session configuration feature allows you to set limits on idle time before your users&#x27; browser sessions automatically expire. Requirements If you&#x27;re on the New Relic One user model, see Session settings. Overview"
      },
      "id": "603e8914196a678f45a83de3"
    },
    {
      "sections": [
        "Overview of changes to pricing and user model",
        "Overview of how pricing plan and user model relate",
        "Pricing plans explained",
        "Determine pricing plan",
        "Convert to new pricing",
        "User models explained",
        "Requirements for new user model",
        "Determine which user model you're on",
        "Feature impacts of user model",
        "Transition to new models"
      ],
      "title": "Overview of changes to pricing and user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "b19d61b5a0c65ca352e2ce0e260e2b53391b94fc",
      "image": "https://docs.newrelic.com/static/1461470cc1ef0be91120c84d76a7ccdd/c1b63/new-relic-one-pricing-plan-billing-ui.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-product-based-pricing/overview-changes-pricing-user-model/",
      "published_at": "2021-10-24T19:44:08Z",
      "updated_at": "2021-09-13T20:48:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In 2020, New Relic released both a newer pricing plan and a newer user model. Keep reading to learn about: How the pricing plan and the user model relate to each other Pricing plans explained User models explained How to switch to the new models Overview of how pricing plan and user model relate In 2020, we released both a new, improved pricing plan and a new, improved user model. These models represent the future. All new sign-ups are on these new models and eventually all organizations will be on these models. But currently, our customers from before July 2020 may have one of several combinations of these as they either switch to the new pricing or migrate their users to the new user model. This table shows how pricing and user model relate to each other: Pricing plan factors User model factors Original pricing If your organization was created before July 30 2020, you remain on our original pricing plan until you transition to New Relic One pricing. For original pricing accounts, you have users on the original user model unless you've migrated your users to the new model. Note that if you've added users via automated user management, they're on the new model. This means it's possible to have some users on both models. New Relic One pricing An organization is on the New Relic One pricing plan: If it was created on or after July 30 2020, or If it's an older organization but has switched to New Relic One pricing. If your organization was created on or after July 30 2020, your users are on the New Relic One user model. If you have an older organization, you have users on the original user model unless you've migrated your users to the new model. Pricing plans explained New Relic organizations are on one of two pricing plans: New Relic One pricing: Our new pricing plan is simpler. It bills on a) which edition you're on (Standard, Pro, or Enterprise), b) the GBs of data ingested, and c) how many billable full users you have. All organizations created on or after July 30 2020 are on this pricing plan, as are older organizations that have switched to this pricing. There are two versions of this pricing plan. Our original product-based pricing plan: this is based on subscriptions to specific products (for example, APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer pricing plan: in that case, their users remain on our original user model. Determine pricing plan To determine which pricing plan you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see billing information about data ingested and the number of billable users, you’re on the new pricing plan. If you're on New Relic One pricing, you'll see a billing UI like this. Convert to new pricing Some organizations are able to switch to new pricing. Learn more about switching your pricing plan. User models explained In this context, the term \"user model\" refers to the structure of a New Relic user record and how it interacts with the broader New Relic organization that it's in. Our two user models are: New Relic One user model: this newer, improved user model has these major differences from the original user model: All your accounts and users are contained under a top-level organization. This gives an organization stronger control over managing users and what they can access. One impact of this is that users who work with multiple New Relic organizations may have an email address associated with multiple logins. Users on this model have a different system for managing permissions and account access. Using access grants, you assign users access to specific roles on specific accounts. Original user model: some aspects of this older model that are different from our newer model: There wasn't as much organization-level control over users. For example, a New Relic user had the ability to access multiple accounts they'd been granted access to using a single login. Users on the original user model have a different user management system. To learn more about benefits of the new model, see our blog post about user model changes and an explanation of the new account structure. For impacts and limitations, see Feature impacts. Requirements for new user model Here's a synopsis of the factors governing what organizations use the new model: All New Relic organizations that signed up after July 30 2020 have users on this model, and also have the new pricing plan. Some older New Relic organizations have had their users migrated to the new model by New Relic or by using the user migration procedure. Note that switching to the new pricing plan is independent from migrating users. Partner accounts (resellers, managed service providers), and organizations using the partnership account structure, cannot yet migrate their users to the new model. Determine which user model you're on To determine what user model you're on, from the account dropdown select User preferences. If you see the UI below, you're on the New Relic One user model. If you see a different UI with more content displayed, you're on the original user model (see original user docs). To determine if you can manage users on the New Relic One user model, see Manage users. The user model is independent of your pricing plan. For how user model relates to pricing, see the Pricing and user model table. Feature impacts of user model The new user model offers many benefits. Here are some feature impacts of being on the New Relic One user model that may be not obvious to users accustomed to our previous user model: More separation of organizations/accounts: If you have an email address associated with multiple New Relic accounts, this may mean you need to log out and log back in. Learn more about account access. Adding accounts: Pro and Enterprise edition can have more than one account in their organization. Currently users in these organizations cannot, on their own, add accounts. They must get help from their New Relic account representative. To learn about adding users to accounts, see Manage users. Alerts-related impacts: Policy actions: For alert policies and conditions, some UI locations display the user that made the last modification. For users on the new model, it will display their user ID and not their user name. For example, a policy might read Last modified Sep 7, '20 4:26 pm by user 1234567 instead of by John Doe. If you have user management permissions, you can determine what user this is by going to the User management UI. Notifications: Users on the new model won’t show up as an option when choosing users to receive alert notifications. The result of this is that these users will not get New Relic mobile app push notifications. As a workaround, you can instead use their email address as the notification channel. You can't use the REST API to generate a list of users (only original model users). Instead you'd use the user management UI. Changing account name: These users cannot change the name of their organization after it has been created. Transition to new models Some New Relic organizations on the old models are able to transition to the new models. To learn more about this, see Transition to new models.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.18797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of changes to <em>pricing</em> <em>and</em> user model",
        "sections": "Overview of changes to <em>pricing</em> <em>and</em> user model",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": ". There are two versions of this <em>pricing</em> plan. Our <em>original</em> <em>product</em>-<em>based</em> <em>pricing</em> plan: this is <em>based</em> on subscriptions to specific products (for example, APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer <em>pricing</em> plan: in that case, their users remain"
      },
      "id": "603e97fa28ccbcb7c2eba754"
    }
  ],
  "/docs/accounts/original-accounts-billing/product-pricing/product-based-pricing": [
    {
      "sections": [
        "Set session timeouts",
        "Original pricing plan",
        "Requirements",
        "Overview",
        "Features",
        "Tip",
        "Select the session timeout value",
        "Select SAML SSO browser re-authentication",
        "Redirect after SAML timeout"
      ],
      "title": "Set session timeouts",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "a61d4c61f52ee18be0763a9cd526634d9d2f50f5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/account-maintenance/set-session-timeouts/",
      "published_at": "2021-10-24T22:52:07Z",
      "updated_at": "2021-09-14T10:20:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Original pricing plan This doc is for users on our original user model. New Relic's session configuration feature allows you to set limits on idle time before your users' browser sessions automatically expire. Requirements If you're on the New Relic One user model, see Session settings. Overview Session configuration allows you to set limits on idle time before your users' browser sessions automatically expire. A message appears three minutes before the system logs them out. Users then need to sign back in to continue. For accounts configured with SAML Single Sign On (SSO), an additional option is available to set how often the users' browser sessions are re-authenticated. Users and Restricted Users can view the time period for automatic timeout, but they cannot change it. To view the timeout value: Go to account dropdown > Account settings > Authentication > Session configuration. Features Tip Owner or Admins The session configuration options provide an additional level of security to ensure that unattended browsers will automatically time out. Session values are automatically stored in the session cookie. Additional features include: Feature Notes Easy setup Admins use the slide bar in New Relic's user interface to select predefined time periods. Default is two weeks. Separate options available by role Admins can choose for Restricted User sessions to never time out even if they select a session timeout setting. This is useful, for example, when you use a Restricted User login for demos. Automatic inheritance for child accounts By default, child accounts inherit the same session configuration as their parent account. Most restrictive by default If users have multiple accounts, the most restrictive setting applies, regardless of which account the user currently is using. Integration with SAML SSO logout URL If the account's SAML SSO configuration does not include a logout URL, New Relic includes a link from Session configuration for the Owner to set it up. If the Admin is not also the Owner, a message about the SAML SSO logout URL requirement appears. Additional re-authentication setting for SAML SSO In addition to the session timeout option, Admins can select the time (15 minutes to 2 weeks, or never) for how often a SAML-authenticated browser session must be re-authenticated. Select the session timeout value The process to select the session timeout value is the same for both SAML and non-SAML configurations. For additional SAML configuration options, see SAML SSO browser reauthentication. To select a predefined period for session timeouts with SAML SSO accounts, the account Owner must have previously identified the logout URL in the SAML SSO configuration settings. If this has not been set up, the account Admin can view the session timeout slide bar but not change it. If the Admin is also the account Owner, the Session configuration includes a link to go directly to New Relic's SAML SSO Configuration and identify the logout URL. For more information, see Setting up SSO. To select a predefined period for session timeouts for users on our original user model: Go to: account dropdown > Account settings > Authentication > Session configuration. Use the slide bar to select a time period for idle sessions to expire and log out automatically. Optional: Select the checkbox option if you do not want restricted users' browser sessions to expire. Select Save my changes. Changes take effect immediately. Select SAML SSO browser re-authentication To select a predefined period for SAML SSO-authenticated browser sessions to be re-authenticated: Go to: account dropdown > Account settings > Authentication > Session configuration. Use the SAML re-authentication time slide bar to select a time period for New Relic to check the browser session. Select Save my changes. Redirect after SAML timeout If you are logged out due to a session idle timeout on an account configured for SAML, you will be sent to the New Relic login page. Because your account is configured for SAML, you do not have a direct New Relic login. To be redirected to your SAML provider for authentication: Enter your email address in the Email field. Leave the Password field blank. Click the Sign In button. You will then be redirected to your SAML provider. Once reauthorized, you will then be returned to the New Relic website.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.68585,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Original</em> <em>pricing</em> plan",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": "<em>Original</em> <em>pricing</em> plan This doc is for users on our <em>original</em> user model. New Relic&#x27;s session configuration feature allows you to set limits on idle time before your users&#x27; browser sessions automatically expire. Requirements If you&#x27;re on the New Relic One user model, see Session settings. Overview"
      },
      "id": "603e8914196a678f45a83de3"
    },
    {
      "sections": [
        "Overview of changes to pricing and user model",
        "Overview of how pricing plan and user model relate",
        "Pricing plans explained",
        "Determine pricing plan",
        "Convert to new pricing",
        "User models explained",
        "Requirements for new user model",
        "Determine which user model you're on",
        "Feature impacts of user model",
        "Transition to new models"
      ],
      "title": "Overview of changes to pricing and user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "b19d61b5a0c65ca352e2ce0e260e2b53391b94fc",
      "image": "https://docs.newrelic.com/static/1461470cc1ef0be91120c84d76a7ccdd/c1b63/new-relic-one-pricing-plan-billing-ui.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-product-based-pricing/overview-changes-pricing-user-model/",
      "published_at": "2021-10-24T19:44:08Z",
      "updated_at": "2021-09-13T20:48:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In 2020, New Relic released both a newer pricing plan and a newer user model. Keep reading to learn about: How the pricing plan and the user model relate to each other Pricing plans explained User models explained How to switch to the new models Overview of how pricing plan and user model relate In 2020, we released both a new, improved pricing plan and a new, improved user model. These models represent the future. All new sign-ups are on these new models and eventually all organizations will be on these models. But currently, our customers from before July 2020 may have one of several combinations of these as they either switch to the new pricing or migrate their users to the new user model. This table shows how pricing and user model relate to each other: Pricing plan factors User model factors Original pricing If your organization was created before July 30 2020, you remain on our original pricing plan until you transition to New Relic One pricing. For original pricing accounts, you have users on the original user model unless you've migrated your users to the new model. Note that if you've added users via automated user management, they're on the new model. This means it's possible to have some users on both models. New Relic One pricing An organization is on the New Relic One pricing plan: If it was created on or after July 30 2020, or If it's an older organization but has switched to New Relic One pricing. If your organization was created on or after July 30 2020, your users are on the New Relic One user model. If you have an older organization, you have users on the original user model unless you've migrated your users to the new model. Pricing plans explained New Relic organizations are on one of two pricing plans: New Relic One pricing: Our new pricing plan is simpler. It bills on a) which edition you're on (Standard, Pro, or Enterprise), b) the GBs of data ingested, and c) how many billable full users you have. All organizations created on or after July 30 2020 are on this pricing plan, as are older organizations that have switched to this pricing. There are two versions of this pricing plan. Our original product-based pricing plan: this is based on subscriptions to specific products (for example, APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer pricing plan: in that case, their users remain on our original user model. Determine pricing plan To determine which pricing plan you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see billing information about data ingested and the number of billable users, you’re on the new pricing plan. If you're on New Relic One pricing, you'll see a billing UI like this. Convert to new pricing Some organizations are able to switch to new pricing. Learn more about switching your pricing plan. User models explained In this context, the term \"user model\" refers to the structure of a New Relic user record and how it interacts with the broader New Relic organization that it's in. Our two user models are: New Relic One user model: this newer, improved user model has these major differences from the original user model: All your accounts and users are contained under a top-level organization. This gives an organization stronger control over managing users and what they can access. One impact of this is that users who work with multiple New Relic organizations may have an email address associated with multiple logins. Users on this model have a different system for managing permissions and account access. Using access grants, you assign users access to specific roles on specific accounts. Original user model: some aspects of this older model that are different from our newer model: There wasn't as much organization-level control over users. For example, a New Relic user had the ability to access multiple accounts they'd been granted access to using a single login. Users on the original user model have a different user management system. To learn more about benefits of the new model, see our blog post about user model changes and an explanation of the new account structure. For impacts and limitations, see Feature impacts. Requirements for new user model Here's a synopsis of the factors governing what organizations use the new model: All New Relic organizations that signed up after July 30 2020 have users on this model, and also have the new pricing plan. Some older New Relic organizations have had their users migrated to the new model by New Relic or by using the user migration procedure. Note that switching to the new pricing plan is independent from migrating users. Partner accounts (resellers, managed service providers), and organizations using the partnership account structure, cannot yet migrate their users to the new model. Determine which user model you're on To determine what user model you're on, from the account dropdown select User preferences. If you see the UI below, you're on the New Relic One user model. If you see a different UI with more content displayed, you're on the original user model (see original user docs). To determine if you can manage users on the New Relic One user model, see Manage users. The user model is independent of your pricing plan. For how user model relates to pricing, see the Pricing and user model table. Feature impacts of user model The new user model offers many benefits. Here are some feature impacts of being on the New Relic One user model that may be not obvious to users accustomed to our previous user model: More separation of organizations/accounts: If you have an email address associated with multiple New Relic accounts, this may mean you need to log out and log back in. Learn more about account access. Adding accounts: Pro and Enterprise edition can have more than one account in their organization. Currently users in these organizations cannot, on their own, add accounts. They must get help from their New Relic account representative. To learn about adding users to accounts, see Manage users. Alerts-related impacts: Policy actions: For alert policies and conditions, some UI locations display the user that made the last modification. For users on the new model, it will display their user ID and not their user name. For example, a policy might read Last modified Sep 7, '20 4:26 pm by user 1234567 instead of by John Doe. If you have user management permissions, you can determine what user this is by going to the User management UI. Notifications: Users on the new model won’t show up as an option when choosing users to receive alert notifications. The result of this is that these users will not get New Relic mobile app push notifications. As a workaround, you can instead use their email address as the notification channel. You can't use the REST API to generate a list of users (only original model users). Instead you'd use the user management UI. Changing account name: These users cannot change the name of their organization after it has been created. Transition to new models Some New Relic organizations on the old models are able to transition to the new models. To learn more about this, see Transition to new models.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.18796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of changes to <em>pricing</em> <em>and</em> user model",
        "sections": "Overview of changes to <em>pricing</em> <em>and</em> user model",
        "tags": "<em>Original</em> <em>product</em>-<em>based</em> <em>pricing</em>",
        "body": ". There are two versions of this <em>pricing</em> plan. Our <em>original</em> <em>product</em>-<em>based</em> <em>pricing</em> plan: this is <em>based</em> on subscriptions to specific products (for example, APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer <em>pricing</em> plan: in that case, their users remain"
      },
      "id": "603e97fa28ccbcb7c2eba754"
    },
    {
      "sections": [
        "Overview of data retention (original pricing plan)",
        "Important",
        "Limits on editing and deleting data",
        "Product and API data retention policies",
        "APM",
        "APM data retention policies",
        "Legacy APM data retention policies",
        "Browser",
        "Infrastructure",
        "Tip",
        "Infrastructure downsampling and data retention",
        "Integration compute unit event limits",
        "Insights",
        "Logs",
        "Logs in context data retention",
        "Mobile",
        "Mobile data retention policies",
        "Standard Mobile (legacy) data retention policies",
        "Plugins",
        "Plugins data retention",
        "Legacy Plugins data retention",
        "Synthetics",
        "Synthetics data retention policies",
        "Metric API",
        "Trace API",
        "Data components",
        "Event data: reported by most products",
        "Metric timeslice data: reported by APM, Browser, and Mobile",
        "Aggregate metric timeslice data: reported by APM, Browser, and Mobile",
        "Key metrics: reported by APM, Browser, and Mobile",
        "Trace data: reported by APM, Browser, and Mobile"
      ],
      "title": "Overview of data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "22d5ab9f4d623ead28ee7bb82c118d91804dee22",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-based-pricing/overview-data-retention-components/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-09-14T14:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on our New Relic One pricing plan, see Manage your data. Not sure which you're on? See Overview of pricing plans. If you're on the original product-based pricing plan, you retain your existing subscriptions and data retention values. You manage these existing retention settings from the Data management hub in New Relic One. To manage your retention settings, go to the Data management UI. You'll see your existing retention settings. Adjust retention values by clicking Edit retention. New Relic stores different types of data for different periods of time. The retention period for a type of data will vary depending on the product, the subscription level, and the feature. Limits on editing and deleting data Once telemetry data (events, metrics, logs, traces) is reported to New Relic and available for querying, that data cannot be edited or deleted. This is a purposeful design decision that optimizes New Relic's speed and performance. Data will expire after its data retention ends. If you sent unwanted data or sensitive data to New Relic that must be removed, contact your account representative at New Relic, or get support at support.newrelic.com. Product and API data retention policies Select a New Relic product to see details about its data retention: APM Specific retention policies apply to each APM subscription level, including Lite, Essentials, Pro, and Enterprise. This includes metric timeslice data, key metrics, trace data, and event data. In addition to retention limits, your data is subject to aggregation (averaging) after certain elapsed time periods. For more information, see the aggregate metric data description. APM data retention policies For accounts on our original product-based pricing, APM data retention policies depend on your APM product subscription level. Component Lite Essentials Pro Metric timeslice data 24 hours 3 days 90 days Key metrics none forever forever Distributed tracing and logs in context none none 8 days Other trace data * 1 day 3 days 7 days Event data * * 1 day 3 days 8 days * If you view a transaction trace in the New Relic UI, New Relic stores that trace data for up to one year. * * Learn about how to extend the retention of event data. Legacy APM data retention policies Component Standard Startup Small Business Enterprise Metric timeslice data 7 days 14 days 30 days 90 days Key metrics none none none forever Trace data 7 days 7 days 7 days 7 days Event data none 8 days 8 days 8 days Browser For accounts on our original product-based pricing, Browser data is stored depending on your subscription level: Component Lite Pro Metric data 24 hours 90 days Key metrics 24 hours forever Trace data 7 days 7 days Event data * 1 day 8 days SPA data Unavailable 8 days * Learn about how to extend the retention of event data. Infrastructure For accounts on our original product-based pricing, Infrastructure data retention policies depend on your Infrastructure subscription level and your New Relic Infrastructure compute units pricing model. Data retention rules apply the same whether that data is displayed in the UI or queried. Tip Infrastructure data retention is not governed by your Insights subscription. Infrastructure downsampling and data retention Types of data are stored depending on your subscription level: Component Essentials Pro Infrastructure data 3 months 13 months Host count Host count will stop reflecting a host whose agent is no longer reporting after three minutes. However, host data will be available, subject to other retention criteria. 3 minutes 3 minutes Inventory attributes removed Inventory attributes for a host are retained for 24 hours after the agent stops reporting. 24 hours 24 hours Integration data Not available with Essentials Limit of 2275 integration events per compute unit per month In addition, Infrastructure downsamples your data on the fly, as it's generated. All Infrastructure metric data types (including On-Host Integrations metrics) will display different granularity depending on the age of the data and the size of the time window. The following table illustrates when different downsampled buckets will be used, both in the Infrastructure UI and for queries: Bucket Size Used For Time Windows Covering... Data Retained For... Raw (5, 10 or 15 second) 0 to 59 minutes 7 days 1 minute 60 minutes to 6 hours 30 days 10 minutes 6 hours to 3 days Full account retention period 1 hour 3 days to 14 days Full account retention period 3 hours 14+ days Full account retention period Integration compute unit event limits The 2275 limit on integration events per compute unit per month is a limit on total Infrastructure integration events. It's not a limit of 2275 for each integration's events. Additional details and clarifications about this limit: This limit applies to all events from all integrations (cloud integrations and on-host integrations). The events are all handled the same. Default data received by the Infrastructure agent does not count against the 2275 event per compute unit limit. If you exceed your limit, we do not enforce this limit. If you exceed your limit, we'll review pricing options with you to ensure you get the most cost-effective pricing for your organization's integrations. Insights For accounts on our original product-based pricing, an Insights subscription extends your event data retention. An Insights Pro subscription allows you to customize the length of your event data retention. Logs For accounts on our original product-based pricing, log data can be retained for up to 30 days by New Relic. Shorter retention periods of 8 or 15 days are also available. Logs in context data retention New Relic Logs logs in context data retention policy is based on your current APM product subscription level. For more information, see APM data retention. Mobile For accounts on our original product-based pricing, Mobile data retention policies depend on your New Relic Mobile product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and event data. For information about your subscription-related data usage, see Mobile subscription usage. Mobile data retention policies Component Lite Enterprise Overview page data 24 hours 90 days Crash data and stack traces 24 hours 90 days HTTP requests (except errors) as metric data Unavailable 90 days HTTP request errors as metric data Unavailable 3 days Interaction traces Unavailable 90 days Custom events * Unavailable 1 day Mobile events * 1 day 8 days MobileBreadcrumb events * Unavailable 3 days MobileCrash events * 1 day 90 days MobileHandledException events * Unavailable 3 days MobileJSError events (React Native beta) * Unavailable 3 days MobileRequest events * Unavailable 3 days MobileRequestError events * Unavailable 3 days MobileSession events * 1 day 90 days * Learn how to extend retention of event data. Standard Mobile (legacy) data retention policies Unless otherwise noted, Insights event data is unavailable for Standard subscriptions. Component Standard Overview page data 7 days Crash data and stack traces 7 days HTTP requests (except errors) as metric data 7 days HTTP request errors as metric data 3 days Interaction traces Unavailable MobileCrash events 8 days MobileSession events 8 days Plugins The retention period for historical data depends on the product and subscription level. The following data retention periods exist for New Relic Plugins. Important Plugins is not supported with accounts that host data in the EU region data center. Plugins data retention Component Lite Essentials Pro Enterprise Metric data 24 hours 3 days 90 days 90 days Legacy Plugins data retention Component Standard Startup Small Business Metric data 7 days 14 days 30 days Synthetics For accounts on our original product-based pricing, Synthetics data retention policies depend on your Synthetics product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and Insights events. Tip Synthetics events do not count against an Insights Pro subscription. Your current subscription level appears in the right column of the Account summary page: Go to synthetics.newrelic.com > (account dropdown) > Account settings > Account > Summary. Synthetics data retention policies Component Lite Pro Synthetics monitor data 2 weeks 13 months Event data 2 weeks 13 months Also see the data retention details for APIs, including: Metric API All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Trace API See Trace API general requirements and limits. Data components For accounts on our original product-based pricing, the section below provides an explanation of some types of data components governed by the data retention rules of specific products: Event data: reported by most products See Event data retention for information on the event data type. Metric timeslice data: reported by APM, Browser, and Mobile Metric timeslice data is a specific type of data that is used for most metric charts and reports in APM, mobile, and browser. Important Note that metric timeslice data differs from other metric data types. All metric timeslice data is aggregated, but New Relic deals with fresh data and old data in different ways. Fresh data has specific policies applied to the data to keep granular views of performance as aggregate metrics. As data ages and becomes less useful in a granular state, we summarize that data and only keep key metrics. Aggregate metric timeslice data: reported by APM, Browser, and Mobile Aggregate metric timeslice data summarizes calls to specific methods in your application: how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on your subscription level. Subscription Level Aggregate retention Enterprise Aggregates (averages) to 1-hour periods after 8 days. After 90 days, the permanent metric data continues to be stored in 1-hour periods. This means you cannot obtain data granularity of less than 1 hour after 8 days, and only a subset of metrics are available after 90 days. Pro After 8 days Essentials After 3 days. Legacy Small Business, Startup, and Standard After 3 days. Lite After 2 hours. We retain your most recent data in one-minute increments. We also aggregate permanent metric data to day-size increments after 90 days. When looking at older data in small time windows, you may notice that charts show less detail. As data ages, it is aggregated into larger segments. Key metrics: reported by APM, Browser, and Mobile New Relic retains certain \"key\" metric timeslice data aggregations forever for Enterprise and Pro customers, for any number of applications. New Relic aggregates permanent key metric data to hour-size increments after 90 days. Product Key metrics APM Apdex, for app server Throughput and page views Response time, plus breakdown into tiers or categories on your app's main Overview chart Page load time, plus breakdown into segments Error rate CPU usage Memory usage Browser Apdex, for browser Browser page load time Throughput total. After 90 days, there is no breakout by browser type, and only the combined average value is available for the time range requested. Mobile Crash rate: For iOS and for Android Network throughput Network response time Network error rates Interaction traces Trace data: reported by APM, Browser, and Mobile Depending on the product, New Relic retains different types of trace data: Product Trace data APM Types of trace data: Transaction traces Distributed tracing Slow query samples Error details See APM data retention details. Browser Types of trace data: Session traces Browser traces JavaScript errors* See Browser data retention details. Mobile Types of trace data: App crash stack traces Interaction traces See Mobile data retention details. * JavaScript errors in the stack trace UI are saved as trace data. JS errors are also saved as events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.07422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of data retention (<em>original</em> <em>pricing</em> plan)",
        "sections": "Overview of data retention (<em>original</em> <em>pricing</em> plan)",
        "tags": "<em>Original</em> <em>accounts</em> <em>and</em> <em>billing</em>",
        "body": "Important This doc is for <em>accounts</em> on our <em>original</em> <em>Product</em>-<em>based</em> <em>pricing</em>. If you&#x27;re on our New Relic One <em>pricing</em> plan, see Manage your data. Not sure which you&#x27;re on? See Overview of <em>pricing</em> plans. If you&#x27;re on the <em>original</em> <em>product</em>-<em>based</em> <em>pricing</em> plan, you retain your existing subscriptions and data"
      },
      "id": "6043f75364441f6967378ec6"
    }
  ],
  "/docs/agile-handbook/appendices/backlog-review": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/project-scoping-cheatsheet/",
      "sections": [
        "Project scoping cheatsheet",
        "What is this",
        "Dates",
        "Scope",
        "Resources",
        "People",
        "Before meeting ends",
        "For more help"
      ],
      "published_at": "2021-10-24T23:19:07Z",
      "title": "Project scoping cheatsheet",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "57d5de7b1eeb1ae1800d8186e1302ff677d1e278",
      "document_type": "page",
      "popularity": 1,
      "body": "We use this cheatsheet to help us scope projects in a consistent way. What is this What's the elevator pitch for the feature? What's the user value? What are the most exciting tasks/stories we can tell for this feature? Who is the primary audience? Any docs deliverables you already have in mind? Dates What are you working on right now? When does this \"release\" (private beta, public beta, GA, etc.)? If private beta, how many customers and do they need docs? Scope Who will write first drafts? Do you need any templates? Does this need a liaison? Resources Is there a test account/is this in staging? Are there mockups or other resources? Do you have any other collateral to share? People Who is the primary reviewer (and backups)? Who is product manager? Who is lead dev? Who is the designer? Who is program manager? Who is the researcher? Are we doing any user research? Who is the PMM? Who is the support point person? Before meeting ends Who is writing? When is it due? Do we need tickets? Who is following up with who? ← Appendix: Ticket best practices Appendix: Backlog review → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 703.114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " is the support point person? Before meeting ends Who is writing? When is it due? Do we need tickets? Who is following up with who? ← Appendix: Ticket best practices Appendix: <em>Backlog</em> <em>review</em> → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dfa28ccbc90b0002530"
    },
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Sprint workflow",
      "updated_at": "2021-10-17T11:49:20Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it maes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. ← Planning poker Liaisonships → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.27402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Jira boards: <em>Backlog</em> and future sprints",
        "body": " ticket if necessary. Move the ticket to the next sprint. If you do: <em>Review</em> the ticket&#x27;s action items and description to make sure they&#x27;re still current. Clear out the ticket points. Move the ticket back to the <em>backlog</em>. If you do: Update the action items and description to make sure they&#x27;re still"
      },
      "id": "616c0dc0196a67e6583c8164"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/meetings-and-ceremonies/",
      "sections": [
        "Meetings and ceremonies",
        "Tip",
        "Sprint planning",
        "Backlog grooming",
        "Retro",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Meetings and ceremonies",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "873983fa778f17f1a92871ed4ad7673b333d4acc",
      "document_type": "page",
      "popularity": 1,
      "body": "Monday Tuesday Wednesday Thursday Friday Week 1 Sprint retro (every other sprint) Backlog grooming (end of sprint) Sprint planning (start of new sprint) Team meeting Meeting-free day Week 2 Team meeting Meeting-free day We break our work into two-week sprints. The new sprint starts on a Tuesday with sprint planning, where we commit to a set of stories that we're confident we can complete by the end of the sprint. Near the end of the sprint, we prepare for the next sprint with backlog grooming. The sprint closes with a retro where we discuss what went right and what went wrong, and then we kick off a new cycle. Each squad does their own backlog grooming and sprint planning, and manages their sprint backlog independently. We do retros together so we can talk through issues that affect both squads and share expertise and ideas. Tip Why do we end sprints on Mondays and start Tuesdays? This funny schedule makes things easier to work across timezones. If we ended sprints on Fridays, our Barcelona-based writers would need to do retros and grooming on Friday evening, and who wants that? Sprint planning On the first Tuesday of a new sprint, we commit to a series of stories until we have filled our capacity for the sprint. This is the largest meeting in the sprint---about 60 to 90 minutes. Before the sprint planning meeting, the scrum master for each squad calculates their point budget. Then, during the meeting: We select the highest priority item in the backlog. The person who nominated the story introduces it, and the team asks questions until everyone feels ready to vote. The team plays planning poker. Everyone secretly chooses a card, then we reveal them at the same time: If everyone picks the same card, that's the point value and we move on. If there's an even split between two cards, we choose the larger and move on. If it's mixed, the highest and lowest voters briefly explain their votes. Then we vote again. Once we're sure we can fit the story in, we subtract its story points from the sprint's points budget. We repeat the above steps until we've used up our points budget. We generally avoid pre-assigning people to stories during sprint planning. Instead, we pick up the next story or peer edit in the To Do column as stories are completed. Backlog grooming The day before the sprint starts, we do two rounds of backlog grooming. The purpose of backlog grooming is to prioritize work for sprint planning, and identify stories that need to be fixed before sprint planning to ensure scope is clear and planning runs smoothly. The first round of backlog grooming is by squad, where the members and manager of the squad get together and work through the grooming checklist. Then we do a second round of grooming with the managers and scrum masters to look at the sprint backlog for both squads and ensure nothing is or has fallen through the cracks. In the grooming, we: Each writer brings their personal \"top five\" tickets. The manager works with writers to prioritize those into a single, stack-ranked list for the team. We talk through stories and ensure they look ready for sprint planning (essentially, do they fit the Checklist for story readiness?). After grooming, the scrum master sends out a list of \"homework\" for stories that need improving. Retro Every other sprint, we conduct a 60 minute retrospective meeting, where we discuss: How do we feel about the sprint? What went well? Where can we improve? Anything we should start or stop doing? The goal of the retro is to improve the way we work together. That could be related to the sprint process, to how we collaborate with SMEs, to peer edits, and so on. ← Agile roles Planning poker → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.934586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Backlog</em> grooming",
        "body": "Monday Tuesday Wednesday Thursday Friday Week 1 Sprint retro (every other sprint) <em>Backlog</em> grooming (end of sprint) Sprint planning (start of new sprint) Team meeting Meeting-free day Week 2 Team meeting Meeting-free day We break our work into two-week sprints. The new sprint starts on a Tuesday"
      },
      "id": "616c0dfa196a679fd43c9791"
    }
  ],
  "/docs/agile-handbook/appendices/project-scoping-cheatsheet": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/backlog-review/",
      "sections": [
        "Backlog review",
        "Goals of backlog review",
        "Who reviews the backlog",
        "What to look for in a backlog review",
        "For more help"
      ],
      "published_at": "2021-10-24T23:19:07Z",
      "title": "Backlog review",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "6c1e047df7f4a43eaa253c0183625df4785455de",
      "document_type": "page",
      "popularity": 1,
      "body": "About once a quarter, the Docs team reviews our entire backlog in Jira and GitHub. This ensures that we actually know what's in there, and that we're bubbling up the right stories from the backlog into upcoming sprints. Goals of backlog review Fix easy issues: If you can fix something quickly, just do it. Find broken windows: What are the small (or big!) broken windows lurking in our backlog? What should we consider bubbling up into a future sprint? Identify gaps in the backlog: Discover important issues that are not at all covered in the backlog. Clear out cruft: Find duplicate issues, things we'll never fix, or issues that are just no longer relevant. Check labels and fields: Is the ticket assigned a correct priority score? Do we have the correct labels for other fields? Who reviews the backlog Sometimes we'll involve the whole team in a backlog review; other times, just the managers will handle the review. The most useful time to involve the whole team is when we're onboarding a new writer: Talking through issues promotes a lot of knowledge-sharing about the product, docs, stakeholders, and how to write a good ticket. Otherwise, we'll usually assign the review to the managers. This saves time, and it also tends to make it easier to close out issues (since our managers are also our product owners). If we don't involve the whole team, we'll prepare a spreadsheet of which issues we closed and list writers who might care so they can weigh in on whether the issue should have stayed open. What to look for in a backlog review When you review an issue, perform the following checks: Check if the issue can be closed: It's already resolved, or you can't reproduce the issue It's old, and we have little evidence anyone cares It's not important enough to fix If the issue doesn't have a clear goal/task, try to discover one (but don't feel obligated to rewrite the whole issue). Add context and update as-needed. Review fields and labels and ensure they're accurate. Add a label to the issue once you're done with your review. Use this format: year_month_backlog_review. For example: 2021_october_backlog_review. This helps keep track of which issues you've reviewed on this round of backlog review It's also a useful nudge for future round of review: If an issue has more than one or two review labels, you should probably close it. ← Appendix: Project scoping cheatsheet For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1839.5094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". For example: 2021_october_backlog_review. This helps keep track of which issues you&#x27;ve reviewed on this round of backlog review It&#x27;s also a useful nudge for future round of review: If an issue has more than one or two review labels, you should probably close it. ← Appendix: <em>Project</em> <em>scoping</em> <em>cheatsheet</em> For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dfa64441f2cb01d33a5"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/ticket-best-practices/",
      "sections": [
        "Ticket best practices: How to write a sprint-ready Jira",
        "Tip",
        "Why do we use Jira?",
        "What work needs a ticket?",
        "Keeping tickets up-to-date",
        "Add Jira context to PRs and commits",
        "Checklist for writing a good ticket",
        "For more help"
      ],
      "published_at": "2021-10-24T19:34:40Z",
      "title": "Ticket best practices: How to write a sprint-ready Jira",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "2109a54437970761f71a3940f189b7f10aef0bc1",
      "document_type": "page",
      "popularity": 1,
      "body": "Jira, a project management tool made by Atlassian, is how we manage our projects and understand the work we are doing and have done. Jira tickets may seem at first to be simple to-do lists that we use to know what things to do for a project. But they are much more important than that. Tip For Relics: Use the docs.newrelic.com/jira template when you create a ticket! It'll automatically pre-fill your ticket with a template that helps create a good ticket. Why do we use Jira? We create tickets to record work-to-be done for a project, scope new work, share information for any writer to complete a story, forecast our output and to estimate project timelines, and have a record of work done. In other words, Jira has a role at every point in a project: Before a project Scoping, syncing on expectations, giving tech writer instructions During a project Keeps team and management posted about project; allows for hand-offs and swarming After a project Understand what work we did, and helps researching on future projects What work needs a ticket? There aren't hard-and-fast rules about what work needs a Jira ticket and what doesn't. A good shorthand is that any project that takes more than a couple hours is a good candidate for a ticket. However, the goal of creating tickets is not to track writer time in detail. So many kinds of work (meetings, ongoing minor liaison tasks, hero work) generally do not need to go into Jira. Keeping tickets up-to-date In general, you should write your tickets as though you might win the lottery tomorrow (a principle known as lottery factor or bus factor). In practice, someone should be able to read your ticket and figure out within about ten minutes what the status is and what the next step is. This makes it easy for us to take vacations, pass work off to another docs writer if needed, and escalate blockers. These things help with lottery factor: Update the Action Item list as you complete tasks and add or remove scope. When you move a ticket to Blocked, include a note explaining the change in status. When you close a ticket, give a summary of the work done and any relevant thoughts you have on the work and potential related issues. Update the Timeline, People, and Resources sections as the project evolves. Add important conversations (emails or Slack convos from SMEs) that give important context for the work done. (Note: It's a good idea to ask permission before doing this, because some people might not like their informal words placed in a public place.) Add Jira context to PRs and commits When you edit the site, include the Jira issue key (DOC-1234, for example) in your pull request title and/or commit summary. That makes it easier for other writers to connect the dots later if we're trying to figure out why something changed or who knows about a particular subject. Checklist for writing a good ticket Helpful title A ticket name should be easy to find via search, understand the work at a glance, mention the product or feature, and describe the goal or issue. Examples of good ticket titles: Browser API: Update custom attribute-related docs or Distributed tracing: Add more detail about CAT relationship. Action items An action item list describing the work to be done What docs are affected Links to pull requests, Google Docs drafts, etc. How substantial the writing work is in each doc How the resulting work should be structured Whether or not a peer edit is needed Anyone who should be notified when a doc is published Proper sizing Story is scoped to the smallest reasonable size Can be completed within a 2 week sprint Delivers incremental value Dates Publication date or due date Dates for other key events (betas, limited releases, etc.) Resources and people People, including last names and roles List of related or affected docs Other internal and external resources Related issues Labels and fields Jira tickets: Component, Product Group, and Priority GitHub issues: from_, pg_, and content labels ← Managing the GitHub boards Appendix: Project scoping cheatsheet → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1463.4131,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ": Component, Product Group, and Priority GitHub issues: from_, pg_, and content labels ← Managing the GitHub boards Appendix: <em>Project</em> <em>scoping</em> <em>cheatsheet</em> → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d9628ccbc919400346e"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/liaisonships/",
      "sections": [
        "Liaisonships",
        "Liaison responsibilities: Manage project flow",
        "Liaison responsibilities: Build expertise",
        "Liaison responsibilities: Define content strategy (oh, and do the writing)",
        "For more help"
      ],
      "published_at": "2021-10-24T19:34:40Z",
      "title": "Liaisonships",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "bf8ec36541058fe18f8395db811344baf7f23e22",
      "document_type": "page",
      "popularity": 1,
      "body": "For large projects, we'll typically assign a particular tech writer to that project as a \"liaison.\" The liaison’s job is to ensure that we get complete, consistent, and timely docs. Not every project gets a liaisonship! For smaller projects, we'll encourage teams to edit the docs directly, and then have the hero review their changes. And a smallish project may not need a full liaison—a single ticket might be enough to manage the work. To figure out which type of support is best for a given project, one of the managers on the team will have a scoping conversation with a subject matter expert. Here's a few reasons a project might get a dedicated liaison: Project is complex and would benefit from intimate familiarity with the feature. Project requires significant information architecture work. Project will produce enough docs that consistency across those docs will be hard to achieve without a centralized editor. Project SMEs would benefit from a consistent \"face\" of the tech writing team. However, a liaison is not the only author on a project. Liaisons should structure their work to maximize swarming and knowledge sharing. Liaison responsibilities: Manage project flow Activity Who? Notes Learn new thing exists Team Ideally the Hero or a Tech Docs manager gets notified directly by a PM about a new project. But sometimes we'll find out about something unexpectedly. If you're not sure whether we have a writer working on something, ask a manager on the team and they'll reach out to the subject matter expert to scope it. Have a scoping meeting Tech Docs manager The manager is responsible for tracking the general state of major projects across the company, and is generally the first point of contact for new projects. When a large new project comes up, the manager will do a pre-scope meeting with the requestor. (Appendix: Project scoping cheatsheet has a list of common questions for this pre-scope meeting.) That conversation helps figure out timeline, complexity, key docs considerations, and which writer will be a good fit as liaison. Assign a liaison Tech Docs manager Once we know we need a liaison, a manager on our team will figure out who to assign. Some of the factors we use to decide who to assign include bandwidth, familiarity with the product or feature, career goals and writing strengths, and simple interest in the topic. Keep track of project dates Liaison The managers on the team keep track of upcoming projects that don't have a liaison assigned. Once a writer gets involved, that liaison keeps track of the specifics of dates: Betas, limited releases, GAs, fast-follows, and so on. Your manager's always here to help out if you're getting blocked or dates are shifting too rapidly to plan properly. Validate the docs plan with the project team Liaison The liaison works with their stakeholders to define the information architecture and deliverables. Create tickets Liaison Since the liaison defines the information architecture, the liaison will know what kinds of deliverables we need. The liaison also acts as an advocate for their tickets in the backlog grooming and sprint planning processes, and ensures their stories meet the story quality requirements. The liaison should also ensure that our partner teams have appropriate tickets in their backlogs for their work. Remove blockers (such as reviewer delay) Liaison + Manager While the liaison is primarily responsible for handling SME relationships and removing day-to-day blockers, your manager is here to help unstick things anytime you need help. Wrap up the liaisonship Liaison Liaisonships are not forever assignments! When the bulk of your work on a project is complete, it might be time to consider ending the liaisonship. Reach out to your manager to talk about it. When you end it, let stakeholders know and update the liaison roster. Also let your stakeholders know they can always ping the docs hero for help or if they have a new project. Liaison responsibilities: Build expertise Activity Who? Notes Develop a deep expertise on feature and audience. Liaison Become the Docs Team's local expert on the feature. Understand what it does, what problems it solves, and the implications for our content. Educate the team on the feature Liaison Part of your responsibility as liaison is to share expertise around the team. That helps with swarming, but it also makes for better hero review and a smarter team that can write more intelligently about the entire New Relic One platform. Coordinate with design and/or research and test your docs Liaison Reach out to the designer and/or researcher for the project, and periodically sync on any shared concerns, user needs, etc. And you should advocate for user testing and validation of your content. Liaison responsibilities: Define content strategy (oh, and do the writing) Activity Who? Notes Define the information architecture Liaison As liaison, you're the expert on both the feature the product team is building, and the docs content (new and existing) that will support that feature. Build an IA that will meet all project needs and scale to the future. Write content Team The liaison writes much of the content for their project, especially the conceptual content like intro docs. But the whole team is expected to swarm and contribute to large projects, with the liaison coordinating that work. Peer edit drafts Liaison When we swarm and have someone else contribute to the project, the liaison peer edits their drafts to ensure consistency with the overall vision. Coordinate publication Liaison When the time comes to release (whether that's beta, GA, limited release, or EoL), it's the liaison's job to coordinate with PM, Eng, and Product Marketing to ensure docs go out on time with other deliverables. ← Sprint workflow and Jira boards What is a hero? → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1184.2389,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Liaison responsibilities: Manage <em>project</em> flow",
        "body": "-<em>scope</em> meeting with the requestor. (Appendix: <em>Project</em> <em>scoping</em> <em>cheatsheet</em> has a list of common questions for this pre-<em>scope</em> meeting.) That conversation helps figure out timeline, complexity, key docs considerations, and which writer will be a good fit as liaison. Assign a liaison Tech Docs manager"
      },
      "id": "616c0d97e7b9d227264780c5"
    }
  ],
  "/docs/agile-handbook/appendices/ticket-best-practices": [
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-24T23:20:14Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.2438,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agile</em> vs <em>sprints</em> (vs <em>Jira</em> vs GitHub): <em>A</em> profusion of terms",
        "sections": "<em>Agile</em> vs <em>sprints</em> (vs <em>Jira</em> vs GitHub): <em>A</em> profusion of terms",
        "body": " research percolates. We have a backlog, board, and future <em>sprint</em> list in <em>Jira</em> that help us track what people want, what&#x27;s coming up, and what we&#x27;re working on now. For more on the mechanics of <em>how</em> we use <em>Jira</em>, see <em>Sprint</em> workflow and <em>Jira</em> boards and <em>Ticket</em> <em>best</em> <em>practices</em>. We use GitHub projects"
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Sprint workflow",
      "updated_at": "2021-10-17T11:49:20Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it maes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. ← Planning poker Liaisonships → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.26271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Sprint</em> workflow",
        "sections": "<em>Jira</em> boards: Backlog <em>and</em> future <em>sprints</em>",
        "body": "All of our <em>sprint</em> work is tracked in <em>Jira</em>. The workflow depends on what type of work we&#x27;re dealing with: Planned or unplanned (&quot;surprise!&quot;) work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current <em>sprint</em> as a result of a <em>Sprint</em> Planning"
      },
      "id": "616c0dc0196a67e6583c8164"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/backlog-review/",
      "sections": [
        "Backlog review",
        "Goals of backlog review",
        "Who reviews the backlog",
        "What to look for in a backlog review",
        "For more help"
      ],
      "published_at": "2021-10-24T23:19:07Z",
      "title": "Backlog review",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "6c1e047df7f4a43eaa253c0183625df4785455de",
      "document_type": "page",
      "popularity": 1,
      "body": "About once a quarter, the Docs team reviews our entire backlog in Jira and GitHub. This ensures that we actually know what's in there, and that we're bubbling up the right stories from the backlog into upcoming sprints. Goals of backlog review Fix easy issues: If you can fix something quickly, just do it. Find broken windows: What are the small (or big!) broken windows lurking in our backlog? What should we consider bubbling up into a future sprint? Identify gaps in the backlog: Discover important issues that are not at all covered in the backlog. Clear out cruft: Find duplicate issues, things we'll never fix, or issues that are just no longer relevant. Check labels and fields: Is the ticket assigned a correct priority score? Do we have the correct labels for other fields? Who reviews the backlog Sometimes we'll involve the whole team in a backlog review; other times, just the managers will handle the review. The most useful time to involve the whole team is when we're onboarding a new writer: Talking through issues promotes a lot of knowledge-sharing about the product, docs, stakeholders, and how to write a good ticket. Otherwise, we'll usually assign the review to the managers. This saves time, and it also tends to make it easier to close out issues (since our managers are also our product owners). If we don't involve the whole team, we'll prepare a spreadsheet of which issues we closed and list writers who might care so they can weigh in on whether the issue should have stayed open. What to look for in a backlog review When you review an issue, perform the following checks: Check if the issue can be closed: It's already resolved, or you can't reproduce the issue It's old, and we have little evidence anyone cares It's not important enough to fix If the issue doesn't have a clear goal/task, try to discover one (but don't feel obligated to rewrite the whole issue). Add context and update as-needed. Review fields and labels and ensure they're accurate. Add a label to the issue once you're done with your review. Use this format: year_month_backlog_review. For example: 2021_october_backlog_review. This helps keep track of which issues you've reviewed on this round of backlog review It's also a useful nudge for future round of review: If an issue has more than one or two review labels, you should probably close it. ← Appendix: Project scoping cheatsheet For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.52167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "What <em>to</em> look for in <em>a</em> backlog review",
        "body": " will handle the review. The most useful time to involve the whole team is when we&#x27;re onboarding a new writer: Talking through issues promotes a lot of knowledge-sharing about the product, docs, stakeholders, and <em>how</em> to <em>write</em> a good <em>ticket</em>. Otherwise, we&#x27;ll usually assign the review to the managers"
      },
      "id": "616c0dfa64441f2cb01d33a5"
    }
  ],
  "/docs/agile-handbook/heroing/managing-the-github-boards": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/heroing/what-is-a-hero/",
      "sections": [
        "What is a hero?",
        "Goals for heroing",
        "Heroing is a full-time job",
        "GitHub hero responsibilities",
        "Triage issues and PRs",
        "Review PRs",
        "Merge develop into main",
        "Provide peer reviews if time allows",
        "Slack hero responsibilities",
        "Update the Slack alias",
        "Field questions in the #documentation channel",
        "Second-shift hero support",
        "For more help"
      ],
      "published_at": "2021-10-24T19:34:40Z",
      "title": "What is a hero?",
      "updated_at": "2021-10-17T11:46:24Z",
      "type": "docs",
      "external_id": "d861167d0bea38aa6f7efdcef760bfcdcb0610ff",
      "document_type": "page",
      "popularity": 1,
      "body": "\"Hero\" is a common term across New Relic for a dedicated, interruptible person who acts as an interface for a team. When you're a docs hero, you're the face of the team. We have two heroes at any given time: the GitHub hero (for issues and pull requests) and the Slack hero (for questions through Slack). We also have a second-shift hero to support EMEA Relics. Every hero's job is to keep things moving for Relics and users. We change GitHub and heroes once a day (we used to do weekly shifts, but we've found daily shifts reduce hero burnout). Goals for heroing A Relic once described the New Relic culture this way: In the end, everyone here is working toward the same purpose [...] That person pinging you with some random request that seems unrelated to your world has the same goals as you. Help them, be kind, be patient. Your mission as hero is to personify that attitude in Docs-land. Here's what that looks like in practice: Create a consistent interface for the team. Having a dedicated hero means the answer to how to get help is always the same: \"Ping the hero!\" Because we've made this our mantra for 7 years, we don't have to re-educate the org on how to get help or who to go to with docs questions. Even as new people join the team, our processes evolve, and our entire publication toolchain has changed, our interaction model remains consistent. Directing questions to the hero avoids having a single point of failure: Even if a liaison is on leave, on the beach, or has moved onto another project, the hero is there to help. Provide a great (internal and external) customer experience. The heroes respond quickly to questions, give timely draft reviews, and perform great customer service and problem solving. Build and share knowledge about the site and our products. The heroes end up touching all kinds of obscure areas of our site and interacting with teams they may never have worked with directly. It's a great opportunity to learn more about New Relic and to build relationships across the org. Edit new content to our standards. We depend on self-service to cover lots of products with relatively few writers. The GitHub hero gives us a single accountable person who can review new content against Tech Docs team standards and turn it around quickly. Buffer the team from interrupts. Since the heroes are our \"designated interruptibles\" for their shifts, the rest of the team is freed up for deeper focus time. When it is appropriate to bring in another team member, heroes can help in streamlining the handoff and providing helpful context so that their teammate can get started quickly with the lowest possible context-switching burden. Heroing is a full-time job As the hero, you're often pulled in a lot of directions in a given shift. Because of this, the expectation is that you do not take on sprint work during your hero shift, unless you really have nothing else to do after completing your hero duties. You're also not expected to know everything as a hero! If something comes up for which you have no easy answer, let the requestor know you're on it and then ping your fellow writers or other SMEs and helpers from across New Relic for help. GitHub hero responsibilities The GitHub hero monitors the GitHub board and the flow of work through GitHub. Triage issues and PRs The GitHub hero triages every incoming pull request and issue. You'll tag the issue and pull request, route it to the correct column or team, and also help review incoming edits. For details on handling all of this, see Managing the GitHub boards. Review PRs The bulk of your time is generally spent reviewing and approving PRs from non-writers. To review an incoming PR: Label the pull request appropriately (see Managing the GitHub boards for details). Assign yourself to the pull request, so it's clear that you're on point to review and merge. Review the pull request, depending on what type of edit it is: If it's a simple \"cosmetic\" edit, review the pull request to ensure it's formatted correctly, technically accurate, and fits New Relic style guidelines. If it's a deeper edit, or a completely new doc, give it an in-depth review. The Docs site edit checklist is a great resource here. If it's a really complex or large edit, consider creating a Jira ticket for an upcoming sprint to give it the review time it needs. If it's a What's new post, pay special attention to frontmatter, links, and image formatting. This content follows marketing style, so it doesn't need to fully match our style guidelines for things like capitalization. If it's a release note, focus your review on formatting and basic style, and ensuring the release note itself is helpful. Release notes don't need to follow all docs style guidelines religiously. Preview your change in Gatsby Cloud or locally. Merge the pull request into develop. Merge develop into main We merge the develop branch into the main branch a few times a day. This kicks off a build, and ultimately is how draft docs become published docs. Currently we do this three times a day: Around 9 am PST, noon PST, and 3 pm PST. To merge, just click this magic link and follow the prompts. Provide peer reviews if time allows During super busy shifts, you likely won't have time for many of these, but if you're having a slow shift please take some time to periodically check the Writer Needs Peer Edit swim lane for fresh peer edit asks from your teammates before you switch over to doing sprint work. Slack hero responsibilities The Slack hero monitors Slack and helps answer questions about docs and route people to the right resource on the team. Update the Slack alias Update the alias to ping your name at the start of your hero shift. To update the alias, type the following into the chat box: !hero set @YOUR_SLACK_HANDLE. For example, if it's Austin's hero shift, the thing to type would be !hero set @austin. Field questions in the #documentation channel Common questions and requests include: Questions about docs content. Answer the question if you know it, or reach out to other writers if it's an area you're not familiar with. Encourage the requestor to edit the docs or submit an issue wherever possible. Triage requests for docs support. If it's a project that already has a liaison attached, connect the requestor to the appropriate writer. If it's a project without exisitng writing support, connect them to a tech docs team manager to have a scoping conversation. Questions about status of a pull request or issue. Check in and see if you can figure out, or pull in the assignee for that pull reuqest if the status isn't clear. Questions about things we don't own (blog, API Explorer, newrelic.com, etc). Help them out by directing them to the appropriate Slack channel. (For a list of properties and their owner, see Who owns the other wesbites? in Google Docs.) If you can't figure out who owns it, try asking the writing team in Slack. Second-shift hero support Our tech writers in Barcelona cover the 2nd shift heroing during their regular working hours. Unlike the US-based heroes, our Barcelona writers hero for an entire two-week sprint. Second-shift heroes cover both GitHub and Slack, but we don't expect that second-shift heroes will field every single request that comes in during their working hours since they're also carrying standard sprint duties during their hero shift. ← Liaisonships Managing the GitHub boards → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1577.8513,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>GitHub</em> hero responsibilities",
        "body": " issues and PRs The <em>GitHub</em> hero triages every incoming pull request and issue. You&#x27;ll tag the issue and pull request, route it to the correct column or team, and also help review incoming edits. For details on handling all of this, see <em>Managing</em> the <em>GitHub</em> <em>boards</em>. Review PRs The bulk of your time"
      },
      "id": "616c0d10e7b9d259f647857b"
    },
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-24T23:20:14Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1037.3809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Agile vs sprints (vs Jira vs <em>GitHub</em>): A profusion of terms",
        "sections": "Agile vs sprints (vs Jira vs <em>GitHub</em>): A profusion of terms",
        "body": " research percolates. We have a backlog, <em>board</em>, and future sprint list in Jira that help us track what people want, what&#x27;s coming up, and what we&#x27;re working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira <em>boards</em> and Ticket best practices. We use <em>GitHub</em> projects"
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/ticket-best-practices/",
      "sections": [
        "Ticket best practices: How to write a sprint-ready Jira",
        "Tip",
        "Why do we use Jira?",
        "What work needs a ticket?",
        "Keeping tickets up-to-date",
        "Add Jira context to PRs and commits",
        "Checklist for writing a good ticket",
        "For more help"
      ],
      "published_at": "2021-10-24T19:34:40Z",
      "title": "Ticket best practices: How to write a sprint-ready Jira",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "2109a54437970761f71a3940f189b7f10aef0bc1",
      "document_type": "page",
      "popularity": 1,
      "body": "Jira, a project management tool made by Atlassian, is how we manage our projects and understand the work we are doing and have done. Jira tickets may seem at first to be simple to-do lists that we use to know what things to do for a project. But they are much more important than that. Tip For Relics: Use the docs.newrelic.com/jira template when you create a ticket! It'll automatically pre-fill your ticket with a template that helps create a good ticket. Why do we use Jira? We create tickets to record work-to-be done for a project, scope new work, share information for any writer to complete a story, forecast our output and to estimate project timelines, and have a record of work done. In other words, Jira has a role at every point in a project: Before a project Scoping, syncing on expectations, giving tech writer instructions During a project Keeps team and management posted about project; allows for hand-offs and swarming After a project Understand what work we did, and helps researching on future projects What work needs a ticket? There aren't hard-and-fast rules about what work needs a Jira ticket and what doesn't. A good shorthand is that any project that takes more than a couple hours is a good candidate for a ticket. However, the goal of creating tickets is not to track writer time in detail. So many kinds of work (meetings, ongoing minor liaison tasks, hero work) generally do not need to go into Jira. Keeping tickets up-to-date In general, you should write your tickets as though you might win the lottery tomorrow (a principle known as lottery factor or bus factor). In practice, someone should be able to read your ticket and figure out within about ten minutes what the status is and what the next step is. This makes it easy for us to take vacations, pass work off to another docs writer if needed, and escalate blockers. These things help with lottery factor: Update the Action Item list as you complete tasks and add or remove scope. When you move a ticket to Blocked, include a note explaining the change in status. When you close a ticket, give a summary of the work done and any relevant thoughts you have on the work and potential related issues. Update the Timeline, People, and Resources sections as the project evolves. Add important conversations (emails or Slack convos from SMEs) that give important context for the work done. (Note: It's a good idea to ask permission before doing this, because some people might not like their informal words placed in a public place.) Add Jira context to PRs and commits When you edit the site, include the Jira issue key (DOC-1234, for example) in your pull request title and/or commit summary. That makes it easier for other writers to connect the dots later if we're trying to figure out why something changed or who knows about a particular subject. Checklist for writing a good ticket Helpful title A ticket name should be easy to find via search, understand the work at a glance, mention the product or feature, and describe the goal or issue. Examples of good ticket titles: Browser API: Update custom attribute-related docs or Distributed tracing: Add more detail about CAT relationship. Action items An action item list describing the work to be done What docs are affected Links to pull requests, Google Docs drafts, etc. How substantial the writing work is in each doc How the resulting work should be structured Whether or not a peer edit is needed Anyone who should be notified when a doc is published Proper sizing Story is scoped to the smallest reasonable size Can be completed within a 2 week sprint Delivers incremental value Dates Publication date or due date Dates for other key events (betas, limited releases, etc.) Resources and people People, including last names and roles List of related or affected docs Other internal and external resources Related issues Labels and fields Jira tickets: Component, Product Group, and Priority GitHub issues: from_, pg_, and content labels ← Managing the GitHub boards Appendix: Project scoping cheatsheet → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 965.41016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ": Component, Product Group, and Priority <em>GitHub</em> issues: from_, pg_, and content labels ← <em>Managing</em> the <em>GitHub</em> <em>boards</em> Appendix: Project scoping cheatsheet → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a <em>GitHub</em> issue."
      },
      "id": "616c0d9628ccbc919400346e"
    }
  ],
  "/docs/agile-handbook/heroing/what-is-a-hero": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge from develop into main work (or, when do we publish?)",
        "Github labels",
        "Check the edit history of a doc or file"
      ],
      "published_at": "2021-10-24T19:43:13Z",
      "title": "Get around GitHub",
      "updated_at": "2021-10-19T03:50:09Z",
      "type": "docs",
      "external_id": "d691040a18c70d6cd84f6a12546e39099547ab5e",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of the New Relic organization. If they aren't, try to find them on Slack based on their username. If you're not sure about someone's affiliation, treat them as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review and label issues and PRs in this column, then drag them to the appropriate column. If a PR or issue is labeled eng, the Hero/Sidekick can go ahead and click its ellipses icon to archive it. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress, and not necessarily ready to merge immediately. You can't merge a Draft PR directly—you have to move it out of draft first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero or Sidekick, make sure you attend to the following throughout your day: Check in with the Hero/Sidekick at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jira tickets, but reference tickets by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge from develop into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM, noon, and 3 PM Pacific. Slackbot will remind us about this in #docs_deploys. The hero (or delegate) is the one who should create a PR for this and merge it. Github labels Every issue needs these labels: Always add content Add one of the pg_* labels (see this internal doc ) Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optional: Jira’d: Issues that have a corresponding Jira ticket. Make sure you leave the Jira number in the comments of the issue (for example, DOC-1234). Every pull request needs these labels: Always add content Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer. Optional: Jira’d: Issues that have a corresponding Jira ticket. Make sure you leave the Jira number in the comments of the PR (for example, DOC-1234). Check the edit history of a doc or file There are a few options for checking the history of a file: Option 1: Github history tab Navigate to the doc on the doc site and click Edit page in the right nav. Click History in the top right corner of the doc. Bob's your uncle Option 2: githistory.xy Navigate to your specific file on Github.com: https://github.com/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx Copy In the url, replace github.com with github.githistory.xyz: https://github.githistory.xyz/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx Copy It will take you to a site which presents the visual history of that specific file. You can view changes by clicking through the commit history at the top of your page. Option 3: Git blame Follow Github's documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.18875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get <em>around</em> GitHub",
        "sections": "Who <em>is</em> who in <em>an</em> <em>issue</em>&#x2F;PR?",
        "body": " yourself as Assignee. In review (<em>Hero</em> or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and <em>what</em> is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass"
      },
      "id": "60c6a916196a67e82b5e1604"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/heroing/managing-the-github-boards/",
      "sections": [
        "Managing the GitHub boards",
        "A note on Assignee vs Reviewer",
        "Drafts column",
        "Hero to triage column",
        "Hero: To do column",
        "In progress/being reviewed column",
        "Writer needs PR review column",
        "Writer needs peer edit column",
        "Waiting on SME/blocked column",
        "Waiting on TW to merge column",
        "For more help"
      ],
      "published_at": "2021-10-24T19:07:21Z",
      "title": "Managing the GitHub boards",
      "updated_at": "2021-10-19T03:45:55Z",
      "type": "docs",
      "external_id": "8552cb5f3cec74364831b7d0d85a5d3bdd734e09",
      "document_type": "page",
      "popularity": 1,
      "body": "The Docs pull requests and Issues board is our source of truth for what's going on in our project. The board is divided into a series of columns so we can see visually what the status of each issue and pull request is. A note on Assignee vs Reviewer Assignee and Reviewer have different meanings: Assignee means you own the pull request or issue and are getting it into a merge-ready state. If you are no longer owning a given pull request or issue, take your name off as assignee. Reviewer means you are actively reviewing a pull request. If it's a pull request from outside the docs team, the reviewer is also responsible for merging the pull request into develop. If you're reviewing a pull request from a fellow docs writer, add your comments and mark the pull request as Approved, then move it to Waiting on TW to merge. Drafts column These issues and pull requests are in a draft state. Do not merge until their owner moves them out of the column. This column should only be for draft pull requests. Do not \"hold\" pull requests or issues here. The Hero should look at this column multiple times per day in case a pull request has been marked ready for review. Move any ready-for-review pull requests into the correct column. Hero to triage column New issues and pull requests flow into this column automatically. As hero, you need to triage each one: Determine if the pull request or issue is content-related. If it's an eng issue or pull request, you can just Archive it to remove it from the board. Assign mandatory labels: Label type Required on Description content Issues and pull requests Use this label to indicate an issue or pull request relates to content (versus the code of the site). from_ Issues and pull requests Use this label to indicate who created the issue or pull request. Use from_tw when it's created by a docs writer, from_internal when it's created by a Relic, and from_external when it's from outside the company. pg_ Issues Indicates which New Relic product group is associated with this issue. Give the ticket an assignee (most likely you). Move the ticket to the appropriate column. Hero: To do column Work that the GitHub has triaged, but hasn't started working on yet. Tickets in this column need to have an assignee. In progress/being reviewed column Work is underway on this issue or pull request. For example, reviewing pull requests from outside the team, doing a peer edit, investigating a GitHub issue. The person doing the work should make themselves the assignee as soon as they move the pull request or issue into this column to prevent others from duplicating work. Writer needs PR review column Exactly what it says. Typically, the writer who submitted the pull request will move it to this column. A pull request review means reviewing for basic stuff like is it rendering correctly, are there typos or wording issues, and are there any obvious errors in the .mdx content shown in the diff. Once you've reviewed the pull request, mark it approved in the GitHub review UI, and move it to the Waiting on TW to merge column. Writer needs peer edit column Also exactly what it says. As with pull request review column, the writer who submitted the pull request will drag to this column. This includes all the stuff in a pull request review plus an actual peer edit. Once you've reviewed the pull request and left your feedback in the GitHub review UI, mark it Approved and move it to the Waiting on TW to merge column. From there, the author of pull request is responsible for reviewing the feedback and updating it before merging. If you find significant issues (inaccuracies, bad formatting, build issues), don't mark it Approved. Waiting on SME/blocked column Blocked until something else happens. Usually this means it's waiting on answers or approval from the SME or the person who submitted the pull request. Waiting on TW to merge column When a docs writer creates a pull request, it's their responsibility to merge it into develop at the appropriate time. After a reviewer is done with their pull request review or peer edit, they move it into this column so the original writer can merge when ready. ← What is a hero? Appendix: Ticket best practices → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.45691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>A</em> note on <em>Assignee</em> vs Reviewer",
        "body": " a docs writer creates a pull request, it&#x27;s their responsibility to merge it into develop at the appropriate time. After a reviewer is done with their pull request review or peer edit, they move it into this column so the original writer can merge when ready. ← <em>What</em> is a <em>hero</em>? Appendix: Ticket best practices → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d6628ccbcbb0b003a72"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/create-edit-content/",
      "sections": [
        "Create and edit content",
        "Edit a doc",
        "Create new docs",
        "Clone (copy) an existing doc",
        "For bigger projects",
        "Delete pages",
        "Private edits",
        "Request a future publication date (for New Relic employees)"
      ],
      "published_at": "2021-10-24T23:46:44Z",
      "title": "Create and edit content",
      "updated_at": "2021-10-24T23:46:44Z",
      "type": "docs",
      "external_id": "96d8ee8adf5279fde74c26bf462be94d11dfa6fe",
      "document_type": "page",
      "popularity": 1,
      "body": "We welcome your contributions, whether you are a New Relic employee or a New Relic user! And we don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. That said, if you're curious about our style guidelines, you're welcome (but not obligated) to take a look. Edit a doc If you see a minor problem in our documentation that you want to quickly fix, you can use GitHub to edit the file and submit your pull request. A member of the Docs team will review your edit and publish your changes. We'll follow up with you if we have any questions. To edit existing content without building the site locally: On the docs site, navigate to the doc you'd like to edit. Click Edit page on the top corner of the right nav. A GitHub page will open with the source of the doc. Click the pencil icon in the top right. Make your edits (don't worry too much about formatting or grammar, we're happy to take care of that). At the bottom of the page, enter a commit message that describes your change, then click Commit changes. Follow the prompts to submit your pull request. A member of the Docs team will review your pull request and comment with any feedback. Once we've merged your pull request into the Develop branch, your changes will go live with our next deploy (usually within a few hours). Create new docs You can use article templates or clone an existing doc as a template. To create a new doc: Clone the repo on your computer. In /src/content/docs/, find a good location for your doc. Using your text editor, create a new .mdx file or copy an existing doc. Write your content. Optional: Add your doc to the right nav .yml file. The navigation files can be a bit hard to work with, so feel free to leave this step for a Docs writer to handle when they review your pull request. Commit your changes and create a pull request. The Tech Docs team has two heroes watching for new pull requests. We'll help you get the content finalized and make sure that it's in the right place. Clone (copy) an existing doc Once you've cloned the docs-website repository, use your text editor to copy an existing doc. Rename and edit the copy and then save it as a new doc. Your cloned doc automatically inherits the original doc's frontmatter content. Make sure to change that, too. If you want your cloned doc to be translated, follow standard procedures to request translation. For bigger projects If you're making larger changes like adding a whole new doc or editing many existing docs, it can be helpful to run the site locally. For instructions, see Tech writer workflow. Delete pages If you are comfortable with deleting the page yourself, go for it. If not, ask us by: File an issue in the docs-website repo, or contact the @hero in the #documentation channel if you're a New Relic employee. We'll take a look at your issue and help out. Private edits If you need to stage content for a private beta or limited release, contact the docs hero in the #documentation Slack channel. Request a future publication date (for New Relic employees) If your draft needs to be released on a specific date or within a specific timeframe (for example, right before a release), contact the Tech Docs @hero in the #documentation Slack channel. If you're not a New Relic employee, please create a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.92758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>and</em> edit content",
        "sections": "Create <em>and</em> edit content",
        "body": " for it. If not, ask us by: File an issue in the docs-website repo, or contact the @<em>hero</em> in the #documentation channel if you&#x27;re a New Relic employee. We&#x27;ll take a look at your issue and help out. Private edits If you need to stage content for a private beta or limited release, contact the docs <em>hero</em>"
      },
      "id": "6042219c196a67b1ada83d81"
    }
  ],
  "/docs/agile-handbook/key-concepts/agile-roles": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/key-agile-principles/",
      "sections": [
        "Key agile principles for our team",
        "Focus on the team's work",
        "Maximize swarming",
        "Enforce our points budgets",
        "Work incrementally",
        "Encourage self-service edits",
        "For more help"
      ],
      "published_at": "2021-10-24T23:20:14Z",
      "title": "Key agile principles for our team",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "749e499964c577501e9ae64249513d23f3d97cdb",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses a fairly \"by the book\" agile-scrum implementation, with the understanding that we can tweak the workflow as needed to work better for our flow. This handbook doesn't describe every aspect of how a sprint system should work, but focuses on the specific choices our team made as we evolved our agile process. As we evolve the system, it's helpful to know what our goals are. That can help illuminate whether a problem with the system is worth solving, and how to solve it without compromising on the essential things that make the team run smoothly. Focus on the team's work Our goal is for our team to deliver the most valuable work for the business and our users, every sprint. This description from Scrum: A Breathtakingly Brief and Agile Introduction nails what that means in practice: The role of each and every team member is to help the team deliver potentially shippable product in each sprint. Often, the best way to do this is by contributing work in their area of specialty. Other times, however, the team will need them to work outside of their area of specialty in order to best move backlog items from \"in progress\" to \"done.\" What we are describing is a mindset change from \"doing my job\" to \"doing the job.\" We aim to complete 100% of our work every sprint. In practice this is rarely attainable: We know that dates will move, scopes will expand, or our estimates will be wrong. But we've found that this 100% benchmark ensures we prioritize our shared team goal (the sprint), rather than our individual deliverables. Maximize swarming We want writers to build expertise, but we don't want to isolate ourselves. An alerts team at New Relic summed it up nicely: Our philosophy is, \"The team is the unit of work.\" This means that teams contribute to projects, teams solve problems, etc. We don't assign projects to individuals, and no one should ever be a single point of failure in the organization. If your team struggles to function effectively without you, your flexibility to take time off will be very limited. In such a case, we need to improve the skills and overall health of your team, ensure the team is setup for success, and ensure we have an appropriate team structure and charter in place. And an ops team demonstrates the most important practical implication: Our intention for tickets is that anyone should be able to select a task and have the information needed to understand and start on the work. Sometimes, this means we work a little slower in order to learn or teach something---and that's okay! Ultimately, working this way makes our team more resilient and makes it easier for New Relic to get consistent, high-quality docs. The Ticket best practices doc describes in detail the rules and best practices we've discovered help us achieve this. Enforce our points budgets Our team votes on all stories brought into a sprint, and we cap the number of stories based on our points budget. We generally vote as though the least-experienced person on the team will take the ticket. Having a strict points budget allows us to protect the team from overwork, predict our velocity over time, and ensure we actually have enough time to finish our work. Work incrementally Our goal is to deliver value as often as possible. Work that sits in a draft state for a long time can easily become wasted work: SMEs can become unavailable, priorities can change, and our knowledge can become stale. In practice, this means we work in fairly short two week sprints, publish early and often, and plan our projects so we can easily deliver 70% and then pivot to different priorities if something more important comes along. Encourage self-service edits Anyone can edit our open-sourced docs. With hundreds of Relics and users editing the docs each year, we can spend more of our writing time on high-impact work rather than simple maintenance edits. In order to reward teams that help us work this way, we prioritize this work in our queue. For work the writers need to do themselves, we ask for at least one full sprint of lead time. If someone comes to us the Tuesday after a sprint starts, that means they could be waiting up to two weeks for us to kick off work! But if someone edits the docs themselves, we promise to get their edit live within a 1 to 3 business day SLA. This lets us create win-wins: Rather than a simple \"no,\" a requestor can decide whether they truly need that content out now (in which case they can create that first draft) or whether they're okay waiting a week or two. ← Agile vs sprints: A profusion of terms Agile roles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 557.5765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Key <em>agile</em> principles for our team",
        "sections": "Key <em>agile</em> principles for our team",
        "body": " is for our team to deliver the most valuable work for the business and our users, every sprint. This description from Scrum: A Breathtakingly Brief and <em>Agile</em> Introduction nails what that means in practice: The <em>role</em> of each and every team member is to help the team deliver potentially shippable product"
      },
      "id": "616c0d96196a6768873c845b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/meetings-and-ceremonies/",
      "sections": [
        "Meetings and ceremonies",
        "Tip",
        "Sprint planning",
        "Backlog grooming",
        "Retro",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Meetings and ceremonies",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "873983fa778f17f1a92871ed4ad7673b333d4acc",
      "document_type": "page",
      "popularity": 1,
      "body": "Monday Tuesday Wednesday Thursday Friday Week 1 Sprint retro (every other sprint) Backlog grooming (end of sprint) Sprint planning (start of new sprint) Team meeting Meeting-free day Week 2 Team meeting Meeting-free day We break our work into two-week sprints. The new sprint starts on a Tuesday with sprint planning, where we commit to a set of stories that we're confident we can complete by the end of the sprint. Near the end of the sprint, we prepare for the next sprint with backlog grooming. The sprint closes with a retro where we discuss what went right and what went wrong, and then we kick off a new cycle. Each squad does their own backlog grooming and sprint planning, and manages their sprint backlog independently. We do retros together so we can talk through issues that affect both squads and share expertise and ideas. Tip Why do we end sprints on Mondays and start Tuesdays? This funny schedule makes things easier to work across timezones. If we ended sprints on Fridays, our Barcelona-based writers would need to do retros and grooming on Friday evening, and who wants that? Sprint planning On the first Tuesday of a new sprint, we commit to a series of stories until we have filled our capacity for the sprint. This is the largest meeting in the sprint---about 60 to 90 minutes. Before the sprint planning meeting, the scrum master for each squad calculates their point budget. Then, during the meeting: We select the highest priority item in the backlog. The person who nominated the story introduces it, and the team asks questions until everyone feels ready to vote. The team plays planning poker. Everyone secretly chooses a card, then we reveal them at the same time: If everyone picks the same card, that's the point value and we move on. If there's an even split between two cards, we choose the larger and move on. If it's mixed, the highest and lowest voters briefly explain their votes. Then we vote again. Once we're sure we can fit the story in, we subtract its story points from the sprint's points budget. We repeat the above steps until we've used up our points budget. We generally avoid pre-assigning people to stories during sprint planning. Instead, we pick up the next story or peer edit in the To Do column as stories are completed. Backlog grooming The day before the sprint starts, we do two rounds of backlog grooming. The purpose of backlog grooming is to prioritize work for sprint planning, and identify stories that need to be fixed before sprint planning to ensure scope is clear and planning runs smoothly. The first round of backlog grooming is by squad, where the members and manager of the squad get together and work through the grooming checklist. Then we do a second round of grooming with the managers and scrum masters to look at the sprint backlog for both squads and ensure nothing is or has fallen through the cracks. In the grooming, we: Each writer brings their personal \"top five\" tickets. The manager works with writers to prioritize those into a single, stack-ranked list for the team. We talk through stories and ensure they look ready for sprint planning (essentially, do they fit the Checklist for story readiness?). After grooming, the scrum master sends out a list of \"homework\" for stories that need improving. Retro Every other sprint, we conduct a 60 minute retrospective meeting, where we discuss: How do we feel about the sprint? What went well? Where can we improve? Anything we should start or stop doing? The goal of the retro is to improve the way we work together. That could be related to the sprint process, to how we collaborate with SMEs, to peer edits, and so on. ← Agile roles Planning poker → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 520.5035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " we collaborate with SMEs, to peer edits, and so on. ← <em>Agile</em> <em>roles</em> Planning poker → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dfa196a679fd43c9791"
    },
    {
      "image": "https://docs.newrelic.com/static/565d4ebddf52a4592c594032696516b9/c1b63/New-Relic-capabilities-UI-screenshot.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/new-relic-one-user-model-understand-user-structure/",
      "sections": [
        "Users, roles, permissions (New Relic One user model)",
        "Important",
        "Overview",
        "User type: basic and full",
        "Compare full vs basic capabilities",
        "Tips on choosing user type",
        "Understand user-related billing",
        "Have questions about why you can't access something?",
        "Default groups: Admin and User",
        "How do user type, roles, and groups relate to each other?",
        "Roles and capabilities",
        "Standard (default) roles",
        "Capabilities",
        "Manage users",
        "2020 user model changes"
      ],
      "published_at": "2021-10-24T20:31:19Z",
      "title": "Users, roles, permissions (New Relic One user model)",
      "updated_at": "2021-10-24T20:31:18Z",
      "type": "docs",
      "external_id": "169383c2678ce973404db07195b2dee6eda9163d",
      "document_type": "page",
      "popularity": 1,
      "body": "Your New Relic users can be on one of two user models: this doc explains the New Relic One user model. Important If your New Relic organization was created before July 30 2020 and you haven't gone through a user migration process, your users are likely on our original user model. For more on this, see User model changes. Overview This doc will explain the structure of the New Relic One user model, including: User type (basic user versus full user) Default user groups, including Admin and User Roles and capabilities For how to add and manage users in the UI, see User management. User type: basic and full Important This section is for users on our New Relic One user model. If you're on our original user model, see Original users. A user's user type determines if they have access to our basic features (basic user) or can access all of our curated observability UI features (full user). The user type is something meant to be set long-term based on that user's expected New Relic responsibilities. Below are details on the two user types. Note that full users are billable only if you're on New Relic One pricing. Basic user. Details: These users are free and have access to a wide range of features, including setting up and configuring any New Relic data-reporting tool, running queries of your data, using our logs UI, making custom charts and dashboards, and setting up alerts. Unlike full users, they do not have access to our more curated observability UI experiences or some Applied Intelligence features (for a detailed comparison, see Capabilities). Basic users will see prompts to become a full user when they attempt to access unavailable features. For details, see Upgrade. Full user. Details: Full users have access to everything (depending on any role restrictions), including all our observability UI experiences, such as APM, infrastructure monitoring, browser monitoring, mobile monitoring, synthetic monitors, access to New Relic One apps, and more. For details, see Capabilities. Standard edition includes one free full user and up to five total full users. A full user can downgrade to a basic user twice in a 12-month period. To view and edit the user type of your users, use the User management UI. Learn more about basic user versus full user differences: Compare full vs basic capabilities Below is a table comparing what basic users and full users can do. A simple way to think about it is that full users have theoretical access (dependent on any chosen role restrictions) to all of our curated UI experiences, while basic users are restricted to fairly basic capabilities. Features Full user Basic user Observability UI experiences Application performance monitoring (APM) UI Infrastructure monitoring UI Digital Experience Monitoring UI, which includes: Browser monitoring UI Mobile monitoring UI Synthetic monitoring UI Synthetics checks Serverless monitoring UI Logs in context Distributed tracing Infinite Tracing (Pro and Enterprise edition) Assorted UI experiences, including: Kubernetes cluster explorer UI Key transaction UI Workloads UI Manage other users Access to New Relic One apps Can build apps but can't access other apps Applied Intelligence Automatic anomaly detection Correlated alerts and events Anomaly/alert analysis Root cause details in issues Basic platform capabilities Data ingest from any source (agents, integrations, APIs) Query your data Create custom charts and dashboards Alerts and notifications Our APIs, including NerdGraph (GraphQL) (with some restrictions) Query and chart log data Build New Relic One apps (but cannot access other apps) Encryption at rest Standard data retention Security and compliance Data management Note that the pricing edition (Standard, Pro, or Enterprise) will also affect what features you have access to. For organizations with New Relic One pricing, learn more about how full users impact billing. Tips on choosing user type A user's type (basic user vs full user) is meant to be a long-term assignment, based on the New Relic responsibilities that user is expected to perform. A full user can be downgraded to a basic user only twice in one year. Below are tips for why you'd choose full user versus basic user. Reasons to make someone a full user: They play a key role in the development, testing, deployment, and maintenance phases of the application development lifecycle. They break/fix code regularly; they are responsible for triaging workflows, troubleshooting, or managing users and roles for their team. They have DevOps practices (i.e. version control systems and implement CI/CD). They need to use New Relic's curated dashboards and experiences (not just the ability to create their own custom queries and charts); in other words, they need full access to our platform. They need to be able to manage users and/or billing. Reasons to make someone a basic user: They play a key role in the planning phase of the application development lifecycle. They use and configure New Relic agents, APIs, and integrations to send us data, and access, configure, and use alerts on such data (not necessarily responsible for triaging workflows, troubleshooting, or managing users and roles for their team). They want to see high-level analytics and business metrics for future planning (such as C-Suite executives). They do not need to use our curated experiences and dashboards, but would benefit from the ability to create their own custom queries and charts of data; in other words, they don't need full access to the platform. They don't manage users. For accounts on New Relic One pricing, learn more about user-related billing calculations. Understand user-related billing If you're on the New Relic One pricing plan, full users are billable, and there are restrictions around how often a full user can downgrade to a basic user. For details, see User count billing details. For how to query and alert on usage data, see Query usage data. Have questions about why you can't access something? See Factors affecting access. Default groups: Admin and User For users on our New Relic One user model, a \"group\" is what allows the grouping together and managing of multiple users at the same time. Your New Relic users are assigned to a group, and that group is granted access to specific roles on specific accounts. We have two default groups: User: This group allows a user to use and configure monitoring/analysis features but not perform account-related tasks like managing billing or users. It has access to the All product admin role, which gives access to our observability platform tools but not to the organization and user management capabilities governed by the Organization manager and Authentication manager roles. Admin: has full access and capabilities, including the organization-level admin abilities. This is the equivalent of having the All product admin, the Billing user, the Organization manager and the Authentication domain manager roles. These groups are added inside your default authentication domain, which includes the default settings of users a) being managed via New Relic and b) logging in via standard email and password. If you add other authentication domains (for SAML SSO and/or SCIM provisioning of users), you'd have new custom groups in those new domains to govern those users. Note that groups, whether default or custom, are not what limit a user's capabilities: it is the role that is assigned to that group (with any basic user restrictions on top of that). If your organization is Pro or Enterprise edition and you want to understand how users are granted access to specific roles and accounts, see Access grants. To change the group a user is in, use the User management UI. How do user type, roles, and groups relate to each other? For users on the New Relic One user model, here's a table explaining how user type (basic vs full user), roles, and groups relate to each other: Full user Basic user Group Full users can be assigned to default groups (User and Admin) or custom groups. When basic users are added to a group, that group's role-related restrictions apply. A basic user's capabilities can be restricted in that way, but a basic user can never be granted more capabilities than they start with. For Standard edition, basic users can't be assigned to groups. For Pro and Enterprise edition, they can. Role For an explanation of the roles our default groups have, see Default groups. Custom groups can have either our default standard roles, or custom roles. A basic user's abilities aren't directly defined by a specific role. A basic user can best be described as having the All product admin role but without access to our more curated UI experiences (learn more about user type). When basic users are added to a group, that group's role-related restrictions apply, but a basic user can never be granted more capabilities than they start with. Roles and capabilities For users on the New Relic One user model, a \"role\" can be defined as \"a set of capabilities.\" A capability is defined as the ability to do a specific New Relic task, like 'Delete alert conditions' (learn more about capabilities). Roles are assigned to user groups. Our default groups Admin and User already have our standard roles (defined below) assigned. Organizations on Pro or Enterprise edition can also create custom roles. Standard (default) roles Roles are sets of capabilities. We have several \"standard roles,\" which are roles that satisfy some commonly needed use cases. To view roles and their associated capabilities, use the Organization and access UI. Important Note that some of our standard roles have hidden, non-exposed capabilities that are not available for selection when creating a custom role. The only standard roles that can be replicated with a custom role are Standard user and Read only; all others have some hidden capabilities. Our standard roles include: Standard roles Scope Description All product admin Account Provides admin-level access to observability platform features but not organization-level and user management features. In other words, this role includes all New Relic capabilities with the exception of managing users (Authentication domain manager role), managing organization/account-structure settings (Organization manager role), and managing billing (Billing user role). Note: the Standard user role is essentially the All product admin role minus observability feature configuration capabilities. Standard user Account Provides access to observability platform features, but lacks permissions for configuring those features (for example, ability to configure synthetic monitor secure credentials) and lacks organization-level and user management permissions. Note: the Standard user role is essentially the All product admin role without that role's ability to configure platform features. Billing user Account Provides ability to manage subscriptions and billing setup, and read-only access to the rest of the platform. For organizations with multiple accounts, billing is aggregated in the primary (first-created) account, which is why assigning this role to that primary account grants billing permissions for the entire organization. Organization manager Organization Provides the ability to manage organization settings, including organization structure, name, and preferences. Due to our recent switch to the New Relic One user model, this role currently has few abilities but more will be added over time. For how to grant this role, see Add user management capability. Organization read only Organization Provides the ability to view organization-level settings. For how to grant this role, see Add user management capability. Authentication domain manager Organization Provides ability to add and manage users, and configure authentication domains for users on the New Relic One user model. For how to grant this role, see Add user management capability. Authentication domain read only Organization Provides the ability to view users in your organization and view the configuration of authentication domains. For how to grant this role, see Add user management capability. Read only Account Provides read-only access to the New Relic platform (except for synthetic monitor secure credentials). Manage v1 users Account For New Relic organizations that existed before July 30 2020 and have users on our original user model, this role lets you manage those \"v1\" users. For more about how you'd assign roles to groups and create custom roles, see the user management tutorial. Capabilities A role, whether one of our standard roles or a custom role, is defined as a set of capabilities. To view roles and their associated capabilities, use the Organization and access UI. Important Some of our standard roles have hidden capabilities that aren't available for selection when creating a custom role. For details, see Standard roles. A view of the capabilities associated with the All product admin role. When creating a custom role, you select a custom set of capabilities. Note that the capabilities we expose may change over time: this screenshot was taken in April of 2021. For how to set up roles with custom capabilities, see the user management tutorial. Manage users To learn how to add users, assign them to groups, and create custom groups and roles, see Manage users. 2020 user model changes If you'd like to understand how our user model changed in 2020 and what the impacts of that change were, see User model changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.07411,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Users, <em>roles</em>, permissions (New Relic One user model)",
        "sections": "Users, <em>roles</em>, permissions (New Relic One user model)",
        "body": " versus basic user. Reasons to make someone a full user: They play a key <em>role</em> in the development, testing, deployment, and maintenance phases of the application development lifecycle. They break&#x2F;fix code regularly; they are responsible for triaging workflows, troubleshooting, or managing users and <em>roles</em>"
      },
      "id": "603e88e328ccbcfcbaeba7a8"
    }
  ],
  "/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms": [
    {
      "image": "https://docs.newrelic.com/static/8945e0a9c512b8638ebf8165d47aee04/69902/QS-SignUp3.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-user-guide/",
      "sections": [
        "CodeStream user guide",
        "Quick Start",
        "1. Install the CodeStream extension in your IDE and sign up.",
        "2. Connect your tools",
        "3. Discuss any block of code, at any time",
        "4. Get feedback on your work in progress",
        "5. Create or review a pull request",
        "Help & Feedback"
      ],
      "published_at": "2021-10-24T21:19:37Z",
      "title": "CodeStream user guide",
      "updated_at": "2021-10-23T17:07:02Z",
      "type": "docs",
      "external_id": "fa9af0118a8872fea89fda91482c44fb69913ea2",
      "document_type": "page",
      "popularity": 1,
      "body": "Quick Start Use the navigation to the left to jump straight to any topic. Otherwise, read on to get started with CodeStream. 1. Install the CodeStream extension in your IDE and sign up. Install CodeStream for VS Code, Visual Studio or JetBrains. The CodeStream pane should automatically appear in the sidebar for VS Code, or in a tool window at the right side for a JetBrains IDE or Visual Studio. Click on \"Sign Up and Create a team\" if you are the first person from your team to join CodeStream, or paste in your invitation code if you were invited to a team already on CodeStream. Learn more about how to use CodeStream. 2. Connect your tools Create and review pull requests on GitHub, GitLab or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click on your headshot at the top of the CodeStream pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, just select the code and ask your question. Learn more about discussing code. 4. Get feedback on your work in progress Select \"Request Feedback\" from the \"+\" menu at any time in the development cycle, whether it’s a quick look over some work in progress (even uncommitted code!) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. 5. Create or review a pull request Look for the Pull Requests section of the CodeStream sidebar to review an open pull request. Just click on a pull request (or load one from URL) to get a complete GitHub experience right in your IDE! Note that you can create a pull request in GitHub, GitLab or Bitbucket, but support for reviewing pull requests is currently only available for GitHub (cloud or Enterprise). Learn more about pull requests. Help & Feedback Report a bug or send a suggestion in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 429.43256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "3. Discuss <em>any</em> block <em>of</em> code, <em>at</em> <em>any</em> time",
        "body": " about how to use CodeStream. 2. Connect your tools Create and review pull requests on <em>GitHub</em>, <em>Git</em>Lab or Bitbucket. Create issues on <em>Jira</em>, Trello, and other issue trackers. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click"
      },
      "id": "61744137e7b9d2428b13c6a0"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/codestream/troubleshooting/client-logs/",
      "sections": [
        "Where can I find my CodeStream client-side logs?"
      ],
      "published_at": "2021-10-24T21:21:51Z",
      "title": "Where can I find my CodeStream client-side logs?",
      "updated_at": "2021-10-23T17:11:08Z",
      "type": "docs",
      "external_id": "3c9d73c62ba313ecd37ce32e87cd085aacd11bad",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of submitting a bug report on our GitHub it would be very helpful if you also included log files. Below are instructions for getting log files based on which IDE you're using. You can attach the log files to the GitHub issue, or if you’d prefer, you can email them to support@codestream.com and reference the GitHub issue number in the subject. JetBrains Reproduce the issue and then in your IDE go to Help > Collect Logs and Diagnostic Data. This will open the finder where you should see a newly created zip file. VS Code Reproduce the issue and then open the Output view in VS Code (“View: Toggle Output” from the command palette) and select \"CodeStream (Agent)\" from the dropdown menu at the top-right. Copy all of the output you see and save it in a text file. Visual Studio Go to Tools > Options > CodeStream and make sure your log level is set to at least Debug. If it is set to Info, Errors, or Silent, change it to Debug, then restart Visual Studio. Reproduce the issue. Grab vs-extension.log and vs-agent.log from %localappdata%\\CodeStream\\Logs as well as the ActivityLog.xml from %AppData%\\Microsoft\\VisualStudio\\16.0_<RandomText> for Visual Studio 2019 or %AppData%\\Microsoft\\VisualStudio\\15.0_<RandomText> for Visual Studio 2017",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 393.46313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " and reference the <em>GitHub</em> issue number in the subject. JetBrains Reproduce the issue and then in your IDE go to Help &gt; Collect Logs and Diagnostic Data. This will open the finder where you should see a newly created zip file. <em>VS</em> Code Reproduce the issue and then open the Output view in <em>VS</em> Code (“View"
      },
      "id": "6174422c28ccbcb856c6b20e"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/key-agile-principles/",
      "sections": [
        "Key agile principles for our team",
        "Focus on the team's work",
        "Maximize swarming",
        "Enforce our points budgets",
        "Work incrementally",
        "Encourage self-service edits",
        "For more help"
      ],
      "published_at": "2021-10-24T23:20:14Z",
      "title": "Key agile principles for our team",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "749e499964c577501e9ae64249513d23f3d97cdb",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses a fairly \"by the book\" agile-scrum implementation, with the understanding that we can tweak the workflow as needed to work better for our flow. This handbook doesn't describe every aspect of how a sprint system should work, but focuses on the specific choices our team made as we evolved our agile process. As we evolve the system, it's helpful to know what our goals are. That can help illuminate whether a problem with the system is worth solving, and how to solve it without compromising on the essential things that make the team run smoothly. Focus on the team's work Our goal is for our team to deliver the most valuable work for the business and our users, every sprint. This description from Scrum: A Breathtakingly Brief and Agile Introduction nails what that means in practice: The role of each and every team member is to help the team deliver potentially shippable product in each sprint. Often, the best way to do this is by contributing work in their area of specialty. Other times, however, the team will need them to work outside of their area of specialty in order to best move backlog items from \"in progress\" to \"done.\" What we are describing is a mindset change from \"doing my job\" to \"doing the job.\" We aim to complete 100% of our work every sprint. In practice this is rarely attainable: We know that dates will move, scopes will expand, or our estimates will be wrong. But we've found that this 100% benchmark ensures we prioritize our shared team goal (the sprint), rather than our individual deliverables. Maximize swarming We want writers to build expertise, but we don't want to isolate ourselves. An alerts team at New Relic summed it up nicely: Our philosophy is, \"The team is the unit of work.\" This means that teams contribute to projects, teams solve problems, etc. We don't assign projects to individuals, and no one should ever be a single point of failure in the organization. If your team struggles to function effectively without you, your flexibility to take time off will be very limited. In such a case, we need to improve the skills and overall health of your team, ensure the team is setup for success, and ensure we have an appropriate team structure and charter in place. And an ops team demonstrates the most important practical implication: Our intention for tickets is that anyone should be able to select a task and have the information needed to understand and start on the work. Sometimes, this means we work a little slower in order to learn or teach something---and that's okay! Ultimately, working this way makes our team more resilient and makes it easier for New Relic to get consistent, high-quality docs. The Ticket best practices doc describes in detail the rules and best practices we've discovered help us achieve this. Enforce our points budgets Our team votes on all stories brought into a sprint, and we cap the number of stories based on our points budget. We generally vote as though the least-experienced person on the team will take the ticket. Having a strict points budget allows us to protect the team from overwork, predict our velocity over time, and ensure we actually have enough time to finish our work. Work incrementally Our goal is to deliver value as often as possible. Work that sits in a draft state for a long time can easily become wasted work: SMEs can become unavailable, priorities can change, and our knowledge can become stale. In practice, this means we work in fairly short two week sprints, publish early and often, and plan our projects so we can easily deliver 70% and then pivot to different priorities if something more important comes along. Encourage self-service edits Anyone can edit our open-sourced docs. With hundreds of Relics and users editing the docs each year, we can spend more of our writing time on high-impact work rather than simple maintenance edits. In order to reward teams that help us work this way, we prioritize this work in our queue. For work the writers need to do themselves, we ask for at least one full sprint of lead time. If someone comes to us the Tuesday after a sprint starts, that means they could be waiting up to two weeks for us to kick off work! But if someone edits the docs themselves, we promise to get their edit live within a 1 to 3 business day SLA. This lets us create win-wins: Rather than a simple \"no,\" a requestor can decide whether they truly need that content out now (in which case they can create that first draft) or whether they're okay waiting a week or two. ← Agile vs sprints: A profusion of terms Agile roles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 390.96744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Key <em>agile</em> principles for our team",
        "sections": "Key <em>agile</em> principles for our team",
        "body": " okay waiting a week or two. ← <em>Agile</em> <em>vs</em> <em>sprints</em>: A <em>profusion</em> of <em>terms</em> <em>Agile</em> roles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a <em>GitHub</em> issue."
      },
      "id": "616c0d96196a6768873c845b"
    }
  ],
  "/docs/agile-handbook/key-concepts/key-agile-principles": [
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-24T23:20:14Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.44138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agile</em> vs sprints (vs Jira vs GitHub): A profusion of terms",
        "sections": "<em>Agile</em> vs sprints (vs Jira vs GitHub): A profusion of terms",
        "body": " meeting <em>our</em> overall goals as a <em>team</em>. <em>Key</em> <em>agile</em> <em>principles</em> → For more help We welcome thoughts or questions on <em>our</em> handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-roles/",
      "sections": [
        "Agile roles",
        "Team member",
        "Scrum master",
        "Tech Docs managers (and product owner)",
        "Key stakeholders",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Agile roles",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "fcfd8b2a56ccc61ba57d207f49876b4788a1ca51",
      "document_type": "page",
      "popularity": 1,
      "body": "Like most agile teams, we divide up the roles on our team into team members, scrum masters, product owners, and managers. We treat some of those roles differently than a traditional engineer-centric scrum team: We combine the role of team manager and product owner into one person. Each writer is responsible for \"liaisonships\" where they track work across a particular product or feature and bring in appropriate stories. We don't expect scrum masters to clear blockers (that's a manager's job), and scrum mastering is not a full-time job. We divide the team further into two squads, each with its own team members, scrum master, and product owners. Team member Team members are responsible for: Doing writing work. Improving the team's processes and how we work together. Writing stories for sprints in accordance with their work (via laisionships, SME conversations, hero work, etc.). The person who nominates a story will also present it during sprint planning. See Ticket best practices for tips on writing a good ticket. Most team members will be assigned one or more Liaisonships (project assignments). Liaisons are responsible for nominating stories for sprints from other teams. Scrum master Each squad has a scrum master. The scrum master is not responsible for unblocking stories or communicating with stakeholders on behalf of the team (this work belongs to individual writers and their manager). We believe this lets the business have a single point of accountability (managers) for decisions, and ensures scrum masters have hands-on experience of what it's like to be a writer. Instead, for us the scrum master is a custodian of the sprint process and the MC for sprint meetings. In backlog grooming: The scrum master handles the mechanics of talking through each ticket and facilitating conversations about story quality. In sprint planning: The scrum master leads conversation, tracks discussion time, adds point values to stories, and organizes/ranks sprint candidates in real time. They don't present the stories, though—stories should be introduced by the person who nominated the story for the sprint. In retros: The scrum master facilitates the discussion, captures action items, and takes notes. Tech Docs managers (and product owner) Each squad has a manager---or perhaps you could say each manager has a squad. Either way, the manager's role is to prioritize the right work for the business, maintain a healthy workload, and help escalate when a writer needs help. The managers are responsible for understanding how our entire body of work serves the organization, and making informed decisions about our velocity and workload. The manager engages with other teams to know which features may be coming into the pipeline and has a general understanding of work that may be in future sprints. This lets them make final priority decisions for the team and be accountable to the business for those tradeoffs. The manager is also responsible for assigning liaisonships and ensuring we're covering the portfolio. They'll also work with other teams to unblock writers when needed. Key stakeholders Our key internal stakeholders include PMs, engineers, designers, and executives. Writers work with the stakeholders to know when new work is coming, and to communicate documentation needs/timelines. We should ensure our stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. ← Key agile principles Meetings and ceremonies → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.13654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agile</em> roles",
        "sections": "<em>Agile</em> roles",
        "body": " needs&#x2F;timelines. We should ensure <em>our</em> stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. ← <em>Key</em> <em>agile</em> <em>principles</em> Meetings and ceremonies → For more help We welcome thoughts or questions on <em>our</em> handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d97e7b9d2b2f047837d"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/planning-poker/",
      "sections": [
        "Planning poker and points budgets",
        "Poker card definitions",
        "How we calculate the points budget",
        "Tip",
        "For more help"
      ],
      "published_at": "2021-10-24T23:22:20Z",
      "title": "Planning poker and points budgets",
      "updated_at": "2021-10-17T11:51:09Z",
      "type": "docs",
      "external_id": "d002b0635204648ebe36dbdc6c242e80fa971aa3",
      "document_type": "page",
      "popularity": 1,
      "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the team. Then, the team all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most agile teams that estimate with planning poker use cards that follow a Fibonacci sequence. We've found over the years that those large jumps weren't very helpful to us in estimating, and that we estimated better with smaller numbers. So we use fairly small, granular numbers that roughly break down to 1 point ≈ 1 day. Note that even though each of the possible scores have approximate time values associated with them, we vote in points, not time. Scoring with points prevents getting into weedsy debates about exactly how long something will take, and instead focuses us on the requirements and difficulty of the story. Poker card definitions These how we define our poker cards: Card Value ¼ An hour or two. Anything smaller than this isn't worth bringing into a sprint or even ticketing—just do it right now. ½ About half of an \"ideal\" day. We define an \"ideal\" day as one without meetings or interruptions. Using \"ideal\" days makes it easier to estimate a story without litigating the details of how we spend our time. 1 About one \"ideal\" day. This is one of our most common story sizes. 1½ About one and a half \"ideal\" days. This is our other most common story size. 2 About two \"ideal\" days. 3 About three \"ideal\" days. We jump from 2 straight to 3 to avoid unrealistic granularity in our estimates. 5 About a week of work. 7 About a full sprint (two weeks) of work. We very rarely use this card—a ticket that takes a full sprint on its own is almost always too large and should be chunked into smaller, incremental tickets. Break! \"I need a break.\" When someone plays a break card, we finish estimating the current story then immediately take a five minute break. Defer No strong opinion. Don't play this card on the first round of poker! Seeing wildly different estimates is a sign we don't have a shared understanding of the work. Playing an early Defer card can mask that uncertainty. How we calculate the points budget In order to ensure we're not filling up our sprint with more \"ideal days\" of time than we realistically have available, we calculate the points budget based on the actual output of the team. Over time, we've found writers average 0.6 (technically, 0.57) points per day. Tip This value is totally unique to each team! A high number doesn't indicate a more productive team, and a low number isn't a problem. Story points are only meaningful within a team. If you're starting a new team or new process, you'll need to zero in on the ideal number of points per writer. An easy way to figure out the right budget is to have the team vote in retro on whether to increase, decrease, or keep the same budget next sprint. You'll overshoot or undershoot a few times, but after a couple sprints you'll get a good sense of what constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let's say 5 writers and a 10 business day (2 calendar week) sprint. Or, 50 person-days total. Subtract out time off days, plus 1 day for each day of hero duty. Let's say we have 1 writer on vacation in Maui, and 1 day of hero time per day. 50 person days, minus 10 days of vacation and 10 days of hero time, gives us 30 person-days. Multiply the number of days times the average velocity per writer, per day. Our average velocity is 0.6 points/writer/day. 30 person days multiplied by 0.6 would give us an 18 point budget for the sprint. Because we work in two squads, we calculate a separate points budget for each squad ahead of sprint planning. ← Meetings and ceremonies Sprint workflow and Jira boards → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 70.74403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>For</em> more help",
        "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the <em>team</em>. Then, the <em>team</em> all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most <em>agile</em> teams"
      },
      "id": "616c0e2d28ccbc6e5e00337f"
    }
  ],
  "/docs/agile-handbook/sprint-mechanics/liaisonships": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-roles/",
      "sections": [
        "Agile roles",
        "Team member",
        "Scrum master",
        "Tech Docs managers (and product owner)",
        "Key stakeholders",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Agile roles",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "fcfd8b2a56ccc61ba57d207f49876b4788a1ca51",
      "document_type": "page",
      "popularity": 1,
      "body": "Like most agile teams, we divide up the roles on our team into team members, scrum masters, product owners, and managers. We treat some of those roles differently than a traditional engineer-centric scrum team: We combine the role of team manager and product owner into one person. Each writer is responsible for \"liaisonships\" where they track work across a particular product or feature and bring in appropriate stories. We don't expect scrum masters to clear blockers (that's a manager's job), and scrum mastering is not a full-time job. We divide the team further into two squads, each with its own team members, scrum master, and product owners. Team member Team members are responsible for: Doing writing work. Improving the team's processes and how we work together. Writing stories for sprints in accordance with their work (via laisionships, SME conversations, hero work, etc.). The person who nominates a story will also present it during sprint planning. See Ticket best practices for tips on writing a good ticket. Most team members will be assigned one or more Liaisonships (project assignments). Liaisons are responsible for nominating stories for sprints from other teams. Scrum master Each squad has a scrum master. The scrum master is not responsible for unblocking stories or communicating with stakeholders on behalf of the team (this work belongs to individual writers and their manager). We believe this lets the business have a single point of accountability (managers) for decisions, and ensures scrum masters have hands-on experience of what it's like to be a writer. Instead, for us the scrum master is a custodian of the sprint process and the MC for sprint meetings. In backlog grooming: The scrum master handles the mechanics of talking through each ticket and facilitating conversations about story quality. In sprint planning: The scrum master leads conversation, tracks discussion time, adds point values to stories, and organizes/ranks sprint candidates in real time. They don't present the stories, though—stories should be introduced by the person who nominated the story for the sprint. In retros: The scrum master facilitates the discussion, captures action items, and takes notes. Tech Docs managers (and product owner) Each squad has a manager---or perhaps you could say each manager has a squad. Either way, the manager's role is to prioritize the right work for the business, maintain a healthy workload, and help escalate when a writer needs help. The managers are responsible for understanding how our entire body of work serves the organization, and making informed decisions about our velocity and workload. The manager engages with other teams to know which features may be coming into the pipeline and has a general understanding of work that may be in future sprints. This lets them make final priority decisions for the team and be accountable to the business for those tradeoffs. The manager is also responsible for assigning liaisonships and ensuring we're covering the portfolio. They'll also work with other teams to unblock writers when needed. Key stakeholders Our key internal stakeholders include PMs, engineers, designers, and executives. Writers work with the stakeholders to know when new work is coming, and to communicate documentation needs/timelines. We should ensure our stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. ← Key agile principles Meetings and ceremonies → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.013626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " is responsible for &quot;<em>liaisonships</em>&quot; where they track work across a particular product or feature and bring in appropriate stories. We don&#x27;t expect scrum masters to clear blockers (that&#x27;s a manager&#x27;s job), and scrum mastering is not a full-time job. We divide the team further into two squads, each with its"
      },
      "id": "616c0d97e7b9d2b2f047837d"
    },
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-24T23:20:14Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 62.528305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and <em>liaisonships</em>. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain"
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Sprint workflow",
      "updated_at": "2021-10-17T11:49:20Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it maes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. ← Planning poker Liaisonships → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 49.312504,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " current. Note why we moved to the backlog rather than carry over. ← Planning poker <em>Liaisonships</em> → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dc0196a67e6583c8164"
    }
  ],
  "/docs/agile-handbook/sprint-mechanics/meetings-and-ceremonies": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-roles/",
      "sections": [
        "Agile roles",
        "Team member",
        "Scrum master",
        "Tech Docs managers (and product owner)",
        "Key stakeholders",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Agile roles",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "fcfd8b2a56ccc61ba57d207f49876b4788a1ca51",
      "document_type": "page",
      "popularity": 1,
      "body": "Like most agile teams, we divide up the roles on our team into team members, scrum masters, product owners, and managers. We treat some of those roles differently than a traditional engineer-centric scrum team: We combine the role of team manager and product owner into one person. Each writer is responsible for \"liaisonships\" where they track work across a particular product or feature and bring in appropriate stories. We don't expect scrum masters to clear blockers (that's a manager's job), and scrum mastering is not a full-time job. We divide the team further into two squads, each with its own team members, scrum master, and product owners. Team member Team members are responsible for: Doing writing work. Improving the team's processes and how we work together. Writing stories for sprints in accordance with their work (via laisionships, SME conversations, hero work, etc.). The person who nominates a story will also present it during sprint planning. See Ticket best practices for tips on writing a good ticket. Most team members will be assigned one or more Liaisonships (project assignments). Liaisons are responsible for nominating stories for sprints from other teams. Scrum master Each squad has a scrum master. The scrum master is not responsible for unblocking stories or communicating with stakeholders on behalf of the team (this work belongs to individual writers and their manager). We believe this lets the business have a single point of accountability (managers) for decisions, and ensures scrum masters have hands-on experience of what it's like to be a writer. Instead, for us the scrum master is a custodian of the sprint process and the MC for sprint meetings. In backlog grooming: The scrum master handles the mechanics of talking through each ticket and facilitating conversations about story quality. In sprint planning: The scrum master leads conversation, tracks discussion time, adds point values to stories, and organizes/ranks sprint candidates in real time. They don't present the stories, though—stories should be introduced by the person who nominated the story for the sprint. In retros: The scrum master facilitates the discussion, captures action items, and takes notes. Tech Docs managers (and product owner) Each squad has a manager---or perhaps you could say each manager has a squad. Either way, the manager's role is to prioritize the right work for the business, maintain a healthy workload, and help escalate when a writer needs help. The managers are responsible for understanding how our entire body of work serves the organization, and making informed decisions about our velocity and workload. The manager engages with other teams to know which features may be coming into the pipeline and has a general understanding of work that may be in future sprints. This lets them make final priority decisions for the team and be accountable to the business for those tradeoffs. The manager is also responsible for assigning liaisonships and ensuring we're covering the portfolio. They'll also work with other teams to unblock writers when needed. Key stakeholders Our key internal stakeholders include PMs, engineers, designers, and executives. Writers work with the stakeholders to know when new work is coming, and to communicate documentation needs/timelines. We should ensure our stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. ← Key agile principles Meetings and ceremonies → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1349.6708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Tech Docs managers (<em>and</em> product owner)",
        "body": " needs&#x2F;timelines. We should ensure our stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. ← Key agile principles <em>Meetings</em> and <em>ceremonies</em> → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d97e7b9d2b2f047837d"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/planning-poker/",
      "sections": [
        "Planning poker and points budgets",
        "Poker card definitions",
        "How we calculate the points budget",
        "Tip",
        "For more help"
      ],
      "published_at": "2021-10-24T23:22:20Z",
      "title": "Planning poker and points budgets",
      "updated_at": "2021-10-17T11:51:09Z",
      "type": "docs",
      "external_id": "d002b0635204648ebe36dbdc6c242e80fa971aa3",
      "document_type": "page",
      "popularity": 1,
      "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the team. Then, the team all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most agile teams that estimate with planning poker use cards that follow a Fibonacci sequence. We've found over the years that those large jumps weren't very helpful to us in estimating, and that we estimated better with smaller numbers. So we use fairly small, granular numbers that roughly break down to 1 point ≈ 1 day. Note that even though each of the possible scores have approximate time values associated with them, we vote in points, not time. Scoring with points prevents getting into weedsy debates about exactly how long something will take, and instead focuses us on the requirements and difficulty of the story. Poker card definitions These how we define our poker cards: Card Value ¼ An hour or two. Anything smaller than this isn't worth bringing into a sprint or even ticketing—just do it right now. ½ About half of an \"ideal\" day. We define an \"ideal\" day as one without meetings or interruptions. Using \"ideal\" days makes it easier to estimate a story without litigating the details of how we spend our time. 1 About one \"ideal\" day. This is one of our most common story sizes. 1½ About one and a half \"ideal\" days. This is our other most common story size. 2 About two \"ideal\" days. 3 About three \"ideal\" days. We jump from 2 straight to 3 to avoid unrealistic granularity in our estimates. 5 About a week of work. 7 About a full sprint (two weeks) of work. We very rarely use this card—a ticket that takes a full sprint on its own is almost always too large and should be chunked into smaller, incremental tickets. Break! \"I need a break.\" When someone plays a break card, we finish estimating the current story then immediately take a five minute break. Defer No strong opinion. Don't play this card on the first round of poker! Seeing wildly different estimates is a sign we don't have a shared understanding of the work. Playing an early Defer card can mask that uncertainty. How we calculate the points budget In order to ensure we're not filling up our sprint with more \"ideal days\" of time than we realistically have available, we calculate the points budget based on the actual output of the team. Over time, we've found writers average 0.6 (technically, 0.57) points per day. Tip This value is totally unique to each team! A high number doesn't indicate a more productive team, and a low number isn't a problem. Story points are only meaningful within a team. If you're starting a new team or new process, you'll need to zero in on the ideal number of points per writer. An easy way to figure out the right budget is to have the team vote in retro on whether to increase, decrease, or keep the same budget next sprint. You'll overshoot or undershoot a few times, but after a couple sprints you'll get a good sense of what constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let's say 5 writers and a 10 business day (2 calendar week) sprint. Or, 50 person-days total. Subtract out time off days, plus 1 day for each day of hero duty. Let's say we have 1 writer on vacation in Maui, and 1 day of hero time per day. 50 person days, minus 10 days of vacation and 10 days of hero time, gives us 30 person-days. Multiply the number of days times the average velocity per writer, per day. Our average velocity is 0.6 points/writer/day. 30 person days multiplied by 0.6 would give us an 18 point budget for the sprint. Because we work in two squads, we calculate a separate points budget for each squad ahead of sprint planning. ← Meetings and ceremonies Sprint workflow and Jira boards → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1156.4678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Planning poker <em>and</em> points budgets",
        "sections": "Planning poker <em>and</em> points budgets",
        "body": ". Poker card definitions These how we define our poker cards: Card Value ¼ An hour or two. Anything smaller than this isn&#x27;t worth bringing into a sprint or even ticketing—just do it right now. ½ About half of an &quot;ideal&quot; day. We define an &quot;ideal&quot; day as one without <em>meetings</em> or interruptions. Using"
      },
      "id": "616c0e2d28ccbc6e5e00337f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/ticket-best-practices/",
      "sections": [
        "Ticket best practices: How to write a sprint-ready Jira",
        "Tip",
        "Why do we use Jira?",
        "What work needs a ticket?",
        "Keeping tickets up-to-date",
        "Add Jira context to PRs and commits",
        "Checklist for writing a good ticket",
        "For more help"
      ],
      "published_at": "2021-10-24T19:34:40Z",
      "title": "Ticket best practices: How to write a sprint-ready Jira",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "2109a54437970761f71a3940f189b7f10aef0bc1",
      "document_type": "page",
      "popularity": 1,
      "body": "Jira, a project management tool made by Atlassian, is how we manage our projects and understand the work we are doing and have done. Jira tickets may seem at first to be simple to-do lists that we use to know what things to do for a project. But they are much more important than that. Tip For Relics: Use the docs.newrelic.com/jira template when you create a ticket! It'll automatically pre-fill your ticket with a template that helps create a good ticket. Why do we use Jira? We create tickets to record work-to-be done for a project, scope new work, share information for any writer to complete a story, forecast our output and to estimate project timelines, and have a record of work done. In other words, Jira has a role at every point in a project: Before a project Scoping, syncing on expectations, giving tech writer instructions During a project Keeps team and management posted about project; allows for hand-offs and swarming After a project Understand what work we did, and helps researching on future projects What work needs a ticket? There aren't hard-and-fast rules about what work needs a Jira ticket and what doesn't. A good shorthand is that any project that takes more than a couple hours is a good candidate for a ticket. However, the goal of creating tickets is not to track writer time in detail. So many kinds of work (meetings, ongoing minor liaison tasks, hero work) generally do not need to go into Jira. Keeping tickets up-to-date In general, you should write your tickets as though you might win the lottery tomorrow (a principle known as lottery factor or bus factor). In practice, someone should be able to read your ticket and figure out within about ten minutes what the status is and what the next step is. This makes it easy for us to take vacations, pass work off to another docs writer if needed, and escalate blockers. These things help with lottery factor: Update the Action Item list as you complete tasks and add or remove scope. When you move a ticket to Blocked, include a note explaining the change in status. When you close a ticket, give a summary of the work done and any relevant thoughts you have on the work and potential related issues. Update the Timeline, People, and Resources sections as the project evolves. Add important conversations (emails or Slack convos from SMEs) that give important context for the work done. (Note: It's a good idea to ask permission before doing this, because some people might not like their informal words placed in a public place.) Add Jira context to PRs and commits When you edit the site, include the Jira issue key (DOC-1234, for example) in your pull request title and/or commit summary. That makes it easier for other writers to connect the dots later if we're trying to figure out why something changed or who knows about a particular subject. Checklist for writing a good ticket Helpful title A ticket name should be easy to find via search, understand the work at a glance, mention the product or feature, and describe the goal or issue. Examples of good ticket titles: Browser API: Update custom attribute-related docs or Distributed tracing: Add more detail about CAT relationship. Action items An action item list describing the work to be done What docs are affected Links to pull requests, Google Docs drafts, etc. How substantial the writing work is in each doc How the resulting work should be structured Whether or not a peer edit is needed Anyone who should be notified when a doc is published Proper sizing Story is scoped to the smallest reasonable size Can be completed within a 2 week sprint Delivers incremental value Dates Publication date or due date Dates for other key events (betas, limited releases, etc.) Resources and people People, including last names and roles List of related or affected docs Other internal and external resources Related issues Labels and fields Jira tickets: Component, Product Group, and Priority GitHub issues: from_, pg_, and content labels ← Managing the GitHub boards Appendix: Project scoping cheatsheet → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.869232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Add Jira context to PRs <em>and</em> commits",
        "body": " a couple hours is a good candidate for a ticket. However, the goal of creating tickets is not to track writer time in detail. So many kinds of work (<em>meetings</em>, ongoing minor liaison tasks, hero work) generally do not need to go into Jira. Keeping tickets up-to-date In general, you should write your"
      },
      "id": "616c0d9628ccbc919400346e"
    }
  ],
  "/docs/agile-handbook/sprint-mechanics/planning-poker": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/meetings-and-ceremonies/",
      "sections": [
        "Meetings and ceremonies",
        "Tip",
        "Sprint planning",
        "Backlog grooming",
        "Retro",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Meetings and ceremonies",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "873983fa778f17f1a92871ed4ad7673b333d4acc",
      "document_type": "page",
      "popularity": 1,
      "body": "Monday Tuesday Wednesday Thursday Friday Week 1 Sprint retro (every other sprint) Backlog grooming (end of sprint) Sprint planning (start of new sprint) Team meeting Meeting-free day Week 2 Team meeting Meeting-free day We break our work into two-week sprints. The new sprint starts on a Tuesday with sprint planning, where we commit to a set of stories that we're confident we can complete by the end of the sprint. Near the end of the sprint, we prepare for the next sprint with backlog grooming. The sprint closes with a retro where we discuss what went right and what went wrong, and then we kick off a new cycle. Each squad does their own backlog grooming and sprint planning, and manages their sprint backlog independently. We do retros together so we can talk through issues that affect both squads and share expertise and ideas. Tip Why do we end sprints on Mondays and start Tuesdays? This funny schedule makes things easier to work across timezones. If we ended sprints on Fridays, our Barcelona-based writers would need to do retros and grooming on Friday evening, and who wants that? Sprint planning On the first Tuesday of a new sprint, we commit to a series of stories until we have filled our capacity for the sprint. This is the largest meeting in the sprint---about 60 to 90 minutes. Before the sprint planning meeting, the scrum master for each squad calculates their point budget. Then, during the meeting: We select the highest priority item in the backlog. The person who nominated the story introduces it, and the team asks questions until everyone feels ready to vote. The team plays planning poker. Everyone secretly chooses a card, then we reveal them at the same time: If everyone picks the same card, that's the point value and we move on. If there's an even split between two cards, we choose the larger and move on. If it's mixed, the highest and lowest voters briefly explain their votes. Then we vote again. Once we're sure we can fit the story in, we subtract its story points from the sprint's points budget. We repeat the above steps until we've used up our points budget. We generally avoid pre-assigning people to stories during sprint planning. Instead, we pick up the next story or peer edit in the To Do column as stories are completed. Backlog grooming The day before the sprint starts, we do two rounds of backlog grooming. The purpose of backlog grooming is to prioritize work for sprint planning, and identify stories that need to be fixed before sprint planning to ensure scope is clear and planning runs smoothly. The first round of backlog grooming is by squad, where the members and manager of the squad get together and work through the grooming checklist. Then we do a second round of grooming with the managers and scrum masters to look at the sprint backlog for both squads and ensure nothing is or has fallen through the cracks. In the grooming, we: Each writer brings their personal \"top five\" tickets. The manager works with writers to prioritize those into a single, stack-ranked list for the team. We talk through stories and ensure they look ready for sprint planning (essentially, do they fit the Checklist for story readiness?). After grooming, the scrum master sends out a list of \"homework\" for stories that need improving. Retro Every other sprint, we conduct a 60 minute retrospective meeting, where we discuss: How do we feel about the sprint? What went well? Where can we improve? Anything we should start or stop doing? The goal of the retro is to improve the way we work together. That could be related to the sprint process, to how we collaborate with SMEs, to peer edits, and so on. ← Agile roles Planning poker → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.86806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Meetings <em>and</em> ceremonies",
        "sections": "Sprint <em>planning</em>",
        "body": " filled our capacity for the sprint. This is the largest meeting in the sprint---about 60 to 90 minutes. Before the sprint <em>planning</em> meeting, the scrum master for each squad calculates their <em>point</em> <em>budget</em>. Then, during the meeting: We select the highest priority item in the backlog. The person who"
      },
      "id": "616c0dfa196a679fd43c9791"
    },
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "For more help"
      ],
      "published_at": "2021-10-24T23:21:06Z",
      "title": "Sprint workflow",
      "updated_at": "2021-10-17T11:49:20Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it maes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. ← Planning poker Liaisonships → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.56944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Planned</em> work",
        "body": " current. Note why we moved to the backlog rather than carry over. ← <em>Planning</em> <em>poker</em> Liaisonships → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dc0196a67e6583c8164"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/key-agile-principles/",
      "sections": [
        "Key agile principles for our team",
        "Focus on the team's work",
        "Maximize swarming",
        "Enforce our points budgets",
        "Work incrementally",
        "Encourage self-service edits",
        "For more help"
      ],
      "published_at": "2021-10-24T23:20:14Z",
      "title": "Key agile principles for our team",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "749e499964c577501e9ae64249513d23f3d97cdb",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses a fairly \"by the book\" agile-scrum implementation, with the understanding that we can tweak the workflow as needed to work better for our flow. This handbook doesn't describe every aspect of how a sprint system should work, but focuses on the specific choices our team made as we evolved our agile process. As we evolve the system, it's helpful to know what our goals are. That can help illuminate whether a problem with the system is worth solving, and how to solve it without compromising on the essential things that make the team run smoothly. Focus on the team's work Our goal is for our team to deliver the most valuable work for the business and our users, every sprint. This description from Scrum: A Breathtakingly Brief and Agile Introduction nails what that means in practice: The role of each and every team member is to help the team deliver potentially shippable product in each sprint. Often, the best way to do this is by contributing work in their area of specialty. Other times, however, the team will need them to work outside of their area of specialty in order to best move backlog items from \"in progress\" to \"done.\" What we are describing is a mindset change from \"doing my job\" to \"doing the job.\" We aim to complete 100% of our work every sprint. In practice this is rarely attainable: We know that dates will move, scopes will expand, or our estimates will be wrong. But we've found that this 100% benchmark ensures we prioritize our shared team goal (the sprint), rather than our individual deliverables. Maximize swarming We want writers to build expertise, but we don't want to isolate ourselves. An alerts team at New Relic summed it up nicely: Our philosophy is, \"The team is the unit of work.\" This means that teams contribute to projects, teams solve problems, etc. We don't assign projects to individuals, and no one should ever be a single point of failure in the organization. If your team struggles to function effectively without you, your flexibility to take time off will be very limited. In such a case, we need to improve the skills and overall health of your team, ensure the team is setup for success, and ensure we have an appropriate team structure and charter in place. And an ops team demonstrates the most important practical implication: Our intention for tickets is that anyone should be able to select a task and have the information needed to understand and start on the work. Sometimes, this means we work a little slower in order to learn or teach something---and that's okay! Ultimately, working this way makes our team more resilient and makes it easier for New Relic to get consistent, high-quality docs. The Ticket best practices doc describes in detail the rules and best practices we've discovered help us achieve this. Enforce our points budgets Our team votes on all stories brought into a sprint, and we cap the number of stories based on our points budget. We generally vote as though the least-experienced person on the team will take the ticket. Having a strict points budget allows us to protect the team from overwork, predict our velocity over time, and ensure we actually have enough time to finish our work. Work incrementally Our goal is to deliver value as often as possible. Work that sits in a draft state for a long time can easily become wasted work: SMEs can become unavailable, priorities can change, and our knowledge can become stale. In practice, this means we work in fairly short two week sprints, publish early and often, and plan our projects so we can easily deliver 70% and then pivot to different priorities if something more important comes along. Encourage self-service edits Anyone can edit our open-sourced docs. With hundreds of Relics and users editing the docs each year, we can spend more of our writing time on high-impact work rather than simple maintenance edits. In order to reward teams that help us work this way, we prioritize this work in our queue. For work the writers need to do themselves, we ask for at least one full sprint of lead time. If someone comes to us the Tuesday after a sprint starts, that means they could be waiting up to two weeks for us to kick off work! But if someone edits the docs themselves, we promise to get their edit live within a 1 to 3 business day SLA. This lets us create win-wins: Rather than a simple \"no,\" a requestor can decide whether they truly need that content out now (in which case they can create that first draft) or whether they're okay waiting a week or two. ← Agile vs sprints: A profusion of terms Agile roles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.15187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Enforce our <em>points</em> <em>budgets</em>",
        "body": " practices doc describes in detail the rules and best practices we&#x27;ve discovered help us achieve this. Enforce our <em>points</em> <em>budgets</em> Our team votes on all stories brought into a sprint, and we cap the number of stories based on our <em>points</em> <em>budget</em>. We generally vote as though the least-experienced person"
      },
      "id": "616c0d96196a6768873c845b"
    }
  ],
  "/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards": [
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-24T23:20:14Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1042.0873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Agile vs <em>sprints</em> (vs Jira vs GitHub): A profusion of terms",
        "sections": "Agile vs <em>sprints</em> (vs Jira vs GitHub): A profusion of terms",
        "body": "Our team uses an agile <em>Sprint</em> <em>workflow</em> in Jira and GitHub to manage our work. We&#x27;ve further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let&#x27;s break them down further. Agile People use agile to mean"
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/planning-poker/",
      "sections": [
        "Planning poker and points budgets",
        "Poker card definitions",
        "How we calculate the points budget",
        "Tip",
        "For more help"
      ],
      "published_at": "2021-10-24T23:22:20Z",
      "title": "Planning poker and points budgets",
      "updated_at": "2021-10-17T11:51:09Z",
      "type": "docs",
      "external_id": "d002b0635204648ebe36dbdc6c242e80fa971aa3",
      "document_type": "page",
      "popularity": 1,
      "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the team. Then, the team all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most agile teams that estimate with planning poker use cards that follow a Fibonacci sequence. We've found over the years that those large jumps weren't very helpful to us in estimating, and that we estimated better with smaller numbers. So we use fairly small, granular numbers that roughly break down to 1 point ≈ 1 day. Note that even though each of the possible scores have approximate time values associated with them, we vote in points, not time. Scoring with points prevents getting into weedsy debates about exactly how long something will take, and instead focuses us on the requirements and difficulty of the story. Poker card definitions These how we define our poker cards: Card Value ¼ An hour or two. Anything smaller than this isn't worth bringing into a sprint or even ticketing—just do it right now. ½ About half of an \"ideal\" day. We define an \"ideal\" day as one without meetings or interruptions. Using \"ideal\" days makes it easier to estimate a story without litigating the details of how we spend our time. 1 About one \"ideal\" day. This is one of our most common story sizes. 1½ About one and a half \"ideal\" days. This is our other most common story size. 2 About two \"ideal\" days. 3 About three \"ideal\" days. We jump from 2 straight to 3 to avoid unrealistic granularity in our estimates. 5 About a week of work. 7 About a full sprint (two weeks) of work. We very rarely use this card—a ticket that takes a full sprint on its own is almost always too large and should be chunked into smaller, incremental tickets. Break! \"I need a break.\" When someone plays a break card, we finish estimating the current story then immediately take a five minute break. Defer No strong opinion. Don't play this card on the first round of poker! Seeing wildly different estimates is a sign we don't have a shared understanding of the work. Playing an early Defer card can mask that uncertainty. How we calculate the points budget In order to ensure we're not filling up our sprint with more \"ideal days\" of time than we realistically have available, we calculate the points budget based on the actual output of the team. Over time, we've found writers average 0.6 (technically, 0.57) points per day. Tip This value is totally unique to each team! A high number doesn't indicate a more productive team, and a low number isn't a problem. Story points are only meaningful within a team. If you're starting a new team or new process, you'll need to zero in on the ideal number of points per writer. An easy way to figure out the right budget is to have the team vote in retro on whether to increase, decrease, or keep the same budget next sprint. You'll overshoot or undershoot a few times, but after a couple sprints you'll get a good sense of what constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let's say 5 writers and a 10 business day (2 calendar week) sprint. Or, 50 person-days total. Subtract out time off days, plus 1 day for each day of hero duty. Let's say we have 1 writer on vacation in Maui, and 1 day of hero time per day. 50 person days, minus 10 days of vacation and 10 days of hero time, gives us 30 person-days. Multiply the number of days times the average velocity per writer, per day. Our average velocity is 0.6 points/writer/day. 30 person days multiplied by 0.6 would give us an 18 point budget for the sprint. Because we work in two squads, we calculate a separate points budget for each squad ahead of sprint planning. ← Meetings and ceremonies Sprint workflow and Jira boards → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 662.7217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " and ceremonies <em>Sprint</em> <em>workflow</em> and Jira boards → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0e2d28ccbc6e5e00337f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/liaisonships/",
      "sections": [
        "Liaisonships",
        "Liaison responsibilities: Manage project flow",
        "Liaison responsibilities: Build expertise",
        "Liaison responsibilities: Define content strategy (oh, and do the writing)",
        "For more help"
      ],
      "published_at": "2021-10-24T19:34:40Z",
      "title": "Liaisonships",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "bf8ec36541058fe18f8395db811344baf7f23e22",
      "document_type": "page",
      "popularity": 1,
      "body": "For large projects, we'll typically assign a particular tech writer to that project as a \"liaison.\" The liaison’s job is to ensure that we get complete, consistent, and timely docs. Not every project gets a liaisonship! For smaller projects, we'll encourage teams to edit the docs directly, and then have the hero review their changes. And a smallish project may not need a full liaison—a single ticket might be enough to manage the work. To figure out which type of support is best for a given project, one of the managers on the team will have a scoping conversation with a subject matter expert. Here's a few reasons a project might get a dedicated liaison: Project is complex and would benefit from intimate familiarity with the feature. Project requires significant information architecture work. Project will produce enough docs that consistency across those docs will be hard to achieve without a centralized editor. Project SMEs would benefit from a consistent \"face\" of the tech writing team. However, a liaison is not the only author on a project. Liaisons should structure their work to maximize swarming and knowledge sharing. Liaison responsibilities: Manage project flow Activity Who? Notes Learn new thing exists Team Ideally the Hero or a Tech Docs manager gets notified directly by a PM about a new project. But sometimes we'll find out about something unexpectedly. If you're not sure whether we have a writer working on something, ask a manager on the team and they'll reach out to the subject matter expert to scope it. Have a scoping meeting Tech Docs manager The manager is responsible for tracking the general state of major projects across the company, and is generally the first point of contact for new projects. When a large new project comes up, the manager will do a pre-scope meeting with the requestor. (Appendix: Project scoping cheatsheet has a list of common questions for this pre-scope meeting.) That conversation helps figure out timeline, complexity, key docs considerations, and which writer will be a good fit as liaison. Assign a liaison Tech Docs manager Once we know we need a liaison, a manager on our team will figure out who to assign. Some of the factors we use to decide who to assign include bandwidth, familiarity with the product or feature, career goals and writing strengths, and simple interest in the topic. Keep track of project dates Liaison The managers on the team keep track of upcoming projects that don't have a liaison assigned. Once a writer gets involved, that liaison keeps track of the specifics of dates: Betas, limited releases, GAs, fast-follows, and so on. Your manager's always here to help out if you're getting blocked or dates are shifting too rapidly to plan properly. Validate the docs plan with the project team Liaison The liaison works with their stakeholders to define the information architecture and deliverables. Create tickets Liaison Since the liaison defines the information architecture, the liaison will know what kinds of deliverables we need. The liaison also acts as an advocate for their tickets in the backlog grooming and sprint planning processes, and ensures their stories meet the story quality requirements. The liaison should also ensure that our partner teams have appropriate tickets in their backlogs for their work. Remove blockers (such as reviewer delay) Liaison + Manager While the liaison is primarily responsible for handling SME relationships and removing day-to-day blockers, your manager is here to help unstick things anytime you need help. Wrap up the liaisonship Liaison Liaisonships are not forever assignments! When the bulk of your work on a project is complete, it might be time to consider ending the liaisonship. Reach out to your manager to talk about it. When you end it, let stakeholders know and update the liaison roster. Also let your stakeholders know they can always ping the docs hero for help or if they have a new project. Liaison responsibilities: Build expertise Activity Who? Notes Develop a deep expertise on feature and audience. Liaison Become the Docs Team's local expert on the feature. Understand what it does, what problems it solves, and the implications for our content. Educate the team on the feature Liaison Part of your responsibility as liaison is to share expertise around the team. That helps with swarming, but it also makes for better hero review and a smarter team that can write more intelligently about the entire New Relic One platform. Coordinate with design and/or research and test your docs Liaison Reach out to the designer and/or researcher for the project, and periodically sync on any shared concerns, user needs, etc. And you should advocate for user testing and validation of your content. Liaison responsibilities: Define content strategy (oh, and do the writing) Activity Who? Notes Define the information architecture Liaison As liaison, you're the expert on both the feature the product team is building, and the docs content (new and existing) that will support that feature. Build an IA that will meet all project needs and scale to the future. Write content Team The liaison writes much of the content for their project, especially the conceptual content like intro docs. But the whole team is expected to swarm and contribute to large projects, with the liaison coordinating that work. Peer edit drafts Liaison When we swarm and have someone else contribute to the project, the liaison peer edits their drafts to ensure consistency with the overall vision. Coordinate publication Liaison When the time comes to release (whether that's beta, GA, limited release, or EoL), it's the liaison's job to coordinate with PM, Eng, and Product Marketing to ensure docs go out on time with other deliverables. ← Sprint workflow and Jira boards What is a hero? → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 498.32938,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ", and Product Marketing to ensure docs go out on time with other deliverables. ← <em>Sprint</em> <em>workflow</em> and Jira boards What is a hero? → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d97e7b9d227264780c5"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.99026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection <em>with</em> <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection <em>with</em> <em>Applied</em> <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>Applied</em> <em>Intelligence</em>&#x27;s Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.02585,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "sections": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "As part of <em>Applied</em> <em>Intelligence</em>, Incident <em>Intelligence</em> helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident <em>Intelligence</em> Before setting up Incident <em>Intelligence</em>, note"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": ", sys_choice, sys_user, <em>change</em>_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.9669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to <em>Incident</em> <em>Intelligence</em>. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the <em>Applied</em> <em>Intelligence</em> Slack application to your selected channel"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 327.289,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " get context and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.21387,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> workflows",
        "sections": "<em>Incident</em> workflows",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " entities.kinds Impacted Entities Kinds <em>incident</em>Ids <em>Incident</em> IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels <em>Alerts</em> Aggregation Key labels.conditionNames Labels <em>Alert</em> Condition Names labels.originalAccountIds"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.96667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to <em>Incident</em> <em>Intelligence</em>. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the <em>Applied</em> <em>Intelligence</em> Slack application to your selected channel"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.21379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> workflows",
        "sections": "<em>Incident</em> workflows",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " entities.kinds Impacted Entities Kinds <em>incident</em>Ids <em>Incident</em> IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels <em>Alerts</em> Aggregation Key labels.conditionNames Labels <em>Alert</em> Condition Names labels.originalAccountIds"
      },
      "id": "603e967664441f7e6f4e889b"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-24T19:52:38Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.96419,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.96667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to <em>Incident</em> <em>Intelligence</em>. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the <em>Applied</em> <em>Intelligence</em> Slack application to your selected channel"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 327.28888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " get context and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.21379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> workflows",
        "sections": "<em>Incident</em> workflows",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " entities.kinds Impacted Entities Kinds <em>incident</em>Ids <em>Incident</em> IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels <em>Alerts</em> Aggregation Key labels.conditionNames Labels <em>Alert</em> Condition Names labels.originalAccountIds"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/rest-api-applied-intelligence": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.96667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to <em>Incident</em> <em>Intelligence</em>. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the <em>Applied</em> <em>Intelligence</em> Slack application to your selected channel"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 327.28888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " get context and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.21379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> workflows",
        "sections": "<em>Incident</em> workflows",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " entities.kinds Impacted Entities Kinds <em>incident</em>Ids <em>Incident</em> IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels <em>Alerts</em> Aggregation Key labels.conditionNames Labels <em>Alert</em> Condition Names labels.originalAccountIds"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.9665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to <em>Incident</em> <em>Intelligence</em>. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the <em>Applied</em> <em>Intelligence</em> Slack application to your selected channel"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 327.28882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " get context and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.21373,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> workflows",
        "sections": "<em>Incident</em> workflows",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " entities.kinds Impacted Entities Kinds <em>incident</em>Ids <em>Incident</em> IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels <em>Alerts</em> Aggregation Key labels.conditionNames Labels <em>Alert</em> Condition Names labels.originalAccountIds"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows": [
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 368.33673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>workflows</em>",
        "sections": "<em>Incident</em> <em>workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "EOL NOTICE We&#x27;re discontinuing support for several capabilities in November 2021, including the <em>Incident</em> <em>Workflows</em> beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With <em>incident</em> <em>workflow</em> control when and where you want to receive"
      },
      "id": "603e967664441f7e6f4e889b"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to <em>Incident</em> <em>Intelligence</em>. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the <em>workflow</em> to add the <em>Applied</em> <em>Intelligence</em> Slack application to your selected channel"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.2092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " get context and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add"
      },
      "id": "603ea62e64441f119f4e883f"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.87683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to <em>Incident</em> <em>Intelligence</em>. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the <em>workflow</em> to add the <em>Applied</em> <em>Intelligence</em> Slack application to your selected channel"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "BETA FEATURE",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-09-14T20:01:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.9716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "sections": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "BETA FEATURE This feature is currently in beta. With <em>Incident</em> <em>Workflows</em>, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the <em>workflow</em>, and violation attributes are transferred into the notification creation. Custom variables are violation"
      },
      "id": "603e7a6528ccbcad47eba77f"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.20914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " get context and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add"
      },
      "id": "603ea62e64441f119f4e883f"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/algorithmia-mlops-integration": [
    {
      "sections": [
        "DagsHub MLOps integration",
        "What is MLOps?",
        "The DagsHub integration",
        "Integrate DagsHub with New Relic",
        "View and explore your DagsHub models in New Relic dashboards"
      ],
      "title": "DagsHub MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOps integrations",
        "DagsHub integrations"
      ],
      "external_id": "7a93ba8b53a1d905a60dcdfc242ffa4ab9e03ae2",
      "image": "https://docs.newrelic.com/static/d78db1e800d8c753d87ad615803b3411/c1b63/dagshub1.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/dagshub-mlops-integration/",
      "published_at": "2021-10-24T23:55:00Z",
      "updated_at": "2021-10-23T17:33:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "What is MLOps? MLOps stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there's a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those models. MLOps provides a tool for monitoring and observing the performance and effectiveness of machine-learning models in a production environment. This increases the possibilities for collaboration between data science and DevOps teams, feeding into a continuous process of development, testing, and operational monitoring. The DagsHub integration DagsHub is a platform for data scientists and machine learning engineers to version and sync their data, models, experiments, and code. It allows you and your team to easily share, review and reuse your work, providing a GitHub-like experience for machine learning. DagsHub is built on popular open-source tools and formats, making it easy to integrate with the tools you already use like New Relic. New Relic now offers an integration with DagsHub to monitor and analyze your machine learning training metrics in real-time. Integrate DagsHub with New Relic Integrating DagsHub and New Relic enables you to analyze and monitor machine learning training metrics in real-time. You can visualize your metrics in a New Relic dashboard, create custom metrics, and set alerts to notify you of events and incidents happening during your training runs. In order to receive data from DagsHub into New Relic, you need your account number and a special key which you can obtain as follows: Log into your New Relic account: Go to one.newrelic.com, and click Explorer. On the upper hand right corner, on the main navigation menu, click on +Add more data. Click on DagsHub: Type DagsHub in the search bar, or scroll down to the MLOps Integration section, and click the DagsHub icon. Select the account ID you want DagsHub to integrate with. Create an access token: Once you've selected an account ID, under real-time insert metrics, click Create an API key . This will be your new telemetry API key. Keep the New Relic page open for future steps. Log into the DagsHub portal and select the repository you're working on. Click Settings, and select the integrations button from the left hand menu. Click on the New Relic tile. Copy and paste the token in DagsHub. Go back to the New Relic integration dashboard and copy the token you created by clicking on the copy icon next to the insert key. On the DagsHub’s portal, paste the insert key under New Relic Insight insert key, and finish by clicking Next. The token will be verified, and a confirmation screen will appear. View and explore your DagsHub models in New Relic dashboards Once you configure the New Relic integration in DagsHub, all the training metrics logged to DagsHub in real time are sent to New Relic. Go to the DagsHub integration dashboard: Once you’ve tested your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. You will be redirected to an automatically generated New Relic dashboard powered by DagsHub. Analyze the DagsHub dashboard: The DagsHub dashboard contains one chart, Loss metric by repository, which displays the loss of your models, grouped by their respective repository. It works for any models that you have trained. Display customized metrics: You can easily customize training metrics coming from DagsHub. For more information on using NRQL and creating queries to track your data, refer to NRQL syntax, clauses, and functions. Set up alerts notifications: Once you've created some dashboards, you can get alerted on your data. To create NRQL alerts conditions from a chart, click the ... chart menu, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy, or create a new one. Get notified: Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. You’ve now successfully integrated New Relic with DagsHub. Newly created alerts are correlated with your New Relic alerts, and you'll see data about newly reported predictions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.5589,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "DagsHub <em>MLOps</em> <em>integration</em>",
        "sections": "DagsHub <em>MLOps</em> <em>integration</em>",
        "tags": "<em>MLOps</em> <em>integrations</em>",
        "body": "What is <em>MLOps</em>? <em>MLOps</em> stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there&#x27;s a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those"
      },
      "id": "6175f254196a67a8242f0923"
    },
    {
      "sections": [
        "Cloud services integrations",
        "AWS integrations",
        "GCP integrations",
        "Azure integrations"
      ],
      "title": "Cloud services integrations",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Instrument core services and applications"
      ],
      "external_id": "509277aa4f9f8ad66cf5f82a94104531df64c296",
      "image": "https://docs.newrelic.com/static/78ac85c1fc41f94776fce7235e327f01/69538/img-integration-aws%25402x.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/cloud-services-integrations/",
      "published_at": "2021-10-25T16:29:51Z",
      "updated_at": "2021-10-24T00:48:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.520916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cloud services <em>integrations</em>",
        "sections": "Cloud services <em>integrations</em>",
        "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS <em>integrations</em> Introduction to AWS <em>integrations</em> List of AWS <em>integrations</em> GCP <em>integrations</em> Introduction to GCP <em>integrations</em> List of GCP <em>integrations</em> Azure <em>integrations</em> Introduction to Azure <em>integrations</em> List of Azure <em>integrations</em>"
      },
      "id": "603e829ae7b9d20bb12a080c"
    },
    {
      "sections": [
        "PowerDNS monitoring integration",
        "BETA FEATURE",
        "Compatibility and requirements",
        "Install and activate",
        "Linux installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "PowerDNS instance settings",
        "Example configurations",
        "Basic configuration",
        "Find and use data",
        "Metric data",
        "Check the source code"
      ],
      "title": "PowerDNS monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "e84cc75e844cd8780c859ff6ae4730a8c561b29d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/powerdns-monitoring-integration/",
      "published_at": "2021-10-24T22:02:11Z",
      "updated_at": "2021-10-24T02:18:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in open beta and only applies to the versions starting on 0.0.5 released in October 2021. Our PowerDNS integration collects and sends dimensional metrics from PowerDNS. You can view this metric data in pre-built dashboards, create alert policies, and create custom queries and charts. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with PowerDNS Recursor and Authoritative. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent, minimum version 1.19.2. Linux distribution compatible with the infrastructure agent. The integration obtains data by scrapping the PowerDNS API through a Prometheus exporter. To enable the API, the webserver and the HTTP API need to be enabled. Add these lines to the pdns.conf: api=yes api-key=changeme Copy And restart, the following examples should start working: curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1/servers/localhost | jq . curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1 Copy For more information, Enabling Webserver and Api Install and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp powerdns-config.yml.sample powerdns-config.yml Copy Edit the powerdns-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration To configure the integration, edit the config in the integration's YAML configuration file powerdns-config.yml. Use the YAML configuration to place required login credentials and configure how your data is collected, depending on your setup and preference. Since this integration is based on a prometheus exporter, settings applicable to other integrations, like interval, timeout or inventory_source are not supported. PowerDNS instance settings The PowerDNS integration collects dimensional Metrics: Setting Description Default powerdns_url API URL of the powerdns service N/A exporter_port Port to expose scrape endpoint on, If this is not provided a random port will be used to launch the exporter random-port api_key API key used to connect to the PowerDNS server N/A Example configurations Basic configuration This is the basic configuration used to collect metrics from an authoritative and a recursor instance: integrations: - name: nri-powerdns config: api_key: authoritative-secret exporter_port: 9121 powerdns_url: http://localhost:8081/api/v1/ - name: nri-powerdns config: api_key: recursor-secret exporter_port: 9122 powerdns_url: http://localhost:8082/api/v1/ Copy Find and use data For more on how to find and use your data, see Understand integration data. Metrics are attached to the Metric sample and event types of the entities POWERDNS_AUTHORITATIVE and POWERDNS_RECURSOR. You can query this data for troubleshooting purposes, or to create custom charts and dashboards. Metric data The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_AUTHORITATIVE: Name Description Dimensions powerdns_authoritative_uptime (count) Uptime in seconds of the daemon. type powerdns_authoritative_packet_cache_size (gauge) Number of entries in the packet cache. powerdns_authoritative_recursive_queries_total (count) Total number of recursive queries by status. status powerdns_authoritative_remote_queries (count) Remote server IP addresses. remote powerdns_authoritative_security_status (gauge) PDNS Server Security status based on security-status.secpoll.powerdns.com. powerdns_authoritative_exceptions_total (count) Total number of exceptions by error. error powerdns_authoritative_latency_average_seconds (gauge) Average number of microseconds a packet spends within PowerDNS. powerdns_authoritative_dnsupdate_queries_total (count) Total number of DNS update queries by status. status powerdns_authoritative_qsize (gauge) Number of packets waiting for database attention. powerdns_authoritative_response_rcodes (count) Distribution of rcodes. rcode powerdns_authoritative_signature_cache_size (gauge) Number of entries in the signature cache. powerdns_authoritative_queries_unauth (count) Queries for domains that we are not authoritative for. record powerdns_authoritative_answers_bytes_total (count) Total number of answer bytes sent over by protocol. proto powerdns_authoritative_queries (count) UDP Queries Received. record powerdns_authoritative_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_authoritative_deferred_cache_actions (count) Deferred cache actions because of maintenance by type. type powerdns_authoritative_up (gauge) The last scrape of PowerDNS was successful. powerdns_authoritative_query_cache_lookup (count) Query cache lookups by result. result powerdns_authoritative_key_cache_size (gauge) Number of entries in the key cache. powerdns_authoritative_answers_total (count) Total number of answers by protocol. proto powerdns_authoritative_packet_cache_lookup (count) Packet cache lookups by result. result powerdns_authoritative_metadata_cache_size (gauge) Number of entries in the metadata cache. powerdns_authoritative_queries_total (count) Total number of queries by protocol. proto powerdns_authoritative_cpu_utilisation (count) Number of CPU milliseconds spent in user, and kernel space. type powerdns_authoritative_dnssec (count) DNSSEC counters. type powerdns_authoritative_response_sizes (count) Size distribution of responses. size powerdns_authoritative_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_authoritative_remote_queries_unauth (count) Remote hosts querying domains for which we are not authoritative. remote The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_RECURSOR: Name Description Dimensions powerdns_recursor_incoming_queries_total (count) Total number of incoming queries by network. net powerdns_recursor_outgoing_queries_total (count) Total number of outgoing queries by network. net powerdns_recursor_cache_size (gauge) Number of entries in the cache. powerdns_recursor_cache_lookups_total (count) Total number of cache lookups by result. result powerdns_recursor_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_recursor_answers_rcodes_total (count) Total number of answers by response code. rcode powerdns_recursor_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_recursor_concurrent_queries (gauge) Number of concurrent queries. powerdns_recursor_answers_rtime_total (count) Total number of answers grouped by response time slots. timeslot powerdns_recursor_latency_average_seconds (gauge) Exponential moving average of question-to-answer latency. powerdns_recursor_exceptions_total (count) Total number of exceptions by error. error powerdns_recursor_response_time_seconds_sum (count) Histogram of PowerDNS recursor response times in seconds. (sum metric) powerdns_recursor_response_time_seconds_bucket (count) Histogram of PowerDNS recursor response times in seconds. (bucket metric) le powerdns_recursor_up (gauge) The last scrape of PowerDNS was successful. Check the source code This integration is open source software. This means you can browse its source code and send improvements, or create your own fork and build it. Moreover this integration leverages an opensource exporter created by the community.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.05033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "PowerDNS monitoring <em>integration</em>",
        "sections": "PowerDNS monitoring <em>integration</em>",
        "tags": "<em>Integrations</em>",
        "body": " and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the <em>integrations</em> folder: cd &#x2F;etc&#x2F;newrelic-infra&#x2F;<em>integrations</em>.d Copy Copy of the sample configuration"
      },
      "id": "6174c27628ccbc1575c6b8dd"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/aporia-mlops-integration": [
    {
      "sections": [
        "DagsHub MLOps integration",
        "What is MLOps?",
        "The DagsHub integration",
        "Integrate DagsHub with New Relic",
        "View and explore your DagsHub models in New Relic dashboards"
      ],
      "title": "DagsHub MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOps integrations",
        "DagsHub integrations"
      ],
      "external_id": "7a93ba8b53a1d905a60dcdfc242ffa4ab9e03ae2",
      "image": "https://docs.newrelic.com/static/d78db1e800d8c753d87ad615803b3411/c1b63/dagshub1.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/dagshub-mlops-integration/",
      "published_at": "2021-10-24T23:55:00Z",
      "updated_at": "2021-10-23T17:33:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "What is MLOps? MLOps stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there's a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those models. MLOps provides a tool for monitoring and observing the performance and effectiveness of machine-learning models in a production environment. This increases the possibilities for collaboration between data science and DevOps teams, feeding into a continuous process of development, testing, and operational monitoring. The DagsHub integration DagsHub is a platform for data scientists and machine learning engineers to version and sync their data, models, experiments, and code. It allows you and your team to easily share, review and reuse your work, providing a GitHub-like experience for machine learning. DagsHub is built on popular open-source tools and formats, making it easy to integrate with the tools you already use like New Relic. New Relic now offers an integration with DagsHub to monitor and analyze your machine learning training metrics in real-time. Integrate DagsHub with New Relic Integrating DagsHub and New Relic enables you to analyze and monitor machine learning training metrics in real-time. You can visualize your metrics in a New Relic dashboard, create custom metrics, and set alerts to notify you of events and incidents happening during your training runs. In order to receive data from DagsHub into New Relic, you need your account number and a special key which you can obtain as follows: Log into your New Relic account: Go to one.newrelic.com, and click Explorer. On the upper hand right corner, on the main navigation menu, click on +Add more data. Click on DagsHub: Type DagsHub in the search bar, or scroll down to the MLOps Integration section, and click the DagsHub icon. Select the account ID you want DagsHub to integrate with. Create an access token: Once you've selected an account ID, under real-time insert metrics, click Create an API key . This will be your new telemetry API key. Keep the New Relic page open for future steps. Log into the DagsHub portal and select the repository you're working on. Click Settings, and select the integrations button from the left hand menu. Click on the New Relic tile. Copy and paste the token in DagsHub. Go back to the New Relic integration dashboard and copy the token you created by clicking on the copy icon next to the insert key. On the DagsHub’s portal, paste the insert key under New Relic Insight insert key, and finish by clicking Next. The token will be verified, and a confirmation screen will appear. View and explore your DagsHub models in New Relic dashboards Once you configure the New Relic integration in DagsHub, all the training metrics logged to DagsHub in real time are sent to New Relic. Go to the DagsHub integration dashboard: Once you’ve tested your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. You will be redirected to an automatically generated New Relic dashboard powered by DagsHub. Analyze the DagsHub dashboard: The DagsHub dashboard contains one chart, Loss metric by repository, which displays the loss of your models, grouped by their respective repository. It works for any models that you have trained. Display customized metrics: You can easily customize training metrics coming from DagsHub. For more information on using NRQL and creating queries to track your data, refer to NRQL syntax, clauses, and functions. Set up alerts notifications: Once you've created some dashboards, you can get alerted on your data. To create NRQL alerts conditions from a chart, click the ... chart menu, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy, or create a new one. Get notified: Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. You’ve now successfully integrated New Relic with DagsHub. Newly created alerts are correlated with your New Relic alerts, and you'll see data about newly reported predictions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.5588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "DagsHub <em>MLOps</em> <em>integration</em>",
        "sections": "DagsHub <em>MLOps</em> <em>integration</em>",
        "tags": "<em>MLOps</em> <em>integrations</em>",
        "body": "What is <em>MLOps</em>? <em>MLOps</em> stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there&#x27;s a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those"
      },
      "id": "6175f254196a67a8242f0923"
    },
    {
      "sections": [
        "Cloud services integrations",
        "AWS integrations",
        "GCP integrations",
        "Azure integrations"
      ],
      "title": "Cloud services integrations",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Instrument core services and applications"
      ],
      "external_id": "509277aa4f9f8ad66cf5f82a94104531df64c296",
      "image": "https://docs.newrelic.com/static/78ac85c1fc41f94776fce7235e327f01/69538/img-integration-aws%25402x.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/cloud-services-integrations/",
      "published_at": "2021-10-25T16:29:51Z",
      "updated_at": "2021-10-24T00:48:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.52089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cloud services <em>integrations</em>",
        "sections": "Cloud services <em>integrations</em>",
        "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS <em>integrations</em> Introduction to AWS <em>integrations</em> List of AWS <em>integrations</em> GCP <em>integrations</em> Introduction to GCP <em>integrations</em> List of GCP <em>integrations</em> Azure <em>integrations</em> Introduction to Azure <em>integrations</em> List of Azure <em>integrations</em>"
      },
      "id": "603e829ae7b9d20bb12a080c"
    },
    {
      "sections": [
        "PowerDNS monitoring integration",
        "BETA FEATURE",
        "Compatibility and requirements",
        "Install and activate",
        "Linux installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "PowerDNS instance settings",
        "Example configurations",
        "Basic configuration",
        "Find and use data",
        "Metric data",
        "Check the source code"
      ],
      "title": "PowerDNS monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "e84cc75e844cd8780c859ff6ae4730a8c561b29d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/powerdns-monitoring-integration/",
      "published_at": "2021-10-24T22:02:11Z",
      "updated_at": "2021-10-24T02:18:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in open beta and only applies to the versions starting on 0.0.5 released in October 2021. Our PowerDNS integration collects and sends dimensional metrics from PowerDNS. You can view this metric data in pre-built dashboards, create alert policies, and create custom queries and charts. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with PowerDNS Recursor and Authoritative. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent, minimum version 1.19.2. Linux distribution compatible with the infrastructure agent. The integration obtains data by scrapping the PowerDNS API through a Prometheus exporter. To enable the API, the webserver and the HTTP API need to be enabled. Add these lines to the pdns.conf: api=yes api-key=changeme Copy And restart, the following examples should start working: curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1/servers/localhost | jq . curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1 Copy For more information, Enabling Webserver and Api Install and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp powerdns-config.yml.sample powerdns-config.yml Copy Edit the powerdns-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration To configure the integration, edit the config in the integration's YAML configuration file powerdns-config.yml. Use the YAML configuration to place required login credentials and configure how your data is collected, depending on your setup and preference. Since this integration is based on a prometheus exporter, settings applicable to other integrations, like interval, timeout or inventory_source are not supported. PowerDNS instance settings The PowerDNS integration collects dimensional Metrics: Setting Description Default powerdns_url API URL of the powerdns service N/A exporter_port Port to expose scrape endpoint on, If this is not provided a random port will be used to launch the exporter random-port api_key API key used to connect to the PowerDNS server N/A Example configurations Basic configuration This is the basic configuration used to collect metrics from an authoritative and a recursor instance: integrations: - name: nri-powerdns config: api_key: authoritative-secret exporter_port: 9121 powerdns_url: http://localhost:8081/api/v1/ - name: nri-powerdns config: api_key: recursor-secret exporter_port: 9122 powerdns_url: http://localhost:8082/api/v1/ Copy Find and use data For more on how to find and use your data, see Understand integration data. Metrics are attached to the Metric sample and event types of the entities POWERDNS_AUTHORITATIVE and POWERDNS_RECURSOR. You can query this data for troubleshooting purposes, or to create custom charts and dashboards. Metric data The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_AUTHORITATIVE: Name Description Dimensions powerdns_authoritative_uptime (count) Uptime in seconds of the daemon. type powerdns_authoritative_packet_cache_size (gauge) Number of entries in the packet cache. powerdns_authoritative_recursive_queries_total (count) Total number of recursive queries by status. status powerdns_authoritative_remote_queries (count) Remote server IP addresses. remote powerdns_authoritative_security_status (gauge) PDNS Server Security status based on security-status.secpoll.powerdns.com. powerdns_authoritative_exceptions_total (count) Total number of exceptions by error. error powerdns_authoritative_latency_average_seconds (gauge) Average number of microseconds a packet spends within PowerDNS. powerdns_authoritative_dnsupdate_queries_total (count) Total number of DNS update queries by status. status powerdns_authoritative_qsize (gauge) Number of packets waiting for database attention. powerdns_authoritative_response_rcodes (count) Distribution of rcodes. rcode powerdns_authoritative_signature_cache_size (gauge) Number of entries in the signature cache. powerdns_authoritative_queries_unauth (count) Queries for domains that we are not authoritative for. record powerdns_authoritative_answers_bytes_total (count) Total number of answer bytes sent over by protocol. proto powerdns_authoritative_queries (count) UDP Queries Received. record powerdns_authoritative_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_authoritative_deferred_cache_actions (count) Deferred cache actions because of maintenance by type. type powerdns_authoritative_up (gauge) The last scrape of PowerDNS was successful. powerdns_authoritative_query_cache_lookup (count) Query cache lookups by result. result powerdns_authoritative_key_cache_size (gauge) Number of entries in the key cache. powerdns_authoritative_answers_total (count) Total number of answers by protocol. proto powerdns_authoritative_packet_cache_lookup (count) Packet cache lookups by result. result powerdns_authoritative_metadata_cache_size (gauge) Number of entries in the metadata cache. powerdns_authoritative_queries_total (count) Total number of queries by protocol. proto powerdns_authoritative_cpu_utilisation (count) Number of CPU milliseconds spent in user, and kernel space. type powerdns_authoritative_dnssec (count) DNSSEC counters. type powerdns_authoritative_response_sizes (count) Size distribution of responses. size powerdns_authoritative_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_authoritative_remote_queries_unauth (count) Remote hosts querying domains for which we are not authoritative. remote The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_RECURSOR: Name Description Dimensions powerdns_recursor_incoming_queries_total (count) Total number of incoming queries by network. net powerdns_recursor_outgoing_queries_total (count) Total number of outgoing queries by network. net powerdns_recursor_cache_size (gauge) Number of entries in the cache. powerdns_recursor_cache_lookups_total (count) Total number of cache lookups by result. result powerdns_recursor_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_recursor_answers_rcodes_total (count) Total number of answers by response code. rcode powerdns_recursor_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_recursor_concurrent_queries (gauge) Number of concurrent queries. powerdns_recursor_answers_rtime_total (count) Total number of answers grouped by response time slots. timeslot powerdns_recursor_latency_average_seconds (gauge) Exponential moving average of question-to-answer latency. powerdns_recursor_exceptions_total (count) Total number of exceptions by error. error powerdns_recursor_response_time_seconds_sum (count) Histogram of PowerDNS recursor response times in seconds. (sum metric) powerdns_recursor_response_time_seconds_bucket (count) Histogram of PowerDNS recursor response times in seconds. (bucket metric) le powerdns_recursor_up (gauge) The last scrape of PowerDNS was successful. Check the source code This integration is open source software. This means you can browse its source code and send improvements, or create your own fork and build it. Moreover this integration leverages an opensource exporter created by the community.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.05031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "PowerDNS monitoring <em>integration</em>",
        "sections": "PowerDNS monitoring <em>integration</em>",
        "tags": "<em>Integrations</em>",
        "body": " and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the <em>integrations</em> folder: cd &#x2F;etc&#x2F;newrelic-infra&#x2F;<em>integrations</em>.d Copy Copy of the sample configuration"
      },
      "id": "6174c27628ccbc1575c6b8dd"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/dagshub-mlops-integration": [
    {
      "sections": [
        "Cloud services integrations",
        "AWS integrations",
        "GCP integrations",
        "Azure integrations"
      ],
      "title": "Cloud services integrations",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Instrument core services and applications"
      ],
      "external_id": "509277aa4f9f8ad66cf5f82a94104531df64c296",
      "image": "https://docs.newrelic.com/static/78ac85c1fc41f94776fce7235e327f01/69538/img-integration-aws%25402x.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/cloud-services-integrations/",
      "published_at": "2021-10-25T16:29:51Z",
      "updated_at": "2021-10-24T00:48:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.52089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cloud services <em>integrations</em>",
        "sections": "Cloud services <em>integrations</em>",
        "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS <em>integrations</em> Introduction to AWS <em>integrations</em> List of AWS <em>integrations</em> GCP <em>integrations</em> Introduction to GCP <em>integrations</em> List of GCP <em>integrations</em> Azure <em>integrations</em> Introduction to Azure <em>integrations</em> List of Azure <em>integrations</em>"
      },
      "id": "603e829ae7b9d20bb12a080c"
    },
    {
      "sections": [
        "PowerDNS monitoring integration",
        "BETA FEATURE",
        "Compatibility and requirements",
        "Install and activate",
        "Linux installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "PowerDNS instance settings",
        "Example configurations",
        "Basic configuration",
        "Find and use data",
        "Metric data",
        "Check the source code"
      ],
      "title": "PowerDNS monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "e84cc75e844cd8780c859ff6ae4730a8c561b29d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/powerdns-monitoring-integration/",
      "published_at": "2021-10-24T22:02:11Z",
      "updated_at": "2021-10-24T02:18:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in open beta and only applies to the versions starting on 0.0.5 released in October 2021. Our PowerDNS integration collects and sends dimensional metrics from PowerDNS. You can view this metric data in pre-built dashboards, create alert policies, and create custom queries and charts. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with PowerDNS Recursor and Authoritative. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent, minimum version 1.19.2. Linux distribution compatible with the infrastructure agent. The integration obtains data by scrapping the PowerDNS API through a Prometheus exporter. To enable the API, the webserver and the HTTP API need to be enabled. Add these lines to the pdns.conf: api=yes api-key=changeme Copy And restart, the following examples should start working: curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1/servers/localhost | jq . curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1 Copy For more information, Enabling Webserver and Api Install and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp powerdns-config.yml.sample powerdns-config.yml Copy Edit the powerdns-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration To configure the integration, edit the config in the integration's YAML configuration file powerdns-config.yml. Use the YAML configuration to place required login credentials and configure how your data is collected, depending on your setup and preference. Since this integration is based on a prometheus exporter, settings applicable to other integrations, like interval, timeout or inventory_source are not supported. PowerDNS instance settings The PowerDNS integration collects dimensional Metrics: Setting Description Default powerdns_url API URL of the powerdns service N/A exporter_port Port to expose scrape endpoint on, If this is not provided a random port will be used to launch the exporter random-port api_key API key used to connect to the PowerDNS server N/A Example configurations Basic configuration This is the basic configuration used to collect metrics from an authoritative and a recursor instance: integrations: - name: nri-powerdns config: api_key: authoritative-secret exporter_port: 9121 powerdns_url: http://localhost:8081/api/v1/ - name: nri-powerdns config: api_key: recursor-secret exporter_port: 9122 powerdns_url: http://localhost:8082/api/v1/ Copy Find and use data For more on how to find and use your data, see Understand integration data. Metrics are attached to the Metric sample and event types of the entities POWERDNS_AUTHORITATIVE and POWERDNS_RECURSOR. You can query this data for troubleshooting purposes, or to create custom charts and dashboards. Metric data The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_AUTHORITATIVE: Name Description Dimensions powerdns_authoritative_uptime (count) Uptime in seconds of the daemon. type powerdns_authoritative_packet_cache_size (gauge) Number of entries in the packet cache. powerdns_authoritative_recursive_queries_total (count) Total number of recursive queries by status. status powerdns_authoritative_remote_queries (count) Remote server IP addresses. remote powerdns_authoritative_security_status (gauge) PDNS Server Security status based on security-status.secpoll.powerdns.com. powerdns_authoritative_exceptions_total (count) Total number of exceptions by error. error powerdns_authoritative_latency_average_seconds (gauge) Average number of microseconds a packet spends within PowerDNS. powerdns_authoritative_dnsupdate_queries_total (count) Total number of DNS update queries by status. status powerdns_authoritative_qsize (gauge) Number of packets waiting for database attention. powerdns_authoritative_response_rcodes (count) Distribution of rcodes. rcode powerdns_authoritative_signature_cache_size (gauge) Number of entries in the signature cache. powerdns_authoritative_queries_unauth (count) Queries for domains that we are not authoritative for. record powerdns_authoritative_answers_bytes_total (count) Total number of answer bytes sent over by protocol. proto powerdns_authoritative_queries (count) UDP Queries Received. record powerdns_authoritative_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_authoritative_deferred_cache_actions (count) Deferred cache actions because of maintenance by type. type powerdns_authoritative_up (gauge) The last scrape of PowerDNS was successful. powerdns_authoritative_query_cache_lookup (count) Query cache lookups by result. result powerdns_authoritative_key_cache_size (gauge) Number of entries in the key cache. powerdns_authoritative_answers_total (count) Total number of answers by protocol. proto powerdns_authoritative_packet_cache_lookup (count) Packet cache lookups by result. result powerdns_authoritative_metadata_cache_size (gauge) Number of entries in the metadata cache. powerdns_authoritative_queries_total (count) Total number of queries by protocol. proto powerdns_authoritative_cpu_utilisation (count) Number of CPU milliseconds spent in user, and kernel space. type powerdns_authoritative_dnssec (count) DNSSEC counters. type powerdns_authoritative_response_sizes (count) Size distribution of responses. size powerdns_authoritative_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_authoritative_remote_queries_unauth (count) Remote hosts querying domains for which we are not authoritative. remote The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_RECURSOR: Name Description Dimensions powerdns_recursor_incoming_queries_total (count) Total number of incoming queries by network. net powerdns_recursor_outgoing_queries_total (count) Total number of outgoing queries by network. net powerdns_recursor_cache_size (gauge) Number of entries in the cache. powerdns_recursor_cache_lookups_total (count) Total number of cache lookups by result. result powerdns_recursor_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_recursor_answers_rcodes_total (count) Total number of answers by response code. rcode powerdns_recursor_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_recursor_concurrent_queries (gauge) Number of concurrent queries. powerdns_recursor_answers_rtime_total (count) Total number of answers grouped by response time slots. timeslot powerdns_recursor_latency_average_seconds (gauge) Exponential moving average of question-to-answer latency. powerdns_recursor_exceptions_total (count) Total number of exceptions by error. error powerdns_recursor_response_time_seconds_sum (count) Histogram of PowerDNS recursor response times in seconds. (sum metric) powerdns_recursor_response_time_seconds_bucket (count) Histogram of PowerDNS recursor response times in seconds. (bucket metric) le powerdns_recursor_up (gauge) The last scrape of PowerDNS was successful. Check the source code This integration is open source software. This means you can browse its source code and send improvements, or create your own fork and build it. Moreover this integration leverages an opensource exporter created by the community.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.05031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "PowerDNS monitoring <em>integration</em>",
        "sections": "PowerDNS monitoring <em>integration</em>",
        "tags": "<em>Integrations</em>",
        "body": " and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the <em>integrations</em> folder: cd &#x2F;etc&#x2F;newrelic-infra&#x2F;<em>integrations</em>.d Copy Copy of the sample configuration"
      },
      "id": "6174c27628ccbc1575c6b8dd"
    },
    {
      "sections": [
        "StatsD monitoring integration",
        "Requirements",
        "Install",
        "Install for Kubernetes",
        "Kubernetes manifest examples",
        "Configure",
        "Tip",
        "Example of custom configuration",
        "Docker: overwrite default configuration",
        "Kubernetes: overwrite default configuration",
        "Metric format",
        "Metric types",
        "Counter",
        "Gauge",
        "Timer",
        "Add tags (attributes)",
        "Add default tags that apply to all metrics",
        "Add metric-level tags",
        "Create alerts",
        "Alert example",
        "Find and use data",
        "Check the source code"
      ],
      "title": "StatsD monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "48ab117ae50533224877d767224d85edd939db42",
      "image": "https://docs.newrelic.com/static/9c86375ad0ec12433df78b2116819aab/c1b63/statsd-nrql-alert-condition-example.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/statsd-monitoring-integration-version-2/",
      "published_at": "2021-10-24T21:10:05Z",
      "updated_at": "2021-10-24T00:56:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our StatsD integration lets you easily get StatsD-format data into New Relic. You can also add any arbitrary tags (key-value pairs) to your data. Once your metrics are in New Relic, you can query your data and create custom charts and dashboards. Want to try out our StatsD integration? Create a New Relic account for free! No credit card required. Requirements This integration uses our Metric API and our Event API to ingest data. To use these APIs, you'll need a license key. The integration adheres to the Metric API requirements and data limits. The default rate limit is 100,000 data points per minute (DPM). If you think you're missing metrics or sending more than 100K DPM, see Request data changes. To see if your account is hitting the rate limit, run the following NRQL query of the NrIntegrationError event: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' FACET category, message LIMIT 100 since 1 day ago Copy Install This section will explain how to do a standard install. If you want to run StatsD in Kubernetes, see Kubernetes install. To install the StatsD integration, run the following command and include your New Relic account ID and New Relic license key. This generates a TOML configuration file used by gostatsd. docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=NEW_RELIC_LICENSE_KEY \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy If your account is in the EU data center region, add this to the above command: -e NR_EU_REGION=true \\ Copy After installing, you can: Do optional additional configuration Define your metrics Add custom tags to your data Create alerts Install for Kubernetes Here are examples of Kubernetes manifests for deployment and service objects: Kubernetes manifest examples Below are examples of Kubernetes manifests to deploy StatsD in a Kubernetes environment and create a StatsD service named newrelic-statsd. You need to insert your account ID and your license key. deployment.yml: apiVersion: apps/v1 kind: Deployment metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: selector: matchLabels: app: newrelic-statsd replicas: 2 revisionHistoryLimit: 2 template: metadata: labels: app: newrelic-statsd spec: containers: - name: newrelic-statsd image: newrelic/nri-statsd:2.0.0 env: - name: NR_ACCOUNT_ID value: \"NEW_RELIC_ACCOUNT_ID\" - name: NR_API_KEY value: \"NEW_RELIC_LICENSE_KEY\" Copy service.yml: apiVersion: v1 kind: Service metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: type: ClusterIP ports: - name: newrelic-statsd port: 80 targetPort: 8125 protocol: UDP selector: app: newrelic-statsd Copy For configuration details, see Kubernetes configuration. Configure In the install procedure, you run nri-statsd with environment variables, and this generates a TOML configuration file. Additionally, you can set these configuration options: Configuration options Description expiry-interval string If a metric is not updated for this amount of time, we stop reporting that metric. Default is 5m. If you want to send the metrics only if the value was updated between the flush intervals, configure this to 1ms. To never expire metrics, set it to 0. percent-threshold list of integers Specifies the percentiles used for metrics aggregation. Default: 90. metrics-addr string Indicates address on which to listen for metrics. Default: :8125. Tip To ensure FedRAMP compliance when using the StatsD integration you must define the following endpoints in the custom configuration: address = 'https://gov-insights-collector.newrelic.com/v1/accounts/ $NR_ACCOUNT_ID/events' Copy address-metrics = 'https://gov-infra-api.newrelic.com/metric/v1' Copy Here are some examples of customizing configuration by overwriting the default configuration: Example of custom configuration # Specify after how long do we expire metrics, default:5m expiry-interval = '1ms' # percent-threshold specify a list of percentiles for metrics aggregation, default:90 percent-threshold = [90, 99] backends='newrelic' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://insights-collector.newrelic.com/v1/accounts/$NR_ACCOUNT_ID/events' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_LICENSE_KEY' Copy Disable timer sub-metrics: By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. If you want to disable those metrics you can do it by adding a disabled-sub-metrics configuration section and set true for the ones you want disabled. Here's an example: # disabled-sub-metrics configuration section allows disabling timer sub-metrics [disabled-sub-metrics] # Regular metrics count=false count-per-second=false mean=false median=false lower=false upper=false stddev=false sum=false sum-squares=false # Percentile metrics count-pct=false mean-pct=false sum-pct=false sum-squares-pct=false lower-pct=false upper-pct=false Copy Docker: overwrite default configuration To overwrite the default nri-statsd configuration while running in a container, you can mount a configuration file inside the container. You can adopt the following template as needed for your situation. Example: backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_LICENSE_KEY' Copy To run the container with the file mounted in the appropriate path: docker run \\ ... -v ${PWD}/nri-statsd.toml:/etc/opt/newrelic/nri-statsd.toml \\ ... newrelic/nri-statsd:2.0.0 Copy Kubernetes: overwrite default configuration The best approach to configure nri-statsd running in Kubernetes is to use a configMap and mount the configMap into the container. (This is a similar process to mounting the configuration file in Docker.) Example: apiVersion: v1 kind: ConfigMap metadata: name: nri-statsd-config namespace: default data: nri-statsd.toml: | backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://metric-api.newrelic.com/metric/v1' api-key = '$NEW_RELIC_LICENSE_KEY' Copy To use the configMap, declare a volume on your deployment spec template and then declare a volumeMount on your container spec. Example: apiVersion: apps/v1 kind: Deployment spec: template: spec: containers: .... volumeMounts: - mountPath: /etc/opt/newrelic/ name: nri-statsd-config volumes: - name: nri-statsd-config configMap: name: nri-statsd-config Copy Metric format The integration receives metrics using the StatsD protocol. Optionally, the sample rate can be configured and tags can be added. Here's the metric data format we use: <metric name>:<value>|<type>|@<sample rate>|#<tags> Copy Here are explanations of these fields: Field name Description < metric name> string Required. Name of the metric. < value> string Required. The metric type: c = counter g = gauge ms = timer @ < sample rate> float Optional for simple counters or timer counters. When many metrics must be sent, you can use sampling to reduce network traffic. The downside is a reduction in the resolution of the data. An example of how this would work for sample rates below 1: If you set this to 0.1, the counter would send a measurement one out of every 10 times. # < tags> string Optional. Tags attached to your metrics are converted into attributes (key-value pairs). For more on tagging options, see Tags. Metric types Here are the types of metrics and how to format them: Counter A counter measures the number of occurrences of an event. Examples include cache hits per reporting interval and the number of threads created per reporting interval. A counter can be incremented or decremented during the same flush interval by adding a sign to the value. In the following example, the counter value will be 2: counter:4|c counter:-2|c Copy At each flush, the current count is sent and reset to 0. If the count is not updated, at the next flush it will send the value 0. You can opt to disable this behavior by setting expiry-interval to 1ms. Here’s an example of a counter that is being sampled 1 out of 10 times: counter:4|c@0.1 Copy Gauge A gauge represents a value that can increase or decrease with time. Examples of gauges include temperature, CPU usage, and memory. Here's an example: temperature:40|g Copy If the gauge is not updated, at the next flush it will send the previous value. You can opt to disable this behavior by setting expiry-interval to 1ms. Timer The timer metric type measures timing data. By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. These are sent as sub-metrics in the following format: <metric_base_name>.std_dev <metric_base_name>.median <metric_base_name>.summary <metric_base_name>.sum_squares <metric_base_name>.mean <metric_base_name>.per_second Copy The configured percentiles will generate the following metrics. The percentile threshold value will be attached as a tag. <metric_base_name>.sum_squares.percentiles <metric_base_name>.sum.percentiles <metric_base_name>.count.percentiles <metric_base_name>.upper.percentiles <metric_base_name>.mean.percentiles Copy The percentile threshold can be tweaked with the percent-threshold config option. These can be controlled through the disabled-sub-metrics configuration section. Add tags (attributes) You can add tags to your data, which we save as attributes (key-value pairs). There are two options for adding tags: Add default tags that apply to all metrics: These apply to all metrics. They are fixed and don't change over time. Add metric-level tags: These apply to specific metrics and allow the value to be changed between two submits. Add default tags that apply to all metrics Add tags to metrics and events by defining an environment variable in the startup command. Here's an example that would create two tags: -e TAGS=\"environment:production region:us\" Copy Here's that environment variable used in the startup command: docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=NEW_RELIC_LICENSE_KEY \\ -e TAGS=\"environment:production region:us\" \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy Add metric-level tags When defining the metric format, you can add tags using this format: <bucket name>:<value>|<type>|#<tags> Copy In this example, <tags> is a comma-separated list of tags. Tags format is: simple or key:value. Here's an example NRQL query that includes a custom tag: SELECT count(*) FROM Metric WHERE environment = 'production' Copy Create alerts You can alert on StatsD data using NRQL alert conditions. Alert example This procedure walks you through sending some sample data and then creating an alert condition using that data. First, send this data to New Relic’s StatsD container: echo \"prod.test.num:32|g\" | nc -v -w 1 -u localhost 8125 Copy Next, create a NRQL alert condition using this query: SELECT latest(prod.test.num) FROM Metric WHERE metricName = 'prod.test.num' Copy Here's an image showing creating this NRQL alert condition. Notice that the sample data sent in is represented by the blue dot on the upper right of the chart. Now we can create the alert condition with these settings: When you create the NRQL alert condition, be sure to set the Condition name. If a metric with a value above 50 is sent, then an incident is created and notified. The incident is closed automatically after 24 hours. To test that the alert is working, run this command: echo \"prod.test.num:60|g\" | nc -v -w 1 -u localhost 8125 Copy Find and use data To query your data, you'd use any New Relic query option. For example, you might run a NRQL query like: SELECT count(*) FROM Metric WHERE metricName = 'myMetric' and environment = 'production' Copy For more on how to query the Metric data type, see Query metric data. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 47.92978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "StatsD monitoring <em>integration</em>",
        "sections": "StatsD monitoring <em>integration</em>",
        "tags": "<em>Integrations</em>"
      },
      "id": "6174af22e7b9d253c613b73d"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/mona-mlops-integration": [
    {
      "sections": [
        "DagsHub MLOps integration",
        "What is MLOps?",
        "The DagsHub integration",
        "Integrate DagsHub with New Relic",
        "View and explore your DagsHub models in New Relic dashboards"
      ],
      "title": "DagsHub MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOps integrations",
        "DagsHub integrations"
      ],
      "external_id": "7a93ba8b53a1d905a60dcdfc242ffa4ab9e03ae2",
      "image": "https://docs.newrelic.com/static/d78db1e800d8c753d87ad615803b3411/c1b63/dagshub1.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/dagshub-mlops-integration/",
      "published_at": "2021-10-24T23:55:00Z",
      "updated_at": "2021-10-23T17:33:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "What is MLOps? MLOps stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there's a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those models. MLOps provides a tool for monitoring and observing the performance and effectiveness of machine-learning models in a production environment. This increases the possibilities for collaboration between data science and DevOps teams, feeding into a continuous process of development, testing, and operational monitoring. The DagsHub integration DagsHub is a platform for data scientists and machine learning engineers to version and sync their data, models, experiments, and code. It allows you and your team to easily share, review and reuse your work, providing a GitHub-like experience for machine learning. DagsHub is built on popular open-source tools and formats, making it easy to integrate with the tools you already use like New Relic. New Relic now offers an integration with DagsHub to monitor and analyze your machine learning training metrics in real-time. Integrate DagsHub with New Relic Integrating DagsHub and New Relic enables you to analyze and monitor machine learning training metrics in real-time. You can visualize your metrics in a New Relic dashboard, create custom metrics, and set alerts to notify you of events and incidents happening during your training runs. In order to receive data from DagsHub into New Relic, you need your account number and a special key which you can obtain as follows: Log into your New Relic account: Go to one.newrelic.com, and click Explorer. On the upper hand right corner, on the main navigation menu, click on +Add more data. Click on DagsHub: Type DagsHub in the search bar, or scroll down to the MLOps Integration section, and click the DagsHub icon. Select the account ID you want DagsHub to integrate with. Create an access token: Once you've selected an account ID, under real-time insert metrics, click Create an API key . This will be your new telemetry API key. Keep the New Relic page open for future steps. Log into the DagsHub portal and select the repository you're working on. Click Settings, and select the integrations button from the left hand menu. Click on the New Relic tile. Copy and paste the token in DagsHub. Go back to the New Relic integration dashboard and copy the token you created by clicking on the copy icon next to the insert key. On the DagsHub’s portal, paste the insert key under New Relic Insight insert key, and finish by clicking Next. The token will be verified, and a confirmation screen will appear. View and explore your DagsHub models in New Relic dashboards Once you configure the New Relic integration in DagsHub, all the training metrics logged to DagsHub in real time are sent to New Relic. Go to the DagsHub integration dashboard: Once you’ve tested your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. You will be redirected to an automatically generated New Relic dashboard powered by DagsHub. Analyze the DagsHub dashboard: The DagsHub dashboard contains one chart, Loss metric by repository, which displays the loss of your models, grouped by their respective repository. It works for any models that you have trained. Display customized metrics: You can easily customize training metrics coming from DagsHub. For more information on using NRQL and creating queries to track your data, refer to NRQL syntax, clauses, and functions. Set up alerts notifications: Once you've created some dashboards, you can get alerted on your data. To create NRQL alerts conditions from a chart, click the ... chart menu, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy, or create a new one. Get notified: Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. You’ve now successfully integrated New Relic with DagsHub. Newly created alerts are correlated with your New Relic alerts, and you'll see data about newly reported predictions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.55873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "DagsHub <em>MLOps</em> <em>integration</em>",
        "sections": "DagsHub <em>MLOps</em> <em>integration</em>",
        "tags": "<em>MLOps</em> <em>integrations</em>",
        "body": "What is <em>MLOps</em>? <em>MLOps</em> stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there&#x27;s a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those"
      },
      "id": "6175f254196a67a8242f0923"
    },
    {
      "sections": [
        "Cloud services integrations",
        "AWS integrations",
        "GCP integrations",
        "Azure integrations"
      ],
      "title": "Cloud services integrations",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Instrument core services and applications"
      ],
      "external_id": "509277aa4f9f8ad66cf5f82a94104531df64c296",
      "image": "https://docs.newrelic.com/static/78ac85c1fc41f94776fce7235e327f01/69538/img-integration-aws%25402x.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/cloud-services-integrations/",
      "published_at": "2021-10-25T16:29:51Z",
      "updated_at": "2021-10-24T00:48:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.520866,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cloud services <em>integrations</em>",
        "sections": "Cloud services <em>integrations</em>",
        "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS <em>integrations</em> Introduction to AWS <em>integrations</em> List of AWS <em>integrations</em> GCP <em>integrations</em> Introduction to GCP <em>integrations</em> List of GCP <em>integrations</em> Azure <em>integrations</em> Introduction to Azure <em>integrations</em> List of Azure <em>integrations</em>"
      },
      "id": "603e829ae7b9d20bb12a080c"
    },
    {
      "sections": [
        "PowerDNS monitoring integration",
        "BETA FEATURE",
        "Compatibility and requirements",
        "Install and activate",
        "Linux installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "PowerDNS instance settings",
        "Example configurations",
        "Basic configuration",
        "Find and use data",
        "Metric data",
        "Check the source code"
      ],
      "title": "PowerDNS monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "e84cc75e844cd8780c859ff6ae4730a8c561b29d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/powerdns-monitoring-integration/",
      "published_at": "2021-10-24T22:02:11Z",
      "updated_at": "2021-10-24T02:18:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in open beta and only applies to the versions starting on 0.0.5 released in October 2021. Our PowerDNS integration collects and sends dimensional metrics from PowerDNS. You can view this metric data in pre-built dashboards, create alert policies, and create custom queries and charts. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with PowerDNS Recursor and Authoritative. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent, minimum version 1.19.2. Linux distribution compatible with the infrastructure agent. The integration obtains data by scrapping the PowerDNS API through a Prometheus exporter. To enable the API, the webserver and the HTTP API need to be enabled. Add these lines to the pdns.conf: api=yes api-key=changeme Copy And restart, the following examples should start working: curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1/servers/localhost | jq . curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1 Copy For more information, Enabling Webserver and Api Install and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp powerdns-config.yml.sample powerdns-config.yml Copy Edit the powerdns-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration To configure the integration, edit the config in the integration's YAML configuration file powerdns-config.yml. Use the YAML configuration to place required login credentials and configure how your data is collected, depending on your setup and preference. Since this integration is based on a prometheus exporter, settings applicable to other integrations, like interval, timeout or inventory_source are not supported. PowerDNS instance settings The PowerDNS integration collects dimensional Metrics: Setting Description Default powerdns_url API URL of the powerdns service N/A exporter_port Port to expose scrape endpoint on, If this is not provided a random port will be used to launch the exporter random-port api_key API key used to connect to the PowerDNS server N/A Example configurations Basic configuration This is the basic configuration used to collect metrics from an authoritative and a recursor instance: integrations: - name: nri-powerdns config: api_key: authoritative-secret exporter_port: 9121 powerdns_url: http://localhost:8081/api/v1/ - name: nri-powerdns config: api_key: recursor-secret exporter_port: 9122 powerdns_url: http://localhost:8082/api/v1/ Copy Find and use data For more on how to find and use your data, see Understand integration data. Metrics are attached to the Metric sample and event types of the entities POWERDNS_AUTHORITATIVE and POWERDNS_RECURSOR. You can query this data for troubleshooting purposes, or to create custom charts and dashboards. Metric data The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_AUTHORITATIVE: Name Description Dimensions powerdns_authoritative_uptime (count) Uptime in seconds of the daemon. type powerdns_authoritative_packet_cache_size (gauge) Number of entries in the packet cache. powerdns_authoritative_recursive_queries_total (count) Total number of recursive queries by status. status powerdns_authoritative_remote_queries (count) Remote server IP addresses. remote powerdns_authoritative_security_status (gauge) PDNS Server Security status based on security-status.secpoll.powerdns.com. powerdns_authoritative_exceptions_total (count) Total number of exceptions by error. error powerdns_authoritative_latency_average_seconds (gauge) Average number of microseconds a packet spends within PowerDNS. powerdns_authoritative_dnsupdate_queries_total (count) Total number of DNS update queries by status. status powerdns_authoritative_qsize (gauge) Number of packets waiting for database attention. powerdns_authoritative_response_rcodes (count) Distribution of rcodes. rcode powerdns_authoritative_signature_cache_size (gauge) Number of entries in the signature cache. powerdns_authoritative_queries_unauth (count) Queries for domains that we are not authoritative for. record powerdns_authoritative_answers_bytes_total (count) Total number of answer bytes sent over by protocol. proto powerdns_authoritative_queries (count) UDP Queries Received. record powerdns_authoritative_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_authoritative_deferred_cache_actions (count) Deferred cache actions because of maintenance by type. type powerdns_authoritative_up (gauge) The last scrape of PowerDNS was successful. powerdns_authoritative_query_cache_lookup (count) Query cache lookups by result. result powerdns_authoritative_key_cache_size (gauge) Number of entries in the key cache. powerdns_authoritative_answers_total (count) Total number of answers by protocol. proto powerdns_authoritative_packet_cache_lookup (count) Packet cache lookups by result. result powerdns_authoritative_metadata_cache_size (gauge) Number of entries in the metadata cache. powerdns_authoritative_queries_total (count) Total number of queries by protocol. proto powerdns_authoritative_cpu_utilisation (count) Number of CPU milliseconds spent in user, and kernel space. type powerdns_authoritative_dnssec (count) DNSSEC counters. type powerdns_authoritative_response_sizes (count) Size distribution of responses. size powerdns_authoritative_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_authoritative_remote_queries_unauth (count) Remote hosts querying domains for which we are not authoritative. remote The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_RECURSOR: Name Description Dimensions powerdns_recursor_incoming_queries_total (count) Total number of incoming queries by network. net powerdns_recursor_outgoing_queries_total (count) Total number of outgoing queries by network. net powerdns_recursor_cache_size (gauge) Number of entries in the cache. powerdns_recursor_cache_lookups_total (count) Total number of cache lookups by result. result powerdns_recursor_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_recursor_answers_rcodes_total (count) Total number of answers by response code. rcode powerdns_recursor_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_recursor_concurrent_queries (gauge) Number of concurrent queries. powerdns_recursor_answers_rtime_total (count) Total number of answers grouped by response time slots. timeslot powerdns_recursor_latency_average_seconds (gauge) Exponential moving average of question-to-answer latency. powerdns_recursor_exceptions_total (count) Total number of exceptions by error. error powerdns_recursor_response_time_seconds_sum (count) Histogram of PowerDNS recursor response times in seconds. (sum metric) powerdns_recursor_response_time_seconds_bucket (count) Histogram of PowerDNS recursor response times in seconds. (bucket metric) le powerdns_recursor_up (gauge) The last scrape of PowerDNS was successful. Check the source code This integration is open source software. This means you can browse its source code and send improvements, or create your own fork and build it. Moreover this integration leverages an opensource exporter created by the community.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.050285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "PowerDNS monitoring <em>integration</em>",
        "sections": "PowerDNS monitoring <em>integration</em>",
        "tags": "<em>Integrations</em>",
        "body": " and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the <em>integrations</em> folder: cd &#x2F;etc&#x2F;newrelic-infra&#x2F;<em>integrations</em>.d Copy Copy of the sample configuration"
      },
      "id": "6174c27628ccbc1575c6b8dd"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/superwise-mlops-integration": [
    {
      "sections": [
        "DagsHub MLOps integration",
        "What is MLOps?",
        "The DagsHub integration",
        "Integrate DagsHub with New Relic",
        "View and explore your DagsHub models in New Relic dashboards"
      ],
      "title": "DagsHub MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOps integrations",
        "DagsHub integrations"
      ],
      "external_id": "7a93ba8b53a1d905a60dcdfc242ffa4ab9e03ae2",
      "image": "https://docs.newrelic.com/static/d78db1e800d8c753d87ad615803b3411/c1b63/dagshub1.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/mlops-integrations/dagshub-mlops-integration/",
      "published_at": "2021-10-24T23:55:00Z",
      "updated_at": "2021-10-23T17:33:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "What is MLOps? MLOps stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there's a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those models. MLOps provides a tool for monitoring and observing the performance and effectiveness of machine-learning models in a production environment. This increases the possibilities for collaboration between data science and DevOps teams, feeding into a continuous process of development, testing, and operational monitoring. The DagsHub integration DagsHub is a platform for data scientists and machine learning engineers to version and sync their data, models, experiments, and code. It allows you and your team to easily share, review and reuse your work, providing a GitHub-like experience for machine learning. DagsHub is built on popular open-source tools and formats, making it easy to integrate with the tools you already use like New Relic. New Relic now offers an integration with DagsHub to monitor and analyze your machine learning training metrics in real-time. Integrate DagsHub with New Relic Integrating DagsHub and New Relic enables you to analyze and monitor machine learning training metrics in real-time. You can visualize your metrics in a New Relic dashboard, create custom metrics, and set alerts to notify you of events and incidents happening during your training runs. In order to receive data from DagsHub into New Relic, you need your account number and a special key which you can obtain as follows: Log into your New Relic account: Go to one.newrelic.com, and click Explorer. On the upper hand right corner, on the main navigation menu, click on +Add more data. Click on DagsHub: Type DagsHub in the search bar, or scroll down to the MLOps Integration section, and click the DagsHub icon. Select the account ID you want DagsHub to integrate with. Create an access token: Once you've selected an account ID, under real-time insert metrics, click Create an API key . This will be your new telemetry API key. Keep the New Relic page open for future steps. Log into the DagsHub portal and select the repository you're working on. Click Settings, and select the integrations button from the left hand menu. Click on the New Relic tile. Copy and paste the token in DagsHub. Go back to the New Relic integration dashboard and copy the token you created by clicking on the copy icon next to the insert key. On the DagsHub’s portal, paste the insert key under New Relic Insight insert key, and finish by clicking Next. The token will be verified, and a confirmation screen will appear. View and explore your DagsHub models in New Relic dashboards Once you configure the New Relic integration in DagsHub, all the training metrics logged to DagsHub in real time are sent to New Relic. Go to the DagsHub integration dashboard: Once you’ve tested your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. You will be redirected to an automatically generated New Relic dashboard powered by DagsHub. Analyze the DagsHub dashboard: The DagsHub dashboard contains one chart, Loss metric by repository, which displays the loss of your models, grouped by their respective repository. It works for any models that you have trained. Display customized metrics: You can easily customize training metrics coming from DagsHub. For more information on using NRQL and creating queries to track your data, refer to NRQL syntax, clauses, and functions. Set up alerts notifications: Once you've created some dashboards, you can get alerted on your data. To create NRQL alerts conditions from a chart, click the ... chart menu, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy, or create a new one. Get notified: Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. You’ve now successfully integrated New Relic with DagsHub. Newly created alerts are correlated with your New Relic alerts, and you'll see data about newly reported predictions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.07889,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "DagsHub <em>MLOps</em> <em>integration</em>",
        "sections": "DagsHub <em>MLOps</em> <em>integration</em>",
        "tags": "<em>MLOps</em> <em>integrations</em>",
        "body": "What is <em>MLOps</em>? <em>MLOps</em> stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there&#x27;s a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those"
      },
      "id": "6175f254196a67a8242f0923"
    },
    {
      "sections": [
        "PowerDNS monitoring integration",
        "BETA FEATURE",
        "Compatibility and requirements",
        "Install and activate",
        "Linux installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "PowerDNS instance settings",
        "Example configurations",
        "Basic configuration",
        "Find and use data",
        "Metric data",
        "Check the source code"
      ],
      "title": "PowerDNS monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "e84cc75e844cd8780c859ff6ae4730a8c561b29d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/powerdns-monitoring-integration/",
      "published_at": "2021-10-24T22:02:11Z",
      "updated_at": "2021-10-24T02:18:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in open beta and only applies to the versions starting on 0.0.5 released in October 2021. Our PowerDNS integration collects and sends dimensional metrics from PowerDNS. You can view this metric data in pre-built dashboards, create alert policies, and create custom queries and charts. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with PowerDNS Recursor and Authoritative. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent, minimum version 1.19.2. Linux distribution compatible with the infrastructure agent. The integration obtains data by scrapping the PowerDNS API through a Prometheus exporter. To enable the API, the webserver and the HTTP API need to be enabled. Add these lines to the pdns.conf: api=yes api-key=changeme Copy And restart, the following examples should start working: curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1/servers/localhost | jq . curl -v -H 'X-API-Key: changeme' http://127.0.0.1:8081/api/v1 Copy For more information, Enabling Webserver and Api Install and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp powerdns-config.yml.sample powerdns-config.yml Copy Edit the powerdns-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration To configure the integration, edit the config in the integration's YAML configuration file powerdns-config.yml. Use the YAML configuration to place required login credentials and configure how your data is collected, depending on your setup and preference. Since this integration is based on a prometheus exporter, settings applicable to other integrations, like interval, timeout or inventory_source are not supported. PowerDNS instance settings The PowerDNS integration collects dimensional Metrics: Setting Description Default powerdns_url API URL of the powerdns service N/A exporter_port Port to expose scrape endpoint on, If this is not provided a random port will be used to launch the exporter random-port api_key API key used to connect to the PowerDNS server N/A Example configurations Basic configuration This is the basic configuration used to collect metrics from an authoritative and a recursor instance: integrations: - name: nri-powerdns config: api_key: authoritative-secret exporter_port: 9121 powerdns_url: http://localhost:8081/api/v1/ - name: nri-powerdns config: api_key: recursor-secret exporter_port: 9122 powerdns_url: http://localhost:8082/api/v1/ Copy Find and use data For more on how to find and use your data, see Understand integration data. Metrics are attached to the Metric sample and event types of the entities POWERDNS_AUTHORITATIVE and POWERDNS_RECURSOR. You can query this data for troubleshooting purposes, or to create custom charts and dashboards. Metric data The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_AUTHORITATIVE: Name Description Dimensions powerdns_authoritative_uptime (count) Uptime in seconds of the daemon. type powerdns_authoritative_packet_cache_size (gauge) Number of entries in the packet cache. powerdns_authoritative_recursive_queries_total (count) Total number of recursive queries by status. status powerdns_authoritative_remote_queries (count) Remote server IP addresses. remote powerdns_authoritative_security_status (gauge) PDNS Server Security status based on security-status.secpoll.powerdns.com. powerdns_authoritative_exceptions_total (count) Total number of exceptions by error. error powerdns_authoritative_latency_average_seconds (gauge) Average number of microseconds a packet spends within PowerDNS. powerdns_authoritative_dnsupdate_queries_total (count) Total number of DNS update queries by status. status powerdns_authoritative_qsize (gauge) Number of packets waiting for database attention. powerdns_authoritative_response_rcodes (count) Distribution of rcodes. rcode powerdns_authoritative_signature_cache_size (gauge) Number of entries in the signature cache. powerdns_authoritative_queries_unauth (count) Queries for domains that we are not authoritative for. record powerdns_authoritative_answers_bytes_total (count) Total number of answer bytes sent over by protocol. proto powerdns_authoritative_queries (count) UDP Queries Received. record powerdns_authoritative_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_authoritative_deferred_cache_actions (count) Deferred cache actions because of maintenance by type. type powerdns_authoritative_up (gauge) The last scrape of PowerDNS was successful. powerdns_authoritative_query_cache_lookup (count) Query cache lookups by result. result powerdns_authoritative_key_cache_size (gauge) Number of entries in the key cache. powerdns_authoritative_answers_total (count) Total number of answers by protocol. proto powerdns_authoritative_packet_cache_lookup (count) Packet cache lookups by result. result powerdns_authoritative_metadata_cache_size (gauge) Number of entries in the metadata cache. powerdns_authoritative_queries_total (count) Total number of queries by protocol. proto powerdns_authoritative_cpu_utilisation (count) Number of CPU milliseconds spent in user, and kernel space. type powerdns_authoritative_dnssec (count) DNSSEC counters. type powerdns_authoritative_response_sizes (count) Size distribution of responses. size powerdns_authoritative_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_authoritative_remote_queries_unauth (count) Remote hosts querying domains for which we are not authoritative. remote The following dimensional metrics are captured scraping the exporter and linked to the entity POWERDNS_RECURSOR: Name Description Dimensions powerdns_recursor_incoming_queries_total (count) Total number of incoming queries by network. net powerdns_recursor_outgoing_queries_total (count) Total number of outgoing queries by network. net powerdns_recursor_cache_size (gauge) Number of entries in the cache. powerdns_recursor_cache_lookups_total (count) Total number of cache lookups by result. result powerdns_recursor_exporter_json_parse_failures (count) Number of errors while parsing PowerDNS JSON stats. powerdns_recursor_answers_rcodes_total (count) Total number of answers by response code. rcode powerdns_recursor_exporter_total_scrapes (count) Current total PowerDNS scrapes. powerdns_recursor_concurrent_queries (gauge) Number of concurrent queries. powerdns_recursor_answers_rtime_total (count) Total number of answers grouped by response time slots. timeslot powerdns_recursor_latency_average_seconds (gauge) Exponential moving average of question-to-answer latency. powerdns_recursor_exceptions_total (count) Total number of exceptions by error. error powerdns_recursor_response_time_seconds_sum (count) Histogram of PowerDNS recursor response times in seconds. (sum metric) powerdns_recursor_response_time_seconds_bucket (count) Histogram of PowerDNS recursor response times in seconds. (bucket metric) le powerdns_recursor_up (gauge) The last scrape of PowerDNS was successful. Check the source code This integration is open source software. This means you can browse its source code and send improvements, or create your own fork and build it. Moreover this integration leverages an opensource exporter created by the community.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 50.455055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "PowerDNS monitoring <em>integration</em>",
        "sections": "PowerDNS monitoring <em>integration</em>",
        "tags": "<em>Integrations</em>",
        "body": " and activate To install the PowerDNS integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-powerdns. Change the directory to the <em>integrations</em> folder: cd &#x2F;etc&#x2F;newrelic-infra&#x2F;<em>integrations</em>.d Copy Copy of the sample configuration"
      },
      "id": "6174c27628ccbc1575c6b8dd"
    },
    {
      "sections": [
        "StatsD monitoring integration",
        "Requirements",
        "Install",
        "Install for Kubernetes",
        "Kubernetes manifest examples",
        "Configure",
        "Tip",
        "Example of custom configuration",
        "Docker: overwrite default configuration",
        "Kubernetes: overwrite default configuration",
        "Metric format",
        "Metric types",
        "Counter",
        "Gauge",
        "Timer",
        "Add tags (attributes)",
        "Add default tags that apply to all metrics",
        "Add metric-level tags",
        "Create alerts",
        "Alert example",
        "Find and use data",
        "Check the source code"
      ],
      "title": "StatsD monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "48ab117ae50533224877d767224d85edd939db42",
      "image": "https://docs.newrelic.com/static/9c86375ad0ec12433df78b2116819aab/c1b63/statsd-nrql-alert-condition-example.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/statsd-monitoring-integration-version-2/",
      "published_at": "2021-10-24T21:10:05Z",
      "updated_at": "2021-10-24T00:56:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our StatsD integration lets you easily get StatsD-format data into New Relic. You can also add any arbitrary tags (key-value pairs) to your data. Once your metrics are in New Relic, you can query your data and create custom charts and dashboards. Want to try out our StatsD integration? Create a New Relic account for free! No credit card required. Requirements This integration uses our Metric API and our Event API to ingest data. To use these APIs, you'll need a license key. The integration adheres to the Metric API requirements and data limits. The default rate limit is 100,000 data points per minute (DPM). If you think you're missing metrics or sending more than 100K DPM, see Request data changes. To see if your account is hitting the rate limit, run the following NRQL query of the NrIntegrationError event: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' FACET category, message LIMIT 100 since 1 day ago Copy Install This section will explain how to do a standard install. If you want to run StatsD in Kubernetes, see Kubernetes install. To install the StatsD integration, run the following command and include your New Relic account ID and New Relic license key. This generates a TOML configuration file used by gostatsd. docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=NEW_RELIC_LICENSE_KEY \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy If your account is in the EU data center region, add this to the above command: -e NR_EU_REGION=true \\ Copy After installing, you can: Do optional additional configuration Define your metrics Add custom tags to your data Create alerts Install for Kubernetes Here are examples of Kubernetes manifests for deployment and service objects: Kubernetes manifest examples Below are examples of Kubernetes manifests to deploy StatsD in a Kubernetes environment and create a StatsD service named newrelic-statsd. You need to insert your account ID and your license key. deployment.yml: apiVersion: apps/v1 kind: Deployment metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: selector: matchLabels: app: newrelic-statsd replicas: 2 revisionHistoryLimit: 2 template: metadata: labels: app: newrelic-statsd spec: containers: - name: newrelic-statsd image: newrelic/nri-statsd:2.0.0 env: - name: NR_ACCOUNT_ID value: \"NEW_RELIC_ACCOUNT_ID\" - name: NR_API_KEY value: \"NEW_RELIC_LICENSE_KEY\" Copy service.yml: apiVersion: v1 kind: Service metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: type: ClusterIP ports: - name: newrelic-statsd port: 80 targetPort: 8125 protocol: UDP selector: app: newrelic-statsd Copy For configuration details, see Kubernetes configuration. Configure In the install procedure, you run nri-statsd with environment variables, and this generates a TOML configuration file. Additionally, you can set these configuration options: Configuration options Description expiry-interval string If a metric is not updated for this amount of time, we stop reporting that metric. Default is 5m. If you want to send the metrics only if the value was updated between the flush intervals, configure this to 1ms. To never expire metrics, set it to 0. percent-threshold list of integers Specifies the percentiles used for metrics aggregation. Default: 90. metrics-addr string Indicates address on which to listen for metrics. Default: :8125. Tip To ensure FedRAMP compliance when using the StatsD integration you must define the following endpoints in the custom configuration: address = 'https://gov-insights-collector.newrelic.com/v1/accounts/ $NR_ACCOUNT_ID/events' Copy address-metrics = 'https://gov-infra-api.newrelic.com/metric/v1' Copy Here are some examples of customizing configuration by overwriting the default configuration: Example of custom configuration # Specify after how long do we expire metrics, default:5m expiry-interval = '1ms' # percent-threshold specify a list of percentiles for metrics aggregation, default:90 percent-threshold = [90, 99] backends='newrelic' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://insights-collector.newrelic.com/v1/accounts/$NR_ACCOUNT_ID/events' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_LICENSE_KEY' Copy Disable timer sub-metrics: By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. If you want to disable those metrics you can do it by adding a disabled-sub-metrics configuration section and set true for the ones you want disabled. Here's an example: # disabled-sub-metrics configuration section allows disabling timer sub-metrics [disabled-sub-metrics] # Regular metrics count=false count-per-second=false mean=false median=false lower=false upper=false stddev=false sum=false sum-squares=false # Percentile metrics count-pct=false mean-pct=false sum-pct=false sum-squares-pct=false lower-pct=false upper-pct=false Copy Docker: overwrite default configuration To overwrite the default nri-statsd configuration while running in a container, you can mount a configuration file inside the container. You can adopt the following template as needed for your situation. Example: backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_LICENSE_KEY' Copy To run the container with the file mounted in the appropriate path: docker run \\ ... -v ${PWD}/nri-statsd.toml:/etc/opt/newrelic/nri-statsd.toml \\ ... newrelic/nri-statsd:2.0.0 Copy Kubernetes: overwrite default configuration The best approach to configure nri-statsd running in Kubernetes is to use a configMap and mount the configMap into the container. (This is a similar process to mounting the configuration file in Docker.) Example: apiVersion: v1 kind: ConfigMap metadata: name: nri-statsd-config namespace: default data: nri-statsd.toml: | backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://metric-api.newrelic.com/metric/v1' api-key = '$NEW_RELIC_LICENSE_KEY' Copy To use the configMap, declare a volume on your deployment spec template and then declare a volumeMount on your container spec. Example: apiVersion: apps/v1 kind: Deployment spec: template: spec: containers: .... volumeMounts: - mountPath: /etc/opt/newrelic/ name: nri-statsd-config volumes: - name: nri-statsd-config configMap: name: nri-statsd-config Copy Metric format The integration receives metrics using the StatsD protocol. Optionally, the sample rate can be configured and tags can be added. Here's the metric data format we use: <metric name>:<value>|<type>|@<sample rate>|#<tags> Copy Here are explanations of these fields: Field name Description < metric name> string Required. Name of the metric. < value> string Required. The metric type: c = counter g = gauge ms = timer @ < sample rate> float Optional for simple counters or timer counters. When many metrics must be sent, you can use sampling to reduce network traffic. The downside is a reduction in the resolution of the data. An example of how this would work for sample rates below 1: If you set this to 0.1, the counter would send a measurement one out of every 10 times. # < tags> string Optional. Tags attached to your metrics are converted into attributes (key-value pairs). For more on tagging options, see Tags. Metric types Here are the types of metrics and how to format them: Counter A counter measures the number of occurrences of an event. Examples include cache hits per reporting interval and the number of threads created per reporting interval. A counter can be incremented or decremented during the same flush interval by adding a sign to the value. In the following example, the counter value will be 2: counter:4|c counter:-2|c Copy At each flush, the current count is sent and reset to 0. If the count is not updated, at the next flush it will send the value 0. You can opt to disable this behavior by setting expiry-interval to 1ms. Here’s an example of a counter that is being sampled 1 out of 10 times: counter:4|c@0.1 Copy Gauge A gauge represents a value that can increase or decrease with time. Examples of gauges include temperature, CPU usage, and memory. Here's an example: temperature:40|g Copy If the gauge is not updated, at the next flush it will send the previous value. You can opt to disable this behavior by setting expiry-interval to 1ms. Timer The timer metric type measures timing data. By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. These are sent as sub-metrics in the following format: <metric_base_name>.std_dev <metric_base_name>.median <metric_base_name>.summary <metric_base_name>.sum_squares <metric_base_name>.mean <metric_base_name>.per_second Copy The configured percentiles will generate the following metrics. The percentile threshold value will be attached as a tag. <metric_base_name>.sum_squares.percentiles <metric_base_name>.sum.percentiles <metric_base_name>.count.percentiles <metric_base_name>.upper.percentiles <metric_base_name>.mean.percentiles Copy The percentile threshold can be tweaked with the percent-threshold config option. These can be controlled through the disabled-sub-metrics configuration section. Add tags (attributes) You can add tags to your data, which we save as attributes (key-value pairs). There are two options for adding tags: Add default tags that apply to all metrics: These apply to all metrics. They are fixed and don't change over time. Add metric-level tags: These apply to specific metrics and allow the value to be changed between two submits. Add default tags that apply to all metrics Add tags to metrics and events by defining an environment variable in the startup command. Here's an example that would create two tags: -e TAGS=\"environment:production region:us\" Copy Here's that environment variable used in the startup command: docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=NEW_RELIC_LICENSE_KEY \\ -e TAGS=\"environment:production region:us\" \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy Add metric-level tags When defining the metric format, you can add tags using this format: <bucket name>:<value>|<type>|#<tags> Copy In this example, <tags> is a comma-separated list of tags. Tags format is: simple or key:value. Here's an example NRQL query that includes a custom tag: SELECT count(*) FROM Metric WHERE environment = 'production' Copy Create alerts You can alert on StatsD data using NRQL alert conditions. Alert example This procedure walks you through sending some sample data and then creating an alert condition using that data. First, send this data to New Relic’s StatsD container: echo \"prod.test.num:32|g\" | nc -v -w 1 -u localhost 8125 Copy Next, create a NRQL alert condition using this query: SELECT latest(prod.test.num) FROM Metric WHERE metricName = 'prod.test.num' Copy Here's an image showing creating this NRQL alert condition. Notice that the sample data sent in is represented by the blue dot on the upper right of the chart. Now we can create the alert condition with these settings: When you create the NRQL alert condition, be sure to set the Condition name. If a metric with a value above 50 is sent, then an incident is created and notified. The incident is closed automatically after 24 hours. To test that the alert is working, run this command: echo \"prod.test.num:60|g\" | nc -v -w 1 -u localhost 8125 Copy Find and use data To query your data, you'd use any New Relic query option. For example, you might run a NRQL query like: SELECT count(*) FROM Metric WHERE metricName = 'myMetric' and environment = 'production' Copy For more on how to query the Metric data type, see Query metric data. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 50.32849,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "StatsD monitoring <em>integration</em>",
        "sections": "StatsD monitoring <em>integration</em>",
        "tags": "<em>Integrations</em>"
      },
      "id": "6174af22e7b9d253c613b73d"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 475.82227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "sections": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " an anomaly is detected, you can view it in the <em>Applied</em> <em>Intelligence</em> anomalies feed, or we&#x27;ll send notifications directly to your Slack channel or a webhook. How it works <em>Proactive</em> <em>Detection</em> uses the following methods to <em>detect</em> anomalies in your app data: <em>Proactive</em> <em>Detection</em> monitors metric data"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.78284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources, then <em>Alerts</em>. Tip Adding anomalies as a source won&#x27;t affect your current <em>Proactive</em> <em>Detection</em> configurations or notifications. AWS You can integrate"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.21347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels <em>Alerts</em> Aggregation Key labels.conditionNames Labels <em>Alert</em> Condition Names labels.originalAccountIds"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-24T19:52:04Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE We're discontinuing support for several capabilities, including suggested responders for PagerDuty sources in October 2021. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.78284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources, then <em>Alerts</em>. Tip Adding anomalies as a source won&#x27;t affect your current <em>Proactive</em> <em>Detection</em> configurations or notifications. AWS You can integrate"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Expanded anomaly detection",
        "Important",
        "Requirements",
        "Why it matters",
        "Get started with anomaly detection",
        "Detect anomalies with a faceted NRQL query",
        "See your anomalies in one place",
        "Tip",
        "Query anomaly data",
        "Reduce the number of detected anomalies"
      ],
      "title": "Expanded anomaly detection",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "0b07c0b6ce27f39b5edb3e112a0f949835cbb8c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-09-14T10:33:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This feature is a limited release. We’ve expanded anomaly detection coverage beyond your APM applications. Configure anomaly detection for your browser applications, mobile applications, infrastructure hosts, and nearly anything you want to monitor. Requirements Expanded anomaly detection is available as a limited beta. You can request access here. Why it matters When starting to configure alert conditions for a variety of applications and hosts, it can be difficult to know what you’ll want to be notified about ahead of time. Anomaly detection helps you distinguish between what’s typical performance in your system and where you’re starting to have trouble. Instead of creating your alert conditions manually, you can simply tell us what you want to monitor. Anomaly detection will help you identify baseline performance in your system and flags anomalous activity in your system. Get started with anomaly detection To get started with expanded anomaly detection: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload or entities you’d like to monitor. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name your configuration and save. Detect anomalies with a faceted NRQL query To detect anomalies with a faceted NRQL query: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Click Use a query instead. You may need to select an account, if you have more than one. Add one or more queries with a FACET clause. Name the query and confirm the facets you want to monitor for anomalies. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name the configuration and save. See your anomalies in one place When you set up anomaly detection, New Relic starts analyzing the golden signals of your entities and workloads. Anomalies appear in your activity feeds throughout New Relic One and the Anomalies tab as soon as they’re detected. Click any anomaly to get more detail about it, including analysis and context for the anomaly. Tip For this limited release, anomaly detection won’t generate notifications. However, you can configure a NRQL alert condition for the NrAiAnomaly event. To view anomalies, from one.newrelic.com, go to Alerts & AI > Issues & activity > Anomalies. Query anomaly data Detected anomalies are written to the NrAiAnomaly event in your NRDB account. You can learn more about this event and how to query it here. Reduce the number of detected anomalies If you’re seeing too many anomalies, the first step is to make sure your sensitivity level is set to Low. If it’s already set to Low, you can define specific thresholds to distinguish between normal and anomalous behavior. To define custom thresholds: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab and the configuration you want to modify. Select an entity or workload, and then change the sensitivity level. You can use custom sensitivity to define specific thresholds for different entity types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.84183,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Expanded anomaly <em>detection</em>",
        "sections": "Expanded anomaly <em>detection</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Get started with anomaly <em>detection</em> To get started with expanded anomaly <em>detection</em>: From one.newrelic.com, go to <em>Alerts</em> &amp; AI &gt; <em>Proactive</em> <em>Detection</em> &gt; Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload"
      },
      "id": "60b5124064441ff965e2cb01"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.21347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels <em>Alerts</em> Aggregation Key labels.conditionNames Labels <em>Alert</em> Condition Names labels.originalAccountIds"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/index": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-24T23:54:15Z",
      "updated_at": "2021-10-24T23:54:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1942.1619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " activity streams and in the <em>Applied</em> <em>Intelligence</em> anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from <em>Alerts</em> &amp; AI, under Proactive"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1653.8563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "REST API calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our REST API (v2) allows you to configure settings for <em>alerts</em>. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Incident workflows",
        "EOL NOTICE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-24T23:53:22Z",
      "updated_at": "2021-10-19T03:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "EOL NOTICE We're discontinuing support for several capabilities in November 2021, including the Incident Workflows beta. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1581.0747,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels <em>Alerts</em> Aggregation Key labels.conditionNames Labels <em>Alert</em> Condition Names labels.originalAccountIds"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/alert-custom-violation-descriptions": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.09366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts_synthetics_conditions</em>.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy <em>Conditions</em> for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list <em>conditions</em> for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-24T19:56:46Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.7207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-24T23:56:29Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.53673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.36298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "Create <em>new</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts</em>_synthetics_conditions.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-25T15:31:44Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.64133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: <em>Notification</em> channels",
        "sections": "NerdGraph tutorial: <em>Notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " has been created, it can be associated with one or more <em>alert</em> policies. Once associated, those channels will receive <em>notifications</em> from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "Manage alert notification channels",
        "Tip",
        "Reference for updating channels",
        "View email channels",
        "Add or update email channels",
        "Create more channels",
        "Add or remove policies assigned to a channel",
        "Assign a channel to a policy",
        "Change a channel's name",
        "Check for policies assigned to a user",
        "Check how many policies are assigned to a channel",
        "View assigned alert policies",
        "Delete a channel",
        "Basic process"
      ],
      "title": "Manage alert notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "521bed5aa6fdcea5c1cffd11d01e6dad19bc7c40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/update-alert-notification-channels/",
      "published_at": "2021-10-24T19:55:45Z",
      "updated_at": "2021-09-08T15:38:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To keep alert notifications consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a new channel entirely, and more. Tip Your selected channel type determines the communication method that appears. For example, if your channel type is email, then the channel will include an email address value. For more information, see channel types. Reference for updating channels Here's a quick reference for updating channels which also includes links to more detailed information and procedures. View email channels Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update email channels Users can't unsubscribe from email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy. Create more channels To create a new notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Click New notification channel. Add or remove policies assigned to a channel To add or remove policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Choose a channel, and then click Alert policies. From the selected policy, use the windows to select, remove, or clear all notification channels. Assign a channel to a policy To add a notification channel to one or more policies: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies. Choose a policy, click Notification channels, and then click Add notification channels. Choose a channel, and then click Update policy. Change a channel's name To rename an existing notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details, change the name (maximum 64 characters) based on the channel type if applicable, and then save. Check for policies assigned to a user To check whether an account user has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Optional: Search by \"user\" to browse users or a specific username or email. Choose the user, then click Alert policies. Check how many policies are assigned to a channel To check whether a notification channel has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. The Policy subscriptions column lists how many policies are assigned to the channel. View assigned alert policies To view the policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, choose a channel, and then click Alert policies. OR To view the notification channels assigned to a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, choose a policy, then click Notification channels. Delete a channel To delete a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. In the list, click the Delete icon. Basic process Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details page, make any necessary changes, and then save. The user interface shows a Last modified time stamp for any changes to policies, including their conditions and notification channels.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.91937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>alert</em> <em>notification</em> channels",
        "sections": "Manage <em>alert</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "To keep <em>alert</em> <em>notifications</em> consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a <em>new</em> channel entirely, and more. Tip Your selected channel type determines the communication method that appears"
      },
      "id": "603eca45e7b9d2d1d82a0806"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.09352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts_synthetics_conditions</em>.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy <em>Conditions</em> for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list <em>conditions</em> for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-24T19:56:46Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.72066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-24T23:56:29Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.53668,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/monitor-scheduled-jobs": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.09338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts_synthetics_conditions</em>.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy <em>Conditions</em> for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list <em>conditions</em> for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-24T19:56:46Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.72061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-24T23:56:29Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.53665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/multi-location-synthetic-monitoring-alert-conditions": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.09338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts_synthetics_conditions</em>.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy <em>Conditions</em> for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list <em>conditions</em> for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-24T19:56:46Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.72061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-24T23:56:29Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.53665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.09323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts_synthetics_conditions</em>.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy <em>Conditions</em> for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list <em>conditions</em> for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-24T19:56:46Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.72058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-24T23:56:29Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.53662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/scope-alert-thresholds-specific-instances": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.09323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts_synthetics_conditions</em>.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy <em>Conditions</em> for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list <em>conditions</em> for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-24T19:56:46Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.72058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-24T23:56:29Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.53662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/select-product-targets-alert-condition": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.0931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts_synthetics_conditions</em>.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy <em>Conditions</em> for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list <em>conditions</em> for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-24T19:56:46Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.72055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-24T23:56:29Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.53659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-24T22:26:58Z",
      "updated_at": "2021-10-24T22:26:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 60 for aggregation_window and 120 for aggregation_delay. EVENT_FLOW works in most use-cases, but for a discussion on which use cases work better with EVENT_TIMER, see Which aggregation method to use?. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"aggregation_method\": \"string\", \"aggregation_delay\": integer, \"aggregation_timer\": integer, \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.0931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&#x2F;<em>alerts_synthetics_conditions</em>.json&#x27; \\ -H &#x27;Api-Key:$API_KEY&#x27; -i \\ -d &#x27;policy_id=$POLICY_ID&#x27; Copy <em>Conditions</em> for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list <em>conditions</em> for your <em>alert</em> policies. The API calls can be used with plugins from <em>New</em> <em>Relic</em>"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-24T19:56:46Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.72055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-24T23:56:29Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.53659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ]
}