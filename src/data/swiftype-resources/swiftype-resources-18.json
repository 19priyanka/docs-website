{
  "/docs/style-guide/structure/tables": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "BETA FEATURE",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation, docs site",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "1a874659169393e08e5c0cb986f258482797af4d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/word-choice/usage-dictionary/",
      "published_at": "2021-12-30T06:25:07Z",
      "updated_at": "2021-12-09T22:55:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For consistency across New Relic content, here are our general word usage guidelines: We generally follow the Microsoft Style Guide, which is based on the Chicago Manual of Style. We follow American English conventions, rather than British English ones. We defer to the official product names for references to products. (For example, for Amazon Web Services (AWS), see aws.amazon.com/products.) For terminology specific to New Relic, we use the product glossary. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta Use the beta callout. In the body text, use lowercase. For example: BETA FEATURE This feature is currently in beta. If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation, docs site If you need to refer to the docs themselves—don't. Generally it's better to directly link to the doc you're referencing and use the doc title as your link text. For example, See [Install the .NET agent](URL) rather than See our [.NET agent install docs](URL). If there's not a good alternative, doc generally sounds more natural than document or documentation. If you're tempted to use a longer form, try reading it aloud to see which reads best. If you must refer to the site as a whole, call it the docs site rather than Docs site or documentation site. Internally, you can also refer to the whole URL docs.newrelic.com to avoid ambiguity with other sources of docs like internal platform docs or API explorer docs. To refer to our docs GitHub repo, use the repo name docs-website or the repo path newrelic/docs-website. dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Avoid these Latin abbreviations. Instead of e.g., use for example or such as. Subbing for i.e. is tricker, because sometimes people use it to mean that is, while at other times it's mis-used to mean for example. Read the context to be clear, but usually the best solution is to rewrite so the description is clear without needing explanatory text. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. It should have a period at the end (etc.). Ensure that you have several meaningful examples, though, before using it. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Avoid using generically, to avoid confusion with infrastructure monitoring. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS, Mac OS X, or OS X. master account We previously used master account and sub-account but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with New Relic. For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original user model but still plays a role for some behind-the-scenes features on our New Relic One user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say we and our when it works with the flow of your writing. Avoid overloading paragraphs with New Relic mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use you and your liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 291.58838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some"
      },
      "id": "619e1c0a64441fb97e9858d2"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution",
        "Important",
        "Tip",
        "User-related permissions",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "046f0435c8098009144e40689b5a0f0ffc07755f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/formatting/callouts/",
      "published_at": "2021-12-30T03:18:06Z",
      "updated_at": "2021-12-04T10:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts We have a number of callout types, and each is controlled by the variant you include in the <Callout> tag. Here's an example of the format for a tip callout: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy Here are examples of our callout variants: Caution Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use <Callout variant=\"caution\">. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use <Callout variant=\"important\">. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use <Callout variant=\"tip\">. At a traffic light, a Tip would be a green light. User-related permissions For recommended wording, see User-related language and styles. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, add a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.30734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Lists",
        "Tip",
        "In-line lists"
      ],
      "title": "Lists",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8dd72524718c4e6e1d36d0f23b9af6ab4203e2a",
      "image": "https://docs.newrelic.com/static/425a3955215de94222a432e13be5dc84/8c557/tables-example.png",
      "url": "https://docs.newrelic.com/docs/style-guide/structure/lists/",
      "published_at": "2021-12-30T09:55:23Z",
      "updated_at": "2021-11-24T09:17:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Lists are a powerful way to organize information, but they don't always make for a pleasant reading experience. Keep these points in mind when you're writing a list: Always capitalize the first letter of the first word in each list item. Use ordered (numbered) lists for step-by-step procedures, where the order matters. Use unordered (bulleted) lists to make it easier for users to skim related information. Use OR on a separate line when there is more than one option for a numbered step or a bullet point. Use tables when your ordered or unordered list would benefit from some extra detail. Tip For punctuation guidelines, follow the Microsoft Writing Style Guide, which includes considerations for localization. Here's an example of an ordered list as a table. Because each step is a row, the table helps to structure the levels of detail. In-line lists As an alternative to using bullet point lists, you can do an in-line list, like this: C SDK | Go | Java. You might want to use an in-line list when: You're linking to further documentation. Customers will likely be selecting a single option. The list item can be displayed with a short word or phrase (like Java, or Infrastructure). You think a bullet point list takes up a lot of vertical space. This may happen in circumstances where a procedure must include several lists. Here's one example of this. There are only two or three potential options they'll be choosing from and a bullet point list seems unnecessary. Here's an example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.51157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " For punctuation guidelines, follow the Microsoft Writing <em>Style</em> <em>Guide</em>, which includes considerations for localization. Here&#x27;s an example of an ordered list as a table. Because each step is a row, the table helps to structure the levels of detail. In-line lists As an alternative to using bullet point"
      },
      "id": "60421e4e28ccbc71a9eba7a2"
    }
  ],
  "/docs/style-guide/word-choice/pricing-language-guidelines": [
    {
      "sections": [
        "Query and alert on billing/usage data",
        "Available data types",
        "Query examples",
        "Data usage queries",
        "Daily data usage",
        "Daily usage by source",
        "Metrics ingest by source",
        "Month-to-date data usage",
        "Month-to-date estimated data cost",
        "User count queries",
        "Month-to-date full platform users",
        "Projected monthly full platform user count",
        "Count full platform users and basic users",
        "Set usage alerts",
        "Caution",
        "Ingested gigabytes exceed a fixed value",
        "Usage exceeds fixed threshold for GBs",
        "Usage exceeds fixed threshold for users",
        "Usage exceeds fixed threshold for estimated cost",
        "Available attributes"
      ],
      "title": "Query and alert on billing/usage data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "e22ae9e26686d11726a82ad4036ff58520b4a439",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/",
      "published_at": "2021-12-30T08:19:00Z",
      "updated_at": "2021-12-04T21:08:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For accounts on our New Relic One pricing model, we provide a View your usage UI for understanding billing-related usage and a Manage your data UI for managing billing-related data. Additionally, you can: Query your usage data to get more detail than is available in the UI. Set up NRQL alert conditions to get notifications about changes in your usage. Note that account hierarchy may affect queried data. See Account structure. Available data types Usage data is attached to these events: NrConsumption records usage every hour, and is the equivalent of \"real-time\" usage. Use this event to observe usage trends over time. NrMTDConsumption generates aggregate values from the NrConsumption event. Use this event to see usage or estimated cost for a billing period. NrUsage records usage every hour and is used to see usage reported per product. To see changes made to your account (for example, user management changes), you can query NrAuditEvent. Query examples The View your usage UI displays your data usage and billable user count. If you need more detail than that UI provides, you can use these NRQL queries. For definitions of some of the attributes used in these queries, see Attributes. Data usage queries Here are some data usage query examples: Daily data usage This query totals your billable ingested data, and displays a daily value for the past three months: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago TIMESERIES 1 day Copy Daily usage by source This query totals your billable ingested data, and displays a daily value for the past three months faceted by the source: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago FACET usageMetric TIMESERIES 1 day Copy Metrics ingest by source This query breaks down Metric data by the top ten metric names. You could also facet by appName or host to adjust the analysis. FROM Metric SELECT bytecountestimate()/10e8 as 'GB Estimate' SINCE '2021-04-01' UNTIL '2021-04-08' FACET metricName LIMIT 10 TIMESERIES 1 day Copy Month-to-date data usage This query shows the current full platform user count. In other words, it shows how much you'd be billed for your data for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE this month Copy Month-to-date estimated data cost This query shows the estimated cost of your ingested data: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month Copy User count queries Here are some user-related query examples. For details on how users are counted, see User count calculations. Month-to-date full platform users This query shows the billable full platform users for the month. In other words, it shows how much you'd be billed for your users for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(usersBillable) SINCE this month Copy This query shows how many full platform users were counted by hour. This is useful for seeing how the full platform user count changed over time. from NrConsumption SELECT max(FullUsers) SINCE 10 days ago TIMESERIES 1 hour Copy Projected monthly full platform user count This query shows a projected count of monthly users. This query would not be good for using in a dashboard; it requires values based on a) the days remaining in the month, b) the start of the month. Here's an example querying the projected end-of-month count with 10 days left in that month: FROM NrMTDConsumption SELECT predictLinear(FullUsers, 10 days) SINCE '2020-09-01' Copy Count full platform users and basic users The usage UI shows the count of full platform users and basic users. The query used is: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric Copy To see the count of full and basic users over time: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric TIMESERIES 1 hour Copy Set usage alerts To help manage your billable data, you can set alerts to notify you of unexpected increases in usage. Learn how to create alerts with NRQL queries here. Caution When creating alert conditions, you should use the Event Timer method, which works very well with infrequent data. Here are some NRQL alert condition examples. For attribute definitions, see Attributes. Ingested gigabytes exceed a fixed value This query will create an alert when your hourly usage exceeds a fixed value: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy If you have multiple child accounts, you may want to set threshold alerts for a specific subaccount: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' AND consumingAccountId = YOUR_CHILD-ACCOUNT_ID Copy Usage exceeds fixed threshold for GBs This query will create an alert when your usage exceeds fixed monthly threshold for GBs: FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy Usage exceeds fixed threshold for users This query will create an alert when your usage exceeds fixed monthly threshold for billable users: FROM NrMTDConsumption SELECT latest(usersBillable) Copy Usage exceeds fixed threshold for estimated cost This query will create an alert when your usage exceeds fixed threshold for estimated cost: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' Copy Available attributes Below are some of the important attributes attached to usage events. Attribute Description productLine The category of usage. There are three options: DataPlatform, FullStackObservability, and ProactiveDetection. (Starting November 1, 2021, IncidentIntelligence is no longer a billing factor). For more details about these categories, see New Relic platform. metric Consolidates multiple categories of usage into a single metric. Helpful when faceting by productLine. consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. estimatedCost Calculates a cost estimate based on usage and metric cost. This is an estimate of costs to date, not your monthly invoice. For more attributes, see the data dictionary.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.99966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query and alert on <em>billing</em>&#x2F;usage data",
        "sections": "Query and alert on <em>billing</em>&#x2F;usage data",
        "tags": "New Relic One <em>pricing</em> and <em>billing</em>",
        "body": "For accounts on our New Relic One <em>pricing</em> model, we provide a View your usage UI for understanding <em>billing</em>-<em>related</em> usage and a Manage your data UI for managing <em>billing</em>-<em>related</em> data. Additionally, you can: Query your usage data to get more detail than is available in the UI. Set up NRQL alert"
      },
      "id": "6175f12b64441f53a35fc21c"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing model works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Full platform user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-12-30T09:57:26Z",
      "updated_at": "2021-11-24T14:22:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing model. If you’re on our original pricing model, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing model works Starting July 30, 2020, all of our new customers are on a pricing model that we call New Relic One pricing. Customers on our original pricing model are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full platform users, who have access to our more curated UI experiences. Basic users are free. The cost of each full platform user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full platform user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing model, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Full platform user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full platform users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full platform users during the month of January, you'd be billed for 100 full platform users for that month. A full platform user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full platform user can be downgraded to a basic user: a full platform user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full platform user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full platform user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full platform users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full platform user or converted to a full platform user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing model includes one free full platform user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full platform user in another account. In such cases, the full platform user status takes precedence and that user is considered a full platform user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full platform user, and unlimited basic users. To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.98733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One <em>pricing</em> and <em>billing</em> ",
        "sections": "New Relic One <em>pricing</em> and <em>billing</em>",
        "tags": "New Relic One <em>pricing</em> and <em>billing</em>",
        "body": " at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month <em>bill</em>. For how to query user-<em>related</em> usage, see Query and alert on usage. Usage plan details There are two New Relic One <em>pricing</em> usage plans: Pay-as-you-go: This plan bills at the end"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Overview of changes to pricing and user model",
        "Overview of how pricing model and user model relate",
        "Pricing plans explained",
        "Determine pricing model",
        "Convert to new pricing",
        "User models explained",
        "Requirements for new user model",
        "Determine which user model you're on",
        "Feature impacts of user model",
        "Transition to new models"
      ],
      "title": "Overview of changes to pricing and user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "b19d61b5a0c65ca352e2ce0e260e2b53391b94fc",
      "image": "https://docs.newrelic.com/static/1461470cc1ef0be91120c84d76a7ccdd/c1b63/new-relic-one-pricing-plan-billing-ui.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-product-based-pricing/overview-changes-pricing-user-model/",
      "published_at": "2021-12-30T06:27:06Z",
      "updated_at": "2021-11-24T14:34:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In 2020, New Relic released both a newer pricing model and a newer user model. Keep reading to learn about: How the pricing model and the user model relate to each other Pricing plans explained User models explained How to switch to the new models Overview of how pricing model and user model relate In 2020, we released both a new, improved pricing model and a new, improved user model. These models represent the future. All new sign-ups are on these new models and eventually all organizations will be on these models. But currently, our customers from before July 2020 may have one of several combinations of these as they either switch to the new pricing or migrate their users to the new user model. This table shows how pricing and user model relate to each other: Pricing plan factors User model factors Original pricing If your organization was created before July 30 2020, you remain on our original pricing model until you transition to New Relic One pricing. For original pricing accounts, you have users on the original user model unless you've migrated your users to the new model. Note that if you've added users via automated user management, they're on the new model. This means it's possible to have some users on both models. New Relic One pricing An organization is on the New Relic One pricing model: If it was created on or after July 30 2020, or If it's an older organization but has switched to New Relic One pricing. If your organization was created on or after July 30 2020, your users are on the New Relic One user model. If you have an older organization, you have users on the original user model unless you've migrated your users to the new model. Pricing plans explained New Relic organizations are on one of two pricing models: New Relic One pricing: Our new pricing model is simpler. It bills on a) which edition you're on (Standard, Pro, or Enterprise), b) the GBs of data ingested, and c) how many billable full platform users you have. All organizations created on or after July 30 2020 are on this pricing model, as are older organizations that have switched to this pricing. There are two versions of this pricing model. Our original product-based pricing model: this is based on subscriptions to specific products (for example, APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer pricing model: in that case, their users remain on our original user model. Determine pricing model To determine which pricing model you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see billing information about data ingested and the number of billable users, you’re on the new pricing model. If you're on New Relic One pricing, you'll see a billing UI like this. Convert to new pricing Some organizations are able to switch to new pricing. Learn more about switching your pricing model. User models explained In this context, the term \"user model\" refers to the structure of a New Relic user record and how it interacts with the broader New Relic organization that it's in. Our two user models are: New Relic One user model: this newer, improved user model has these major differences from the original user model: All your accounts and users are contained under a top-level organization. This gives an organization stronger control over managing users and what they can access. One impact of this is that users who work with multiple New Relic organizations may have an email address associated with multiple logins. Users on this model have a different system for managing permissions and account access. Using access grants, you assign users access to specific roles on specific accounts. Original user model: some aspects of this older model that are different from our newer model: There wasn't as much organization-level control over users. For example, a New Relic user had the ability to access multiple accounts they'd been granted access to using a single login. Users on the original user model have a different user management system. To learn more about benefits of the new model, see our blog post about user model changes and an explanation of the new account structure. For impacts and limitations, see Feature impacts. Requirements for new user model Here's a synopsis of the factors governing what organizations use the new model: All New Relic organizations that signed up after July 30 2020 have users on this model, and also have the new pricing model. Some older New Relic organizations have had their users migrated to the new model by New Relic or by using the user migration procedure. Note that switching to the new pricing model is independent from migrating users. Partner accounts (resellers, managed service providers), and organizations using the partnership account structure, cannot yet migrate their users to the new model. Determine which user model you're on To determine what user model you're on, from the account dropdown select User preferences. If you see the UI below, you're on the New Relic One user model. If you see a different UI with more content displayed, you're on the original user model (see original user docs). To determine if you can manage users on the New Relic One user model, see Manage users. The user model is independent of your pricing model. For how user model relates to pricing, see the Pricing and user model table. Feature impacts of user model The new user model offers many benefits. Here are some feature impacts of being on the New Relic One user model that may be not obvious to users accustomed to our previous user model: More separation of organizations/accounts: If you have an email address associated with multiple New Relic accounts, this may mean you need to log out and log back in. Learn more about account access. Adding accounts: Pro and Enterprise edition can have more than one account in their organization. Currently users in these organizations cannot, on their own, add accounts. They must get help from their New Relic account representative. To learn about adding users to accounts, see Manage users. Alerts-related impacts: Policy actions: For alert policies and conditions, some UI locations display the user that made the last modification. For users on the new model, it will display their user ID and not their user name. For example, a policy might read Last modified Sep 7, '20 4:26 pm by user 1234567 instead of by John Doe. If you have user management permissions, you can determine what user this is by going to the User management UI. Notifications: Users on the new model won’t show up as an option when choosing users to receive alert notifications. The result of this is that these users will not get New Relic mobile app push notifications. As a workaround, you can instead use their email address as the notification channel. You can't use the REST API to generate a list of users (only original model users). Instead you'd use the user management UI. Changing account name: These users cannot change the name of their organization after it has been created. Transition to new models Some New Relic organizations on the old models are able to transition to the new models. To learn more about this, see Transition to new models.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.51544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of changes to <em>pricing</em> and user model",
        "sections": "Overview of how <em>pricing</em> model and user model <em>relate</em>",
        "tags": "Original accounts and <em>billing</em>",
        "body": ", their users remain on our original user model. Determine <em>pricing</em> model To determine which <em>pricing</em> model you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see <em>billing</em> information about data ingested and the number of billable users, you’re on the new"
      },
      "id": "603e97fa28ccbcb7c2eba754"
    }
  ],
  "/docs/style-guide/word-choice/usage-dictionary": [
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution",
        "Important",
        "Tip",
        "User-related permissions",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "046f0435c8098009144e40689b5a0f0ffc07755f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/formatting/callouts/",
      "published_at": "2021-12-30T03:18:06Z",
      "updated_at": "2021-12-04T10:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts We have a number of callout types, and each is controlled by the variant you include in the <Callout> tag. Here's an example of the format for a tip callout: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy Here are examples of our callout variants: Caution Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use <Callout variant=\"caution\">. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use <Callout variant=\"important\">. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use <Callout variant=\"tip\">. At a traffic light, a Tip would be a green light. User-related permissions For recommended wording, see User-related language and styles. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, add a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.3073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Tables",
        "Table template",
        "Tables to describe UI functions"
      ],
      "title": "Tables",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "88023a9ec5f4275d779fb9bd7b5e74aae24041ad",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/structure/tables/",
      "published_at": "2021-12-30T09:55:44Z",
      "updated_at": "2021-11-24T09:18:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Tables help you organize information to make it easier for readers to skim. However, if your table becomes too long, follow the \"five to nine\" guideline and consider restructuring the information in other ways. Use sentence case for text in every table column unless it's a specific file name or code value that requires lower case or all caps. Table template This is a basic table template. <table> <thead> <tr> <th style={{ width: \"200px\" }}> Item </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Item name </td> <td> Description of item </td> </tr> </tbody> </table> Copy Additional options: If you want to... Do this Shade every other row Use <table class=\"alternate\">. Create a table within a clamshell Use <table class=\"spec\">. Highlight row in gray on hover Add the class table-hover to the <table> element. Specify individual column widths Set style=\"width:###px;\" in the header row. In general, for two-column tables on the docs site: Set the first column as 200 pixels: <th style=\"width:200px\">. To allow the table to adjust automatically to the remaining page width, do not set a width for the second column. Tables to describe UI functions When using tables to describe available functions, give readers a roadmap. They may know what they want to find or accomplish, but they may not know what it's called or how to do it. For example, to provide a list of features for a particular UI page, label the header's first column If you want to... and label the second column Do this.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.5122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " or code value that requires lower case or all caps. Table template This is a <em>basic</em> table template. &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th <em>style</em>={{ width: &quot;200px&quot; }}&gt; Item &lt;&#x2F;th&gt; &lt;th&gt; **Requirements** &lt;&#x2F;th&gt; &lt;&#x2F;tr&gt; &lt;&#x2F;thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Item name &lt;&#x2F;td&gt; &lt;td&gt; Description of item &lt;&#x2F;td&gt; &lt;&#x2F;tr&gt; &lt;&#x2F;tbody&gt; &lt;&#x2F;table&gt; Copy"
      },
      "id": "60421e8228ccbc65f1eba7a0"
    },
    {
      "sections": [
        "Lists",
        "Tip",
        "In-line lists"
      ],
      "title": "Lists",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8dd72524718c4e6e1d36d0f23b9af6ab4203e2a",
      "image": "https://docs.newrelic.com/static/425a3955215de94222a432e13be5dc84/8c557/tables-example.png",
      "url": "https://docs.newrelic.com/docs/style-guide/structure/lists/",
      "published_at": "2021-12-30T09:55:23Z",
      "updated_at": "2021-11-24T09:17:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Lists are a powerful way to organize information, but they don't always make for a pleasant reading experience. Keep these points in mind when you're writing a list: Always capitalize the first letter of the first word in each list item. Use ordered (numbered) lists for step-by-step procedures, where the order matters. Use unordered (bulleted) lists to make it easier for users to skim related information. Use OR on a separate line when there is more than one option for a numbered step or a bullet point. Use tables when your ordered or unordered list would benefit from some extra detail. Tip For punctuation guidelines, follow the Microsoft Writing Style Guide, which includes considerations for localization. Here's an example of an ordered list as a table. Because each step is a row, the table helps to structure the levels of detail. In-line lists As an alternative to using bullet point lists, you can do an in-line list, like this: C SDK | Go | Java. You might want to use an in-line list when: You're linking to further documentation. Customers will likely be selecting a single option. The list item can be displayed with a short word or phrase (like Java, or Infrastructure). You think a bullet point list takes up a lot of vertical space. This may happen in circumstances where a procedure must include several lists. Here's one example of this. There are only two or three potential options they'll be choosing from and a bullet point list seems unnecessary. Here's an example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.51154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " For punctuation guidelines, follow the Microsoft Writing <em>Style</em> <em>Guide</em>, which includes considerations for localization. Here&#x27;s an example of an ordered list as a table. Because each step is a row, the table helps to structure the levels of detail. In-line lists As an alternative to using bullet point"
      },
      "id": "60421e4e28ccbc71a9eba7a2"
    }
  ],
  "/docs/style-guide/word-choice/user-related-language-guidelines": [
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-12-30T06:11:17Z",
      "updated_at": "2021-12-25T14:30:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters Allowed characters: Characters must be UTF-8. When using NerdGraph to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. And check out this short video on querying APM tags (3:20 minutes). Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.99671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Team-<em>related</em> tags",
        "body": ", or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db <em>Role</em> examples: <em>roles</em>: architecture <em>roles</em>: devops <em>roles</em>: pm Region examples: region: emea region: america region: asia Environment-<em>related</em> tags You can create entities"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "image": "https://docs.newrelic.com/static/565d4ebddf52a4592c594032696516b9/c1b63/New-Relic-capabilities-UI-screenshot.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/new-relic-one-user-model-understand-user-structure/",
      "sections": [
        "Users, roles, permissions (New Relic One user model)",
        "Important",
        "Overview",
        "User type: basic users and full platform users",
        "Compare full vs basic capabilities",
        "Tips on choosing user type",
        "Understand user-related billing",
        "Have questions about why you can't access something?",
        "Default groups: Admin and User",
        "How do user type, roles, and groups relate to each other?",
        "Roles and capabilities",
        "Standard (default) roles",
        "Capabilities",
        "Manage users",
        "2020 user model changes"
      ],
      "published_at": "2021-12-30T06:26:18Z",
      "title": "Users, roles, permissions (New Relic One user model)",
      "updated_at": "2021-11-24T02:17:27Z",
      "type": "docs",
      "external_id": "169383c2678ce973404db07195b2dee6eda9163d",
      "document_type": "page",
      "popularity": 1,
      "body": "Your New Relic users can be on one of two user models: this doc explains the New Relic One user model. Important If your New Relic organization was created before July 30 2020 and you haven't gone through a user migration process, your users are likely on our original user model. For more on this, see User model changes. Overview This doc will explain the structure of the New Relic One user model, including: User type (basic user versus full platform user) Default user groups, including Admin and User Roles and capabilities For how to add and manage users in the UI, see User management. User type: basic users and full platform users Important This section is for users on our New Relic One user model. In November, 2021, we changed the user type \"full user\" to \"full platform user.\" A user's user type determines if they have access to our basic features (basic user) or can access all of our curated observability UI features (full platform user). The user type is something meant to be set long-term based on that user's expected New Relic responsibilities. Below are details on the two user types. Note that full platform users are billable only if you're on New Relic One pricing. Basic user. Details: These users are free and have access to a wide range of features, including setting up and configuring any New Relic data-reporting tool, running queries of your data, using our logs UI, making custom charts and dashboards, and setting up alerts. Unlike full platform users, they do not have access to our more curated observability UI experiences or some Applied Intelligence features (for a detailed comparison, see Capabilities). Basic users will see prompts to become a full platform user when they attempt to access unavailable features. For details, see Upgrade. Full platform user, also known as full user. Details: Full platform users have access to everything (depending on any role restrictions), including all our observability UI experiences, such as APM, infrastructure monitoring, browser monitoring, mobile monitoring, synthetic monitors, access to New Relic One apps, and more. For details, see Capabilities. Standard edition includes one free full platform user and up to five total full platform users. A full platform user can downgrade to a basic user twice in a 12-month period. To view and edit the user type of your users, use the User management UI. Learn more about basic user versus full platform user differences: Compare full vs basic capabilities Below is a table comparing what basic users and full platform users can do. A simple way to think about it is that full platform users have theoretical access (dependent on any chosen role restrictions) to all of our curated UI experiences, while basic users are restricted to fairly basic capabilities. Features Full platform user Basic user Observability UI experiences Application monitoring (APM) UI Infrastructure monitoring UI Digital Experience Monitoring UI, which includes: Browser monitoring UI Mobile monitoring UI Synthetic monitoring UI Synthetics checks Serverless monitoring UI Logs in context Distributed tracing UI Infinite Tracing (Pro and Enterprise edition) Assorted UI experiences, including: Kubernetes cluster explorer UI Errors Inbox Key transaction UI Workloads UI CodeStream integration (temporary preview access) Access to New Relic One apps Can build apps but can't access other apps New Relic One platform capabilities Full platform user Basic user Data ingest from any source (agents, integrations, APIs) Query data Create custom charts and dashboards Alerts and notifications APIs, including NerdGraph (basic user permissions) Query and chart log data Build New Relic One apps (but cannot access other apps) Manage New Relic data Manage other New Relic users Applied Intelligence Full platform user Basic user Acknowledge and resolve issues Root cause analysis Incident/anomaly analysis Correlation assistant Issue maps Machine learning classification Note that the pricing edition (Standard, Pro, or Enterprise) will also affect what features you have access to. For organizations with New Relic One pricing, learn more about how full platform users impact billing. Tips on choosing user type A user's user type (basic user vs full platform user) is meant to be a long-term assignment, based on the New Relic responsibilities that user is expected to perform. A full platform user can be downgraded to a basic user only twice in one year. Below are tips for why you'd choose full platform user versus basic user. Reasons to make someone a full platform user: They play a key role in the development, testing, deployment, and maintenance phases of the application development lifecycle. They break/fix code regularly; they are responsible for triaging workflows, troubleshooting, or managing users and roles for their team. They have DevOps practices like version control systems, and they implement CI/CD. They need to use New Relic's curated dashboards and experiences (not just the ability to create their own custom queries and charts); in other words, they need full access to our platform. They need to be able to manage users and/or billing. Reasons to make someone a basic user: They play a key role in the planning phase of the application development lifecycle. They use and configure New Relic agents, APIs, and integrations to send us data, and access, configure, and use alerts on such data (not necessarily responsible for triaging workflows, troubleshooting, or managing users and roles for their team). They want to see high-level analytics and business metrics for future planning (such as C-Suite executives). They do not need to use our curated experiences and dashboards, but would benefit from the ability to create their own custom queries and charts of data; in other words, they don't need full access to the platform. They don't manage users. For accounts on New Relic One pricing, learn more about user-related billing calculations. Understand user-related billing If you're on the New Relic One pricing model, full platform users are billable, and there are restrictions around how often a full platform user can downgrade to a basic user. For details, see User count billing details. For how to query and alert on usage data, see Query usage data. Have questions about why you can't access something? See Factors affecting access. Default groups: Admin and User For users on our New Relic One user model, a \"group\" is what allows the grouping together and managing of multiple users at the same time. Your New Relic users are assigned to a group, and that group is granted access to specific roles on specific accounts. We have two default groups: User: This group allows a user to use and configure monitoring/analysis features but not perform account-related tasks like managing billing or users. It has access to the All product admin role, which gives access to our observability platform tools but not to the organization and user management capabilities governed by the Organization manager and Authentication manager roles. Admin: has full access and capabilities, including the organization-level admin abilities. This is the equivalent of having the All product admin, the Billing user, the Organization manager and the Authentication domain manager roles. These groups are added inside your default authentication domain, which includes the default settings of users a) being managed via New Relic and b) logging in via standard email and password. If you add other authentication domains (for SAML SSO and/or SCIM provisioning of users), you'd have new custom groups in those new domains to govern those users. Note that groups, whether default or custom, are not what limit a user's capabilities: it is the role that is assigned to that group (with any basic user restrictions on top of that). If your organization is Pro or Enterprise edition and you want to understand how users are granted access to specific roles and accounts, see Access grants. To change the group a user is in, use the User management UI. How do user type, roles, and groups relate to each other? For users on the New Relic One user model, here's a table explaining how user type (basic vs full platform), roles, and groups relate to each other: Full platform user Basic user Group Full platform users can be assigned to default groups (User and Admin) or custom groups. When basic users are added to a group, that group's role-related restrictions apply. A basic user's capabilities can be restricted in that way, but a basic user can never be granted more capabilities than they start with. For Standard edition, basic users can't be assigned to groups. For Pro and Enterprise edition, they can. Role For an explanation of the roles our default groups have, see Default groups. Custom groups can have either our default standard roles, or custom roles. A basic user's abilities aren't directly defined by a specific role. A basic user can best be described as having the All product admin role but without access to our more curated UI experiences (learn more about user type). When basic users are added to a group, that group's role-related restrictions apply, but a basic user can never be granted more capabilities than they start with. Roles and capabilities For users on the New Relic One user model, a \"role\" can be defined as \"a set of capabilities.\" A capability is defined as the ability to do a specific New Relic task, like 'Delete alert conditions' (learn more about capabilities). Roles are assigned to user groups. Our default groups Admin and User already have our standard roles (defined below) assigned. Organizations on Pro or Enterprise edition can also create custom roles. Standard (default) roles Roles are sets of capabilities. We have several \"standard roles,\" which are roles that satisfy some commonly needed use cases. To view roles and their associated capabilities, use the Organization and access UI. Important Note that some of our standard roles have hidden, non-exposed capabilities that are not available for selection when creating a custom role. The only standard roles that can be replicated with a custom role are Standard user and Read only; all others have some hidden capabilities. Our standard roles include: Standard roles Scope Description All product admin Account Provides admin-level access to observability platform features but not organization-level and user management features. In other words, this role includes all New Relic capabilities with the exception of managing users (Authentication domain manager role), managing organization/account-structure settings (Organization manager role), and managing billing (Billing user role). Note: the Standard user role is essentially the All product admin role minus observability feature configuration capabilities. Standard user Account Provides access to observability platform features, but lacks permissions for configuring those features (for example, ability to configure synthetic monitor secure credentials) and lacks organization-level and user management permissions. Note: the Standard user role is essentially the All product admin role without that role's ability to configure platform features. Billing user Account Provides ability to manage subscriptions and billing setup, and read-only access to the rest of the platform. For organizations with multiple accounts, billing is aggregated in the primary (first-created) account, which is why assigning this role to that primary account grants billing permissions for the entire organization. Organization manager Organization Provides the ability to manage organization settings, including organization structure, name, and preferences. Due to our recent switch to the New Relic One user model, this role currently has few abilities but more will be added over time. For how to grant this role, see Add user management capability. Organization read only Organization Provides the ability to view organization-level settings. For how to grant this role, see Add user management capability. Authentication domain manager Organization Provides ability to add and manage users, and configure authentication domains for users on the New Relic One user model. For how to grant this role, see Add user management capability. Authentication domain read only Organization Provides the ability to view users in your organization and view the configuration of authentication domains. For how to grant this role, see Add user management capability. Read only Account Provides read-only access to the New Relic platform (except for synthetic monitor secure credentials). Manage v1 users Account For New Relic organizations that existed before July 30 2020 and have users on our original user model, this role lets you manage those \"v1\" users. For more about how you'd assign roles to groups and create custom roles, see the user management tutorial. Capabilities A role, whether one of our standard roles or a custom role, is defined as a set of capabilities. To view roles and their associated capabilities, use the Organization and access UI. Important Some of our standard roles have hidden capabilities that aren't available for selection when creating a custom role. For details, see Standard roles. A view of the capabilities associated with the All product admin role. When creating a custom role, you select a custom set of capabilities. Note that the capabilities we expose may change over time: this screenshot was taken in April of 2021. For how to set up roles with custom capabilities, see the user management tutorial. Manage users To learn how to add users, assign them to groups, and create custom groups and roles, see Manage users. 2020 user model changes If you'd like to understand how our user model changed in 2020 and what the impacts of that change were, see User model changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.5077,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Users</em>, <em>roles</em>, permissions (New Relic One <em>user</em> model)",
        "sections": "How do <em>user</em> type, <em>roles</em>, and groups <em>relate</em> to each other?",
        "body": ", and that group is granted access to specific <em>roles</em> on specific accounts. We have two default groups: <em>User</em>: This group allows a <em>user</em> to use and configure monitoring&#x2F;analysis features but not perform account-<em>related</em> tasks like managing billing or <em>users</em>. It has access to the All product admin <em>role</em>, which"
      },
      "id": "603e88e328ccbcfcbaeba7a8"
    },
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic and full platform)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full platform users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-12-30T08:20:04Z",
      "updated_at": "2021-11-24T14:23:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full platform) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic and full platform) Note that there are limits around how many times full platform users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full platform users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.36552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to manage <em>users</em>",
        "sections": "Give <em>users</em> access to accounts and <em>roles</em> (access grants)",
        "tags": "New Relic One <em>user</em> management",
        "body": " in the same way. For example, you may have one authentication domain for <em>users</em> who log in via username&#x2F;password and another authentication domain for <em>users</em> who log in via SAML. If a <em>user</em> is a basic <em>user</em>, this takes precedence over any <em>role</em>-<em>related</em> limitations. For more on this, see Basic <em>user</em> and <em>roles</em>."
      },
      "id": "603e7bce28ccbc415beba74c"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/agent-api-guide-template": [
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "13ab0e9d759903149944453fc4392998b6fab974",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/basic-doc-template/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T09:12:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.44522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic doc <em>template</em>",
        "sections": "Basic doc <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " <em>article</em>_url(category, <em>article</em>, options={}) url_for(options.reverse_merge( :controller =&gt; &#x27;articles&#x27;;, :action =&gt; &#x27;show&#x27;, :category =&gt; category, :<em>article</em> =&gt; <em>article</em> )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add"
      },
      "id": "61b3574c64441f1cc6aec5a4"
    },
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "827639827da156b6a36096c0f6a3911052706a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-12-31T00:56:32Z",
      "updated_at": "2021-11-26T09:09:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.44305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL API tutorial <em>template</em>",
        "sections": "GraphQL API tutorial <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61ab330c64441fd067927126"
    },
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "05c35d88b970eee521e2af4e255666e31b915468",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T07:01:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Check if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). We should avoid documenting most of these, with the idea that most customers will only care about the data because it's being reported for them, and won't care about the things that factor into the reasons why it wouldn't be reported. If it's thought that the addition would help customers who already have the data reporting understand the data better, you can include it. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use back ticks to indicate attributes or values (for example, a definition like: Reported when ` category ` is ` http ` ). Using this also sets us up for success if we implement styling in the UI definitions in the future. We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a 'See attribute in docs' link that links to the complete and normally formatted docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.3497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " to be accurate, and place it in the folder of the data type it&#x27;s attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage"
      },
      "id": "61ab4782e7b9d278d80e6e03"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/agent-release-notes-template-123": [
    {
      "sections": [
        "Auto-telemetry with Pixie for instant Kubernetes observability",
        "Quickly start observing and debugging Kubernetes clusters",
        "Important",
        "Explore your cluster",
        "Tip",
        "Investigate usage spikes using the flame graph",
        "Debug live"
      ],
      "title": "Auto-telemetry with Pixie for instant Kubernetes observability",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "1dc7474aedbf84c51593c152fc39fda0a46b4f48",
      "image": "https://docs.newrelic.com/static/521c1e907520f4bc8da33ad27ab47289/c1b63/flamegraph.png",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/get-started-auto-telemetry-pixie/",
      "published_at": "2021-12-30T09:39:07Z",
      "updated_at": "2021-12-30T09:39:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When we say auto-telemetry, we’re not talking about cars — we're talking about instant baseline visibility into your Kubernetes clusters. With the New Relic One integration with Pixie, you get similar data to traditional language agents, but without manually instrumenting your code or redeploying your application. Pixie auto-telemetry is powered by eBPF, a virtual machine-like construct that enables Pixie to seamlessly collect fine-grained telemetry data — service-level metrics, unsampled requests, and more. With one install command, you get deeper insight into your Kubernetes clusters and workloads. No language agents required. Live debugging with Pixie shows a service graph listing the namespaces and the node that are available on the current cluster. Simply put, Auto-telemetry with Pixie offers the quickest option for getting observability into your Kubernetes services. Ready to get started? You'll be able to configure Pixie to suit your environnment after you create a New Relic account (it's free, forever!) and install our Pixie integration. Quickly start observing and debugging Kubernetes clusters Our Pixie integration gives you the best of both worlds: Pixie’s fast and simple Kubernetes observability coupled with New Relic One’s incident correlation, intelligent alerting, and long-term retention. You’ll get visibility into HTTP services using golden signals, HTTP transactions, database transactions, distributed tracing, and JVM metrics. You can operate, debug, and scale your Kubernetes clusters based on the information you learn about how your clusters and services are running. Using the New Relic Explorer, you can see key metrics and events at every level, starting with the cluster, and diving down into namespaces, deployments, and pods. You can quickly spot anomalous behavior, and where it’s happening. And then dive deeper using embedded visualizations of your Pixie data. Quickly identify hot spots with a flame graph display. On the Live debugging with Pixie tab, answer questions like what SQL requests your app is making or which services are talking to each other. This short video (approx. 6:20 minutes) shows how Pixie and Kubernetes work together in New Relic One so you can debug faster with code-level insights: Important Auto-Telemetry with Pixie leverages Community Cloud with Pixie, a separate platform from New Relic One. Use of Community Cloud with Pixie is subject to separate terms of service. Explore your cluster Access the Pixie UI via New Relic's Live debugging with Pixie area of your Kubernetes clusters. The cluster explorer provides a quick overview of the nodes in your cluster, including CPU, memory, and storage, as well as the status of each pod (healthy, warning, or critical). You can also find out what services are running in each container, their latency, throughput, and error rate. For more information about using the cluster explorer, see Navigate the Kubernetes cluster explorer. Note that you cannot log directly into the Pixie UI unless you have created a separate Pixie login. Tip Containers might be listed for up to four hours after they get decommissioned. You can query the Pixie data in New Relic One and create dashboards for at-a-glance monitoring. For more information, see our documentation about the data model and sample queries. Investigate usage spikes using the flame graph Debugging is orders of magnitude easier when you can quickly see what your application is doing. The Pixie flame graph display requires no instrumentation, redeploying, or recompiling. It works for compiled languages like Go, C+, Rust, to name a few. And at a glance, the flame graph tells you what functions your application is spending time on and where you have hot spots. Flame graphs are especially useful for hierarchical resource use, like disk usage and CPU utilization. For more information on how to read a flame graph, see the Pixie flame graph docs. Debug live On the Live debugging with Pixie tab, run PxL scripts — scripts written in Pixie's PxL language — to view live data captured through eBPF. Select the script drop-down and then select a script to run in the tab. (For best results, select a time range that is recent in the time picker.) Scripts enable you to debug: Traffic in multiple formats: HTTP and HTTPs (including encrypted), DNS, Postgres, MySQL, Cassandra, Redis (currently supporting SQL and HTTP in beta). Learn more: Request tracing tutorial. Database request performance. Learn more: Database Query Profiling tutorial. Service maps to learn which services are talking to each other. Learn more: Service Performance tutorial. Network traffic maps to learn which nodes are talking to each other. Learn more: Network Monitoring tutorial. Monitor resource usage by Node and Pod. Learn more: Infra health tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2.0050154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "6174ca7364441f0e385fdea5",
      "highlight": {}
    },
    {
      "sections": [
        "New Relic's data management hub",
        "Important",
        "Where to find the data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "New Relic's data management hub",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "999fa6106dd47250e9a5d822aa2f92b6ea088c78",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/manage-your-data/",
      "published_at": "2021-12-30T09:37:28Z",
      "updated_at": "2021-12-30T09:37:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the account dropdown in the top right of the UI, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the data management hub To find the data management UI: From one.newrelic.com click the account dropdown, and the click Manage your data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. Our data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Important If you're on our original product-based pricing model, you'll see your data ingest, retention, and limits in the data management hub. But on the original pricing plan, you're not billed on data ingest. Not sure which plan you're on? See Overview of pricing and user model. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. One solution for improving performance is to drop data to reduce the amount of data stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about adjusting data ingest. Learn about dropping data. For dropping logs, see Drop log data. Learn how to adjust how long data is retained.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2.0049112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "603e96ff28ccbcf8bceba796",
      "highlight": {}
    },
    {
      "sections": [
        "Drop log data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Manage drop filter rules via NerdGraph API",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop log data with drop filter rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "41ef69e9d8d23b2ab732b489bb5e0cb47b8c16b6",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-12-30T03:01:41Z",
      "updated_at": "2021-12-30T03:01:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been sent to New Relic, it can either be stored in our NRDB database or dropped (discarded). To drop log data, you can use the logs management UI: that is explained in this doc. Alternatively, you can use NerdGraph to drop data. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only the logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules For permissions-related requirements, see Drop data requirements. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Manage drop filter rules via NerdGraph API To manage your drop filter rules programmatically, you can use NerdGraph to create, query, and delete your drop filter rules. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1.9802707,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "603e813f28ccbc08c1eba787",
      "highlight": {}
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/api-tutorial-template": [
    {
      "sections": [
        "apiStyleGuidelines (Example agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Tip",
        "Parameters",
        "Return values",
        "Examples",
        "URL guidelines",
        "Title guidelines",
        "Short title guidelines",
        "Syntax guidelines",
        "Important"
      ],
      "title": "apiStyleGuidelines (Example agent API)",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "fb967e77ea9a94d7a35329c0c87062ff93ab2ff8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/apistyleguidelines-example-agent-api/",
      "published_at": "2021-12-31T00:55:49Z",
      "updated_at": "2021-11-26T09:14:52Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the \"View all methods\" page. Requirements Agent version 1.2.3.4 or higher. Additional requirements on their own line (do not use bullets). Do not use any callouts. If there are no special requirements, write: Compatible with all agent versions. Description Describe the behavior of the call with as much detail as possible. Do not describe what individual parameters do except in broad strokes; details of parameters and call variants belong under the Parameters heading. Similarly, do not describe return values. When cross-referencing another API call, format its name with code blocks, and include parentheses () like this: anotherCoolMethod(). Tip You can include callouts, but use discretion. These pages are already visually busy. Parameters If there are no parameters, leave this section blank. If there is only one call variant, do not include a syntax block in this section. Parameter Description newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) Copy $parameter_name data type Required. Brief description of parameter. $optional_param integer Optional. Brief description of parameter. newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param) Copy $parameter_name data type Required. Brief description of parameter. $different_param array Required. Brief description of parameter. $third_param string Required. Brief description of parameter. Return values What does this call return, and in what circumstances? Are there any things we expect customers to do with that return value? If the call does not return anything, leave this section blank. Examples This section documents rules for oddballs that aren't self-documenting. The rest of the examples are embedded within the page itself. In general, this page is intended for style reference. For examples of how to write good API method pages, check out our existing API docs, such as the PHP API. URL guidelines For the doc's URL: Manually edit the URL slug to remove the agent name. Where the API call does not already include separators (as in newrelic_awesome_call), separate the bits with hyphens -. For example: https://docs.newrelic.com/docs/new-relic-only/advanced-style-guide/writing-guidelines/api-style-guidelines Copy Title guidelines For the doc's title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses () in the call itself. For example: apiStyleGuidelines (Example agent API) Copy Short title guidelines For the doc's short title: Include only the method name. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses (). Adjust if necessary to fit on a single line in the category's sidebar. For example: apiStyleGuidelines Copy Syntax guidelines Important The Python and iOS agents use their own guidelines. For those guidelines, see the existing methods in those languages. Document each variant of a call on its own line. Do not use any formatting except italicizing the data type. Wrap optional parameters (including the comma separator) in square brackets []. Indicate the variable portion by prefacing it with a dollar sign $. If the call must be prefixed with newrelic. or similar, include that in the syntax. Optional: Include the return value, if that seems important for your particular agent. If you do, follow language conventions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.72968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>apiStyleGuidelines</em> (Example agent <em>API</em>)",
        "sections": "URL <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ":&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;new-relic-only&#x2F;advanced-<em>style</em>-<em>guide</em>&#x2F;<em>writing</em>-<em>guidelines</em>&#x2F;<em>api</em>-<em>style</em>-<em>guidelines</em> Copy Title <em>guidelines</em> For the doc&#x27;s title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do"
      },
      "id": "61ab484ee7b9d293670e847e"
    },
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "13ab0e9d759903149944453fc4392998b6fab974",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/basic-doc-template/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T09:12:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61b3574c64441f1cc6aec5a4"
    },
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "827639827da156b6a36096c0f6a3911052706a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-12-31T00:56:32Z",
      "updated_at": "2021-11-26T09:09:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL <em>API</em> tutorial template",
        "sections": "GraphQL <em>API</em> tutorial template",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL <em>API</em> tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what"
      },
      "id": "61ab330c64441fd067927126"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/apistyleguidelines-example-agent-api": [
    {
      "sections": [
        "API tutorial template",
        "Introduction (this heading will not be visible)",
        "Optional: Provide an overview for complex processes",
        "Provide a procedure to accomplish the task",
        "Tip",
        "Step 1. Do something...",
        "If needed: Step 2. Do something else...",
        "If needed: Step 3. Do something else...",
        "Last step. Verify that the task was completed...",
        "Optional: Do something else with the API",
        "Optional: Large example code block",
        "Code block example",
        "Optional: Troubleshooting"
      ],
      "title": "API tutorial template  ",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "b69605a3a5585b2ee7f89c250bbdd5345c5d9311",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/api-tutorial-template/",
      "published_at": "2021-12-31T00:55:49Z",
      "updated_at": "2021-11-26T09:14:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content link in the Page tools box. Delete all content up to Introduction (this heading won't be visible). For the doc title (the field at top of page): Doc should be named in a practical, use-case-focused way. Example: Add custom attributes to transactions Introduction (this heading will not be visible) Provide a brief explanation of what this document will teach customers, and why it is valuable for customers to know how to do that. Focus on the value the API provides to the customers and mention specific, common use cases. Any relevant notes about support/compatability should go here, too. Here's an example from the Java API asynchronous tutorial doc: New Relic for Java includes an API to instrument asynchronous activity. For supported frameworks, the Java agent usually instruments async work automatically. However, the async API can be useful for adding more detail to your data. This document provides examples of using tokens and segments to instrument your app. Optional: Provide an overview for complex processes This is an optional section for complicated tutorials that involve either using several methods in one procedure or that have different alternate steps you can take to achieve similar results. This section can link to lower-down sections to allow users to skip around as needed. For simple tutorials, this section isn't necessary. For an example, see this section of the Java async tutorial. Provide a procedure to accomplish the task Tell the user how to accomplish the task, and link to the methods necessary to accomplish that task. As much as possible, we're looking to describe tasks in \"procedures\" (procedure is tech writer jargon for a series of numbered steps). This may be tough to do for fairly open-ended/variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what the importance of the procedure step is, and how one might verify that the step was done correctly. For code samples, avoid using large chunks of code. Instead, use smaller pieces of code and give context for how they are being used. (If you think a large app code example would be helpful, place that later in the doc in the Example section.) Tip For an example of an open-ended task segmented into procedural chunks, see the Asynchronous doc section Connecting async threads. For another example, see this TomCat GAE Flex procedure. Base your procedure on the simple structure below. Tech writers will edit your content to match our style and formatting requirements: Step 1. Do something... Methods and example code to implement the first step. For each step, if applicable, indicate the significance of that step (why it's important) and how the user might verify that the step was done correctly (for example, something showing up in UI, or running a verification test of some sort). If needed: Step 2. Do something else... Methods and example code to implement step 2. If needed: Step 3. Do something else... Methods and example code to implement step 3. Last step. Verify that the task was completed... Explain how a user would know they'd completed the task correctly. In particular, how would the user find the new change or data in the New Relic UI. What New Relic products and pages would the change be noticed on? If new data shows up in Insights, what event types can it be found under? Optional: Do something else with the API Same as above. Make as many headings and separate procedures as needed. Optional: Large example code block If you think a large app code example would be useful, place here. Within any code block, explain all New Relic functions/methods, not just the main methods. Instead of in-line comments, consider using highlighted sections underneath the code block to give additional context. Here's an example: Code block example The following code example shows a segment starting in the storeItem method to measure how long the Lambda statement is waiting in the thread pool. To stop timing the segment, you must call either .end() or .ignore(). If you don't want to report the segment as part of its parent transaction, call .ignore(). Otherwise, to report the segment as part of its parent transaction, call .end(). private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal (DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()); // fire and forget DB_POOL.submit(() -> { segment.end(); insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For more on this method, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in APM with datastore data. For more information, see reportAsExternal API. segment.end(): Stops timing this segment. For more on this method, see the Javadoc. Optional: Troubleshooting Optional area for any common errors or troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.72952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>API</em> tutorial template  ",
        "sections": "<em>API</em> tutorial template",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " to describe tasks in &quot;procedures&quot; (procedure is <em>tech</em> <em>writer</em> jargon for a series of numbered steps). This may be tough to do for fairly open-ended&#x2F;variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what"
      },
      "id": "61b35723196a675e16a5b0a4"
    },
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "13ab0e9d759903149944453fc4392998b6fab974",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/basic-doc-template/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T09:12:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59618,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61b3574c64441f1cc6aec5a4"
    },
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "827639827da156b6a36096c0f6a3911052706a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-12-31T00:56:32Z",
      "updated_at": "2021-11-26T09:09:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59486,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL <em>API</em> tutorial template",
        "sections": "GraphQL <em>API</em> tutorial template",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL <em>API</em> tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what"
      },
      "id": "61ab330c64441fd067927126"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/basic-doc-template": [
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "827639827da156b6a36096c0f6a3911052706a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-12-31T00:56:32Z",
      "updated_at": "2021-11-26T09:09:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.44304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL API tutorial <em>template</em>",
        "sections": "GraphQL API tutorial <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61ab330c64441fd067927126"
    },
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "05c35d88b970eee521e2af4e255666e31b915468",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T07:01:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Check if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). We should avoid documenting most of these, with the idea that most customers will only care about the data because it's being reported for them, and won't care about the things that factor into the reasons why it wouldn't be reported. If it's thought that the addition would help customers who already have the data reporting understand the data better, you can include it. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use back ticks to indicate attributes or values (for example, a definition like: Reported when ` category ` is ` http ` ). Using this also sets us up for success if we implement styling in the UI definitions in the future. We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a 'See attribute in docs' link that links to the complete and normally formatted docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.34967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " to be accurate, and place it in the folder of the data type it&#x27;s attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage"
      },
      "id": "61ab4782e7b9d278d80e6e03"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "55f439b9842d1f5df9e5ce1b06a5c5d9ae7829f6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-12-31T00:58:00Z",
      "updated_at": "2021-11-25T11:25:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.51396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "61ab4826e7b9d293010e7a46"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/data-dictionary-style-guidelines": [
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "13ab0e9d759903149944453fc4392998b6fab974",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/basic-doc-template/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T09:12:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.44519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic doc <em>template</em>",
        "sections": "Basic doc <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " <em>article</em>_url(category, <em>article</em>, options={}) url_for(options.reverse_merge( :controller =&gt; &#x27;articles&#x27;;, :action =&gt; &#x27;show&#x27;, :category =&gt; category, :<em>article</em> =&gt; <em>article</em> )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add"
      },
      "id": "61b3574c64441f1cc6aec5a4"
    },
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "827639827da156b6a36096c0f6a3911052706a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-12-31T00:56:32Z",
      "updated_at": "2021-11-26T09:09:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.44302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL API tutorial <em>template</em>",
        "sections": "GraphQL API tutorial <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61ab330c64441fd067927126"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "55f439b9842d1f5df9e5ce1b06a5c5d9ae7829f6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-12-31T00:58:00Z",
      "updated_at": "2021-11-25T11:25:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.51395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "61ab4826e7b9d293010e7a46"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/graphql-api-tutorial-template": [
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "13ab0e9d759903149944453fc4392998b6fab974",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/basic-doc-template/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T09:12:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.44519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic doc <em>template</em>",
        "sections": "Basic doc <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " <em>article</em>_url(category, <em>article</em>, options={}) url_for(options.reverse_merge( :controller =&gt; &#x27;articles&#x27;;, :action =&gt; &#x27;show&#x27;, :category =&gt; category, :<em>article</em> =&gt; <em>article</em> )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add"
      },
      "id": "61b3574c64441f1cc6aec5a4"
    },
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "05c35d88b970eee521e2af4e255666e31b915468",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T07:01:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Check if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). We should avoid documenting most of these, with the idea that most customers will only care about the data because it's being reported for them, and won't care about the things that factor into the reasons why it wouldn't be reported. If it's thought that the addition would help customers who already have the data reporting understand the data better, you can include it. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use back ticks to indicate attributes or values (for example, a definition like: Reported when ` category ` is ` http ` ). Using this also sets us up for success if we implement styling in the UI definitions in the future. We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a 'See attribute in docs' link that links to the complete and normally formatted docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.34966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " to be accurate, and place it in the folder of the data type it&#x27;s attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage"
      },
      "id": "61ab4782e7b9d278d80e6e03"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "55f439b9842d1f5df9e5ce1b06a5c5d9ae7829f6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-12-31T00:58:00Z",
      "updated_at": "2021-11-25T11:25:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.51395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "61ab4826e7b9d293010e7a46"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/landing-page-template": [
    {
      "sections": [
        "Update the home page",
        "Update a link's URL",
        "Add a new tile to the home page",
        "Add a new section to the home page",
        "Edit the home page left nav"
      ],
      "title": "Update the home page",
      "type": "docs",
      "tags": [
        "home page",
        "landing pages"
      ],
      "external_id": "1d084fae5223f5b34cec91fcae0bcb35560c7b29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/edit-homepage/",
      "published_at": "2021-12-31T00:59:26Z",
      "updated_at": "2021-12-04T10:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can't just hit the edit button docs.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It's rare that you'll need to make changes to this file. Most home page changes will be to add a new tile or section to the page, or update links. These types of changes are handled in two files: src/data/homepage.yml - contains home page section titles, section descriptions, and the URLs for tiles. src/i18n/translations/en/translation.json - contains tile info, including the title and short description of tiles. Update a link's URL Change or add new links using homepage.yml. In homepage.yml, search for the link you want to change. Edit the URL, save, commit, and PR the change. Add a new tile to the home page You'll make changes to both homepage.yml and translations.json On the translations.json doc, find the spot where you want to add the new tile (which section, and in what order you want it to appear), and add a new entry with this format: \"t#\": { \"title\": \"tile name\", \"description\": \"Short description.\" }, Copy Make sure you update the number on the tile. If you want to insert it in the middle of a group, update all the subsequent tile numbers as well. Save the file. Open homepage.yml, find the spot where the new tile will be, and add a new line with the relative link for the new tile. For example, - /docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster Save and check that your new tile builds properly on a local build. Commit, push, PR when you're ready. Add a new section to the home page On the translations.json page, add a new section modeled in the spot where you want the new section to appear. Include at least one title. For example, here's the TDP entry, with one tile: \"errors-inbox\": { \"title\": \"Errors Inbox\", \"description\": \"A single place to proactively detect, triage, and take action on all the errors before they impact customers.\", \"t1\": { \"title\": \"Introduction to Errors Inbox\", \"description\": \"How to manage all your monitoring in one place.\" }, Copy When you're done creating the info, save the file. In the homepage.yml page, find the corresponding location for the new section, and add the short name you provided in the translation.json file, title, description, and tile URLs. For example, here's the corresponding TDP section on homepage.yml. errors-inbox: title: Errors Inbox description: A single place to proactively detect, triage, and take action on all the errors before they impact customers. tiles: - /docs/errors-inbox/errors-inbox Copy Save, build locally, commit, PR. Edit the home page left nav The left nav of the home page is controlled by src/nav/root.yml. This is a basic yml file, similar to our taxonomy files. Each link on the left nav needs a title and a path: - title: Welcome to New Relic path: /docs/using-new-relic - title: New Relic One path: /docs/new-relic-one/use-new-relic-one - title: Guides and best practices path: /docs/new-relic-solutions - title: section-break - title: Alerts and Applied Intelligence path: /docs/alerts-applied-intelligence Copy You can add a new link by following the pattern above or delete a link by removing the corresponding title and path. Section breaks are added by including a - title: section-break line. The left nav reflects the exact order of root.yml, so it's easy to organize it as needed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.44327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the home <em>page</em>",
        "sections": "Update the home <em>page</em>",
        "tags": "<em>landing</em> <em>pages</em>",
        "body": "You can&#x27;t just hit the edit button docs.newrelic.com to make edits to the home <em>page</em>. The <em>page</em> that opens is index.js, the file that manages the parts of the home <em>page</em>, but not the content. It&#x27;s rare that you&#x27;ll need to make changes to this file. Most home <em>page</em> changes will be to add a new tile"
      },
      "id": "61ab480264441f9ef0927fb8"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "606039ea3f3b44fdecc1bd2d03fd61d77c594db8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-12-31T01:00:15Z",
      "updated_at": "2021-11-26T05:15:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Through some technical wizardry, they generate Related resources links in the right nav area. Start each topic with a - on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.25648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Page</em> <em>templates</em>",
        "body": "Our docs site is made up of different content types and templates. Most of the time, the default <em>page</em> content type and the basic <em>template</em> will have everything you&#x27;ll need. Read on for more information about our <em>page</em> types. Docs meta content (frontmatter) Thr top of every doc begins with a set"
      },
      "id": "61b35517196a677196a59e07"
    },
    {
      "sections": [
        "Alerts and applied intelligence notification integrations",
        "Early access",
        "Integration details",
        "Atlassian Jira",
        "Permissions",
        "Set up a Jira destination",
        "Important",
        "Two-way sync",
        "Configure the message template",
        "Send a test notification",
        "ServiceNow (Incident-Management)",
        "Roles",
        "Set up a destination",
        "Slack",
        "Prerequisites",
        "Set up a Slack destination",
        "Configure the Slack message settings",
        "Webhook",
        "Set up a webhook destination",
        "Configure the webhook event template",
        "Customize the webhook payload",
        "Email",
        "Configure the email settings"
      ],
      "title": "Alerts and applied intelligence notification integrations",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident Intelligence",
        "Destinations"
      ],
      "external_id": "7220c630fc187bb61784ff2cc2213e588b269b00",
      "image": "https://docs.newrelic.com/static/d4e9baecc3a76dd1a5945f8ec0aeca66/c1b63/webhook-notification-template.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/notification-integrations/",
      "published_at": "2021-12-31T01:42:05Z",
      "updated_at": "2021-12-19T15:28:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Alerts and Applied Intelligence notification integrations are specific services and platforms you can use to send notifications from New Relic. Integration details Read more about each of our specific notification integrations. Atlassian Jira Integrate New Relic with Atlassian Jira(Cloud) and automatically create and update Jira issues. Permissions The required permissions from the Jira API-Token are create, edit, and close tickets. To enable the two-way sync toggle, the provided Jira API-Key should have an Admin role. Set up a Jira destination Create Jira issues, then enable Jira and New Relic to share updates and stay synced. To create a Jira destination, enter the following information: Destination name: Custom name to identify the destination Jira account endpoint: the URL of the destination User-name: this will be the email address of the user making the connection API token: generated from your Atlassian account Important New Relic currently supports Atlassian-Jira Classic (company-managed) projects. Before saving the destination, we recommend you test the connection via the test connection button. Jira destination configuration. We recommand to test the connection before saving. Two-way sync You can enable a two-way integration with Jira to keep the issues' state synced with the corresponding state in New Relic. To enable two-way sync, turn on the ‘two-way integration’ toggle. When turned on, a Jira Webhook would be created in your Jira account at a later stage, for the selected project (see ‘customize a message template’). The webhook would contain access details to Newrelic (URL and Newrelic-API-KEY) Configure the message template To configure a template for a Jira issue, you first need to choose a destination. You will be able to create a new destination at this stage. Upon successful connection to the destination, you will need to choose a project, and then select the Jira issue type you would like to be used. Once the issue-type is selected, the configured project's fields are fetched from your account and automatically mapped to your Jira instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Jira message template. Send a test notification You can see how the JIRA issue will appear by clicking a test notification with default field values. If successful, a JIRA issue will be created and a link will appear. ServiceNow (Incident-Management) Integrate New Relic with ServiceNow Incident-Management and automatically create and update incidents. Roles As part of the integrations, we fetch fields from the your serviceNow incident table and optional values. For this, the provided ServiceNow user details required read permissions for the tables: sys_dictionary, sys_choice, sys_user and task. A read/write permission to incident To be able to fetch users for the caller column, we required read permissions for the sys_users table. The above permissions can be achieved with the roles personalize_choices, personalize_dictionary, rest_service, itil. Read/Write permissions to the api_key_credentials table is required to enable two-way integration. This can be covered with the roles credentials_admin and discovery_admin. Set up a destination To create a ServiceNow destination, enter the following information: Destination Name: custom name to identify the destination Domain: the URL of the destination User-name: the name of the user Password: the user name’s password Before saving the destination, we recommend testing the connection by clicking the test connection button. Two-way sync You can configure a two-way integration with ServiceNow Incidents Management to keep the incidents' state synced with the corresponding state in New Relic. Here are some required steps to remember when configuring the two-way integration: Turn on the two-way integration toggle. Open and download this XML file, which includes the business rule triggering events back to New Relic One. In the ServiceNow sidebar menu, go to System Definition > Business Rules. Click the menu icon in one of the column headers, select Import XML and upload the XML file you downloaded. Once the Destination is saved, a New-Relic API-Key will be kept in the api_key_credentials. The key would sent in a header as part of the callback REST call to New-Relic Configure the message template Upon a successful connection, ServiceNow incident table columns are fetched from your account and automatically mapped to your ServiceNow instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Select, edit or remove fields for the ServiceNow-Incident template. Send a test notification You can see how the ServiceNow incident will appear by clicking a test notification with default field values. If successful, an incident will be created and a link will appear. Slack Send notifications-messages to your Slack channels. Prerequisites Your Slack workspace needs to have the New Relic application installed. The application must be approved by a workspace admin before it can be individually installed by users Set up a Slack destination Click on the `one-click Slack authentication' will lead you to the Slack landing page to continue the OAuth2 authentication process. On the Slack landing page, if you're not signed into the required workspace, you're redirected to Slack to sign in. Add your workspace name or select the relevant workspace and click Continue. When signed in to the selected workspace, you are requested to allow New Relic to perform the specified actions. Clicking `Allow' will redirect you back to the Destination page. Configure the Slack message settings Select a Destination(Workspace) and select a Slack-channel where the messages will be sent. You can create a new destination if there is no pre-defined destination for the required workspace. Note that, for privacy reasons, users need to be authenticated to select private channels (one-time process) Send a test notification You can send a test notification with a pre-defined example payload to the channel. This creates a message in the selected Slack-channel. Webhook Use the webhook notifier to send the notification messages to any endpoint you like. Set up a webhook destination To create a webhook destination, you need the following: Destination Name: A unique destination name URL: the endpoint of the target application, authentication and custom headers if needed. Authorization mechanism (Optional):. Can be basic authentication or a bearer token Configure the webhook event template Pick a webhook destination from the list and configure the HTTP-POST request. The request configuration requires you to: Set a name for the template. Select a pre-configured destination from the destinations list or create a new one. Add custom headers (optional). Configure the request’s payload. Customize the webhook payload You can use the default payload or customize it to contain the required data. Pick Variables from the variables menu and apply handlebars syntax to enrich your webhook. Note that the request’s content-type is JSON by default. Hence, the payload needs to keep the JSON form. See Usage examples The ‘preview’ section on the right hand-side shows an expected payload after the template is rendered. If the eventual payload would not form a valid Json, an error will be shown and it won’t be possible to save the template. If the webhook payload conforms a valid Json, you can send a test notification to your defined webhook destination We recommend sending a test notification to make sure that everything's connected correctly. Email Send email notifications to users. Configure the email settings Add one or more recipients. Users with New Relic accounts can be found via autocomplete when searching for their name or email address. To add a user without a New Relic account or email distribution list, add the full email address. Every recipient will be translated into a 'destination'. You can follow the email notifications per destination in the notifications-log Send a test notification You can send a test notification to make sure the email notifications reach the inbox.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.081894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Configure the message <em>template</em>",
        "body": " Click on the `one-click Slack authentication&#x27; will lead you to the Slack <em>landing</em> <em>page</em> to continue the OAuth2 authentication process. On the Slack <em>landing</em> <em>page</em>, if you&#x27;re not signed into the required workspace, you&#x27;re redirected to Slack to sign in. Add your workspace name or select the relevant"
      },
      "id": "618ff71628ccbc60710321e4"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/more-help-section": [
    {
      "sections": [
        "Generate trace log for troubleshooting (Node.js)",
        "Important",
        "Generate log files",
        "Examine log file"
      ],
      "title": "Generate trace log for troubleshooting (Node.js)",
      "type": "docs",
      "tags": [
        "Agents",
        "Nodejs agent",
        "Troubleshooting"
      ],
      "external_id": "3421d4243bcf05070a999d7bc79eab6c6f1372a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/nodejs-agent/troubleshooting/generate-trace-log-troubleshooting-nodejs/",
      "published_at": "2021-12-31T01:39:27Z",
      "updated_at": "2021-12-31T00:07:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your New Relic Node.js agent log captures errors at the default info level. However, when troubleshooting or debugging, generate a more verbose trace log to help find and investigate problems. Important The trace log setting is a highly verbose logging level. To reduce disk space consumption, return the logging : { section's level to its original setting after testing. Generate log files To generate the detailed trace log file: Edit your newrelic.js file and change the logging section's level to trace, or if using environment variables, set the NEW_RELIC_LOG_LEVEL to trace. logging: { level: 'trace' } Copy Restart Node. Exercise your web application for about five minutes to generate sufficient logging data. After testing, change the level to a less verbose logging level, such as info (default). Open and examine the generated log file. Examine log file By default, the Node.js agent stores the log file in the current working directory as newrelic_agent.log. If the log file or folder are not visible: Check whether you have set the logging path to stdout or stderr. Verify that the current working directory is the same as the directory where you expect the log file to be located.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 78.11981,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate trace log <em>for</em> troubleshooting (Node.js)",
        "sections": "Generate trace log <em>for</em> troubleshooting (Node.js)",
        "body": "Your New Relic Node.js agent log captures errors at the default info level. However, when troubleshooting or debugging, generate a <em>more</em> verbose trace log to <em>help</em> find and investigate problems. Important The trace log setting is a highly verbose logging level. To reduce disk space consumption"
      },
      "id": "617ea562e7b9d2fd44c05078"
    },
    {
      "sections": [
        "Node.js agent configuration",
        "Get started",
        "Configuration methods and precedence",
        "Agent configuration file",
        "Environment variables",
        "Server-side configuration",
        "Exports variables",
        "app_name (REQUIRED)",
        "Tip",
        "license_key (REQUIRED)",
        "agent_enabled",
        "allow_all_headers",
        "Caution",
        "apdex_t (DEPRECATED)",
        "certificates",
        "high_security",
        "host",
        "Important",
        "labels",
        "port",
        "proxy",
        "proxy_host",
        "proxy_pass",
        "proxy_port",
        "proxy_user",
        "Logging variables",
        "enabled",
        "level",
        "filepath",
        "Audit logging",
        "endpoints",
        "API configuration",
        "custom_attributes_enabled",
        "custom_events_enabled",
        "notice_error_enabled",
        "Attributes",
        "exclude",
        "include",
        "include_enabled",
        "Error collector variables",
        "ignore_status_codes",
        "ignore_classes",
        "ignore_messages",
        "expected_status_codes",
        "expected_classes",
        "expected_messages",
        "attributes.enabled",
        "attributes.exclude",
        "attributes.include",
        "max_event_samples_stored",
        "Transaction tracer variables",
        "explain_threshold",
        "record_sql",
        "top_n",
        "transaction_threshold",
        "hide_internals",
        "Rules variables",
        "name",
        "ignore",
        "enforce_backstop",
        "Transaction events variables",
        "max_samples_stored",
        "max_samples_stored (DEPRECATED)",
        "max_samples_per_minute (DEPRECATED)",
        "Browser monitoring variables",
        "enable",
        "debug",
        "Custom events variables",
        "Slow queries variables",
        "max_samples",
        "Custom hostname variables",
        "display_name",
        "ipv_preference",
        "Environment variable overrides",
        "NEW_RELIC_HOME",
        "NEW_RELIC_NO_CONFIG_FILE",
        "Datastore tracer variables",
        "instance_reporting.enabled",
        "database_name_reporting.enabled",
        "Cross application tracing (DEPRECATED)",
        "Error message redaction variables",
        "Distributed tracing",
        "exclude_newrelic_header",
        "Span events",
        "Infinite Tracing",
        "trace_observer.host"
      ],
      "title": "Node.js agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Nodejs agent",
        "Installation and configuration"
      ],
      "external_id": "4f576eccf990e090f3c829dba158ac21583f8b5a",
      "image": "https://docs.newrelic.com/static/bab8ec5bda2eda3aaa5ddaefbed52d93/9fc4b/nodejs-configuration-precedence.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/nodejs-agent/installation-configuration/nodejs-agent-configuration/",
      "published_at": "2021-12-30T21:59:02Z",
      "updated_at": "2021-12-20T13:54:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can tailor the Node.js agent to your app's requirements by editing your newrelic.js config file or by setting an environment variable. The config file resides in the root directory of your app. You can also configure a few options from New Relic, or use the Node.js agent API. Get started You'll be able to configure our Node.js agent to suit your environnment after you create a New Relic account (it's free, forever) and install the Node.js agent. The license_key setting is required. Also, we highly recommend setting the app_name so that your app has a meaningful name instead of the default My Application. Configuration methods and precedence The primary method to configure the Node.js agent is the agent configuration file (newrelic.js). You can also configure most settings with environment variables. You can also adjust some settings with server-side configuration. The Node.js agent uses this order of precedence for configuration methods: Node.js configuration hierarchy: Server-side configuration settings override environment variables. Environment variables override the agent config file. The config file overrides the agent defaults. Here are detailed descriptions of each configuration method: Agent configuration file The config file (newrelic.js) contains every Node.js agent setting. When you install the Node.js agent, you must copy newrelic.js into your app's root directory. Most settings are empty by default; they inherit their values from config/default.js. Environment variables Most configuration settings in newrelic.js have equivalent environment variables. These are useful, for example, if your agent runs in a PaaS environment such as Heroku or Microsoft Azure. Node.js agent environment variables always start with NEW_RELIC_. Where available, these environment variables are documented below under individual config options as the Environ variable. There are also two rarely used settings that can only be configured via environment variables. If you're using New Relic APM and CodeStream, see how to associate repositories and how to associate build SHAs or release tags with errors inbox. Server-side configuration Owners and Admins can view and configure a few settings directly in New Relic. Where available, the UI labels for server-side config are listed in this document under individual config options as the Server-side label. Exports variables This section defines the Node.js agent variables in the order they typically appear in the exports.config = { section of your app's newrelic.js configuration file. app_name (REQUIRED) Type String Default \"My Application\" Environ variable NEW_RELIC_APP_NAME The name New Relic uses to identify your app. For example, app_name: ['MyNodeApp']. To use multiple names for your app, specify a comma-delimited list of names. Data for all applications with the same name will be merged in the New Relic UI, so set this carefully. We highly recommend that you replace the default name with a descriptive name to avoid confusion and unintended aggregation of data. Tip For Azure users, the Node.js agent will use APP_POOL_ID if it is set, so you can use the name you chose for your Azure Web Server without setting it twice. license_key (REQUIRED) Type String Default (none) Environ variable NEW_RELIC_LICENSE_KEY This setting is required. Your New Relic license key. For example, license_key: '40HexadecimalCharacters'. agent_enabled Type Boolean Default true Environ variable NEW_RELIC_ENABLED Set to false to stop the agent from starting up. This is useful when debugging your code requires temporarily disabling the agent. It prevents the agent from bootstrapping its instrumentation or setting up all its pieces, which prevents the agent from starting up and connecting to New Relic's servers. allow_all_headers If true, enables capture of all HTTP headers, except for those filtered by exclude rules. If false, collected headers are limited to those defined in Node.js agent attributes. Type Boolean Default false Caution Any header-related include/exclude rules must be in camelCase form to be filtered. apdex_t (DEPRECATED) Type Number Default 0.100 Server-side label Apdex T Set your Apdex T via the New Relic UI. certificates Type Array of strings Default (none) Additional certificates to trust for SSL connections, specified as an array of strings in PEM format. This affects both connections to an HTTPS proxy and connections to New Relic. Tip You can also configure the agent to read its certificates from a file: certificates: [ fs.readFileSync('myca.crt', {encoding: 'utf8'}) ] Copy high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY When set to true, enables high security v2. You must also enable the ssl setting and enable high security in the UI. host Type String Default collector.newrelic.com Environ variable NEW_RELIC_HOST Important Do not edit this value unless New Relic Support asks you to change it. Hostname for the New Relic collector to connect to the Internet; for example, host: 'collector.newrelic.com'. labels Adds tags. Specify your tags as objects or a semicolon-delimited string of colon-separated pairs (for example, Server:One;Data Center:Primary). Type Object or string Default (none) Environ variable NEW_RELIC_LABELS port Type Integer Default 443 Environ variable NEW_RELIC_PORT Important Do not edit this value unless New Relic Support asks you to change it. Port number to connect to the New Relic collector; for example, port: 443. proxy Type String Default (none) Environ variable NEW_RELIC_PROXY_URL A URL specifying the proxy server to connect to the Internet. For example, proxy: 'http://user:pass@10.0.0.1:8000/'. Important The proxy config file setting overrides the other config file proxy settings (proxy_host, proxy_port, proxy_user, proxy_pass) if used. Similarly, the NEW_RELIC_PROXY_URL environment variable overrides the other environment variable proxy settings (NEW_RELIC_PROXY_HOST, NEW_RELIC_PROXY_PORT, NEW_RELIC_PROXY_USER, and NEW_RELIC_PROXY_PASS) if used. proxy_host Type String Default (none) Environ variable NEW_RELIC_PROXY_HOST Hostname or IP address of the proxy server to connect to the Internet. proxy_pass Type String Default (none) Environ variable NEW_RELIC_PROXY_PASS Password for authenticating to the proxy server. The agent supports only basic HTTP authentication. proxy_port Type String Default (none) Environ variable NEW_RELIC_PROXY_PORT Port number of the proxy server to connect to the Internet. proxy_user Type String Default (none) Environ variable NEW_RELIC_PROXY_USER User name for authenticating to the proxy server. The agent supports only basic HTTP authentication. Logging variables This section defines the Node.js agent variables in the order they typically appear in the logging: { section of your app's newrelic.js configuration file. enabled Type String Default true (false in serverless_mode) Environ variable NEW_RELIC_LOG_ENABLED Enables or disables agent specific logging. level Type String Default info Environ variable NEW_RELIC_LOG_LEVEL Defines the level of detail recorded in the agent logs. From least detail to most detail, possible values are fatal, error, warn, info, debug, or trace. Caution Do not use debug or trace logging unless New Relic Support asks you to use them. These levels of logging can generate excessive overhead. For most situations, use info. filepath Type String Default process.cwd() plus newrelic_agent.log Environ variable NEW_RELIC_LOG Complete path to the New Relic agent log, including the filename. Defaults to filepath: require('path').join(process.cwd(), 'newrelic_agent.log'). The agent will shut down the process if it cannot create this file. The agent creates a log file with the same permissions as the parent Node.js agent process. To write all logging to stdout, set this to stdout. To write all logging to stderr, set this to stderr. Audit logging This section defines the Node.js agent variables in the order they typically appear in the audit_log: { section of your app's newrelic.js configuration file. enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED When enabled, the agent logs the payloads it sends to the collector. This data is included in the main log file even when logging level is set to the lowest level. endpoints Type Array Default Empty array (include all types) Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS The agent sends several different types of data to the collector in separate payloads. By default, all of them are included in the log file. This option makes it possible to limit logging only to specific types of data. Valid values include: agent_settings analytic_event_data connect custom_event_data error_data error_event_data metric_data preconnect shutdown span_event_data sql_trace_data transaction_sample_data API configuration This section allows you to choose which API methods are enabled. Each configuration option allows you to modularly enable API methods that are responsible for sending custom information to New Relic. Important All of these are set to false when the agent is in high security mode. custom_attributes_enabled Type Boolean Default true Environ variable NEW_RELIC_API_CUSTOM_ATTRIBUTES This option enables newrelic.addCustomAttribute and newrelic.addCustomAttributes. custom_events_enabled Type Boolean Default true Environ variable NEW_RELIC_API_CUSTOM_EVENTS This option enables recordCustomEvent. notice_error_enabled Type Boolean Default true Environ variable NEW_RELIC_API_NOTICE_ERROR This option enables newrelic.noticeError. Attributes This section defines the variables for Node.js agent attributes in the order they typically appear in the attributes: { section of your app's newrelic.js configuration file. Caution Any header-related include/exclude rules must be in camelCase form to be filtered. enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include from all destinations. Allows * as wildcard at end. include_enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE_ENABLED When true, patterns may be added to the attributes.include list. Error collector variables You can manage how error are handled in New Relic. This section defines the Node.js agent variables in the order they typically appear in the error_collector: { section of your app's newrelic.js configuration file. enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED Server-side label Enable error collection? When enabled, the agent collects error traces from your app. ignore_status_codes Type Array of Integers Default [404] Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERROR_CODES Server-side label Ignore these status codes Comma-delimited list of HTTP status codes for the error collector to ignore. Caution Errors recorded using newrelic.noticeError do not obey this configuration value. ignore_classes Type Array|Object Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Comma-delimited list of javascript error types/classes for the error collector to ignore. The following configuration /* ... */ error_collector: { ignore_classes: [\"ReferenceError\"] } /* ... */ Copy Would ignore all reference errors. Caution Errors recorded using newrelic.noticeError do not obey this configuration value. ignore_messages Type Object Default {} A javascript object describing a list of javascript classes tied to javascript error messages for the collector to ignore. The following configuration. /* ... */ error_collector: { /* ... */ ignore_messages: {\"Error\":[\"Undefined\", \"Out of time\"]} /* ... */ } /* ... */ Copy Would ignore all errors of type Error, with the exact (case-sensitive) message strings of Undefined and Out of time. Caution Errors recorded using newrelic.noticeError do not obey this configuration value. expected_status_codes Type Array of integers Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_ERROR_CODES Comma-delimited list of HTTP status codes for the error collector to mark as expected. Caution Errors recorded using newrelic.noticeError do not obey this configuration value. expected_classes Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_ERRORS The following configuration /* ... */ error_collector: { expected_classes: [\"ReferenceError\"] } /* ... */ Copy Would mark all reference errors as expected. Caution Errors recorded using newrelic.noticeError do not obey this configuration value. expected_messages Type Object Default {} A javascript object describing a list of javascript classes tied to javascript error messages for the collector to ignore. The following configuration. /* ... */ error_collector: { /* ... */ expected_messages: {\"Error\":[\"Undefined\", \"Out of time\"]} /* ... */ } /* ... */ Copy Would mark all errors of type Error, with the exact (case-sensitive) message strings of Undefined and Out of time. Caution Errors recorded using newrelic.noticeError do not obey this configuration value. attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. Caution Any header-related include/exclude rules must be in camelCase form to be filtered. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of events the agent collects per minute. If there are more than this number, the agent collects a statistical sampling. Transaction tracer variables The agent groups your requests into transactions, which are used to: Visualize where your app spends its time (in transaction breakdowns). Identify slow requests. Group metrics. Isolate other issues, such as slow database performance. This section defines the Node.js agent variables in the order they typically appear in the transaction_tracer: { section of your app's newrelic.js configuration file. Important Do not use brackets [suffix] at the end of your transaction name. New Relic automatically strips brackets from the name. Instead, use parentheses (suffix) or other symbols if needed. enabled Type Boolean Default true Environ variable NEW_RELIC_TRACER_ENABLED Server-side label Enable transaction tracing? When enabled, the agent collects slow transaction traces. explain_threshold Type Integer Default 500 Environ variable NEW_RELIC_EXPLAIN_THRESHOLD Minimum query duration (in milliseconds) for a transaction to be eligible for slow queries in transaction traces. record_sql Type String (off, obfuscated, or raw) Default off Environ variable NEW_RELIC_RECORD_SQL This option affects both slow queries and record_sql for transaction traces. It can have one of three values: off, obfuscated, or raw. When set to off no slow queries will be captured, and backtraces and SQL will not be included in transaction traces. If set to raw or obfuscated, the agent sends raw or obfuscated SQL and a slow query sample to the collector. The agent may also send SQL when other criteria are met, such as when slow_sql.enabled is set. top_n Type Integer Default 20 Environ variable NEW_RELIC_TRACER_TOP_N Defines the maximum number of requests eligible for transaction traces. Transactions are named based on the request, and top_n refers to the \"top n slowest transactions\" grouped by these names. The module replaces a recorded trace with a new trace only if the new trace is slower than the previous slowest trace of that name. The default value for this setting is top_n: 20, because the Transactions page also defaults to the 20 slowest transactions. The Node.js agent captures at least five different slow transactions in the first harvest cycle after start up. It will also reset and capture different transactions if no slow transactions have been captured for the last five harvest cycles. This allows you to see more information about more of your app's request paths, at the possible cost of not focusing on the absolutely slowest request for that harvest cycle. Tip To record the absolute slowest transaction over the last minute, you can set top_n: 0 or top_n: 1. However, this causes one very slow route to dominate your transaction traces. transaction_threshold Type Integer or apdex_f Default apdex_f Environ variable NEW_RELIC_TRACER_THRESHOLD Server-side label Threshold Threshold of web transaction response time in seconds beyond which a transaction is eligible for transaction tracing. The default value is apdex_f; this sets the trace threshold to four times your application's Apdex T. You can also enter a specific time value in milliseconds. Example: Threshold set to apdex_f The default apdex_t is 100 milliseconds. If your transaction threshold is set to apdex_f, a \"slow\" transaction is 400 milliseconds. hide_internals Type boolean Default true Environ variable NEW_RELIC_HIDE_INTERNALS The agent uses a small amount of CPU in order to hide internal properties that are attached to the web application. If you change this configuration to false, it may slightly decrease your agent overhead, but it could also have an impact on the performance of the agent. attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. Caution Any header-related include/exclude rules must be in camelCase form to be filtered. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. Rules variables This section defines the Node.js agent variables in the order they typically appear in the rules: { section of your app's newrelic.js configuration file. name Type Strings or regular expressions Default (none) Environ variable NEW_RELIC_NAMING_RULES A comma-delimited list of rules to match incoming request URLs and name the associated New Relic transaction. Uses the format: name: [ {pattern: 'STRING_OR_REGEX', name: 'NAME'}, {pattern: 'STRING_OR_REGEX', name: 'NAME'} ], Copy Both parameters are required. For strings, you must escape control characters. You do not need to escape control characters in regular expressions. Additional attributes are ignored. Regular expressions support JavaScript-style capture groups, and names use $1-style replacement strings. Regular expressions only find the first matching result; subsequent matches are ignored. For more information, see Node.js transaction naming API. For the NEW_RELIC_NAMING_RULES environment variable, pass the rules as comma-delimited JSON object literals: NEW_RELIC_NAMING_RULES='{\"pattern\":\"^t\",\"name\":\"u\"},{\"pattern\":\"^u\",\"name\":\"t\"}' Copy ignore Type Strings or regular expressions Default Regular expression to match socket.io long-polling requests (\"^ \\ /socket \\ .io \\ /. * \\ /xhr-polling/\"). Environ variable NEW_RELIC_IGNORING_RULES Define a list of request URLs you want the agent to ignore. Specify the list as patterns, which can be strings or regular expressions. enforce_backstop Type Boolean Default true Environ variable NEW_RELIC_ENFORCE_BACKSTOP Caution Do not change this setting unless you understand metric grouping issues. When enabled, the agent renames transactions that are not affected by other naming logic (such as the API, rules, or metric normalization rules) to NormalizedUri/*. If you set this to false, the agent sets transaction names to Uri/path/to/resource. Transaction events variables This section defines the Node.js agent variables in the order they typically appear in the transaction_events: { section of your app's newrelic.js configuration file. enabled Type Boolean Default true When enabled, the agent sends transaction events to New Relic. This event data includes transaction timing, transaction name, and any custom parameters. If this is disabled, the agent does not collect this data or send it to New Relic. max_samples_stored Type Integer Default 10000 Environ variable NEW_RELIC_TRANSACTION_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of events the agent collects per minute. If there are more than this number, the agent collects a statistical sampling. We do not recommend configuring past 10,000. The server will cap data at 10,000 per-minute. Important This configuration had different behavior in agent versions lower than 6.0.0. See max_samples_stored (DEPRECATED) for agent versions 5.x or lower. max_samples_stored (DEPRECATED) Type Integer Default 20000 Defines the maximum number of events the agent stores if it is unable to communicate with the New Relic collector. The values from the previous harvest cycle will be merged into the next one, with this option limiting the maximum number. Make sure this number is greater than max_samples_per_minute; for example, set it to twice as much. Consider your memory overhead before increasing this value. Caution This configuration has different behavior starting with agent version 6.0.0 and a new recommended maximum. See max_samples_stored for agent versions 6.x or higher. max_samples_per_minute (DEPRECATED) Type Integer Default 10000 Defines the maximum number of events the agent collects per minute. If there are more than this number, the agent collects a statistical sampling. Caution This configuration has been replaced with max_samples_stored starting with version 6.0.0 of the agent. See max_samples_stored for 6.x or later agents. attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. Caution Any header-related include/exclude rules must be in camelCase form to be filtered. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. Browser monitoring variables This section defines the Node.js agent variables in the order they typically appear in the browser_monitoring: { section of your app's newrelic.js configuration file. enable Type Boolean Default true Environ variable NEW_RELIC_BROWSER_MONITOR_ENABLE Server-side label Enable browser monitoring? Generate JavaScript headers for browser instrumentation. Although this defaults to true, the agent doesn't inject the browser JS code unless you have enabled browser monitoring. Even if you have enabled it and added the browser timing header, you can disable browser monitoring for your app by setting this to false. debug Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITOR_DEBUG If true, request un-minified sources from the server. attributes.enabled Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent sends custom attributes to browser monitoring. Caution Any header-related include/exclude rules must be in camelCase form to be filtered. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. Custom events variables This section defines the Node.js agent variables in the order they typically appear in the custom_insights_events: { section of your app's newrelic.js configuration file. Currently there are no environment variables for custom events. enabled Type Boolean Default true When enabled, the agent sends custom events recorded with recordCustomEvent() to New Relic. If this is disabled, the agent does not collect this data or send it to New Relic. max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of custom events the agent collects per minute. If the number of custom events exceeds this limit, the agent collects a statistical sampling. Important Increasing this limit increases memory usage. Slow queries variables This section defines the Node.js agent variables in the order they typically appear in the slow_sql: { section of your app's newrelic.js configuration file. These options control behavior for slow queries, but do not affect SQL nodes in transaction traces. enabled Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_ENABLED When enabled, the agent collects slow query details. max_samples Type Integer Default 10 Environ variable NEW_RELIC_MAX_SQL_SAMPLES Defines the maximum number of slow queries the agent collects per minute. The agent discards additional queries after the limit is reached. Important Increasing this limit increases memory usage. Custom hostname variables This section defines the Node.js agent variables in the order they typically appear in the process_host: { section of your app's newrelic.js configuration file. These options control behavior regarding the host display name in the APM UI. display_name Type String of 255 bytes or less Default (none) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom hostname for display in New Relic. If you do not set this field, New Relic will continue to use the default hostname found by calling os.hostname(). If you use the default hostname settings, New Relic finds the hostname through os.hostname(). If this call fails, New Relic uses the host's IP as the name. If you set ipv_preference: 4 or ipv_preference: 6, you can select the type of IP address (IPv4 or IPv6) that appears in the New Relic UI. ipv_preference Type Integer (4 or 6) Default 4 Environ variable NEW_RELIC_IPV_PREFERENCE Environment variable overrides This section defines two configuration options only available with environment variables. These overrides are not used in most configurations. NEW_RELIC_HOME Path to the directory containing newrelic.js. This is available only as an environment variable. You cannot set it in your config file. Type String Default (none) NEW_RELIC_NO_CONFIG_FILE If used, this prevents the agent from reading configuration settings from newrelic.js. Default values and values from environment variables will still be set. This is available only as an environment variable. You cannot set it in your config file. Type Boolean Default False Datastore tracer variables This section defines the Node.js agent variables in the order they typically appear in the datastore_tracer section of your app's newrelic.js configuration file. These options control behavior for collecting datastore instance metrics. instance_reporting.enabled Type Boolean Default true When enabled, the agent collects datastore instance metrics (such as host and port) for some database drivers. These are reported on slow query traces and transaction traces. database_name_reporting.enabled Type Boolean Default true When enabled, the agent collects database name on slow query traces and transaction traces for some database drivers. Cross application tracing (DEPRECATED) The Node.js agent variables that control cross application tracing typically appear in the cross_application_tracer section of your app's newrelic.js configuration file: enabled Type Boolean Default false When set to true, allows tracing of transactions across more than one New Relic-monitored applications. Important Cross application tracing (CAT) has been deprecated and will be removed in a future major release. For cross-service visibility, we recommend using distributed tracing, which is enabled by default as of agent version 8.3.0. Before enabling, read the transition guide. Error message redaction variables The Node.js agent variables that control error message redaction appear in the allow_raw_exception_messages section of your app's newrelic.js configuration file: enabled Type Boolean Default true Environ variable NEW_RELIC_ALLOW_RAW_EXCEPTION_MESSAGES_ENABLED When false, the agent will redact the messages of captured errors. Distributed tracing Important Enabling distributed tracing disables cross application tracing, and has effects on other APM features. Before enabling, read the transition guide. Requires Node.js agent version 4.7.0 or higher. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. When configuring via the config file, place the following option in the distributed_tracing section. enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Set this to true to enable distributed tracing. For example, to enable this in the config file, you would use: distributed_tracing: { enabled: true } Copy exclude_newrelic_header Type Boolean Default false Set this to true to exclude the New Relic header that is attached to outbound requests, and instead only rely on W3C Trace Context Headers for distributed tracing. If this is false then both types of headers are used. For example, to enable this in the config file, you would use: distributed_tracing:{ enabled: true, exclude_newrelic_header: true } Copy Span events Span data is reported for distributed tracing. Distributed tracing must be enabled to report spans. Span configuration is set in the span_events stanza. Options include: enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED Turns reporting of span events on or off. attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED This setting can be used to turn reporting of attributes on or off for spans. If attributes.enabled at the root level is false, no attributes will be sent with spans regardless on how this is set. attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE If attributes are enabled for spans, all attribute keys found in this list will be attached to spans. For more information, see the agent attribute rules. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE All attribute keys found in this list will not be sent with spans. For more information, see the agent attribute rules. max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of events the agent collects per minute. If there are more than this number, the agent collects a statistical sampling. We do not recommend configuring past 10k. The server will cap data at 10k per-minute. Infinite Tracing To turn on Infinite Tracing, enable distributed tracing (set distributed_tracing to enabled: true) and add the additional settings below. For an example, see Language agents: configure distributed tracing. trace_observer.host Type String Default (none) Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST For help getting a valid Infinite Tracing trace observer host entry, see Find or create a trace observer endpoint.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 57.303886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " (DEPRECATED) The Node.js agent variables that control cross application tracing typically appear in the cross_application_tracer <em>section</em> of your app&#x27;s newrelic.js configuration file: enabled Type Boolean Default false When set to true, allows tracing of transactions across <em>more</em> than one New Relic"
      },
      "id": "617e95b528ccbc0ba67ffd8b"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Collect data - any source",
        "Add custom attributes",
        "Create custom events",
        "Build queries with NerdGraph",
        "Monitor your network devices with New Relic",
        "Query data with NRQL"
      ],
      "published_at": "2022-01-02T01:39:10Z",
      "title": "Collect data",
      "updated_at": "2022-01-02T01:39:10Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Collect data - any source APIs, agents, OS emitters - get any data 15 min Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 56.17807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this <em>section</em> provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Collect"
      },
      "id": "6091fa38196a67a932d52a29"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/om-implementation-guide": [
    {
      "sections": [
        "Service level management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Service response time",
        "Service quality",
        "Service level objective attainment",
        "Service uptime",
        "Prerequisites",
        "Establish current state",
        "Determine in-scope services",
        "Identify service boundaries",
        "Deploy instrumentation",
        "Perform SLM educational workshops",
        "Analyze KPIs and set baseline SLOs",
        "Establish or optimize alerting",
        "Build problem resolution workflows",
        "Execute continuous improvement review",
        "Next steps",
        "Value realization",
        "Additional resources"
      ],
      "title": "Service level management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Service level management",
        "Implementation guide"
      ],
      "external_id": "e3c4da80186b6d33a301db4a15c0b0cff2034131",
      "image": "https://docs.newrelic.com/static/e2478328e46923877c6dd58993aecf5f/d9199/nrSLMServiceMap.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide/",
      "published_at": "2021-12-30T14:50:28Z",
      "updated_at": "2021-11-25T05:19:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview IT Operations is expected to provide services that meet the business’s requirements for performance and reliability. However, many ops teams attempt to measure performance and reliability using legacy methods, like measuring resource consumption. That, in turn, requires that they create complex dashboards of granular metrics which they then try to correlate with application performance and reliability. These complex dashboards require subject matter experts to interpret the results for business stakeholders. Legacy methods create barriers to understanding what a good system state looks like and how bad system states impact the business. Essentially, IT ends up not sharing a common metric vocabulary with the business. This fundamental disconnect will result in the perception that IT is not able to deliver the services that the business requires, with all the implications and impacts that perception carries. Service Level Management (SLM) eliminates that disconnect by better explaining the overall performance of a system in terms that are easily understood by both IT and the business. The intent is to show whether or not the system is meeting its performance and reliability expectations, and if it is trending toward or away from improvement, so proactive steps can be taken. The end goal is that systems are better oriented toward desired business outcomes with IT’s attention focused on issues in areas with the highest business impact. You are a good candidate for SLM if any of the following are true: The business impact of performance and reliability issues are not well understood by all stakeholders. Your MTTx is too high. You are collecting many resource consumption metrics (such as CPU, disk, or memory) or are maintaining many metric correlation rules in order to identify system problems. You can’t see the value of your observability tool(s). Desired outcome Service Level Management’s overall goal is to easily measure and communicate the overall health, performance, and quality of your digital products and services to all stakeholders. By implementing SLM at key output points in your systems, you will have a simpler and more responsive observability practice, tighter alignment with the business, and faster paths to improvement. The SLM process described in this guide will help you to identify the points in your systems where you should measure the key performance metrics of service performance and quality. It will also define and drive a simpler alerting strategy, continuous improvement methodologies, and improved problem resolution workflows. Key performance indicators You will use the SLM process to collect and measure the following KPIs, often referred to as the “Golden Signals”: Service response time Service response time measures the amount of time a service requires to process a transaction. It starts when a transaction request is received by the service and ends when the response is sent. Goal: Reduce transaction response time. Best practices: Measure response time at service boundaries. Use continuous improvement processes to drive down response times. Ensure that non-business transactions (such as health checks) are not included or measured. Map this KPI back to business impact. Report KPIs to all stakeholders. Service quality Service quality is the number of transactions that result in an unhandled error. Typically, these are transactions whose HTTP response code is greater than or equal to 400. Goal: Reduce the number of unhandled errors. Best practices: Measure error rates at service boundaries. Continually identify and remediate sources of high error volumes. Map this KPI back to business impact. Report KPIs to all stakeholders. Service level objective attainment SLO attainment is the percentage of time a business service is meeting its response time and quality goals. Goal: Improve response time and quality to ensure high SLO attainment. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact. Report KPIs to all stakeholders. Service uptime Service uptime is the percentage of time a service can be reached by at least one client. Typically this is measured using synthetic transactions from representative remote locations. Goal: Use continuous improvement processes to watch uptime metrics and take appropriate steps to ensure uptime meets business requirements. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact Report KPIs to all stakeholders. These KPIs directly measure the most important aspects of an IT service, speed and quality, in a way that is easy and intuitive to understand and communicate to technical and non-technical stakeholders. Prerequisites Before you begin, if you don’t have equivalent experience, you should complete the New Relic University (NRU) Overview Course. You should also have a basic understanding of: New Relic One APM and infrastructure monitoring New Relic One Dashboards and NRQL New Relic One alerting best practices Establish current state As with any continuous improvement process, the first step of SLM is to establish the current state of your KPIs. To do so, you will need to perform the following tasks: Determine in-scope services Identify service boundaries Deploy instrumentation Perform SLM educational workshops Analyze KPIs and set baseline SLOs Establish / optimize Alerting Build problem resolution workflows Execute continuous improvement review To help illustrate this process, we are going to apply it to an example IT service, an ecommerce site for a cellular telephone provider. Determine in-scope services You should first identify the IT services that are going to be in-scope for the initial iteration of the SLM process. These services should be key to ongoing business operations and as close to your customers as possible. Most commonly, you will be applying the SLM process to an application, since that is the service your customers are expecting you to deliver. SLM can be applied to infrastructure-based services; however, it is a more advanced application of SLM which is applicable to a much smaller set of organizations. If you are considering implementing SLM for infrastructure, you should ensure that the service(s) you are instrumenting are actually the closest to your organization’s end-customer. If your infrastructure is hosting a customer-facing app, then the app should be the target of SLM. Absent anything else, a good methodology for identifying in-scope services is to consult your disaster recovery plan. Typically, the most critical business services are prioritized there. Identify service boundaries Next, you should identify each service’s boundary, which is the service component that is closest to the client sending transaction requests. This should be the application receiving the request from the client, browser, or mobile device, and may also be known as the \"external API.\" Reverse proxies, CDNs, and load balancers are not part of the service boundary. Their service level compliance should be measured via the Uptime KPI (external test requests for connectivity). If your services are using APM, you can identify service boundaries using the service map or dependencies features. A service component is on a boundary if it has no inbound connections. In the example below (from a service map), you can see that the WebPortal is on the boundary. An example of using service maps in New Relic One to identify service boundaries. In contrast, the following screenshot (from the dependencies page) shows that the Inventory Service is not on a boundary since it has incoming connections from the WebPortal. Subsequent examples in this guide will build on the WebPortal service boundary. An example of using the dependencies UI in New Relic One to identify service boundaries. You should understand that the SLM process defines a service boundary as being downstream of any dependencies. The service boundary is the point where all the effects and impacts of dependent services are measured as they contribute to the total response time and quality of the service. By measuring service level compliance at the boundary, you will be able to see the impact that all service components upstream of the boundary have on service delivery. This means that your initial steps into SLM can focus on the services that are closest to your users, yet still capture the contribution of more distant services. As your practice matures, you will be able to identify the next round of upstream services that would benefit from direct SLM instrumentation. In our example, the WebService is downstream of the Fulfillment, Plan, Promo, Login, and Inventory services (among others). By applying SLM at the WebService, we will be seeing the impact of the upstream services on the WebService. Any impactful issues with an upstream service will be reflected in the WebService’s service level KPIs. By instrumenting one service, we are capturing the contribution of five additional services. This greatly simplifies our observability practice. In time, problematic upstream services will self-identify themselves as candidates for direct SLM instrumentation. Deploy instrumentation To collect SLM service response time and transaction success KPIs, you need to deploy instrumentation into the components of your production apps on the service boundary. If you don’t have instrumentation that can do this in production already, then you will need to engage the teams and stakeholders that can help you to get this done. For detailed information on deploying the New Relic instrumentation that can gather this information, see our APM install documentation. The uptime KPIs can be collected using synthetic transactions, which don’t require any instrumentation to be added to the service. If needed, you can start your SLM journey there while waiting for the direct instrumentation to be deployed. The uptime tests should perform a basic, yet realistic, check of the service’s functionality. For detailed information on this capability, see our synthetic monitoring documentation. Perform SLM educational workshops You should share the self-paced New Relic Essentials training course with the appropriate stakeholders so they can understand how the New Relic technology platform will aid in the SLM process. Analyze KPIs and set baseline SLOs The SLM process uses speed and quality as its key performance indicators. In technical terms, speed means response time and quality means error rate. At the end of this phase, you will have created baseline service level objectives for each service in the form of a percentage. For example: “98% of service X’s transactions will be error free and occur in less than 500 milliseconds.” For each in-scope service, you should analyze speed and quality at the service boundary. This will give you an overall understanding of how the entire service and all of its dependencies are performing. As you iterate through the SLM process, you can then identify and prioritize the upstream service components that require direct SLM instrumentation. To analyze KPIs, you should do the following for each service: Identify the volume and 95th percentile response time for each of the service’s transactions over a relatively long period of time, typically between seven days and one month. It is important that you use percentile rather than average, so you can see the entire range of response times, including outliers. If you use averages, you will hide outliers. The following is an example of the initial baseline report. Here you can see the volume, p95 response time, and error volume for the WebPortal and a few other services. The WebPortal’s p95 response time is .36 seconds (or 36 milliseconds), so we have decided to set the SLO target to 0.4 seconds. Example of an initial baseline report measuring volume and 95th percentile response time. Next you should review and identify any non-business transactions, since they should not be included in the SLO attainment calculation. For example, you should not include health check / keep alive transactions and you may not want to include administrative transactions. In the example below, we are looking at some of the transactions from the WebPortal service. We have decided that the about.jsp transaction is a non-business transaction that should not be tracked in our SLO attainment calculation. Example showing transaction breakdowns from the initial baseline report to help identify what to track (or not track) for SLO. Finally, import and edit the SLM template dashboard to exclude non-business transactions. Then use the p95 response time as your baseline response time service level objective. For the example chart, we chose 0.4 seconds as our response time threshold and set our service level objective to 95%. This means that we are expecting 95% of the WebPortal’s business transactions to complete in 0.4 seconds or less and without an error. The red line on the chart shows us our 95% service level objective. Example chart now excluding the non-business transactions. As you can see, there are periods of hours where the app is not meeting its SLOs. If we are going to maintain the 95% target, we would need to identify and fix the service components or dependencies that are causing these problems. Establish or optimize alerting After you have set your service level objectives, you will then configure alerts that will inform you when your SLO attainment has dipped below your goal. These alerts will show you when incidents with a high business impact are occurring. When they are triggered, they should be given a high priority and you should engage the proper teams to start the process of diagnosing the source of the problem. A basic starting point is to configure an alert that triggers when your SLO attainment has dipped under your baseline for more than 10 minutes. For more information, see our documentation on configuring alerts. Build problem resolution workflows As we’ve been discussing, the intent of the SLM process is to identify when business impacting issues occur in your IT services. When this occurs, a diagnostic investigation should be launched. The goal of the investigation is to identify what service element is causing the business impacting issue. SLM tells you that there is a problem with business impact, the diagnostic process helps you to find where the problem is. Typically, your high level diagnostic workflow will start at the service boundary and go as follows: Look at the service’s individual transactions and see which one(s) are departing from their performance and/or response time SLOs. Look at each service component responsible for delivering that transaction until you find the component that is failing. Use in-depth diagnostics to identify the root cause of the problem and then resolve it. Execute continuous improvement review This is an ongoing phase of the SLM process where data is reviewed and adjustments are made as required. Your KPIs should be reported to upper management to ensure that stakeholder teams are appropriately prioritizing work and that you are meeting the SLO goals you’ve set. Periodic KPIs should be recorded and retained over periods of months to years to establish a baseline and to show the rate of improvement. In addition, each time you execute the continuous improvement process, you should: Review each service’s architecture to ensure your instrumentation is deployed at the boundary and that there are no observabilty gaps. Review each service’s transactions to confirm that only business transactions are included in your SLO calculations. Review each service’s SLO and determine if it meets the business’s performance and quality requirements. If it does not, then the SLO should be changed and the appropriate stakeholders notified so they can work to improve performance and quality. Review your SLO attainment and determine if any upstream services should be added to the SLM process. Next steps After you’ve established the SLM process, you should identify other services that would benefit from SLM instrumentation. These may be other front-line services or upstream dependencies of services that are covered by SLOs that have shown themselves to be frequent contributors to SLO attainment failures. As you do this, you should start to measure and report your SLM coverage as a percentage of applications covered by SLOs. For example, you may say that 20% of your apps have established SLOs. As SLM expands into your organization and as its value is seen by management and other stakeholders, you may find that you need a dedicated team to manage the SLM process. The SLM process should also become a primary driver to help you prioritize issue resolution activities. SLO attainment failures are a direct indicator that your IT services are having a negative business impact which is visible to your customers as poor performance and/or unhandled errors. Value realization Once the SLM process is established, you will see a reduction in the effort required to identify business impacting issues, a better ability to communicate with your business stakeholders, and an easier time proving the business’ return on investment in IT services. Your SLM KPIs will provide quantifiable proof of these improvements. In addtion, you should be able to simplify your observability strategy by removing or reducing your dependency on legacy consumption metrics and the logic required to correlate them against your true goal of measuring performance and quality. Once you are firmly on the path to SLM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering. You can also move to other observability maturity value streams, such as Customer Experience. Additional resources Need help getting started? Check out the self-paced service level management training",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.225044,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Service level management <em>use</em> <em>case</em> <em>implementation</em> <em>guide</em>",
        "sections": "Service level management <em>use</em> <em>case</em> <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " on the path to SLM&#x27;s goals, consider moving to other <em>use</em> cases within the Uptime, Performance, and Reliability <em>value</em> stream, such as Service Level Management, or Reliability Engineering. You can also move to other <em>observability</em> <em>maturity</em> <em>value</em> streams, such as Customer Experience. Additional resources Need help getting started? Check out the self-paced service level management training"
      },
      "id": "61403d0464441f0457424337"
    },
    {
      "sections": [
        "Service characterization use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Business KPIs",
        "Service quality",
        "Release frequency",
        "Practitioner KPIs",
        "Feature release frequency",
        "Mean time to close",
        "Prerequisites",
        "Establish current state",
        "Determine your instrumentation needs",
        "Decision matrix",
        "Understand endpoint testing",
        "Improvement process",
        "Config based instrumentation",
        "Create an effective service name",
        "Tip",
        "Override default agent configuration",
        "Isolate service functions",
        "Define custom transaction names",
        "Capture parameters with your transactions",
        "Measure service components",
        "Ensure your frameworks are measured",
        "Track every external service call",
        "Test your endpoints",
        "Value realization",
        "Investments",
        "Training",
        "Development and maintenance",
        "Returns",
        "AQM impact",
        "Service quality improvement",
        "Service delivery improvement"
      ],
      "title": "Service characterization use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Operational efficiency",
        "Service characterization",
        "Implementation guide"
      ],
      "external_id": "6c7ba35514950d573261ef4dbc852f6b3c76433a",
      "image": "https://docs.newrelic.com/static/bd4c9daf746228eed022d0c89454469c/39c09/oma-oe-sc-service-diagram.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/operational-efficiency/sc-implementation-guide/",
      "published_at": "2021-12-30T20:46:08Z",
      "updated_at": "2021-11-25T05:17:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview \"Do I have all the telemetry I need to adequately measure my service?\" The process of onboarding a service for production monitoring tends to start from the end and work its way to the beginning. Typically, a service is instantiated with agent based monitoring and the team responsible for service delivery needs to read the telemetry coming out of the agent like tea leaves. They work their way backward to understand how the service functions by what can be observed. At New Relic, through tens of thousands of observability deployments, we have discovered that the more involved designers, architects, and developers can be in the definition of optimal service delivery measurement, the better. The emergence of the IT aphorism shift left speaks to the need to involve developers more directly in the software lifecycle activities that happen after the development stage is complete. In the case of service observability, we find there is little specific guidance on how developers can meaningfully contribute to production telemetry definitions. This guide is intended to provide practical suggestions for developers to evaluate the state of your telemetry and suggest paths to improve it. Observability programs that closely link developer expectations with the runtime behavior of production systems are much more effective to diagnose and remediate aberrant conditions. The closer developer connection also produces services that are more robust and performant. You’re a good candidate for service characterization if any of the following are true: Your development teams are disconnected from production observability design. Your production monitoring program suffers from a lag between the introduction of new services/capabilities and their coverage with telemetry and alerting. You need to provide additional business context to your instrumentation for diagnosis and business KPI measurement. You employ a highly customized or proprietary software framework. Your service is under active development. Legacy services, and services built from commercial-off-the-shelf platforms tend to be better served with generic instrumentation options. Desired outcome This guide focuses on the metrics derived from your service’s runtime operation (its code execution) as well as external measurements of execution (through synthetic testing). Service instrumentation planning is the approach used to describe a single service runtime through telemetry. Modern monitoring systems provide deep insight into the technical details of service implementation. The power of distributed trace or bytecode instrumentation allows operations teams to quickly collect detailed service telemetry. Unfortunately, operations teams are often not in the best position to evaluate the quality of the telemetry gathered from the instrumentation. This challenge is compounded by the fact that service delivery teams are asked to implement telemetry collection for the first time in live production systems. Exposing inadequately instrumented services to production users for the purposes of refining that instrumentation creates a period that puts customer satisfaction at risk. This burn-in period often becomes difficult to escape as new features are delivered from code bases without a strong linkage between software delivery and observability programs. By having your development staff involved in improving your service instrumentation, you should realize observability benefits in the following ways. Better informed development decisions by: Detecting areas of volatility or unexpected behavior and addressing them. Understanding what dependencies in your code lack redundancy or robustness, and taking measures to refactor the service. Appreciating how end-user cohorts are employing your software. You can better understand where improvements will have the biggest impact. Improved troubleshooting: More precise and contextually relevant telemetry from your service will allow for more accurate and actionable detection of faults. With better telemetry naming, operations staff can use a common language with developers during incidents, reducing the time to triage and remediate incidents. Key performance indicators It is important to identify some simple KPIs that help to gauge the ongoing improvements in your software delivery and operations programs. The following outlines some suggested KPIs to consider as you invest in improved instrumentation. Business KPIs are aligned to your overall program objectives and should be consistently measured to demonstrate ongoing program improvement for each service. Practitioner KPIs are used to measure changes in the execution of job functions for those participating in the development and management of services. Business KPIs Service quality A metric is required to define how well your service is operating. This will depend upon the needs of your organization and the constraints of the services being monitored. Goal: Improved service quality attainment score over time. Best practices: Create a graphical representation as a trend of Service Quality achievement for defined periods (Monthly / Quarterly). Service Apdex can provide an effective Service specific quality score. (See Apdex: Measure user satisfaction.) A well defined Service Level Management (SLM) approach using SLIs that describe the level of expected operation for service boundaries can be a useful way to establish a single measurement of quality. Release frequency The number of releases for a given service. This should indicate the velocity of the software delivery organization. Often release frequency isn’t immediately comparable between development organizations. Instead, weighting high-value releases or features to bugs can provide an improved comparative context. Goal: Consistency of attainment with consistent or improving Service Quality indicator. Best practices: Can be derived from deployment markers or other events sent to New Relic. Measure directly from code or project management tools such as Jira, BitBucket, GitHub. Consider implementing a collection mechanism to capture release events and store them directly in New Relic. See NR1 CICD Innovation for example JIRA and BitBucket configs. Practitioner KPIs Feature release frequency Quantification of the percentage of releases that are directly related to new feature development versus bug fixes or technical debt retirement. The relationship to feature to fix will vary between teams and projects based on the history of the service. Goal: A consistent or improving feature release frequency consistent with the service delivery goals. Best practices: Practitioner feature release frequency is often acquired in the same manner as the broader release frequency business KPI. This metric is then made available to the development team for the service. Mean time to close Average duration of alert-driven incidents in New Relic. See Alert Quality Management Use Case Implementation Guide for more details. Goal: Steady decrease of incident close time for identified services. Best practices: Follow the Alert Quality Management Use Case Implementation Guide, understanding Service behavior through the lens of the alerts defined to help improve service delivery. Prerequisites Before you begin to introduce Service Instrumentation into your development processes, get acquainted with New Relic fundamentals available from New Relic University. In addition to NRU training, review and keep the following documentation resources handy: APM agent install and configuration Instrumentation guides: C-SDK Go Java .NET Node.js PHP Python Ruby OpenTelemetry SDKs Introduction to New Relic synthetic monitoring Establish current state Determine your instrumentation needs Understand endpoint testing Determine your instrumentation needs Instrumentation is the process to acquire telemetry from a software system and its associated services for the purpose of describing that software system's runtime behavior and business function. Monitoring systems tend to provide generic capabilities for telemetry acquisition that can be fine tuned to close gaps when monitoring the function of a software system. This use case assumes that your Observability Program has completed the Quality Foundation OMA use case implementation guide and that you have a well considered and deployed telemetry collection architecture for your services. With the possible exception of alert definition, instrumentation offers the most open-ended and customizable activities related to observability. The New Relic One platform provides features to highly customize your use of instrumentation. Because of this, you should carefully consider the amount of time and effort you’re going to put into instrumenting your services. Like all service instrumentation assets and dependencies, the introduction of instrumentation will require ongoing oversight and maintenance and therefore is a form of technical debt you will accrue for your project. As you begin the process of instrumentation, you want to continually ask yourself the question: Is the visibility I will gain from this instrumentation worth the cost of implementation and support? Decision matrix As a first step you should evaluate the default instrumentation you obtain from your Observability platform and ask yourself the question: Does the telemetry adequately describe the function and the purpose of my service? Think about what your service does. Perhaps it receives an order, needs to validate the order for integrity, conveys that order to a clearinghouse service, and receives a confirmation code that is relayed back to the requestor. This example gives a clear path to break down the function of service and evaluate if we have enough telemetry and context to make informed appraisals of how the service is functioning. Conceptual service that receives and processes http requests. If this conceptual diagram represents the implementation of the service, you need to know at any moment in time: How many requests do I receive? How many messages and HTTP requests do I send? How many requests are successful? What is the response time for a full request? What is the response time for invocation to a dependency? How much resource should this process take under what number of requests? What are all my points of failure? Most monitoring frameworks for application runtimes will gather telemetry like this as basic functionality. However, sometimes specific implementation of your service will pose a challenge to the generic instrumentation assumptions made by the monitoring software. In this case your Observability platform will need to accommodate your needs and provide an ability to modify a default monitoring configuration. The following table documents some additional situations where you would consider adding additional telemetry or metadata capture through instrumentation. The practices section that follows describes how to close those gaps to ensure your observability platform provides telemetry needed to manage your service. Considerations for instrumentation: Are my base telemetry requirements satisfied? If not, document the gaps and evaluate if they can be closed through custom configuration or additional instrumentation techniques. Can I isolate discrete user stories within the telemetry? If not, use trace capabilities of agents to capture the invocation of a discrete user story with adequate context metadata. Do I have insight into the parameters that are invoking user stories? If not, use custom attributes through agent SDKs to add context to the transactions and spans. Can I measure the major functional components of the software? If not, use instrumentation SDKs to create baseline metrics on a specific functional element of the code. (cache lookups, processing routines, or utility functions). Can I measure the client interactions from my code to external systems? If not, ensure requests and responses are encapsulated by component level tracking. If the client invocation is asynchronous, consider implementing distributed trace features to view the successive processing. Understand endpoint testing Endpoint testing is a simple and practical approach that greatly expedites how to determine the root cause of a given system failure. It allows operations and supporting teams to quickly know there is a real problem, and isolate that problem to a specific service. Modern software systems depend on a number of services to complete their tasks. Historically, the process of monitoring those service endpoints was straightforward. The architecture team would produce a well documented map of dependencies for the operations team. The operations team would dutifully create a check of the itemized endpoints. Today, with continuous delivery processes and small batch changes, new endpoints and dependencies can be created and deployed at a rate that makes it difficult for an operations team to anticipate and proactively define synthetic checks. By giving the service developers greater scope of control to define production services tests during the development phase, you will greatly increase the coverage of endpoint tests for your Observability program. Decision matrix To determine whether to create a synthetic check is straightforward. You will want to know the first occurrence of a failure for a dependency. If you answer “yes” to any of the following questions, consider creating a dedicated synthetic check. Is the end point customer facing? Does the endpoint invoke new dependencies? Is the endpoint on a different network infrastructure? Is the endpoint shared between multiple services? Is the endpoint a content origin supported by a CDN? Improvement process Config based instrumentation Isolate service functions Define custom transaction names Measure service components Ensure your frameworks are measured Track every external call Test your endpoints Config based instrumentation Each New Relic agent provides a variety of configuration options. Typically you will define a standard approach to include the agents within infrastructure hosts, application runtimes, and connections to your cloud service providers. Default agent configurations are generic and widely applicable. One of the best ways for developers to influence the applicability of deployment is by overriding the default configuration options for your service instance. The following are default instrumentation options to consider. Create an effective service name Tip New Relic agents provide a variety of mechanisms to define the Service runtime name. Please see the application naming guide to find the implementation details for your runtime environment. The name you give a service provides the namespace (where you will find the agent data). One of the most important strategies New Relic uses to understand the behavior of your services is to aggregate like things together and to use the commonalities derived from aggregation to isolate variance. Modern services are often deployed to multiple contexts to ensure capacity handling or specific functional segmentation. In order to take advantage of the benefits of aggregation, it is very important that your service runtimes are grouping instances with identical operational characteristics. Therefore, when deploying services, pay close attention to the following three criteria to help you name your deployed services: Does my service target a specific audience? Is my service running a different codebase? Is my codebase using a different runtime configuration? If you answer “yes” to any of these questions, consider creating a unique name for your service. Audience criteria Think of the audience as the group of end users or service functions. If your service is split between North American and European deployments, the runtimes in those deployments should be grouped accordingly. For example: newrelic.appname = PORTAL_AMER Copy and newrelic.appname = PORTAL_EMEA Copy This will group the telemetry created by that audience together, allowing you to better understand the contextual similarities of service problems related to a specific user audience. Sometimes the way we deploy applications divides the operational context of a service, such as a portal application with administrative functions. Maybe the admin functions are baked into the general portal codebase, but only one instance in a cluster is handling the portal admin requests. In that case you have a functional audience segmentation opportunity, so you should ensure that it is named appropriately. For example: newrelic.appname = PORTAL_MAIN Copy and newrelic.appname = PORTAL_ADMIN Copy Codebase criteria If you’re running different code versions under the guise of one service, consider segmenting those runtime instances and incorporating version naming as part of your naming scheme. When you group code together as one service name that is executing different service versions, you’re increasing the noise to signal ratio of any metrics you produce. Different code versions might use different amounts of compute resource or process data differently. It becomes very difficult to determine if a service is behaving normally when the signals you get from the metrics are due to different functional implementations. Consider adding a numeric identifier to the service name if you have multiple versions running concurrently. For example: newrelic.appname = PORTAL_MAIN_V112 Copy and newrelic.appname = PORTAL_MAIN_V115 Copy If you employ feature flag framework frameworks like LaunchDarkly or Split, you may have multiple versions of an application or service within a single codebase. Please consult the Isolating Service Functions section to address those conditions. Runtime criteria If an instance of a service is deployed to a system with different runtime constraints, it should be encapsulated in its own telemetry namespace. This can be a deployment to a different datacenter that offers network connectivity advantages to a shared resource, or perhaps the service is running on a separate compute tier with a different memory or thread configuration. These characteristics that affect the code runtime operation can cause different behaviors that lead to different operations behaviors. For example: newrelic.appname = PORTAL_NYC_DC Copy and newrelic.appname = PORTAL_REALLY_BIG_FOOTPRINT Copy Override default agent configuration Tip The New Relic agents provide a variety of options for runtime configuration. Please refer to the agent configuration guide for the options specific to your runtime. Each New Relic APM agent provides a variety of options to modify the default configuration. The most comprehensive and consistent location is the configuration file that accompanies each agent install. However, New Relic agents can also be configured by passing command line parameters directly to the service instance runtime, by using environment variables, or by calling functions within the agent's SDK at runtime. .NET agent configuration options: Using the New Relic .NET SDK API Environment variables Config file options Isolate service functions As the Create an effective service name section indicated, one of the primary objectives of instrumentation is to configure the New Relic agent to group like runtime constraints together as a single named unit. We suggest this because software systems should behave in deterministic ways. For a specific set of inputs, you should get an expected range of measurable outcomes. The degree to which we can comfortably contain these constraints into named service runtime components greatly helps us understand normal behavior and isolate aberrant behavior. Once you have settled on an effective service naming strategy, the next step is to look within the telemetry collected for the service and determine if it suitably isolates the service’s functionality. The implementation pattern we most often encounter is a series of functions being invoked by a web request. The initial receipt and handling of a web request to a service runtime results in the allocation of processing resources. New Relic defines this resource allocation and code execution as a transaction. The New Relic agent is configured with a set of assumptions that create namespaces for transactions as they are detected. Those assumptions differ between the agent language runtime. For example, a good example of how the New Relic Java agent determines the transaction name can be found in the Java agent's transaction naming documentation. However, even after the agent transaction naming protocol has been applied, it may leave you with an unsatisfactory result. By adding additional instrumentation to name the transaction to improve its context, this can greatly improve your understanding of the service’s execution behavior. The goal for transaction naming should be an APM transactions view that provides good segmentation of the services functions in an approach that is easy to understand for a non-developer. New Relic service transaction breakdown view. The transaction breakdown image is a good example of transaction segmentation. It provides detailed tracking of the amount of work being done by each transaction within the broader codebase of the service. It also displays the transaction with a plain user-friendly name that offers some hint of its business context (what the transaction does). As you learn more about naming transactions and including attributes, be sure to make your naming approach accessible for non-technical observers of the data. Transaction breakdown: the transactions in this service seem to be highly weighted to one transaction name with a pretty generic name. Breakdowns like this beg the question: \"Is this a good representation of the work my service does?\" The obtuse transaction breakdown image demonstrates a bad example of transaction name segmentation. In this case we have about 60% of the transaction volume being named OperationHandler/handle. Both the percentage attribution of the transaction volume and the generic nature of the name indicate there might be an overly zealous aggregation of transactions underneath that transaction namespace. A good way to validate your transaction naming approach is to review the distribution of response times for your transaction over a significant period of time in the service web transaction histogram dashboard. The service transaction histogram view shows the count of transactions that fall into each response time bucket. A good naming strategy tends to display a normal distribution. The service transaction image shows a wide range of transaction response rates. Although the bulk of the transactions land in the 0-200 millisecond range, it indicates values ranging from 200-1000 milliseconds. When you have a highly distributed range of responses for a transaction, you should ask yourself: What information do I have during the transaction execution that can help me name this transaction? In many cases, non-normal distributions are a direct result of the parameters being passed to a request, or the work the transaction is being asked to do. It is pretty easy to consider that a service query transaction might take a data range as a parameter. The date range when small might provide a faster lookup time. Therefore, perhaps providing a meaning scheme that is derived from some expected parameter constraints (> 1day, 1-5 days, >5 days) might provide a more meaningful segmentation. Your objective is to create a transaction name that facilitates grouping transactions with the fewest unique characteristics. A more normal distribution of transaction segmentation where individual transactions report more consistent response time attainment with fewer exceptions. The normal distribution image demonstrates more purposefully named transactions within a service. In this case the web transaction response times are more closely grouped, indicating consistent execution characteristics. By ensuring your transaction naming strategy provides a consistent mechanism to group your service’s functions by the types of operations they are performing, you will be able to quickly isolate aberrant behavior, or better understand the root cause of the variations. This will allow you to refactor your application and increase the overall predictability of your service’s functions. Define custom transaction names Tip Consult the New Relic agent API guide for your language agent to review the transaction naming procedure for your runtime. The New Relic agent transaction naming service requires the invocation of a SetName(String name) like API call to the New Relic agent SDK. Each language runtime agent has its own syntax and option for setting the name. For example, to take the value of an http request parameter and use it to name a transaction in the New Relic Java agent, you can use code similar to this: com.newrelic.agent.Agent.LOG.finer(\"[my query handler] Renaming transaction based on an important query parameter\"); com.newrelic.api.agent.NewRelic.setTransactionName(\"Query Handler_\" + (javax.servlet.http.HttpServletRequest)_servletrequest_0).getParameter(\"important_query_parm\")); Copy Please note: There is a maximum capacity to transaction names within New Relic. Your transaction naming strategy will have to trade off a degree of specificity if there are thousands of potential transaction names. When too many transaction names are being reported, New Relic will attempt to create rules to group those transaction names. More details can be found in the agent troubleshooting guide related to metric grouping issues. Should you suspect a metric grouping issue, open a support case with New Relic, and we will be happy to work with you to isolate the cause of the transaction naming issue. Capture parameters with your transactions Tip Consult the New Relic agent custom attributes guide for your agent language to review the metadata enhancement options for attribute customization. The transaction name is a powerful way for you to segment your Service’s functionality so that you can better understand its behavior. This allows you to discretely isolate functionality directly in the New Relic UI. However, there are many occasions when you will want to get some additional context on the function of your Service without resorting to isolating the transaction name. This can be accomplished by introducing attribute capture by your Service. You can add name:value pair attributes to decorate the details of each transaction. The attributes will be available in each transaction event through the APM transaction trace and errors UI, or through direct query of parameters from the NRDB transaction event type. After you select a transaction trace, you can view the custom attributes you have set for your Service’s transaction. Here is an example of the transaction trace details you can see in the APM errors UI. Custom attributes displayed in the APM errors UI. If you have developed a useful transaction name segmentation, you can use the additional context of the attributes to better understand the inputs, cohorts, or segments that led to an unexpected result. In addition to being able to understand the context of your transaction within the APM UI, the introduction of parameters is an extremely useful tool to aggregate and analyze transactions by querying transaction data directly. Custom attributes are added to each transaction, making it easy to isolate and facet on specific conditions. NRQL query expression that uses a custom attribute to facet database call duration. The parameter capture approach can also be used with feature flag systems like Split or LaunchDarkly. In this case, as you are implementing the decision handler for the feature flag, consider capturing the flag context (for example, optimized_version = on) that is being applied to the block of code controlling the version or feature the customer sees. NRQL query that demonstrates the result when the state of a feature flag is captured by a transaction custom attribute. The feature flag state attribute allows us to understand the impact of the code execution path on performance, throughput, and dependency utilization. For example, to take the value of an http request parameter and save it as a custom attribute in the New Relic Java agent, you can use code similar to this: com.newrelic.agent.Agent.LOG.finer(\"[my query handler] Adding an Attribute to transaction based on an important query parameter\"); com.newrelic.api.agent.NewRelic.addCustomParameter(\"ImportantParm\", (javax.servlet.http.HttpServletRequest)_servletrequest_0).getParameter(\"important_query_parm\")); Copy Measure service components The behavior of a specific transaction within the context of a service is a powerful way to segregate functionality and ensure a software system is operating effectively. However, another way to look at the behavior of a software system is to review the detailed component execution model of its implementation. The application framework code components are shared throughout the service, and the ongoing evaluation of component performance can provide an insight into the overall service health. Within New Relic One there are two places we can observe component execution details. The service summary dashboard in APM provides a view of the composite execution of the service broken down by its component parts (for example, garbage collection execution or database calls). This summary dashboard provides a breakdown of major component types within the application. Memcached, External Web Invocations, MySQL and Dirac are all examples of shared code frameworks that the collective transactions of the Service are using to execute their business logic. A similar breakdown is provided on a transaction by transaction basis. This single transaction summary view breaks out the contributing execution time by component. This helps you see the aggregate performance of components within a transaction. Transaction component segments will tend to demonstrate consistent performance behavior, you can use this consistency to detect a change in its fundamental behavior. This can be a good indication of an underlying issue. Resource constraints tend to manifest more obviously within component frameworks than within individual transaction details. This allows you to infer characteristics of dependencies through the common constraints being experienced by all code running within a service. Ensure your frameworks are measured Tip Consult the New Relic agent instrumentation and SDK guides under the language agent for your service runtime to find information about adding metric names to your instrumentation. The syntax for framework instrumentation is specific to the language your service is written in, but the general approach is consistent for all. Consider the threads of execution within your Services as an analogy for transactions within New Relic telemetry. Each method or function execution on the stack is an opportunity to add additional instrumentation. In this way New Relic maintains a time-annotated invocation stack for the transaction and uses those method/function start/stop timings to aggregate it into a series of component metrics. A simple Node.js application making a call to a MongoDB. The two major components of the application are the receipt of the request and get/put operations to the MongoDB. If a particular segment of logic is crucial to the function of your Service or transaction, consider wrapping that call with callbacks to the New Relic agent so that the agent can understand that it has entered a discrete code component and can aggregate the time consumed within that component accordingly. By passing a metric name to the callback, you will create a component segment metric for your service and transaction. The metric naming option is specific to the instrumentation language, so be sure to consult the specific language documentation. The New Relic agents allow you to specify a custom metric name for the instrumentation. The metricName will be used to determine the aggregated metric for the component. The following example demonstrates the metricName parameter being passed to a Java agent SDK @Trace annotation. @Weave public abstract class MQOutboundMessageContext implements OutboundTransportMessageContext { @Trace(dispatcher = true, metricName=\"MQTransport\") public void send(final TransportSendListener listener) throws TransportException { try { NewRelic.getAgent().getTracedMethod().setMetricName(\"Message\", \"MQ\", \"Produce\"); MQHelper.processSendMessage(this, NewRelic.getAgent().getTracedMethod()); } catch (Exception e) { NewRelic.getAgent().getLogger().log(Level.FINE, e, \"Unable to set metadata on outgoing MQ message\"); } Weaver.callOriginal(); } } Copy Track every external service call Tip Consult the New Relic agent instrumentation and SDK guides under the language agent for your service runtime to find the details of client library instrumentation. Client instrumentation refers to encapsulating a call from your service to an external resource. Generally, New Relic agents are aware of clients popular for HTTP, gRPC, messaging, and database protocols and will apply the appropriate instrumentation pattern to aggregate calls to those clients as external services. External service dashboard details within New Relic APM. If you have written your own client handler for a protocol, or are using something very new or somewhat niche, the New Relic agent may not recognize the client and record the behavior of the client call. To this end you should verify the external services and databases within APM to represent all expected externalities for your service. Database protocol dashboard details within New Relic APM. It is important to validate that all your services' dependencies are represented here. If you do not see your service dependencies, you will need to introduce new instrumentation to intercept the external call so that your APM agent can track it accordingly. The following example demonstrates wrapping an external call in Golang for capture by the agent. package main import ( \"net/http\" \"github.com/newrelic/go-agent/v3/newrelic\" ) func currentTransaction() *newrelic.Transaction { return nil } func main() { txn := currentTransaction() client := &http.Client{} request, _ := http.NewRequest(\"GET\", \"http://www.example.com\", nil) segment := newrelic.StartExternalSegment(txn, request) response, _ := client.Do(request) segment.Response = response segment.End() } Copy Examples of other agent API external call tracing: Go ExternalSegment Java ExternalParameters Python external_trace Test your endpoints Endpoint testing provides two benefits to your Service Instrumentation program. Defect detection: By encoding a test for an endpoint that produces a simple true/false result, it allows the operations team to isolate discrete failures to determine if the integrity of service delivery has been compromised. Baselining: Synthetic or machine tests provide a predictable set of conditions that allow you to evaluate the consistency of your service delivery from a control perspective. New Relic’s synthetic monitoring offers the ability to create a variety of testing types by employing an enhanced Selenium JavaScript SDK. Once a Selenium-based test script has been defined, New Relic will manage the location of the script execution as well as its frequency. New Relic synthetics launch dashboard. The synthetic test offers a variety of test options, each with its own focus. For more information see our synthetic monitoring documentation. From the perspective of a Service developer, the monitor type that is most frequently employed is Endpoint availability. This monitor type provides the ability to script http request conditions. These can be as simple as a POST or GET to an accessible API, or involve multiple steps where the Selenium monitoring script successively evaluates requests to ascertain functional integrity of a multi-step process. In practice, developers should consider implementing the simplest possible test to evaluate endpoint availability and integrity. For example, you have just created a new Service endpoint that provides the current exchange rate for a group of currencies. This is a simple GET at an endpoint that returns a JSON object array. Request example: http://example-ip:3000/exchange Response example: [ { \"status\": [ \"quote\" ], \"_id\": \"5b9bf97f61c22f4fb5beb5c9\", \"name\": \"cdn\", \"Created_date\": \"2021-07-12T18:10:07.488Z\", \"__v\": 1 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb2a61c22f4fb5beb5ca\", \"name\": \"usd\", \"Created_date\": \"2021-07-12T18:17:14.224Z\", \"__v\": 0.80 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb3261c22f4fb5beb5cb\", \"name\": \"eur\", \"Created_date\": \"2021-07-12T18:17:22.476Z\", \"__v\": 0.68 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb3761c22f4fb5beb5cc\", \"name\": \"mex\", \"Created_date\": \"2021-07-12T18:17:27.009Z\", \"__v\": 15.97 } ] Copy In order for this service to be considered operational, it needs to respond to requests but also provide the four currency responses. We’re not worried about the content at the moment, just the fact we get four elements back in the array one, for each CDN, USD, EUR and MEX currencies. Using New Relic synthetic monitoring, an API test script could look like the following: /** * This script checks to see if we get the currency data from the endpoint. */ var assert = require('assert'); var myQueryKey = 'secret_key'; var options = { uri: 'http://example_ip:3000/exchange', headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; function callback (err, response, body){ var data = JSON.parse(body); var info = body; if (Array.isArray(data)) { if (data.length !== 4) { assert.fail('Unexpected results in API Call, result was ' + JSON.stringify(data)); } } } $http.get(options, callback); Copy The synthetics script can be directly configured in the New Relic interface, but we highly recommend you maintain your endpoint tests within your source repository system and employ automation. This will help ensure your endpoint testing accompanies the new endpoint dependencies that your Services introduce to production service delivery. Value realization The impact of Service Instrumentation will be directly related to the level of attention you’re willing to invest in overseeing the process. Like the process of monitoring services, your Observability program will benefit through a dedicated team function that thinks critically about its expectations of return for its investment in effort. Here is some guidance to think about the cost of investment for your organization and expectation of benefit. The following section outlines an approach for estimating the investments and returns you should expect by incorporating Service Instrumentation into your Observability practice. Investments Training Ensure all developers are familiar with New Relic agent SDKs and platform capabilities. Cost Model: Dependent on your company's developer FTE model and project estimation. Estimation: Typically a number of hours for a developer to become effective using New Relic instrumentation features. Initial: 16 HRS Training / Exploration Recurring: 4 HRS/Q Review Per developer a yearly investment of 16-40 hours training to develop core skills and maintain skills currency for New Relic platform Development and maintenance The development effort required to implement and maintain instrumentation within a Service project. Cost Model: Dependent on your company's developer FTE model and project estimation. Estimation: This tends to be dependent on the scope of the project and the amount of instrumentation work required. Initial: 8 HRS per developer per service Recurring: 4 HRS/Q Maintenance Per developer a project estimation of 16-32 hours developing and maintaining Service instrumentation Returns AQM impact Alert Quality Management delivers significant benefit to the operations team by ensuring the alert notifications from variant system performance are dealt with swiftly. This improves service delivery and resource allocation during incident remediation. An effective instrumentation practice federated into your observability program will greatly improve your team’s ability to create meaningful alerts. KPIs: Volume: Incident Count Volume: Accumulated Incident Duration Volume: Mean-Time-To-Close (MTTC) User Engagement: Mean Time to Investigate Outcomes: Less alert noise Greater alert and incident responsiveness Less unknown root cause Increased operations productivity Improved service delivery Service quality improvement Improving your service quality will have a direct impact on the key financial metrics for your Service. This will require that you have a well rationalized financial model for your application. Typically this return can be projected by associating a currency value for each percent improvement on a core service quality measure like errors or apdex attainment. As your investment in Service Instrumentation increases, you should see improved attainment on your service quality measures. KPIs: Service Quality (Business KPI) Outcomes: Decreased number of user impacting errors More performant and resilient Service components Service delivery improvement By providing better telemetry from your Service instances, your delivery organization should be able to more quickly detect volatility or downtime and remediate faster. This will lead to better overall service delivery KPIs and decrease episodes of outage or degradation. Cost can be associated with the amount of time it takes to detect, investigate and remediate an incident. This might be related to the value the Service provides your organization that will be lost during an event, or may be related to the general cost to deal with the poorly behaving Service. KPIs: Mean time to detect (MTTD) Mean time to identify (MTTI) Mean time to resolve (MTTR) Outcomes: Decreased time to detect incidents Decreased time to resolve incidents",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.224304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Service characterization <em>use</em> <em>case</em> <em>implementation</em> <em>guide</em>",
        "sections": "Service characterization <em>use</em> <em>case</em> <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " acquisition that can be fine tuned to close gaps when monitoring the function of a software system. This <em>use</em> <em>case</em> assumes that your <em>Observability</em> Program has completed the Quality Foundation OMA <em>use</em> <em>case</em> <em>implementation</em> <em>guide</em> and that you have a well considered and deployed telemetry collection"
      },
      "id": "6147550428ccbc5d2156a821"
    },
    {
      "sections": [
        "Alert quality management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Incident volume",
        "Incident count KPI",
        "Accumulated incident duration KPI",
        "Mean time to close (MTTC) KPI",
        "Percent under 5 minutes KPI",
        "User engagement",
        "Percentage Acknowledged KPI",
        "Mean time to investigate (MTTI) KPI",
        "Prerequisites",
        "Establish current state",
        "Install and configure the incident event webhook",
        "Install the AQM dashboard",
        "Perform initial AQM orientation and enablement",
        "Accumulate AQM data",
        "Perform second enablement session",
        "Improvement process",
        "Value realization",
        "KPI reference",
        "Incident engagement",
        "Additional resources"
      ],
      "title": "Alert quality management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Alert quality management",
        "Implementation guide"
      ],
      "external_id": "b69abb6b9b6c1257482958e12952dc189aecec2a",
      "image": "https://docs.newrelic.com/static/2be50db00a885e2d8ada51aa391f60d1/748b0/nrAQMIncidentFlow.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide/",
      "published_at": "2021-12-31T00:27:48Z",
      "updated_at": "2021-11-25T05:13:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Teams suffer from alert fatigue when they experience high alert volumes and alerts that are not aligned to business impact. As they start to believe that most alerts are false, they may prioritize easy to resolve alerts over others.  Also, they may close unresolved incidents so they can stay within their SLA targets. The result will be slower incident responses, magnified issue scope, and increased severity when true business impacting issues occur. Alert Quality Management (AQM) focuses on reducing the number of nuisance incidents so that you focus only on alerts with true business impact.  This reduces alert fatigue and ensures that you and your team focus your attention on the right places at the right times. You are a good candidate for AQM if: You have too many alerts. You have alerts that stay open for long time periods. Your alerts are not relevant. Your customers discover your issues before your monitoring tools do. You can't see the value of your observability tool(s). Desired outcome An alert strategy based on measuring business impact will result in faster response times and greater proactive awareness of critical events.  An improved alert signal to noise ratio reduces confusion and improves rapid identification and problem isolation. AQM's overall goal is to ensure that fewer, more valuable, incidents are created, resulting in: Increased uptime and availability Reduced MTTR Decreased alert volume The ability to easily identify alerts that are not valuable, so you can either make them valuable or remove them. The AQM process described in this guide generates the key performance indicators and metrics that you will use to measure progress towards these goals.  The metrics are measured in real time, published in a dashboard, and are used to drive a continuous improvement process that identifies and reduces nuisance alerts and increases user engagement in incident investigation. AQM does not encompass anomaly detection or AIOps, which are designed to detect unknown or unexpected modes of failure.  The two practices (AQM and ML/AI) work hand in hand, they are not mutually exclusive. Key performance indicators You will use the AQM process to collect and measure the following KPIs: Incident volume Incident Count Accumulated incident time Mean Time to Close (MTTC) Percent Under 5 Minutes User Engagement Mean Time to Investigate  (MTTI) % of Incidents Investigated These KPIs will help you to find the noisiest and least valuable alerts so you can improve their value or eliminate them.  You will then use the long term metric trends to show real business impact to management and stakeholders.  Detailed information on each metric follows. Incident volume You should treat incidents (with or without alerts) like a queue of tasks.  Just like a queue, the number of alerts should spend time near zero. Each incident should be a trigger for action to resolve the condition.  If an alert does not result in action, then you should question the value of the alert condition. If you see a constant rate of incidents or specific incidents that are \"always-on\", then you should question why. Are you in a constant state of business impact, or do you simply have a large volume of noise? The alert volume KPIs help you to answer those questions and to measure progress towards a healthy state of high quality alerting. Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the number of low value / nuisance incidents. Best practices: Ensure condition settings are intended to detect real business impact. Ensure condition settings are detecting abnormal behavior. Communicate that the incident details \"Acknowledge\" feature helps measure meaningful and actionable alerts. See Percentage Incident Acknowledge KPI. Report AQM KPIs to all stakeholders. Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the total accumulated minutes of incidents. Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Eliminate alerts that do not result in any remediation actions from the recipients. Improve percent investigated and mean-time-to-investigate KPIs by communicating their importance in improving detection and response times. Report AQM KPIs to all Stakeholders. Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. Goal: Reduce MTTC Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Improve Reliability Engineering skills. Report AQM KPIs to all stakeholders. Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. Goal: Minimize percentage of incidents with short durations Best practices: Ensure that conditions are detecting legitimate deviations from expected behavior. See Baselining and Service Level Management. Ensure that conditions are detecting legitimate deviations that correlate to business impact or impending business impact. User engagement You should measure the value of an incident by the amount of attention it receives.  Engagement in this context is measured by whether or not an incident has been acknowledged. The amount of engagement an individual alert receives is a direct measurement of its value.  More engagement implies a valuable alert, less (or zero) engagement implies a nuisance alert that should be modified or disabled. There is a significant difference between measuring the moment of incident awareness vs. acknowledging the moment resolution activity begins. If you are using an integration with New Relic Alerting, be sure that the \"acknowledge\" event that is sent to New Relic is triggered when resolution activity begins, not when the incident is sent to the external incident management tool.  For more information regarding the standard Incident Management process, see \"Incident Management Process: 5 Steps to Effective Resolution Posted on August 31, 2020 by OnPage Corporation. -- in reference to ITIL4\" Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. Goal: Increase the percentage of incident engagement. Best practices: Educate the DevOps team on when it is appropriate to acknowledge an incident alert. Gamify alert acknowledgement to drive usage. Discourage mass acknowledgement exercises. Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. Goal: Reduce the mean time to investigate Best practices: Work at building incident responder's confidence in alerts. Ensure that valuable alerts are acknowledged. Incentivize response teams to respond quickly to alerts. Prerequisites Before you begin, if you don't have equivalent experience, complete the New Relic University (NRU) Overview Course. Also, make sure you have a basic understanding of: NR1 Alert policy and conditions configuration NR1 incident notification channel webhook configuration NR1 NRQL NR1 alerting best practices NR1 APM & Infrastructure How to baseline data in order to determine anomalies vs. normal behavior. Establish current state As with any continuous improvement process, the first step of AQM is to establish the current state of your KPIs. To do so, perform the following tasks: Install and configure the incident event webhook Install the AQM Dashboard Perform initial AQM orientation and enablement Accumulate AQM data Perform second enablement session Install and configure the incident event webhook The webhook will create New Relic events for each incident as it proceeds through its lifecycle (open, acknowledge, close). To ensure that the AQM process generates accurate and valuable findings, this webhook must be added as a notification channel to every alert policy. The AQM process requires incident, not violation data. This is why you will not be using the default NrAiIncident event, which provides violation data only.  Instead, you will use this webhook to send the required incident data to New Relic. To use the webhook, do the following: Identify your primary production account and each of your accounts that you will be analyzing with the AQM process. Install the incident event webhook into each account that will participate in the AQM process and configure the webhook to report nrAQMIncident events to your primary production account. Assign the webhook as a notification channel to every alert policy in each account. This example shows a webhook notification channel assigned to each alert policy for a New Relic account with multiple sub-accounts. The webhook, AQM dashboard, and detailed installation instructions can be found in the New Relic OMA resource center on GitHub. Install the AQM dashboard The AQM dashboard is the primary asset that drives the AQM process.  You need to install the AQM dashboard into the primary production account you identified in the \"Install and configure incident event webhook\" step you previously performed by doing the following: Download the dashboard definition JSON file from the New Relic OMA resource center GitHub repo. Import the definition into your primary production account. For more details on importing dashboards, see the New Relic Introduction to dashboards documentation Perform initial AQM orientation and enablement During this phase, your incident management team(s) and other stakeholders will learn the goals of the AQM process and the scope of their involvement in it. The most critical portion of this task is educating your team on the importance of acknowledging incident alerts, since that's how the alert's value is determined.  In general, instruct them to follow these guidelines: If you look at an alert and decide to take any sort of further investigative action, acknowledge the alert. If you typically close an alert without doing anything else, do not acknowledge the alert. If the incident alert is always on, do not close or acknowledge it. For further details, see Second Enablement Session. You can use the first session template presentation to communicate this material to your stakeholders. Accumulate AQM data The overall process requires at least two weeks of data before it can proceed.  During this time, you should periodically check the following items: Confirm that incident alert event data is accumulating. Confirm that the webhook is attached to every alert policy. Ensure that incident responders are following the alert acknowledgement guidelines. Perform second enablement session During this phase, you will introduce incident management teams and other stakeholders to the initial AQM data and the ongoing continuous  improvement process you'll be following. The process consists of four activities: Review AQM Dashboard and KPI Trending: Here you and the stakeholders will look at the AQM KPIs and identify their week over week trends.  The team should identify areas where KPIs are not improving and develop strategies to drive improvement. Identify Achievements, Challenges, and Opportunities: Here you and the stakeholders will map the current state of alert quality to business impact, identifying areas where improvement has resulted in better business outcomes and areas where problems are impacting business outcomes. Incident Policy Review: Using the AQM dashboard, you and the stakeholders will identify the noisiest incident policies.  Once identified, those policies should be evaluated as detailed in step 4 below. Alert Policy Recommendations: In this step, you and the stakeholders will review the noisiest policies using the following criteria: Do the alerts have any business impact? Are the policies properly configured? Are they telling us something about the resource that needs to be fixed? Are the policies necessary? Do they have business impact? Are the thresholds set properly? Technical recommendations: Here, you and the stakeholders will review any technical recommendations, including: Are there application / system problems for engineering to review? Are there poorly constructed policies that need to be fixed? Are there instrumentation gaps? You can use the second session template presentation to keep this part of the AQM process organized. Improvement process This is the ongoing phase of the continuous improvement process where you periodically review your accumulated AQM data and make adjustments as needed to alert policies. You should perform this step once a week until your alert volume is acceptable. You can then perform it less frequently. During this phase you should: Report your KPIs each week to upper management to ensure that the stakeholder teams are appropriately prioritizing the work and to show that progress towards the promised business outcomes are being reached. Record and retain your weekly KPIs  over periods of months to years to establish a baseline and to show the rate of improvement. You should keep in mind that this is a continuous improvment process, you will continue to collect and evaluate the KPIs over long periods of time to ensure you are meeting your AQM goals. Value realization Once the AQM process is established, you will see significant reductions in the volume of alerts while reliability and stability remain the same or improve.  In addition, you should see that your alerts have a clear and unambiguous business impact.  Your AQM KPIs will provide quantifiable proof of these improvements. Once you are firmly on the path to AQM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering.  You can also move to other observability maturity value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform.  These KPIs are also included in the AQM dashboard that can be downloaded from the New Relic OMA resource center GitHub repo. Incident volume Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT count(*) AS 'Incident Count' WHERE current_state='open' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTC (minutes)' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. NRQL: FROM nrAQMIncident SELECT percentage(count(*), WHERE duration <= 5 * 60 * 100) AS '% Under 5min' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Incident engagement Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT filter(count(*), WHERE current_state='acknowledged')/filter(count(*), WHERE current_state='open')*100 AS '% Investigated' WHERE severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTI (minutes)' WHERE current_state='acknowledged' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Additional resources Want to get your hands dirty before you start implementing this in your account? Check out the alert quality management lab",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.22316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alert quality management <em>use</em> <em>case</em> <em>implementation</em> <em>guide</em>",
        "sections": "Alert quality management <em>use</em> <em>case</em> <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": ", such as Service Level Management, or Reliability Engineering.  You can also move to other <em>observability</em> <em>maturity</em> <em>value</em> streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform"
      },
      "id": "61372f5964441f181342436d"
    }
  ],
  "/docs/style-guide/writing-docs/article-templates/troubleshooting-docs-guide": [
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "13ab0e9d759903149944453fc4392998b6fab974",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/basic-doc-template/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T09:12:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.44516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic doc <em>template</em>",
        "sections": "Basic doc <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " <em>article</em>_url(category, <em>article</em>, options={}) url_for(options.reverse_merge( :controller =&gt; &#x27;articles&#x27;;, :action =&gt; &#x27;show&#x27;, :category =&gt; category, :<em>article</em> =&gt; <em>article</em> )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add"
      },
      "id": "61b3574c64441f1cc6aec5a4"
    },
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "827639827da156b6a36096c0f6a3911052706a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-12-31T00:56:32Z",
      "updated_at": "2021-11-26T09:09:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.44301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL API tutorial <em>template</em>",
        "sections": "GraphQL API tutorial <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61ab330c64441fd067927126"
    },
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "05c35d88b970eee521e2af4e255666e31b915468",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-12-31T00:56:31Z",
      "updated_at": "2021-11-26T07:01:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Check if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). We should avoid documenting most of these, with the idea that most customers will only care about the data because it's being reported for them, and won't care about the things that factor into the reasons why it wouldn't be reported. If it's thought that the addition would help customers who already have the data reporting understand the data better, you can include it. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use back ticks to indicate attributes or values (for example, a definition like: Reported when ` category ` is ` http ` ). Using this also sets us up for success if we implement styling in the UI definitions in the future. We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a 'See attribute in docs' link that links to the complete and normally formatted docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.34964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " to be accurate, and place it in the folder of the data type it&#x27;s attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage"
      },
      "id": "61ab4782e7b9d278d80e6e03"
    }
  ],
  "/docs/style-guide/writing-docs/docs-translation": [
    {
      "sections": [
        "Translation disclaimer"
      ],
      "title": "Translation disclaimer",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Translation"
      ],
      "external_id": "cb23af79521feaaa6193002aef89648a9973cf1d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/translated-documentation/translation-disclaimer/",
      "published_at": "2021-12-30T02:52:54Z",
      "updated_at": "2021-12-09T01:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The official version of the Documentation is in English. Portions of the New Relic Documentation may be translated for your convenience as shown on this site. Translated content may contain errors, discrepancies, or differences created in the translation, are not binding, and have no legal effect for enforcement or compliance purposes. New Relic does not make any warranty, express or implied, as to the accuracy, reliability, or correctness of any translated Documentation from the English original to any other language. Any guarantees or commitments in your Agreement with New Relic that the Services, products, or other offerings conform or are consistent with the Documentation do not apply to the extent to which the Documentation has been translated.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.16171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Translation</em> disclaimer",
        "sections": "<em>Translation</em> disclaimer",
        "tags": "<em>Translation</em>",
        "body": "The official version of the Documentation is in English. Portions of the New Relic Documentation may be translated for your convenience as shown on this site. Translated content may contain errors, discrepancies, or differences created in the <em>translation</em>, are not binding, and have no legal effect"
      },
      "id": "61b162bf196a672b190d46f7"
    },
    {
      "sections": [
        "Update the home page",
        "Update a link's URL",
        "Add a new tile to the home page",
        "Add a new section to the home page",
        "Edit the home page left nav"
      ],
      "title": "Update the home page",
      "type": "docs",
      "tags": [
        "home page",
        "landing pages"
      ],
      "external_id": "1d084fae5223f5b34cec91fcae0bcb35560c7b29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/edit-homepage/",
      "published_at": "2021-12-31T00:59:26Z",
      "updated_at": "2021-12-04T10:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can't just hit the edit button docs.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It's rare that you'll need to make changes to this file. Most home page changes will be to add a new tile or section to the page, or update links. These types of changes are handled in two files: src/data/homepage.yml - contains home page section titles, section descriptions, and the URLs for tiles. src/i18n/translations/en/translation.json - contains tile info, including the title and short description of tiles. Update a link's URL Change or add new links using homepage.yml. In homepage.yml, search for the link you want to change. Edit the URL, save, commit, and PR the change. Add a new tile to the home page You'll make changes to both homepage.yml and translations.json On the translations.json doc, find the spot where you want to add the new tile (which section, and in what order you want it to appear), and add a new entry with this format: \"t#\": { \"title\": \"tile name\", \"description\": \"Short description.\" }, Copy Make sure you update the number on the tile. If you want to insert it in the middle of a group, update all the subsequent tile numbers as well. Save the file. Open homepage.yml, find the spot where the new tile will be, and add a new line with the relative link for the new tile. For example, - /docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster Save and check that your new tile builds properly on a local build. Commit, push, PR when you're ready. Add a new section to the home page On the translations.json page, add a new section modeled in the spot where you want the new section to appear. Include at least one title. For example, here's the TDP entry, with one tile: \"errors-inbox\": { \"title\": \"Errors Inbox\", \"description\": \"A single place to proactively detect, triage, and take action on all the errors before they impact customers.\", \"t1\": { \"title\": \"Introduction to Errors Inbox\", \"description\": \"How to manage all your monitoring in one place.\" }, Copy When you're done creating the info, save the file. In the homepage.yml page, find the corresponding location for the new section, and add the short name you provided in the translation.json file, title, description, and tile URLs. For example, here's the corresponding TDP section on homepage.yml. errors-inbox: title: Errors Inbox description: A single place to proactively detect, triage, and take action on all the errors before they impact customers. tiles: - /docs/errors-inbox/errors-inbox Copy Save, build locally, commit, PR. Edit the home page left nav The left nav of the home page is controlled by src/nav/root.yml. This is a basic yml file, similar to our taxonomy files. Each link on the left nav needs a title and a path: - title: Welcome to New Relic path: /docs/using-new-relic - title: New Relic One path: /docs/new-relic-one/use-new-relic-one - title: Guides and best practices path: /docs/new-relic-solutions - title: section-break - title: Alerts and Applied Intelligence path: /docs/alerts-applied-intelligence Copy You can add a new link by following the pattern above or delete a link by removing the corresponding title and path. Section breaks are added by including a - title: section-break line. The left nav reflects the exact order of root.yml, so it's easy to organize it as needed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 61.94414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "You can&#x27;t just hit the edit button <em>docs</em>.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It&#x27;s rare that you&#x27;ll need to make changes to this file. Most home page changes will be to add a new tile"
      },
      "id": "61ab480264441f9ef0927fb8"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-12-30T21:42:49Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 54.98186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Translation</em> from PromQL-style queries",
        "body": ", or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy <em>Translation</em> from PromQL-style queries When applicable"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/style-guide/writing-docs/processes-procedures/create-edit-content": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-strategies/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide"
      ],
      "published_at": "2021-12-30T08:10:30Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-11-24T09:23:43Z",
      "type": "docs",
      "external_id": "56adaf70b517da62915ac6a2a56ff50c6effb7a9",
      "document_type": "page",
      "popularity": 1,
      "body": "Welcome to New Relic's style guide. We've written these guidelines for content creators across New Relic, and for contributors to our open source content projects, like the Docs! This guide also gives you some insight into how we think about good technical writing. We focus on style and usage that's particular to New Relic. We follow American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Find the information you need: For our writing strategy, see docs in this section on voice, five questions for great content, how to organize your content, and more. For a quick reference for terms usage, see our Usage dictionary. For how to write and edit pages on docs.newrelic.com, see Create and edit content.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 883.0302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ": For our writing strategy, see docs in this section on voice, five questions for great <em>content</em>, how to organize your <em>content</em>, and more. For a quick reference for terms usage, see our Usage dictionary. For how to write and <em>edit</em> pages on docs.newrelic.com, see <em>Create</em> and <em>edit</em> <em>content</em>."
      },
      "id": "619e049fe7b9d2f6effe7e25"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-strategies/organize-doc/",
      "sections": [
        "Organize your page",
        "Organize your page to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-12-30T08:10:30Z",
      "title": "Organize your page",
      "updated_at": "2021-11-24T07:56:48Z",
      "type": "docs",
      "external_id": "a3e3c993c0bf65626e805676496bcae8ea8d2c64",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some organization basics. Organize your page to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 562.2082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> <em>and</em> <em>edit</em> categories",
        "body": " of docs at once, please <em>create</em> an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see <em>Create</em> and <em>edit</em> <em>content</em>. To learn how to <em>create</em> and publish release notes, see <em>Create</em> release notes. To make it even easier to start a new doc, use templates."
      },
      "id": "619df04028ccbc2730b9a00a"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-30T20:48:40Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.031006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Add custom <em>content</em> using the markdown <em>editor</em>",
        "tags": "Explore <em>and</em> query data",
        "body": ". <em>Create</em> new <em>content</em> by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/style-guide/writing-docs/processes-procedures/create-release-notes": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-strategies/organize-doc/",
      "sections": [
        "Organize your page",
        "Organize your page to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-12-30T08:10:30Z",
      "title": "Organize your page",
      "updated_at": "2021-11-24T07:56:48Z",
      "type": "docs",
      "external_id": "a3e3c993c0bf65626e805676496bcae8ea8d2c64",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some organization basics. Organize your page to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 539.36896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> and edit categories",
        "body": " of docs at once, please <em>create</em> an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see <em>Create</em> and edit content. To learn how to <em>create</em> and publish <em>release</em> <em>notes</em>, see <em>Create</em> <em>release</em> <em>notes</em>. To make it even easier to start a new doc, use templates."
      },
      "id": "619df04028ccbc2730b9a00a"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "606039ea3f3b44fdecc1bd2d03fd61d77c594db8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-12-31T01:00:15Z",
      "updated_at": "2021-11-26T05:15:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Through some technical wizardry, they generate Related resources links in the right nav area. Start each topic with a - on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 514.9145,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " list views. For more information, see Working with landing pages. <em>Release</em> <em>notes</em> This format includes specific fields for <em>release</em> <em>notes</em>. Users rely on <em>release</em> <em>notes</em> to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see <em>Create</em>"
      },
      "id": "61b35517196a677196a59e07"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-31T00:50:54Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 88.013916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related <em>release</em> <em>notes</em> Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin"
      },
      "id": "6045248b196a67f158960f1b"
    }
  ],
  "/docs/style-guide/writing-docs/processes-procedures/delete-document": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "606039ea3f3b44fdecc1bd2d03fd61d77c594db8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-12-31T01:00:15Z",
      "updated_at": "2021-11-26T05:15:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Through some technical wizardry, they generate Related resources links in the right nav area. Start each topic with a - on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.35056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " release notes. What&#x27;s New posts This format includes specific fields for product announcements. What&#x27;s New posts are created by PMM for larger announcements. They&#x27;re available in the docs site, but they&#x27;re also visible in the New Relic One UI. For more information, see What&#x27;s New <em>style</em> guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs <em>guide</em>."
      },
      "id": "61b35517196a677196a59e07"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "835ddacc0acae04e05c8c2ddc694799819a7d696",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-12-31T00:59:27Z",
      "updated_at": "2021-11-26T05:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. <em>Procedures</em> are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change"
      },
      "id": "61b35af428ccbca9318c6b13"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "9ec2ccd8a8509ab1b54273206e84f9571164c4f9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-12-31T00:59:27Z",
      "updated_at": "2021-11-26T05:13:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or docs site contributor"
      },
      "id": "61b35af4e7b9d2769c5a38f9"
    }
  ],
  "/docs/style-guide/writing-docs/processes-procedures/docs-site-edit-checklist": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "606039ea3f3b44fdecc1bd2d03fd61d77c594db8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-12-31T01:00:15Z",
      "updated_at": "2021-11-26T05:15:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Through some technical wizardry, they generate Related resources links in the right nav area. Start each topic with a - on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.35056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " release notes. What&#x27;s New posts This format includes specific fields for product announcements. What&#x27;s New posts are created by PMM for larger announcements. They&#x27;re available in the docs site, but they&#x27;re also visible in the New Relic One UI. For more information, see What&#x27;s New <em>style</em> guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs <em>guide</em>."
      },
      "id": "61b35517196a677196a59e07"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "835ddacc0acae04e05c8c2ddc694799819a7d696",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-12-31T00:59:27Z",
      "updated_at": "2021-11-26T05:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. <em>Procedures</em> are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change"
      },
      "id": "61b35af428ccbca9318c6b13"
    },
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "2cd80eef8b60c58847511bbd58fd38abdac22d75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/delete-document/",
      "published_at": "2021-12-31T00:58:43Z",
      "updated_at": "2021-11-26T05:12:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.3482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61ab47d9196a679242d10141"
    }
  ],
  "/docs/style-guide/writing-docs/processes-procedures/edit-homepage": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "606039ea3f3b44fdecc1bd2d03fd61d77c594db8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-12-31T01:00:15Z",
      "updated_at": "2021-11-26T05:15:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Through some technical wizardry, they generate Related resources links in the right nav area. Start each topic with a - on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.82973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Page</em> templates",
        "body": " is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. <em>Landing</em> <em>pages</em> This format is for a more user-friendly and readable <em>landing</em> <em>page</em>, which replaces the standard taxonomy"
      },
      "id": "61b35517196a677196a59e07"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/landing-page-template/",
      "sections": [
        "Landing page template",
        "Important",
        "Front matter",
        "Tip",
        "Introduction section",
        "Tiles",
        "Button for viewing all docs in the category",
        "Code sample"
      ],
      "published_at": "2021-12-31T00:57:14Z",
      "title": "Landing page template",
      "updated_at": "2021-11-26T05:11:08Z",
      "type": "docs",
      "external_id": "7f97d929091de18beb47bff4f6dff62e9676bbb5",
      "document_type": "page",
      "popularity": 1,
      "body": "Landing pages are a specialized type of page that serve as the starting pages for various New Relic products. For example, you'll see landing pages for Application monitoring (APM) and Browser monitoring. Important This landing page information does not apply to the docs home page. If you need to create a new landing page, you can either copy an existing landing page, or you can modify the sample landing page shown at the bottom. The next sections look at what you need to include for each landing page. Front matter When you insert the front matter, be sure to designate the type as landingPage. Here's an example: --- title: APM type: landingPage --- Copy Tip In the front matter, the following are optional: tags, translate, and redirects. So, you can leave them out if they don't have any values. Introduction section Following the front matter, the first content section is a two-column introduction (also called the hero section). This includes the following: A <LandingPageHero> component wrapping all the introductory content. A <HeroContent> component wrapping the text portion of the introduction (the content in the left column). An image or video (appears in the right column). A caption (optional), which is wrapped by the <figcaption> component. Here's an example of the hero section that shows you where to insert your content: <LandingPageHero> <HeroContent> INSERT_PARAGRAPHS_FOR_YOUR_INTRODUCTION </HeroContent> ![INSERT_ALT-TEXT_HERE](./images/INSERT_IMAGE_FILE_NAME.png \"INSERT_THE_IMAGE_TITLE_HERE\") <figcaption> INSERT_OPTIONAL_CAPTION_USING_SAME_INDENTATION_AS_IMAGE </figcaption> </LandingPageHero> Copy Tiles Tiles are a series of boxes after the introduction. They contain the main subject areas for your product. You should just list these in order you want them to appear, and the cascading style sheet will render them across the page. Here's an example of a tile: <LandingPageTileGrid> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE.\" href=\"/docs/INSERT_THE_DIRECTORY_PATH_TO_THE_TARGET_LANDING_PAGE_INDEX.HTML\" icon=\"fe-INSERT_THE_ICON_NAME\" > INSERT_TILE_CONTENT_HERE... </LandingPageTile> ... Copy For each tile, do the following: Insert a value for title that explains the purpose of the category. Insert a value for href that links to the target landing page. If the target landing page is index.html, you can just include the directory path with no filename since index.html is the default (it doesn't cause any problems if you include index.html). Insert a value for icon by prefixing the icon name with fe- (Feather icons), logo- (third-party logos), or nr- (New Relic logos). For example, here is the format for a feather icon: fe-alert-triangle). Tip For more details about icons, see Embed images. Between the LandingPageTile tags, insert text, such as a bullet list with links to product documentation. Button for viewing all docs in the category After your tiles, you should have a single button that offers to take users to all the documentation for that category. The table of contents page that gets linked here is always at the same path as the landing page, but with /table-of-contents appended to it. These table of contents pages get built automatically for every landing page. For example, if this landing page was located at /docs/apm, this link should be /docs/apm/table-of-contents. Here's an example: <ButtonLink role=\"button\" to=\"INSERT_LINK_TO_DIRECTORY_WITH_ALL_THESE_DOCS/table-of-contents\" variant=\"normal\" > View all INSERT_YOUR_CATEGORY_HERE docs </ButtonLink> Copy Code sample Here's a sample landing page you could modify to suit your needs: --- title: INSERT_YOUR_TITLE_HERE type: landingPage --- <LandingPageHero> <HeroContent> INSERT_PARAGRAPHS_FOR_YOUR_INTRODUCTION </HeroContent> ![INSERT_ALT-TEXT_HERE](./images/INSERT_IMAGE_FILE_NAME.png \"INSERT_THE_IMAGE_TITLE_HERE\") <figcaption> INSERT_OPTIONAL_CAPTION_USING_SAME_INDENTATION_AS_IMAGE </figcaption> </LandingPageHero> <LandingPageTileGrid> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * [INSERT_LINK_NAME](INSERT_LINK_URL) Aliquam auctor mattis nisl ut iaculis. * [INSERT_LINK_NAME](INSERT_LINK_URL) Suspendisse pharetra elit sit amet risus euismod, a consectetur tortor vulputate. </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) to lectus diam, ornare vitae dui suscipit, laoreet ultrices lacus. * Mauris tempor massa ac augue mattis, nec pharetra quam mollis [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) rhoncus tortor vitae libero laoreet feugiat. * Donec dui elit, fermentum vel faucibus sed, rhoncus in felis [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) uspendisse pharetra elit sit amet risus euismod. * Pellentesque finibus magna vitae hendrerit gravida [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) Etiam imperdiet felis eu ipsum consequat tristique. * Etiam imperdiet felis eu ipsum consequat tristique [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) Quisque hendrerit, dolor sed sodales aliquet. * Vestibulum varius lectus ac velit euismod [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> </LandingPageTileGrid> <ButtonLink role=\"button\" to=\"INSERT_LINK_TO_DIRECTORY_WITH_ALL_THESE_DOCS/table-of-contents\" variant=\"normal\" > View all INSERT_YOUR_CATEGORY_HERE docs </ButtonLink> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.698006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Landing</em> <em>page</em> template",
        "sections": "<em>Landing</em> <em>page</em> template",
        "body": "<em>Landing</em> <em>pages</em> are a specialized type of <em>page</em> that serve as the starting <em>pages</em> for various New Relic products. For example, you&#x27;ll see <em>landing</em> <em>pages</em> for Application monitoring (APM) and Browser monitoring. Important This <em>landing</em> <em>page</em> information does not apply to the docs <em>home</em> <em>page</em>. If you need"
      },
      "id": "61ab487d28ccbcd127c24e10"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/create-release-notes/",
      "sections": [
        "Create release notes",
        "New release note",
        "What makes a great release note?",
        "New release notes category",
        "Category landing page",
        "Landing page",
        "Links from other categories"
      ],
      "published_at": "2021-12-31T00:58:43Z",
      "title": "Create release notes",
      "updated_at": "2021-11-26T05:11:39Z",
      "type": "docs",
      "external_id": "ed8f28b2ba2020f4e61fd1499c5bc9c97472857b",
      "document_type": "page",
      "popularity": 1,
      "body": "This page is for release notes for downloadable software. For product announcements, see What's new style guidelines. New release note To add a release note to the docs site: Find the most recent release note for your agent, and make a copy of it in the same folder. When you rename your copy, avoid potential version naming conflicts by using a - separator in your file name. For example, instead of agent-123, use agent-1-2-3 for version 1.2.3 and agent-12-3 for version 12.3. Fill in the subject, releaseDate, and version. If applicable, include the downloadLink field. Using our standard headings for New features, Improvements, and Bug fixes, add enough summary information in these sections to make a great release note. Link to docs or other resources where they can learn more. Commit your changes and submit a pull request. If your release is date-sensitive, make a note in your PR. A Tech Docs hero will review your release note content and approve your PR to get it published. You can also request others on your team to review your PR. We build and deploy the docs site a few times a day, and sometimes builds can take a few hours to complete. If your release is time-sensitive, ensure you've planned for enough time to get your docs live. What makes a great release note? Great release notes help users quickly become familiar with your important update, so they know why it matters. Great release notes also help our support and security teams. By encouraging users to keep current with your latest release, this reduces support time to solve problems on outdated versions. It also mitigates risks if any potential vulnerabilities have been resolved with your latest version. To write a great release note, be as specific as possible. For example: Briefly describe new functionality. Give an example of the value it provides, and link to more detailed information. Don't use vague wording such as \"various bug fixes.\" Instead, clearly state what has been improved, so readers will know if an issue they’ve experienced has been resolved. New release notes category This information is primarily for the Tech Docs team's use. To add a new release notes category, update the following areas of the docs site. (You do not need to update the releaseNote.js or releaseNoteLandingPage.js files in the nav/templates folder.) Before you submit your pull request to the GitHub docs site, check that the landing pages and placeholder release note build correctly in your localhost. Category landing page In /src/content/docs/release-notes, add the following: A folder for your new release notes category. The RSS feed link, page format, and date order for release notes listed on this page are generated automatically. For example, see the C SDK category landing page format. An index.mdx file in your new folder containing the subject. The subject is the name that will appear on the Release notes landing page. A placeholder release note in this folder for the agent team to fill out. If used, the downloadLink field in the release note will be formatted automatically in the published release note. Before the new category goes live, check with the team's Product Marketing Management (PMM) rep whether they want to include the link in an upcoming What's new post. Landing page In /src/content/docs/release-notes/index.mdx, add a new tile section in alphabetical order for your release notes category. Example: <TechTile name=\"Logs\" icon=\"logo-newrelic\" to=\"/docs/release-notes/logs-release-notes\" /> Copy Logos come from @newrelic/gatsby-theme-newrelic/icons/logo/. If a logo does not already exist for the new agent, use the standard logo-newrelic icon or an image in @newrelic/gatsby-theme-newrelic/icons/feathers.js. If you need other options, talk to the team's designer. Links from other categories Add a link to your new release notes category in the agent's documentation, typically in its Get started category. For more information, see our documentation about docs in multiple menus. Optional: Add a link in the agent's landing page text by updating the index.mdx file in its taxonomy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 53.463577,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Category <em>landing</em> <em>page</em>",
        "body": " that the <em>landing</em> <em>pages</em> and placeholder release note build correctly in your localhost. Category <em>landing</em> <em>page</em> In &#x2F;src&#x2F;content&#x2F;docs&#x2F;release-notes, add the following: A folder for your new release notes category. The RSS feed link, <em>page</em> format, and date order for release notes listed on this <em>page</em>"
      },
      "id": "61ab4941e7b9d25eae0e8af0"
    }
  ],
  "/docs/style-guide/writing-docs/processes-procedures/rename-or-redirect-document": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "606039ea3f3b44fdecc1bd2d03fd61d77c594db8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-12-31T01:00:15Z",
      "updated_at": "2021-11-26T05:15:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Through some technical wizardry, they generate Related resources links in the right nav area. Start each topic with a - on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.35054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " release notes. What&#x27;s New posts This format includes specific fields for product announcements. What&#x27;s New posts are created by PMM for larger announcements. They&#x27;re available in the docs site, but they&#x27;re also visible in the New Relic One UI. For more information, see What&#x27;s New <em>style</em> guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs <em>guide</em>."
      },
      "id": "61b35517196a677196a59e07"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "9ec2ccd8a8509ab1b54273206e84f9571164c4f9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-12-31T00:59:27Z",
      "updated_at": "2021-11-26T05:13:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.3486,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or docs site contributor"
      },
      "id": "61b35af4e7b9d2769c5a38f9"
    },
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "2cd80eef8b60c58847511bbd58fd38abdac22d75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/delete-document/",
      "published_at": "2021-12-31T00:58:43Z",
      "updated_at": "2021-11-26T05:12:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.3482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61ab47d9196a679242d10141"
    }
  ],
  "/docs/style-guide/writing-docs/processes-procedures/understand-edit-docs-site-structure": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "606039ea3f3b44fdecc1bd2d03fd61d77c594db8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-12-31T01:00:15Z",
      "updated_at": "2021-11-26T05:15:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Through some technical wizardry, they generate Related resources links in the right nav area. Start each topic with a - on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.74857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "<em>Docs</em> meta content (frontmatter)",
        "tags": "Processes <em>and</em> procedures",
        "body": " not capitalize any other word in the title unless it&#x27;s a proper noun, such as a specific product name, or it follows a colon (:). If you&#x27;re looking for ideas on how to choose a title, browse the titles of similar <em>docs</em>. The title used in the <em>sidebar</em> (left navigation pane) is set in the <em>nav</em> <em>file</em>. type"
      },
      "id": "61b35517196a677196a59e07"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "835ddacc0acae04e05c8c2ddc694799819a7d696",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-12-31T00:59:27Z",
      "updated_at": "2021-11-26T05:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.26749,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rename or redirect a <em>document</em>",
        "sections": "Rename or redirect a <em>document</em>",
        "tags": "Processes <em>and</em> procedures",
        "body": " a document title, change the title being used in the title field in the frontmatter at the top of the <em>doc</em>. If you want to update a title in the <em>sidebar</em>, change the title for that <em>doc</em> in the <em>nav</em> <em>file</em>. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser"
      },
      "id": "61b35af428ccbca9318c6b13"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/writer-workflow/github-history/",
      "sections": [
        "GitHub history and deleted files",
        "Check the edit history of a doc or file",
        "Docs site history before October 2021",
        "How to find deleted files",
        "Finding the deletion PR",
        "Search through release PRs",
        "Use git log"
      ],
      "published_at": "2021-12-31T01:00:58Z",
      "title": "GitHub history and deleted files",
      "updated_at": "2021-12-19T04:32:24Z",
      "type": "docs",
      "external_id": "d9eb61c221f5fec6251786c5a927f6326b399963",
      "document_type": "page",
      "popularity": 1,
      "body": "GitHub's version control features allow us to see the complete history of a doc, access a doc at any point in time, and find deleted docs without manual backups. Check the edit history of a doc or file Use any of these options to check or \"diff\" the history of a file. Option 1: GitHub history tab Navigate to the doc on the doc site and click Edit page in the right nav. Click History in the top right corner of the doc. Option 2: githistory.xy Navigate to your specific file on GitHub.com: https://github.com/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx Copy In the url, replace github.com with github.githistory.xyz: https://github.githistory.xyz/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx Copy It will take you to a site which presents the visual history of that specific file. You can view changes by clicking through the commit history at the top of your page. Option 3: Git blame Follow GitHub's documentation. Alternatively, you can use the following command in your terminal: git log --follow \"**/file_name_here.mdx\" Copy This will output the commit history of that file. By default, it only shows the first few commits. You can scroll by pressing Return multiple times. For example, to find the commit history for vmware-vsphere-monitoring-integration.mdx, I would run: git log --follow \"**/vmware-vsphere-monitoring-integration.mdx\" Copy Docs site history before October 2021 We had a large site restructure in October 2021 which lost most of the file history for our docs. You can find an archived version of our site pre-rework in the pre-IA-2021 branch. By navigating the pre-rework version of our repo, you can find file history and more. How to find deleted files There are multiple ways to find deleted files. These are roughly ordered by complexity: Finding the deletion PR The easiest way to find a deleted file is to find the pull request that deleted it. There are multiple ways to accomplish this; here are some ideas: Use GitHub's search feature to search for relevant keywords. You can filter search results to only include PRs. If you have a rough idea of when the doc was deleted, you could try finding the pull request in the pull request tab. This list has thousands of PRs, so this may take some time. Lots of docs are deleted because of a Jira ticket. Search Jira for the ticket, where you will find the rough time the doc was deleted and hopefully a link to the PR itself. Ask in #doc_talk! Search through release PRs By searching through release PRs, you can eventually find a branch created before the doc was deleted. You can find a list of release PRs in the GitHub PR tab. A few tips: Search by intervals of a month first. Once you find a branch that contains the doc, you can scope down to a week and then to a day. By decreasing the scope, you will eventually find the deleted doc in it's exact state before deletion. To access the branch a PR comes from, go to that pull request's page and click on the branch name underneath the title and PR number. Use git log The most powerful and realiable way to find deleted files is to use git log. See stackoverflow for more details.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.53825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GitHub history <em>and</em> deleted <em>files</em>",
        "sections": "Check the <em>edit</em> history of a <em>doc</em> or <em>file</em>",
        "body": " Navigate to the <em>doc</em> on the <em>doc</em> <em>site</em> and click <em>Edit</em> page in the right <em>nav</em>. Click History in the top right corner of the <em>doc</em>. Option 2: githistory.xy Navigate to your specific <em>file</em> on GitHub.com: https:&#x2F;&#x2F;github.com&#x2F;newrelic&#x2F;<em>docs</em>-website&#x2F;blob&#x2F;develop&#x2F;src&#x2F;content&#x2F;<em>docs</em>&#x2F;browser&#x2F;new-relic-browser&#x2F;browser"
      },
      "id": "61beb5d864441f378699fc79"
    }
  ],
  "/docs/style-guide/writing-docs/processes-procedures/use-content-types-text-formats": [
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "835ddacc0acae04e05c8c2ddc694799819a7d696",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-12-31T00:59:27Z",
      "updated_at": "2021-11-26T05:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. <em>Procedures</em> are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change"
      },
      "id": "61b35af428ccbca9318c6b13"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "9ec2ccd8a8509ab1b54273206e84f9571164c4f9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-12-31T00:59:27Z",
      "updated_at": "2021-11-26T05:13:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34859,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or docs site contributor"
      },
      "id": "61b35af4e7b9d2769c5a38f9"
    },
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "2cd80eef8b60c58847511bbd58fd38abdac22d75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/delete-document/",
      "published_at": "2021-12-31T00:58:43Z",
      "updated_at": "2021-11-26T05:12:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "61ab47d9196a679242d10141"
    }
  ],
  "/docs/style-guide/writing-docs/writer-workflow/github-history": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "2cd80eef8b60c58847511bbd58fd38abdac22d75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/delete-document/",
      "published_at": "2021-12-31T00:58:43Z",
      "updated_at": "2021-11-26T05:12:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.81029,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Delete</em> a document",
        "sections": "<em>Delete</em> a document",
        "tags": "Processes <em>and</em> procedures",
        "body": "Caution When you delete a document, its content and its redirects will still be available in the <em>GitHub</em> commit <em>history</em>. In general, if you&#x27;re not on the New Relic Docs team, please don&#x27;t delete any docs. Instead, <em>file</em> an issue and someone on our team will help you out. If you are certain you want"
      },
      "id": "61ab47d9196a679242d10141"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge releases into main work (or, when do we publish?)",
        "GitHub labels"
      ],
      "published_at": "2021-12-31T01:00:58Z",
      "title": "Get around GitHub",
      "updated_at": "2021-12-20T04:59:44Z",
      "type": "docs",
      "external_id": "539ae5620ae9be8f8c3752fd3eda664186fbb5c4",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of the New Relic organization. If they aren't, try to find them on Slack based on their username. If you're not sure about someone's affiliation, treat them as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review and label issues and PRs in this column, then drag them to the appropriate column. If a PR or issue is labeled eng, the Hero/Sidekick can go ahead and click its ellipses icon to archive it. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress and not necessarily ready to merge immediately. You can't merge a Draft PR directly. Instead, you must move it out of draft status first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft, and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero, make sure you attend to the following throughout your day: Check in with the previous Hero at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN Hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jira tickets, but reference tickets by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge releases into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM (morning), 12 PM (noon), and 3 PM (evening) Pacific. We merge release branches into main to avoid interuptions when someone merges into develop during a release. To learn more about this workflow, see the gitflow documentation in Atlassian. To start a release: Create a branch based off develop Github Desktop by clicking Current Branch in the top header, clicking New Branch in the dropdown, and then selecting Develop. Name the branch following this pattern: daily-release/mm-dd-yy-morning/noon/evening. Here's an example: daily-release/10-27-21-morning. Push your changes by clicking Push Origin in GitHub Desktop. Create a pull request into main from your new daily release branch by clicking Create Pull Request. This will open a pull request screen on github.com. Pull requests default to merging into develop, so select main as the base branch in the left side of the page and then click Submit Pull Request. Wait until all the checks complete, and then merge the pull request. All branches that follow the daily-release/mm-dd-yy-morning pattern are protected branches. This means the branches can't be deleted or pushed to by non-admins. GitHub labels Every issue needs labels to help us triage and track the health of our backlog: content: Always add, this indicates the issue is content-related rather than a design or engineering issue. pg_*: Always add to indicate the product group. For full definitions, see the \"Doc Jira and GitHub fields\" doc in the internal team Google Drive. Indicate who created the issue: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optionally: docs-issues-migrate: Issues that are too large in scope for the docs team to handle without product team expertise. This label alerts the docs issues team to migrate these issues into the customer feedback channel where they will be triaged and sent to product teams. Jira’d: Issues that have a corresponding Jira ticket. Make sure you leave the Jira number in the comments of the issue (for example, DOC-1234). Every pull request needs these labels so we can see where our contributions come from: content: Always add, this indicates the PR is content-related rather than design or engineering. Indicate who created the pull request: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get around <em>GitHub</em>",
        "sections": "Deal with references in <em>GitHub</em> (<em>and</em> the style guide)",
        "body": " be <em>deleted</em> or pushed to by non-admins. <em>GitHub</em> labels Every issue needs labels to help us triage and track the health of our backlog: content: Always add, this indicates the issue is content-related rather than a design or engineering issue. pg_*: Always add to indicate the product group. For full"
      },
      "id": "61ab4782196a672667d0efa1"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline",
        "Outcomes"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2021-12-31T13:47:32Z",
      "updated_at": "2021-12-30T03:15:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset. Outcomes Here is a sample dashboard you could create to track your code pipeline. Track your code pipeline by creating dashboards in New Relic Insights. A dashboard like this yields a number of benefits, including: Faster deploy cycles. The ability to prioritize reliability work by identifying services with frequent deploy failures or gaps in test coverage. Ensuring teams don’t achieve speed at the expense of quality. Responding more effectively to change-related failures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.17404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " AWS CodePipeline to manage the flow of an application that is sourced in <em>GitHub</em>, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some &quot;glue code&quot; and event handlers needed to push data from <em>GitHub</em> and AWS to New Relic"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    }
  ],
  "/docs/style-guide/writing-docs/writer-workflow/github-intro": [
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline",
        "Outcomes"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2021-12-31T13:47:32Z",
      "updated_at": "2021-12-30T03:15:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset. Outcomes Here is a sample dashboard you could create to track your code pipeline. Track your code pipeline by creating dashboards in New Relic Insights. A dashboard like this yields a number of benefits, including: Faster deploy cycles. The ability to prioritize reliability work by identifying services with frequent deploy failures or gaps in test coverage. Ensuring teams don’t achieve speed at the expense of quality. Responding more effectively to change-related failures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.23148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " AWS CodePipeline to manage the flow of an application that is sourced in <em>GitHub</em>, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some &quot;glue code&quot; and event handlers needed to push data from <em>GitHub</em> and AWS to New Relic"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    },
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-30T03:11:17Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.7446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on <em>GitHub</em>. Use the language-specific <em>GitHub</em> links below to <em>get</em> library details, coding examples, and procedures for how to use"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/writer-workflow/github-history/",
      "sections": [
        "GitHub history and deleted files",
        "Check the edit history of a doc or file",
        "Docs site history before October 2021",
        "How to find deleted files",
        "Finding the deletion PR",
        "Search through release PRs",
        "Use git log"
      ],
      "published_at": "2021-12-31T01:00:58Z",
      "title": "GitHub history and deleted files",
      "updated_at": "2021-12-19T04:32:24Z",
      "type": "docs",
      "external_id": "d9eb61c221f5fec6251786c5a927f6326b399963",
      "document_type": "page",
      "popularity": 1,
      "body": "GitHub's version control features allow us to see the complete history of a doc, access a doc at any point in time, and find deleted docs without manual backups. Check the edit history of a doc or file Use any of these options to check or \"diff\" the history of a file. Option 1: GitHub history tab Navigate to the doc on the doc site and click Edit page in the right nav. Click History in the top right corner of the doc. Option 2: githistory.xy Navigate to your specific file on GitHub.com: https://github.com/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx Copy In the url, replace github.com with github.githistory.xyz: https://github.githistory.xyz/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx Copy It will take you to a site which presents the visual history of that specific file. You can view changes by clicking through the commit history at the top of your page. Option 3: Git blame Follow GitHub's documentation. Alternatively, you can use the following command in your terminal: git log --follow \"**/file_name_here.mdx\" Copy This will output the commit history of that file. By default, it only shows the first few commits. You can scroll by pressing Return multiple times. For example, to find the commit history for vmware-vsphere-monitoring-integration.mdx, I would run: git log --follow \"**/vmware-vsphere-monitoring-integration.mdx\" Copy Docs site history before October 2021 We had a large site restructure in October 2021 which lost most of the file history for our docs. You can find an archived version of our site pre-rework in the pre-IA-2021 branch. By navigating the pre-rework version of our repo, you can find file history and more. How to find deleted files There are multiple ways to find deleted files. These are roughly ordered by complexity: Finding the deletion PR The easiest way to find a deleted file is to find the pull request that deleted it. There are multiple ways to accomplish this; here are some ideas: Use GitHub's search feature to search for relevant keywords. You can filter search results to only include PRs. If you have a rough idea of when the doc was deleted, you could try finding the pull request in the pull request tab. This list has thousands of PRs, so this may take some time. Lots of docs are deleted because of a Jira ticket. Search Jira for the ticket, where you will find the rough time the doc was deleted and hopefully a link to the PR itself. Ask in #doc_talk! Search through release PRs By searching through release PRs, you can eventually find a branch created before the doc was deleted. You can find a list of release PRs in the GitHub PR tab. A few tips: Search by intervals of a month first. Once you find a branch that contains the doc, you can scope down to a week and then to a day. By decreasing the scope, you will eventually find the deleted doc in it's exact state before deletion. To access the branch a PR comes from, go to that pull request's page and click on the branch name underneath the title and PR number. Use git log The most powerful and realiable way to find deleted files is to use git log. See stackoverflow for more details.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.51144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>GitHub</em> history and deleted files",
        "sections": "<em>GitHub</em> history and deleted files",
        "body": "<em>GitHub</em>&#x27;s version control features allow us to see the complete history of a doc, access a doc at any point in time, and find deleted docs without manual backups. Check the edit history of a doc or file Use any of these options to check or &quot;diff&quot; the history of a file. Option 1: <em>GitHub</em> history tab"
      },
      "id": "61beb5d864441f378699fc79"
    }
  ],
  "/docs/style-guide/writing-docs/writer-workflow/github-troubleshooting": [
    {
      "sections": [
        "Diagnostics CLI (nrdiag)",
        "Compatibility",
        "Get started"
      ],
      "title": "Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "a49c65c83dc0ad7450935af104e8fcb0d7490e2c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/diagnostics-cli-nrdiag/",
      "published_at": "2021-12-30T23:41:24Z",
      "updated_at": "2021-12-14T04:11:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version The Diagnostics CLI (nrdiag) is a utility that automatically detects common problems with New Relic products. If the Diagnostics CLI detects a problem, it suggests troubleshooting steps. The Diagnostics CLI can automatically upload troubleshooting data to a New Relic account. The Diagnostics CLI is open source and is located in GitHub. For additional troubleshooting steps for your agent, check out Not seeing data. Here's an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates zipped troubleshooting logs that are ready to be attached to support tickets. Compatibility The Diagnostics CLI is available for Linux, macOS, and Windows. It can detect common configuration issues for: APM: Available for all APM agents except C SDK. For the Go agent, only basic connectivity checks are available. Browser monitoring: Browser agent detection Infrastructure monitoring: Linux and Windows agents Mobile agents: iOS and Android Synthetic monitoring: Containerized private minions (CPM) The Diagnostics CLI does not require superuser or admin permissions to run, although we recommend those permissions for some checks. It will return an error if it does not have permissions to read the files it scans. Get started To use the Diagnostics CLI: Run the Diagnostics CLI, including task suites and command line options as needed. Supply the -attach flag for uploading results to your New Relic account. Optional: Validate your config file settings. Interpret the output. Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. For detailed information, see our Diagnostics CLI licensing and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 748.2475,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". The Diagnostics CLI is open source and is located in <em>GitHub</em>. For additional <em>troubleshooting</em> steps for your agent, check out Not seeing data. Here&#x27;s an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates zipped"
      },
      "id": "604469f8e7b9d2abb65799f0"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline",
        "Outcomes"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2021-12-31T13:47:32Z",
      "updated_at": "2021-12-30T03:15:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset. Outcomes Here is a sample dashboard you could create to track your code pipeline. Track your code pipeline by creating dashboards in New Relic Insights. A dashboard like this yields a number of benefits, including: Faster deploy cycles. The ability to prioritize reliability work by identifying services with frequent deploy failures or gaps in test coverage. Ensuring teams don’t achieve speed at the expense of quality. Responding more effectively to change-related failures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.36931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " AWS CodePipeline to manage the flow of an application that is sourced in <em>GitHub</em>, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some &quot;glue code&quot; and event handlers needed to push data from <em>GitHub</em> and AWS to New Relic"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    },
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-30T03:11:17Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.87689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on <em>GitHub</em>. Use the language-specific <em>GitHub</em> links below to get library details, coding examples, and procedures for how to use"
      },
      "id": "603ea196196a670192a83d83"
    }
  ],
  "/docs/style-guide/writing-docs/writer-workflow/peer-editor-workflow": [
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "Tip"
      ],
      "published_at": "2021-12-30T09:23:00Z",
      "title": "Sprint workflow",
      "updated_at": "2021-11-06T12:49:01Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it makes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. ← Planning poker Liaisonships → Tip We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 720.6127,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sprint <em>workflow</em>",
        "sections": "Needs <em>Peer</em> <em>Editor</em>",
        "body": " that is ready for a <em>peer</em> edit. Once a <em>peer</em> <em>editor</em> picks it up, they move it into In <em>Peer</em> Edit. In <em>Peer</em> Edit This step is for a <em>peer</em> <em>editor</em> to review docs before they go live. Follow the <em>Peer</em> <em>editor</em> <em>workflow</em>, then move the ticket into <em>Peer</em> Edit Done.  <em>Peer</em> Edit Done This step is a holding state once"
      },
      "id": "616c0dc0196a67e6583c8164"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge releases into main work (or, when do we publish?)",
        "GitHub labels"
      ],
      "published_at": "2021-12-31T01:00:58Z",
      "title": "Get around GitHub",
      "updated_at": "2021-12-20T04:59:44Z",
      "type": "docs",
      "external_id": "539ae5620ae9be8f8c3752fd3eda664186fbb5c4",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of the New Relic organization. If they aren't, try to find them on Slack based on their username. If you're not sure about someone's affiliation, treat them as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review and label issues and PRs in this column, then drag them to the appropriate column. If a PR or issue is labeled eng, the Hero/Sidekick can go ahead and click its ellipses icon to archive it. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress and not necessarily ready to merge immediately. You can't merge a Draft PR directly. Instead, you must move it out of draft status first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft, and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero, make sure you attend to the following throughout your day: Check in with the previous Hero at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN Hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jira tickets, but reference tickets by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge releases into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM (morning), 12 PM (noon), and 3 PM (evening) Pacific. We merge release branches into main to avoid interuptions when someone merges into develop during a release. To learn more about this workflow, see the gitflow documentation in Atlassian. To start a release: Create a branch based off develop Github Desktop by clicking Current Branch in the top header, clicking New Branch in the dropdown, and then selecting Develop. Name the branch following this pattern: daily-release/mm-dd-yy-morning/noon/evening. Here's an example: daily-release/10-27-21-morning. Push your changes by clicking Push Origin in GitHub Desktop. Create a pull request into main from your new daily release branch by clicking Create Pull Request. This will open a pull request screen on github.com. Pull requests default to merging into develop, so select main as the base branch in the left side of the page and then click Submit Pull Request. Wait until all the checks complete, and then merge the pull request. All branches that follow the daily-release/mm-dd-yy-morning pattern are protected branches. This means the branches can't be deleted or pushed to by non-admins. GitHub labels Every issue needs labels to help us triage and track the health of our backlog: content: Always add, this indicates the issue is content-related rather than a design or engineering issue. pg_*: Always add to indicate the product group. For full definitions, see the \"Doc Jira and GitHub fields\" doc in the internal team Google Drive. Indicate who created the issue: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optionally: docs-issues-migrate: Issues that are too large in scope for the docs team to handle without product team expertise. This label alerts the docs issues team to migrate these issues into the customer feedback channel where they will be triaged and sent to product teams. Jira’d: Issues that have a corresponding Jira ticket. Make sure you leave the Jira number in the comments of the issue (for example, DOC-1234). Every pull request needs these labels so we can see where our contributions come from: content: Always add, this indicates the PR is content-related rather than design or engineering. Indicate who created the pull request: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.98625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "As tech doc writers (TW) we edit docs, do <em>peer</em> edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue&#x2F;PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR"
      },
      "id": "61ab4782196a672667d0efa1"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "55f439b9842d1f5df9e5ce1b06a5c5d9ae7829f6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-12-31T00:58:00Z",
      "updated_at": "2021-11-25T11:25:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 81.70144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ", and discuss your reasoning with your <em>peer</em> <em>editor</em>. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn&#x27;t solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes"
      },
      "id": "61ab4826e7b9d293010e7a46"
    }
  ],
  "/docs/style-guide/writing-docs/writer-workflow/tech-writer-workflow": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/writer-workflow/peer-editor-workflow/",
      "sections": [
        "Peer editor workflow",
        "Peer editing workflow in GitHub",
        "Developmental edit pass",
        "Copy edit workflow"
      ],
      "published_at": "2021-12-31T01:01:43Z",
      "title": "Peer editor workflow",
      "updated_at": "2021-11-26T05:18:04Z",
      "type": "docs",
      "external_id": "2445f390d928b9af124196fb5aaed74597083b36",
      "document_type": "page",
      "popularity": 1,
      "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the Tech Writer workflow doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing workflow in GitHub If you’re peer editing a doc or have been otherwise assigned to a PR as a reviewer, you have a few choices for how and where to do the work. The most streamlined and open-source approach is to do the edit using GitHub options, rather than copying the file to Google Docs and editing there. Developmental edit pass For cases where you have questions and suggestions rather than straight copy edits, follow these steps. Open the PR that you’re assigned to review. On the Files changed tab, you can either: Click Review changes and then select one of the following: Comment - use if you have a comment that doesn’t require follow up. Approve - use if you just want to approve the PR. You can request changes in the Leave a comment area, and select Approve if you want to let the writer make the edits and merge the file without a follow-up review from you. Request changes - use for times when you want to make sure the changes you request are included. You’ll be notified with any updates that the writer makes. OR, start making comments on lines or sections of the doc. To do this, click the add comment icon , and leave an edit or comment for that specific line in the page. With this option, you get the choice between adding a single comment or starting a review. If you’re going to make comments throughout a doc, choose Start a review so the comments will all be rolled into one commit. Click Finish your review to complete your review. This triggers a notification to the writer alerting them that you’ve made suggestions. Copy edit workflow If you have copy edits for a file rather than comments and suggestions, you can make the changes to the file in different ways. Here are two main options: Edit using the GitHub browser: On the Files changed tab, in the diff window click the editing button (three dots). When you finish your edits, add a comment at the bottom of the file and choose to either commit the changes directly, or create a branch and start a pull request. Choose to branch and start a pull request if you expect a writer to review the diff and accept or revise your edits. Edit locally: Check out the branch containing the file you want to edit. In GitHub Desktop, click the Current branch down arrow and select the branch. Then, make the edits on your local drive, save, and commit your changes to the branch. Note that this approach adds your edits to the open pull request. You can now see the changes you added to the file on the Files changed tab in the PR. These are just a few of many editing options. You’ll find your preferred way, just as with any other tool.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 943.9505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Peer editor <em>workflow</em>",
        "sections": "Peer editor <em>workflow</em>",
        "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the <em>Tech</em> <em>Writer</em> <em>workflow</em> doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing <em>workflow</em> in GitHub If you’re peer editing a doc or have been"
      },
      "id": "61b35900196a67bd1da5b38b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/processes-procedures/create-edit-content/",
      "sections": [
        "Create and edit content",
        "Edit a doc",
        "Create new docs",
        "Clone (copy) an existing doc",
        "For bigger projects",
        "Delete pages",
        "Private edits",
        "Request a future publication date (for New Relic employees)"
      ],
      "published_at": "2021-12-31T00:58:00Z",
      "title": "Create and edit content",
      "updated_at": "2021-11-26T09:11:58Z",
      "type": "docs",
      "external_id": "aa49bd1d71b168fd3da1eaaf781f230c6e603a81",
      "document_type": "page",
      "popularity": 1,
      "body": "We welcome your contributions, whether you are a New Relic employee or a New Relic user! And we don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. That said, if you're curious about our style guidelines, you're welcome (but not obligated) to take a look. Edit a doc If you see a minor problem in our documentation that you want to quickly fix, you can use GitHub to edit the file and submit your pull request. A member of the Docs team will review your edit and publish your changes. We'll follow up with you if we have any questions. To edit existing content without building the site locally: On the docs site, navigate to the doc you'd like to edit. Click Edit page on the top corner of the right nav. A GitHub page will open with the source of the doc. Click the pencil icon in the top right. Make your edits (don't worry too much about formatting or grammar, we're happy to take care of that). At the bottom of the page, enter a commit message that describes your change, then click Commit changes. Follow the prompts to submit your pull request. A member of the Docs team will review your pull request and comment with any feedback. Once we've merged your pull request into the Develop branch, your changes will go live with our next deploy (usually within a few hours). Create new docs You can use article templates or clone an existing doc as a template. To create a new doc: Clone the repo on your computer. In /src/content/docs/, find a good location for your doc. Using your text editor, create a new .mdx file or copy an existing doc. Write your content. Optional: Add your doc to the right nav .yml file. The navigation files can be a bit hard to work with, so feel free to leave this step for a Docs writer to handle when they review your pull request. Commit your changes and create a pull request. The Tech Docs team has two heroes watching for new pull requests. We'll help you get the content finalized and make sure that it's in the right place. Clone (copy) an existing doc Once you've cloned the docs-website repository, use your text editor to copy an existing doc. Rename and edit the copy and then save it as a new doc. Your cloned doc automatically inherits the original doc's frontmatter content. Make sure to change that, too. If you want your cloned doc to be translated, follow standard procedures to request translation. For bigger projects If you're making larger changes like adding a whole new doc or editing many existing docs, it can be helpful to run the site locally. For instructions, see Tech writer workflow. Delete pages If you are comfortable with deleting the page yourself, go for it. If not, ask us by: File an issue in the docs-website repo, or contact the @hero in the #documentation channel if you're a New Relic employee. We'll take a look at your issue and help out. Private edits If you need to stage content for a private beta or limited release, contact the docs hero in the #documentation Slack channel. Request a future publication date (for New Relic employees) If your draft needs to be released on a specific date or within a specific timeframe (for example, right before a release), contact the Tech Docs @hero in the #documentation Slack channel. If you're not a New Relic employee, please create a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 926.3092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " procedures to request translation. For bigger projects If you&#x27;re making larger changes like adding a whole new doc or editing many existing docs, it can be helpful to run the site locally. For instructions, see <em>Tech</em> <em>writer</em> <em>workflow</em>. Delete pages If you are comfortable with deleting the page yourself, go"
      },
      "id": "61b35a97196a67b744a5b860"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge releases into main work (or, when do we publish?)",
        "GitHub labels"
      ],
      "published_at": "2021-12-31T01:00:58Z",
      "title": "Get around GitHub",
      "updated_at": "2021-12-20T04:59:44Z",
      "type": "docs",
      "external_id": "539ae5620ae9be8f8c3752fd3eda664186fbb5c4",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of the New Relic organization. If they aren't, try to find them on Slack based on their username. If you're not sure about someone's affiliation, treat them as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review and label issues and PRs in this column, then drag them to the appropriate column. If a PR or issue is labeled eng, the Hero/Sidekick can go ahead and click its ellipses icon to archive it. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress and not necessarily ready to merge immediately. You can't merge a Draft PR directly. Instead, you must move it out of draft status first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft, and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero, make sure you attend to the following throughout your day: Check in with the previous Hero at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN Hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jira tickets, but reference tickets by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge releases into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM (morning), 12 PM (noon), and 3 PM (evening) Pacific. We merge release branches into main to avoid interuptions when someone merges into develop during a release. To learn more about this workflow, see the gitflow documentation in Atlassian. To start a release: Create a branch based off develop Github Desktop by clicking Current Branch in the top header, clicking New Branch in the dropdown, and then selecting Develop. Name the branch following this pattern: daily-release/mm-dd-yy-morning/noon/evening. Here's an example: daily-release/10-27-21-morning. Push your changes by clicking Push Origin in GitHub Desktop. Create a pull request into main from your new daily release branch by clicking Create Pull Request. This will open a pull request screen on github.com. Pull requests default to merging into develop, so select main as the base branch in the left side of the page and then click Submit Pull Request. Wait until all the checks complete, and then merge the pull request. All branches that follow the daily-release/mm-dd-yy-morning pattern are protected branches. This means the branches can't be deleted or pushed to by non-admins. GitHub labels Every issue needs labels to help us triage and track the health of our backlog: content: Always add, this indicates the issue is content-related rather than a design or engineering issue. pg_*: Always add to indicate the product group. For full definitions, see the \"Doc Jira and GitHub fields\" doc in the internal team Google Drive. Indicate who created the issue: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optionally: docs-issues-migrate: Issues that are too large in scope for the docs team to handle without product team expertise. This label alerts the docs issues team to migrate these issues into the customer feedback channel where they will be triaged and sent to product teams. Jira’d: Issues that have a corresponding Jira ticket. Make sure you leave the Jira number in the comments of the issue (for example, DOC-1234). Every pull request needs these labels so we can see where our contributions come from: content: Always add, this indicates the PR is content-related rather than design or engineering. Indicate who created the pull request: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.89612,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: <em>Writer</em> needs PR review PRs from <em>Tech</em> Docs team members that need a light edit pass"
      },
      "id": "61ab4782196a672667d0efa1"
    }
  ],
  "/docs/style-guide/writing-strategies/five-questions-help-write-docs": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-strategies/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide"
      ],
      "published_at": "2021-12-30T08:10:30Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-11-24T09:23:43Z",
      "type": "docs",
      "external_id": "56adaf70b517da62915ac6a2a56ff50c6effb7a9",
      "document_type": "page",
      "popularity": 1,
      "body": "Welcome to New Relic's style guide. We've written these guidelines for content creators across New Relic, and for contributors to our open source content projects, like the Docs! This guide also gives you some insight into how we think about good technical writing. We focus on style and usage that's particular to New Relic. We follow American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Find the information you need: For our writing strategy, see docs in this section on voice, five questions for great content, how to organize your content, and more. For a quick reference for terms usage, see our Usage dictionary. For how to write and edit pages on docs.newrelic.com, see Create and edit content.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.986046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction <em>to</em> the style guide",
        "sections": "Introduction <em>to</em> the style guide",
        "body": ": For our writing strategy, see <em>docs</em> in this section on voice, <em>five</em> <em>questions</em> for great content, how to organize your content, and more. For a quick reference for terms usage, see our Usage dictionary. For how to <em>write</em> and edit pages on <em>docs</em>.newrelic.com, see Create and edit content."
      },
      "id": "619e049fe7b9d2f6effe7e25"
    },
    {
      "sections": [
        "Use advanced (NRQL) mode to query data",
        "Compare advanced (NRQL) mode query with basic mode specification",
        "Important",
        "Notes about advanced (NRQL) mode"
      ],
      "title": "Use advanced (NRQL) mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "9abf8d760b8e1dacd1a1b2b0556f8fa7f92080f5",
      "image": "https://docs.newrelic.com/static/7db331ae854429d71dc7112a168594a2/69538/inline-advanced-nrql_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data/",
      "published_at": "2021-12-30T20:50:14Z",
      "updated_at": "2021-12-30T20:50:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any data specified in basic mode can be written as an NRQL query in advanced (NRQL) mode. To see what your basic mode data specification looks like as an NRQL query, click the Advanced (NRQL) link from the basic page. Example of an advanced (NRQL) query. Compare advanced (NRQL) mode query with basic mode specification When you switch from basic mode to advanced (NRQL) mode, the query you see produces the exact same chart as the basic data specification. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode. Use this table to understand how basic mode specifications correspond to the equivalent NRQL query. To set this In basic mode, you enter ... In advanced (NRQL) mode, you write ... The event type, attribute, and function on that attribute View a chart with Transaction : Name : unique_count SELECT uniqueCount(name) FROM Transaction Narrowing your results to show only those transactions with a 404 page not found error Narrow results to httpResponseCode='404' WHERE httpResponseCode = '404' Enable a preliminary timeline view not needed in basic mode TIMESERIES — enables line chart type (required for initial chart view) To see a separate value for each application with a 404 error Facet by appName FACET `appName` To view the five applications with the most 404 errors Limit 5 — default value is 10 LIMIT 5 To view errors over the last three hours Select Last 3 hrs — converted to seconds in NRQL query SINCE 10800 seconds ago To enhance the results of sampling transaction data This feature is run automatically in basic mode EXTRAPOLATE Notes about advanced (NRQL) mode Queries written directly in NRQL can be more complex than queries written in basic mode. For example, to learn how to create widgets with multiple NRQL queries, watch this short video (3:40 minutes). The NRQL documentation contains both reference information and query examples. This table identifies some additional items to keep in mind. Item Description Prompts For each statement or function in your query, you can view a list of valid options, with tooltips. Example of a prompt in advanced (NRQL) mode. Events You can use multiple event types in an NRQL query. Attributes You can use multiple attributes per event type in an NRQL query. View previous queries Once you run an NRQL query, use the My recent queries dropdown to view up the last 1,000 queries that you ran. The dropdown has a search box to help you find your query. Working with basic mode and NRQL If you start creating a chart using basic mode and then switch to advanced (NRQL), be aware that if you make any changes to the NRQL query, you will lose those changes in basic mode. Autocompleter The query builder’s autocompleter will display events and attributes reported within the last 60 minutes. An example of this is a process that runs once a day, such as a standard system health check that kicks off every morning at 6:00am. If you attempt to query the event at 7:05am, the event and subsequent attributes will not be visible in the autocomplete dropdown. These events and attributes are still queryable by typing the exact string. Multi query When using the TIMESERIES clause you can run and compare up to 10 queries from different accounts. To use multi query, enter your first query with TIMESERIES and run it. Once the results are rendered, the Add another query button is activated and you can add another query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 86.7184,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced (NRQL) mode <em>to</em> query data",
        "sections": "Use advanced (NRQL) mode <em>to</em> query data",
        "body": "While basic mode is an excellent choice for creating charts without needing to know how to <em>write</em> queries, working in advanced (NRQL) mode offers more power and additional features. Any data specified in basic mode can be written as an NRQL query in advanced (NRQL) mode. To see what your basic mode"
      },
      "id": "603ea876196a67cc1fa83dd5"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/install-configure-remote-write/prometheus-remote-write-integration/",
      "sections": [
        "Prometheus remote write integration",
        "Why it matters",
        "Compatibility",
        "Scale your data and get moving quickly",
        "What's next"
      ],
      "published_at": "2021-12-30T06:53:37Z",
      "title": "Prometheus remote write integration",
      "updated_at": "2021-10-24T02:42:19Z",
      "type": "docs",
      "external_id": "6f7d739c53aa8b1dd7674347d2af44e677084e99",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the Prometheus remote write integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about five minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which scrape data from Prometheus endpoints, the remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. You can leverage the full range of options for setup and management, from raw data to queries and dashboards and beyond. With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional) Compatibility New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Scale your data and get moving quickly Once logged in to New Relic, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. View your data. What's next Ready to get started? Read the setup documentation. Configure a Prometheus data source in Grafana. Set up the integration on New Relic US EU",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 70.29294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Prometheus remote <em>write</em> integration",
        "sections": "Prometheus remote <em>write</em> integration",
        "body": "You can use the Prometheus remote <em>write</em> integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about <em>five</em> minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which"
      },
      "id": "617d57fb64441f2704fbcb24"
    }
  ],
  "/docs/style-guide/writing-strategies/introduction-style-guide": [
    {
      "sections": [
        "Observability implementation guide template",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "KPI1 name",
        "KPI2 name",
        "Prerequisites",
        "Establish the current state",
        "Step 1",
        "Step 2",
        "Step 3",
        "Improvement process",
        "Value realization"
      ],
      "title": "Observability implementation guide template",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Value driver this applies to << change",
        "Use case name << change",
        "Implementation guide"
      ],
      "external_id": "e207c5d5d6379c5a496c46dc890bf51c60274c1c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/om-implementation-guide/",
      "published_at": "2021-12-31T00:57:59Z",
      "updated_at": "2021-12-24T13:23:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is the template for Observability maturity implementation guides. To help you along, refer to: The style guide introduction Other observability maturity implementation guides To get your implementation guide to show up in the left nav as it should, edit ~src/nav/new-relic-solutions.yml. Don't forget to add a link to it to the Observability Maturity introduction page. Overview Put in a brief, executive-level overview of what this guide achieves. Desired outcome What's the benefit of following the steps in this implementation guide? For practitioners? For the business or the organization? Key performance indicators Refer to the KPI section of the service level management (SLM) guide for what this section should look like. KPI1 name Describe the KPI Goal What is your reader trying to do? Best practices Are there any principles your reader should adopt? KPI2 name Describe the KPI Goal What is your reader trying to do? Best practices Are there any principles your reader should adopt? Prerequisites List any of the following that applies: Reading Training Instrumentation Configuration User access needed Stick to what's relevant (don't be exhaustive unless absolutely necessary) and include links wherever possible. Establish the current state Step1 Step2 Step3 If the reader needs to access a JSON file or another file type, make sure those files are available in the oma-resource-center. Step 1 Describe the step. Step 2 Describe the step. Step 3 Describe the step. Improvement process Now that the reader knows where they stand, tell them how to improve what they're trying to improve. Value realization Remind the reader why they did all this work in the first place and what they'll see as a result. Include best practices to adopt going forward so that they can continue to benefit from their hard work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 734.82544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Observability implementation <em>guide</em> template",
        "sections": "Observability implementation <em>guide</em> template",
        "tags": "Implementation <em>guide</em>",
        "body": "This is the template for Observability maturity implementation guides. To help you along, refer to: The <em>style</em> <em>guide</em> <em>introduction</em> Other observability maturity implementation guides To get your implementation <em>guide</em> to show up in the left nav as it should, edit ~src&#x2F;nav&#x2F;new-relic-solutions.yml. Don&#x27;t"
      },
      "id": "61c5c9ec28ccbccadb07ca78"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "BETA FEATURE",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation, docs site",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "1a874659169393e08e5c0cb986f258482797af4d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/word-choice/usage-dictionary/",
      "published_at": "2021-12-30T06:25:07Z",
      "updated_at": "2021-12-09T22:55:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For consistency across New Relic content, here are our general word usage guidelines: We generally follow the Microsoft Style Guide, which is based on the Chicago Manual of Style. We follow American English conventions, rather than British English ones. We defer to the official product names for references to products. (For example, for Amazon Web Services (AWS), see aws.amazon.com/products.) For terminology specific to New Relic, we use the product glossary. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta Use the beta callout. In the body text, use lowercase. For example: BETA FEATURE This feature is currently in beta. If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation, docs site If you need to refer to the docs themselves—don't. Generally it's better to directly link to the doc you're referencing and use the doc title as your link text. For example, See [Install the .NET agent](URL) rather than See our [.NET agent install docs](URL). If there's not a good alternative, doc generally sounds more natural than document or documentation. If you're tempted to use a longer form, try reading it aloud to see which reads best. If you must refer to the site as a whole, call it the docs site rather than Docs site or documentation site. Internally, you can also refer to the whole URL docs.newrelic.com to avoid ambiguity with other sources of docs like internal platform docs or API explorer docs. To refer to our docs GitHub repo, use the repo name docs-website or the repo path newrelic/docs-website. dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Avoid these Latin abbreviations. Instead of e.g., use for example or such as. Subbing for i.e. is tricker, because sometimes people use it to mean that is, while at other times it's mis-used to mean for example. Read the context to be clear, but usually the best solution is to rewrite so the description is clear without needing explanatory text. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. It should have a period at the end (etc.). Ensure that you have several meaningful examples, though, before using it. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Avoid using generically, to avoid confusion with infrastructure monitoring. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS, Mac OS X, or OS X. master account We previously used master account and sub-account but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with New Relic. For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original user model but still plays a role for some behind-the-scenes features on our New Relic One user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say we and our when it works with the flow of your writing. Avoid overloading paragraphs with New Relic mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use you and your liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.55405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>introduction</em>",
        "tags": "Basic <em>style</em> <em>guide</em>",
        "body": "For consistency across New Relic content, here are our general word usage guidelines: We generally follow the Microsoft <em>Style</em> <em>Guide</em>, which is based on the Chicago Manual of <em>Style</em>. We follow American English conventions, rather than British English ones. We defer to the official product names"
      },
      "id": "619e1c0a64441fb97e9858d2"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution",
        "Important",
        "Tip",
        "User-related permissions",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "046f0435c8098009144e40689b5a0f0ffc07755f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/formatting/callouts/",
      "published_at": "2021-12-30T03:18:06Z",
      "updated_at": "2021-12-04T10:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts We have a number of callout types, and each is controlled by the variant you include in the <Callout> tag. Here's an example of the format for a tip callout: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy Here are examples of our callout variants: Caution Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use <Callout variant=\"caution\">. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use <Callout variant=\"important\">. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use <Callout variant=\"tip\">. At a traffic light, a Tip would be a green light. User-related permissions For recommended wording, see User-related language and styles. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, add a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.96155,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Basic <em>style</em> <em>guide</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    }
  ],
  "/docs/style-guide/writing-strategies/organize-doc": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-30T20:48:40Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.339325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "<em>Organize</em> <em>your</em> dashboards with <em>pages</em>",
        "tags": "Query <em>your</em> data",
        "body": " the dashboard name gives the dashboard charts more space on the screen. <em>Page</em> cycle. For dashboards with multiple pages, this automatically cycles from <em>page</em> to <em>page</em>. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy <em>your</em> dashboard as JSON You can"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster",
        "Troubleshoot from anywhere in your stack"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "f47a40a9afd699e69c351f5e87f64ed5dadd7e43",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/intro-new-relic/",
      "published_at": "2021-12-31T01:18:23Z",
      "updated_at": "2021-12-31T01:18:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. This short video shows twenty of the most common ways to get your data into New Relic (approx. 5:22 minutes): With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will set up many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in New Relic One, no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic Instant Observability. There you will find integrations bundled into quickstarts, providing you instant access to pre-built dashboards and alerts specific to your technology. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. As a full platform user you get access to our entire set of observability tools in New Relic One: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified. Troubleshoot from anywhere in your stack Being fully connected, the New Relic UI allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but they can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.54418,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Bring all <em>your</em> data together",
        "body": " capturing and analyzing <em>your</em> data: If you don&#x27;t have a New Relic account, sign up at newrelic.com&#x2F;signup. It&#x27;s free, forever! Follow the steps in our Add <em>your</em> data UI <em>page</em> to get data flowing in. For <em>your</em> first install, we recommend the Guided install option, which will set up many integrations"
      },
      "id": "619d5b3e196a6705bda0837d"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-12-30T06:11:17Z",
      "updated_at": "2021-12-25T14:30:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters Allowed characters: Characters must be UTF-8. When using NerdGraph to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. And check out this short video on querying APM tags (3:20 minutes). Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 81.51628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use tags to help <em>organize</em> and find <em>your</em> data",
        "sections": "Use tags to help <em>organize</em> and find <em>your</em> data",
        "body": " or Terraform. Create recurring reports that identify entities that are non-compliant with <em>your</em> tagging standards. Tag examples Here are some examples of common ways to use tags to <em>organize</em> data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department"
      },
      "id": "603ebd1228ccbc6278eba754"
    }
  ],
  "/docs/style-guide/writing-strategies/voice-strategies-docs-sound-new-relic": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Collect data - any source",
        "Add custom attributes",
        "Create custom events",
        "Build queries with NerdGraph",
        "Monitor your network devices with New Relic",
        "Query data with NRQL"
      ],
      "published_at": "2022-01-02T01:39:10Z",
      "title": "Collect data",
      "updated_at": "2022-01-02T01:39:10Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Collect data - any source APIs, agents, OS emitters - get any data 15 min Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.72984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Monitor your network devices with <em>New</em> <em>Relic</em>",
        "body": "Through our opensource agents or APIs, <em>New</em> <em>Relic</em> makes it easy to collect data from any source. The guides in this section provide <em>strategies</em> for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Collect"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "image": "https://developer.newrelic.com/static/developer-champions-c61b7fb3b08d228679edab34b2d15a0e.jpg",
      "url": "https://developer.newrelic.com/developer-champion/",
      "sections": [
        "New Relic Developer Champions",
        "What do Developer Champions do?",
        "Open-source contributions",
        "Content creation",
        "Community engagement",
        "Why should you join and how will we support?",
        "Developer Champions benefits:"
      ],
      "published_at": "2022-01-02T01:39:10Z",
      "title": "New Relic Developers",
      "updated_at": "2020-12-04T01:45:02Z",
      "type": "developer",
      "external_id": "2cef9996dadc081ed4331e85992a4af9defc87ff",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Champions are the voice of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to New Relic product and engineering teams. Champions solve big problems using New Relic as their toolkit and are recognized as experts and leaders in the New Relic technical community. Nominate a developer champion What do Developer Champions do? New Relic Champions demonstrate expertise in using New Relic products by solving large problems and positioning New Relic as a central force in their strategies. The New Relic Champions is a recognition and partnership program designed to acknowledge the developers that are driving innovation within their companies and making top contributions to the developer community.They also commit to making their work public by: Open-source contributions Serving as an open-source author or maintainer for an accepted public project related to New Relic One Content creation Authoring two pieces of content in the New Relic Explorers Hub / Dev website Community engagement Delivering and/or organizing two events focused on an observability platform theme in which New Relic plays a crucial role Nominate a Developer Champion Why should you join and how will we support? As a benefit of being a Developer Champion, New Relic provides unique access to our Developer Advocacy team and the resources of our product organization, as well as specialized recognition and rewards. Developer Champions benefits: Formal, specialized access to the New Relic Product organization Champions have direct access to the New Relic’s Developer Ecosystem team Custom badge to wear with pride at events Public recognition on the New Relic Developer website and badging in the New Relic Explorers Hub as a Champion Exclusive Champion-only swag Early access program for some of our products (under NDA) Priority access to off-site FutureHack events (including when Lew is participating) Increased Explorer’s Hub support SLA Access to private Developer Champion Explorer’s Hub group",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 72.74935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Developers",
        "sections": "<em>New</em> <em>Relic</em> Developer Champions",
        "body": "<em>New</em> <em>Relic</em> Champions are the <em>voice</em> of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to <em>New</em> <em>Relic</em> product and engineering teams. Champions solve big"
      },
      "id": "5efa993c64441fc2a25f7e65"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-strategies/organize-doc/",
      "sections": [
        "Organize your page",
        "Organize your page to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-12-30T08:10:30Z",
      "title": "Organize your page",
      "updated_at": "2021-11-24T07:56:48Z",
      "type": "docs",
      "external_id": "a3e3c993c0bf65626e805676496bcae8ea8d2c64",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some organization basics. Organize your page to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 62.89449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Use the <em>New</em> <em>Relic</em> <em>voice</em>",
        "body": " of <em>docs</em> at once, please create an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing <em>docs</em> You are ready to start writing and editing <em>New</em> <em>Relic</em> <em>docs</em>! To learn the steps for basic <em>docs</em>, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a <em>new</em> <em>doc</em>, use templates."
      },
      "id": "619df04028ccbc2730b9a00a"
    }
  ],
  "/docs/synthetics/index": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.98726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetics</em>",
        "body": " which users can create, view, or delete secure credentials by managing users&#x27; permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the <em>Synthetics</em> REST API. To add, view, edit, or delete a secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.967606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetics</em>",
        "body": " to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 65.90787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> monitoring",
        "sections": "Get started with <em>synthetic</em> monitoring",
        "tags": "<em>Synthetics</em>"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/pages/synthetics-results-access-individual-monitor-runs": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.3904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " a supported browser. Important To <em>monitor</em> a site behind your firewall, add the <em>synthetic</em> <em>monitoring</em> public minion IP addresses to your allow list. Permissions By default, all users in your account can: View <em>synthetic</em> <em>monitoring</em> <em>pages</em>. Add, edit, and delete monitors. For more fine-grained control, you can"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30591,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/synthetics-api/synthetics-rest-api-version-1": [
    {
      "sections": [
        "Payload attributes for the Synthetics REST API",
        "Synthetic monitoring attributes",
        "Specific monitor endpoint"
      ],
      "title": "Payload attributes for the Synthetics REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "ed3202f6715ae367d5c7c58d63a332d073535995",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/payload-attributes-synthetics-rest-api/",
      "published_at": "2021-12-30T08:26:14Z",
      "updated_at": "2021-10-31T04:10:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For REST API requirements for synthetics, see Use the API. Synthetic monitoring attributes Here are the attributes that can be used when creating and managing monitors with the Synthetics REST API: Synthetics API attribute Definition apiVersion String: The version number. count Integer: The number of monitors returned. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific synthetic monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. options Object: options for SIMPLE and BROWSER monitor types. Options include: validationString: string verifySSL: boolean (true, false) bypassHEADRequest: boolean (true, false) treatRedirectAsFailure: boolean (true, false) Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected synthetic monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.52611,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "sections": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " <em>REST</em> <em>API</em> calls for a specific <em>monitor</em>, include the <em>monitor</em>_uuid as part of the endpoint. The <em>monitor</em>_uuid is the GUID which is part of the URL. For example, a selected synthetic <em>monitor</em> has this URL: https:&#x2F;&#x2F;<em>synthetics</em>.newrelic.com&#x2F;accounts&#x2F;nnnn&#x2F;monitors&#x2F;ab123-c456d-e78-90123-f45g Copy The <em>monitor</em>_uuid is the value that follows &#x2F;monitors&#x2F;."
      },
      "id": "6043f9ae28ccbc98002c607a"
    },
    {
      "sections": [
        "Manage synthetic monitors via REST API",
        "Features",
        "Monitor types in API",
        "Use the API",
        "Caution",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Patch an existing monitor",
        "Delete an existing monitor",
        "Get a list of valid locations",
        "Script API for scripted browser and API test monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Using private location scripts with verified script execution",
        "Important",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Tip"
      ],
      "title": "Manage synthetic monitors via REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "83a3e8ad751c7f0865785a1c2fad193604a7f7da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/manage-synthetics-monitors-rest-api/",
      "published_at": "2021-12-30T03:45:33Z",
      "updated_at": "2021-09-14T18:17:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Synthetics REST API to create and manage synthetic monitors of all types: ping, simple browser, scripted browser, and API test monitors. All synthetic monitoring data is available via the REST API. To use the Synthetics REST API, you must have a user role that allows that capability and a user key. For an overview of all available New Relic APIs, see Intro to APIs. Features The newest version of the Synthetics API (v3) adds these features: Synthetics API (v3) Features Options field for POST and PUT request You can specify the options for SIMPLE and BROWSER type monitors, similar to the way these options are available in the UI. PATCH request You can update only the fields of a monitor you want to change, rather than having to specify the entire monitor entity in a PUT. You can also specify the OPTION, assuming you are using the appropriate type of monitor. More detail with 400 Bad Request errors As of v3, the Synthetics API attempts to return as much information as possible when a validation failure occurs. This will help you figure out what might be wrong with the request. The API runs all validations and returns any failed validation messages, rather than failing on the first validation error as occurred in previous API versions. Pagination Large API responses are properly paginated. You can also use NRQL queries to analyze past changes made via the API. Monitor types in API These are the monitor types and how they're referred to in the API: Monitor type API name Ping SIMPLE Simple browser BROWSER Scripted browser SCRIPT_BROWSER API test SCRIPT_API Use the API To use the Synthetics REST API, you must have the ability to manage synthetics monitors and use a user key (the REST API key won't work). This API can be used for all Synthetics monitors. (Additional API methods for scripted browser and API test monitors are also available to update the script associated with those monitors.) All Synthetics data is available via the API. API examples show cURL commands. For US-based accounts, use the following endpoint: https://synthetics.newrelic.com/synthetics/api Copy For EU-based accounts, use the following endpoint: https://synthetics.eu.newrelic.com/synthetics/api Copy Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. Get all monitors To view a list of all the monitors in your New Relic account, send a GET request to $API_ENDPOINT/v3/monitors. For example: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"monitors\": [ { \"id\": \"2a1bc369-7654-489d-918e-f6g135h7i2jk\", \"name\": \"monitor1\", \"type\": \"BROWSER\", \"frequency\": 60, \"uri\": \"http://example.com\", \"locations\": [ \"AWS_US_WEST_1\" ], \"status\": \"DISABLED\", \"slaThreshold\": 7, \"options\": {}, \"modifiedAt\": \"2016-09-26T23:12:46.981+0000\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"userId\": 0, \"apiVersion\": \"0.2.2\" } ], \"count\": 1 } Copy Query arguments: offset: The monitor count offset. Defaults to 0. For example, if you have 40 monitors and you use an offset value of 20, it will return monitors 21-40. limit: The number of results per page, maximum 100. Defaults to 50. You can include these in your cURL command as follows: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors \\ -G -d 'offset=20&limit=100' Copy The headers include a Link to help you easily page your monitors. For example: <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=0&limit=20>; rel=\"first\", <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=40&limit=20>; rel=\"last\" Copy Get a specific monitor To view a single Synthetics monitor, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your Synthetics account, send a POST request to $API_ENDPOINT/v3/monitors with a JSON payload that describes the monitor. All fields in the following example are required unless stated otherwise: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, \"options\": { \"validationString\": string [only valid for SIMPLE and BROWSER types], \"verifySSL\": boolean (true, false) [only valid for SIMPLE and BROWSER types], \"bypassHEADRequest\": boolean (true, false) [only valid for SIMPLE types], \"treatRedirectAsFailure\": boolean (true, false) [only valid for SIMPLE types] } } Copy In addition, to add the script for a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Replace the Synthetics REST API attributes in the following example with your specific values: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\", \"status\" : \"enabled\", \"slaThreshold\" : \"1.0\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example: the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. All fields are required. However, the TYPE of the monitor cannot be changed. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\", \"type\": \"monitor type\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Patch an existing monitor To patch an existing monitor in New Relic, send a PATCH request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PATCH -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\" }' Copy PATCH requests are intended to update individual attributes of your New Relic Synthetics monitor rather than updating the entire entity, so you may provide only the attributes you want to update. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds, or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic Synthetics, send a DELETE request to $API_ENDPOINT/v3/monitors/$MONITOR_ID: curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response 404 Not Found: The specified monitor does not exist. Get a list of valid locations To retrieve the list of valid locations in New Relic Synthetics, use the following command: curl -v \\ -X GET -H 'Api-Key:$API_KEY' $API_ENDPOINT/v1/locations Copy Script API for scripted browser and API test monitors In addition to the general API, there are several API methods for the scripted browsers (SCRIPT_BROWSER) and API test browsers (SCRIPT_API). These examples show cURL commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script. For example: curl -v -H 'Api-Key: $API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic Synthetics with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the $MONITOR_UUID/script endpoint. For more information, refer to the example. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script with a JSON payload that contains the scriptText (required). scriptPayload='{\"scriptText\":BASE64 encoded string}' curl -v -X PUT \\ -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' \\ $API_ENDPOINT/v3/monitors/$MONITOR_UUID/script \\ -d $scriptPayload Copy If you are using private locations with verified script execution enabled, see script locations with verified script execution. A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Using private location scripts with verified script execution When creating or updating monitors for private locations that have verified script execution turned on, you must use scriptLocations to set the password: { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy The password used to generate the HMAC string must match the password set for the private location. If you have multiple locations with Verified script execution enabled each location must have the HMAC calculated. When generating the HMAC string, use the SHA256 algorithm with the script and password. Here's an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation: curl -v -X PUT -H 'Api-Key: '$API_KEY' -H 'content-type: application/json' $API_ENDPOINT}/v3/monitors/$MONITOR_ID/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4ZQ==\"} ]}' Copy Important You must remove the last newline character from both the script and the calculated HMAC value before encoding in BASE64. Calculation steps: Calculate the HMAC value from the script. One way is to use: cat script | openssl dgst -sha256 -hmac \"password\" > hmac Remove the newline character if one was added by openssl. Encode the HMAC in BASE64 without line breaks. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows cURL commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example shows the bash script that will create the SCRIPTED_BROWSER monitor. Tip In some cases you may want to use -w 0, which will disable line wrapping: base64 -w 0 $scriptfile #!/bin/bash # API key from your account settings API_KEY='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' https://synthetics.newrelic.com/synthetics/api/v3/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload=\"{\\\"scriptText\\\":\\\"$encoded\\\"}\" curl -s -X PUT -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.04715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "sections": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " will disable line wrapping: base64 -w 0 $scriptfile #!&#x2F;bin&#x2F;bash # <em>API</em> key from your account settings <em>API</em>_KEY=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;<em>monitor</em>-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes <em>monitor</em>Name=&#x27;Test <em>API</em> Script&#x27; <em>monitor</em>"
      },
      "id": "60440d4628ccbc74532c606a"
    },
    {
      "sections": [
        "Introduction to New Relic APIs",
        "APIs for data ingest",
        "NerdGraph (GraphQL)",
        "REST API",
        "APIs by feature",
        "Alerts",
        "APM",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Synthetic monitoring",
        "Account management, admin, and usage APIs",
        "Other APIs",
        "Insights"
      ],
      "title": "Introduction to New Relic APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "01e9799a214baad5de04de6146483f6dbbc198aa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/introduction-new-relic-apis/",
      "published_at": "2021-12-30T09:26:24Z",
      "updated_at": "2021-12-19T15:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of APIs and SDKs you can use to: Send data to New Relic. Retrieve data from New Relic. View and configure settings. This document provides examples and reference information for our APIs. APIs for data ingest Our four primary data ingest APIs are some of the many solutions for reporting data to New Relic. These APIs can be used directly, but they're also the underlying ingest route for any of our tools that use those APIs (for example, our OpenTelemetry integration, or our Telemetry SDKs). API type Description Metric API Send dimensional metrics to New Relic from any source (including other telemetry monitoring services). Event API Send custom event data to New Relic without the use of an agent or integration. Log API Send log data to New Relic. Trace API Send distributed tracing data (also referred to as \"spans\") to New Relic without the use of an agent or integration. NerdGraph (GraphQL) NerdGraph is the API we recommend for querying New Relic data, querying account information, and making a range of feature configurations. To learn what you can do, check out the NerdGraph tutorials. NerdGraph is our newest API and is our attempt to bring together in one place some of our older APIs, like our REST API. Note that there is still some functionality you can do with REST APIs that can't yet be done with NerdGraph, and this is why some New Relic organizations still use the REST API. REST API Our REST API is our older API for querying and configuration, which NerdGraph is in the process of replacing. The REST API has some configuration abilities that NerdGraph doesn't yet have, but when possible you should use NerdGraph. The REST API can be used for a wide range of features: for detail, see APIs by feature. APIs by feature New Relic tools and features, like APM, infrastructure monitoring, browser monitoring, and alerts, are often used together, and sometimes can overlap in functionality. This is why multiple APIs may be relevant to each area. Some API functionality will depend on your access to features and data. Alerts Use the REST API for alerts and the API Explorer to: Create and manage policies, conditions, and notification channels. Create alert conditions based on NRQL queries. Create alert conditions based on data from other New Relic capabilities. APM API resources for application monitoring include: Resource Details REST API REST API features include: Retrieve APM data, including metrics, Apdex, error rates, and host data. Report deployments. Change the app name in the UI. Agent APIs Every APM language agent has an API that lets you customize the agent's default behavior, including reporting custom data. APM agent APIs include: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Python agent API Ruby agent API Query API To query APM data, use NerdGraph. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Browser monitoring The browser API resources include: Resource Details Browser agent API Use the browser agent API for tasks such as: Report custom end user data to browser monitoring. Monitor asynchronous browser activity using SPA API calls. Insert custom data into New Relic dashboards . Manage source maps. REST API With the REST API you can: Retrieve page load timing data and throughput. Add or list apps monitored by browser monitoring. Manage alerts conditions for your browser data. Query API To query New Relic data, use NerdGraph. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Infrastructure monitoring The Infrastructure API resources include: Resource Details Query API To query New Relic data, use NerdGraph. Infrastructure alert API To manage your infrastructure alerts, use the Infrastructure alert API. Integrations SDK To make your own custom integrations for reporting data to infrastructure monitoring, use the Integrations SDK. NerdGraph You can use NerdGraph (our GraphQL API) to query your cloud integration data and make changes to cloud integration settings. Mobile monitoring Mobile API resources include: Resource Details Mobile agent APIs Mobile APIs let you custom instrument your own code and send events to New Relic. See the platform-specific documentation: iOS Android REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage New Relic alerts conditions for your mobile apps. Query API To query New Relic data, use NerdGraph. Account management APIs For account-related APIs, see Account APIs. Synthetic monitoring Synthetics API resources include: Resource Details Synthetics REST API The Synthetics REST API functionality includes: Create and manage synthetics monitors. Manage synthetics alert notifications. Add labels to monitors, and retrieve monitors with specific labels. Query API To query New Relic data, use NerdGraph. Alerts API To create and manage alert conditions that target synthetics monitors, use the Alerts API. Account management, admin, and usage APIs Like any other New Relic product or service, you want to be confident that your APIs protect you and your customers' data privacy. The following are API resources related to New Relic account administration and usage. For more information about API capabilities, see the specific New Relic API. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Resource Details REST API REST API features include: Find your API keys, account ID, and information needed to use the REST API. Return a list of account users (original user model only). Get SLA report data for browser and application monitoring. Subscription usage (original pricing model) For organizations on our original pricing model, you can use NerdGraph to query subscription usage data. This can be helpful to see how usage compares to your current subscription level, or for doing departmental chargebacks. Partner API If you're a New Relic partnership organization, you can use the Partner API to retrieve data and make configurations. Other APIs Insights New Relic Insights was the name of our original product that governed custom event reporting and querying. The features associated with Insights have been rolled into our New Relic One platform (learn more), but there are still some APIs and original pricing models that use the term \"Insights\" for these historical reasons. Insights-related APIs include: Resource Details Event API To report custom events, use the Event API. Query API Our Insights Query API is mostly deprecated. Instead, use NerdGraph for querying your New Relic data. Dashboard API Use the Dashboards API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.21597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>APIs</em>",
        "sections": "<em>REST</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": " rate data. Manage New Relic alerts conditions for your mobile apps. Query <em>API</em> To query New Relic data, use NerdGraph. Account management <em>APIs</em> For account-related <em>APIs</em>, see Account <em>APIs</em>. Synthetic monitoring <em>Synthetics</em> <em>API</em> resources include: Resource Details <em>Synthetics</em> <em>REST</em> <em>API</em> The <em>Synthetics</em> <em>REST</em>"
      },
      "id": "609fa5cf196a67066022b194"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.37968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-12-31T01:03:51Z",
      "updated_at": "2021-11-25T11:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing models, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full platform users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.22548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.76016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/identify-synthetic-monitoring-requests-your-app": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.37968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-12-31T01:03:51Z",
      "updated_at": "2021-11-25T11:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing models, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full platform users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.22548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.76016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.37968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-12-31T01:03:51Z",
      "updated_at": "2021-11-25T11:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing models, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full platform users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.22548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.76016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.37958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-12-31T01:03:51Z",
      "updated_at": "2021-11-25T11:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing models, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full platform users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.22546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.76009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.37958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-12-31T01:03:51Z",
      "updated_at": "2021-11-25T11:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing models, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full platform users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.22546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.76009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.37949,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.76,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.98592,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> is a suite of automated, scriptable tools to <em>monitor</em> your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.76,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.7168,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-12-31T01:04:48Z",
      "updated_at": "2021-10-18T21:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor API name: SCRIPT_API Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor API name: SCRIPT_API Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Assert modal Assert text Assert title Assert an element Click an element Dismiss a modal Double click an element Enter a secure credential Hover over an element Locate an element by CSS class, HTML ID, link text, Xpath, or value Navigate to a URL Select from a dropdown Type text Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.6116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.5877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to <em>get</em> <em>started</em>? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless use cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.75992,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.7167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.5877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to <em>get</em> <em>started</em>? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless use cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.75992,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.7167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.38995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " a supported browser. Important To <em>monitor</em> a site behind your firewall, add the <em>synthetic</em> <em>monitoring</em> public minion IP addresses to your allow list. Permissions By default, all users in your account can: View <em>synthetic</em> <em>monitoring</em> <em>pages</em>. Add, edit, and delete monitors. For more fine-grained control, you can"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.38995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " a supported browser. Important To <em>monitor</em> a site behind your firewall, add the <em>synthetic</em> <em>monitoring</em> public minion IP addresses to your allow list. Permissions By default, all users in your account can: View <em>synthetic</em> <em>monitoring</em> <em>pages</em>. Add, edit, and delete monitors. For more fine-grained control, you can"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.38988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " a supported browser. Important To <em>monitor</em> a site behind your firewall, add the <em>synthetic</em> <em>monitoring</em> public minion IP addresses to your allow list. Permissions By default, all users in your account can: View <em>synthetic</em> <em>monitoring</em> <em>pages</em>. Add, edit, and delete monitors. For more fine-grained control, you can"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-understand-load-times": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.38988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " a supported browser. Important To <em>monitor</em> a site behind your firewall, add the <em>synthetic</em> <em>monitoring</em> public minion IP addresses to your allow list. Permissions By default, all users in your account can: View <em>synthetic</em> <em>monitoring</em> <em>pages</em>. Add, edit, and delete monitors. For more fine-grained control, you can"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.38988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " a supported browser. Important To <em>monitor</em> a site behind your firewall, add the <em>synthetic</em> <em>monitoring</em> public minion IP addresses to your allow list. Permissions By default, all users in your account can: View <em>synthetic</em> <em>monitoring</em> <em>pages</em>. Add, edit, and delete monitors. For more fine-grained control, you can"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.27585,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.88776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " sites behind your firewall by adding the <em>synthetic</em> <em>monitoring</em> static IP addresses to your allow list. Use <em>private</em> <em>locations</em> to <em>monitor</em> internal sites or to expand your coverage to new <em>locations</em>. Compatibility with popular analytics platforms <em>Synthetic</em> <em>monitoring</em> specifically excludes scripts"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Tip",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-12-31T01:07:51Z",
      "updated_at": "2021-12-15T12:32:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The following Private Minion dashboard example JSON can be imported to your account using: the Import a dashboard button the Dashboard API Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Details on events from SyntheticPrivateLocationStatus, SyntheticsPrivateMinion, SyntheticCheck, SyntheticRequest, NrAuditEvent, plus a page for Performance Analysis.\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"SyntheticPrivateLocationStatus\", \"description\": \"Details on the private location queue.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 8, \"width\": 3 }, \"title\": \"pending checks by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(checksPending) FROM SyntheticsPrivateLocationStatus FACET name\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 4, \"width\": 9 }, \"title\": \"private location queue\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES max SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 5, \"height\": 4, \"width\": 9 }, \"title\": \"rate of queue growth\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(checksPending,1 minute),0) as 'queue growth rate' FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 9, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'PRIVATE_LOCATION' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticsPrivateMinion\", \"description\": \"Details on the minion instances.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 3 }, \"title\": \"private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(timestamp),uniqueCount(minionId) - 1 as 'restarts' from SyntheticsPrivateMinion since 2 days ago FACET minionLocation\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 3, \"width\": 7 }, \"title\": \"minion details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionId),latest(timestamp) as 'last seen',latest(minionStartTimestamp) as 'started',uniqueCount(minionId) - 1 as 'restarts',latest(minionIpv4),latest(minionJobsQueued),latest(minionJobsFinished),100*latest(minionJobsFailed)/latest(minionJobsQueued) as 'job failure rate',latest(minionJobsRunning),latest(minionJobsTimedout),latest(minionJobsSkipped),latest(minionJobsInternalEngineError),latest(minionWorkers),latest(minionProcessors),latest(minionPhysicalMemoryUsedBytes/(1024*1024*1024)) as 'used memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024)) as 'total memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024))/latest(minionWorkers) as 'memory (GiB) per heavy worker' FROM SyntheticsPrivateMinion FACET minionBuildNumber,minionLocation,minionOsVersion,minionContainerSystemVersion,minionHostname LIMIT 100 SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"minion instances over time\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' from SyntheticsPrivateMinion since 2 days ago TIMESERIES MAX \" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) AS 'CPU load %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"memory utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) AS 'used memory %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"free memory (GiB)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / (1024*1024*1024)) AS 'free (GiB)' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(minionJobsFinished,1 minute),0) FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"skipped jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsSkipped) as 'skipped jobs' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 2 weeks ago TIMESERIES MAX\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"count of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsInternalEngineError) as 'IEE',average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.stacked-bar\" }, \"layout\": { \"column\": 9, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"rate of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*average(minionJobsInternalEngineError)/average(minionJobsFailed) as 'IEE',100*(average(minionJobsFailed)-average(minionJobsInternalEngineError))/average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES AUTO SINCE 2 weeks ago\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticCheck\", \"description\": \"Details on job results.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 non-ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type != 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type = 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type = 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 6, \"width\": 6 }, \"title\": \"monitor details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(id) as 'results',uniqueCount(location)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET monitorName,monitorId,type LIMIT MAX\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 7, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 errors by monitor type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE error IS NOT NULL AND location NOT LIKE 'AWS%' FACET error,type TIMESERIES AUTO SINCE 2 weeks ago LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 10, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping duration with monitor count\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)',uniqueCount(monitorId) as 'monitor count' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job results\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET type TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type = 'SIMPLE' as 'ping',WHERE type != 'SIMPLE' as 'non-ping') TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 11, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type, result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type != 'SIMPLE' as 'non-ping',WHERE type = 'SIMPLE' as 'ping'),result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticRequest\", \"description\": \"Details on responses.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 6, \"width\": 5 }, \"title\": \"jobs per minion\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(jobId) as 'jobs' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' FACET location,minion,minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 6, \"row\": 1, \"height\": 6, \"width\": 4 }, \"title\": \"top 5 error response codes\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(responseCode) as 'responses' FROM SyntheticRequest WHERE responseCode NOT IN (200,201,202,203,204,300,301,302,303,304) AND responseCode IS NOT NULL AND location NOT LIKE 'AWS%' FACET responseCode,responseStatus TIMESERIES AUTO LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 10, \"row\": 1, \"height\": 6, \"width\": 3 }, \"title\": \"job rate\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(jobId), 1 minute) as 'job rate' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'MONITOR' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"Performance Analysis\", \"description\": \"Determine if there are enough heavy worker threads.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"minions (hosts) by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"count of heavy worker threads and cpu cores\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionWorkers),latest(minionProcessors) FROM SyntheticsPrivateMinion FACET minionHostname,minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.markdown\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"\", \"rawConfiguration\": { \"text\": \"See [this Google sheet](https://docs.google.com/spreadsheets/d/1k2Aw11r6-S8pIpXQUINQZ0T5qlxS8iSwSo9t9GKDvzc/edit?usp=sharing) to assist in calculating how many workers will be needed based on the values on this page. This will help you to assess the required size of each host (scaling up) and how many hosts you need (scaling out).\\n\\nFor more info: \\nhttps://discuss.newrelic.com/t/relic-solution-scaling-and-rightsizing-for-the-cpm/123999\" }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'non-ping monitors' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping avg job duration and timeout\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average((nr.internalQueueDuration+nr.executionDuration)/1e3) FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location,cases(WHERE error NOT LIKE '%timeout%' as 'job duration (s)', WHERE error LIKE '%timeout%' as 'job timeout (s)') SINCE 2 days ago TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"job timeout rate by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*latest(minionJobsTimedout)/latest(minionJobsReceived) as 'job timeout rate' FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES AUTO SINCE 2 days ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } Copy Steps to import: Copy the Dashboard JSON and paste into a text editor. Replace \"accountId\": 1, with your New Relic account ID for each occurrence in the JSON code. Copy the Dashboard JSON from your text editor and import using one of the methods described above. Edit any charts that you'd like to use facet filtering with. Tip If your private locations exist in a parent account and Synthetics monitors in a sub account, insert the parent account ID for NRQL queries that use SyntheticPrivateLocationStatus and SyntheticsPrivateMinion, and the sub account ID for queries that use SyntheticCheck and SyntheticRequest. Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.49362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.27585,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.88776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " sites behind your firewall by adding the <em>synthetic</em> <em>monitoring</em> static IP addresses to your allow list. Use <em>private</em> <em>locations</em> to <em>monitor</em> internal sites or to expand your coverage to new <em>locations</em>. Compatibility with popular analytics platforms <em>Synthetic</em> <em>monitoring</em> specifically excludes scripts"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Tip",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-12-31T01:07:51Z",
      "updated_at": "2021-12-15T12:32:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The following Private Minion dashboard example JSON can be imported to your account using: the Import a dashboard button the Dashboard API Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Details on events from SyntheticPrivateLocationStatus, SyntheticsPrivateMinion, SyntheticCheck, SyntheticRequest, NrAuditEvent, plus a page for Performance Analysis.\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"SyntheticPrivateLocationStatus\", \"description\": \"Details on the private location queue.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 8, \"width\": 3 }, \"title\": \"pending checks by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(checksPending) FROM SyntheticsPrivateLocationStatus FACET name\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 4, \"width\": 9 }, \"title\": \"private location queue\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES max SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 5, \"height\": 4, \"width\": 9 }, \"title\": \"rate of queue growth\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(checksPending,1 minute),0) as 'queue growth rate' FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 9, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'PRIVATE_LOCATION' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticsPrivateMinion\", \"description\": \"Details on the minion instances.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 3 }, \"title\": \"private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(timestamp),uniqueCount(minionId) - 1 as 'restarts' from SyntheticsPrivateMinion since 2 days ago FACET minionLocation\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 3, \"width\": 7 }, \"title\": \"minion details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionId),latest(timestamp) as 'last seen',latest(minionStartTimestamp) as 'started',uniqueCount(minionId) - 1 as 'restarts',latest(minionIpv4),latest(minionJobsQueued),latest(minionJobsFinished),100*latest(minionJobsFailed)/latest(minionJobsQueued) as 'job failure rate',latest(minionJobsRunning),latest(minionJobsTimedout),latest(minionJobsSkipped),latest(minionJobsInternalEngineError),latest(minionWorkers),latest(minionProcessors),latest(minionPhysicalMemoryUsedBytes/(1024*1024*1024)) as 'used memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024)) as 'total memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024))/latest(minionWorkers) as 'memory (GiB) per heavy worker' FROM SyntheticsPrivateMinion FACET minionBuildNumber,minionLocation,minionOsVersion,minionContainerSystemVersion,minionHostname LIMIT 100 SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"minion instances over time\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' from SyntheticsPrivateMinion since 2 days ago TIMESERIES MAX \" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) AS 'CPU load %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"memory utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) AS 'used memory %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"free memory (GiB)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / (1024*1024*1024)) AS 'free (GiB)' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(minionJobsFinished,1 minute),0) FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"skipped jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsSkipped) as 'skipped jobs' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 2 weeks ago TIMESERIES MAX\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"count of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsInternalEngineError) as 'IEE',average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.stacked-bar\" }, \"layout\": { \"column\": 9, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"rate of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*average(minionJobsInternalEngineError)/average(minionJobsFailed) as 'IEE',100*(average(minionJobsFailed)-average(minionJobsInternalEngineError))/average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES AUTO SINCE 2 weeks ago\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticCheck\", \"description\": \"Details on job results.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 non-ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type != 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type = 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type = 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 6, \"width\": 6 }, \"title\": \"monitor details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(id) as 'results',uniqueCount(location)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET monitorName,monitorId,type LIMIT MAX\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 7, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 errors by monitor type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE error IS NOT NULL AND location NOT LIKE 'AWS%' FACET error,type TIMESERIES AUTO SINCE 2 weeks ago LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 10, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping duration with monitor count\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)',uniqueCount(monitorId) as 'monitor count' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job results\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET type TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type = 'SIMPLE' as 'ping',WHERE type != 'SIMPLE' as 'non-ping') TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 11, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type, result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type != 'SIMPLE' as 'non-ping',WHERE type = 'SIMPLE' as 'ping'),result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticRequest\", \"description\": \"Details on responses.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 6, \"width\": 5 }, \"title\": \"jobs per minion\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(jobId) as 'jobs' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' FACET location,minion,minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 6, \"row\": 1, \"height\": 6, \"width\": 4 }, \"title\": \"top 5 error response codes\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(responseCode) as 'responses' FROM SyntheticRequest WHERE responseCode NOT IN (200,201,202,203,204,300,301,302,303,304) AND responseCode IS NOT NULL AND location NOT LIKE 'AWS%' FACET responseCode,responseStatus TIMESERIES AUTO LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 10, \"row\": 1, \"height\": 6, \"width\": 3 }, \"title\": \"job rate\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(jobId), 1 minute) as 'job rate' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'MONITOR' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"Performance Analysis\", \"description\": \"Determine if there are enough heavy worker threads.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"minions (hosts) by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"count of heavy worker threads and cpu cores\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionWorkers),latest(minionProcessors) FROM SyntheticsPrivateMinion FACET minionHostname,minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.markdown\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"\", \"rawConfiguration\": { \"text\": \"See [this Google sheet](https://docs.google.com/spreadsheets/d/1k2Aw11r6-S8pIpXQUINQZ0T5qlxS8iSwSo9t9GKDvzc/edit?usp=sharing) to assist in calculating how many workers will be needed based on the values on this page. This will help you to assess the required size of each host (scaling up) and how many hosts you need (scaling out).\\n\\nFor more info: \\nhttps://discuss.newrelic.com/t/relic-solution-scaling-and-rightsizing-for-the-cpm/123999\" }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'non-ping monitors' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping avg job duration and timeout\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average((nr.internalQueueDuration+nr.executionDuration)/1e3) FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location,cases(WHERE error NOT LIKE '%timeout%' as 'job duration (s)', WHERE error LIKE '%timeout%' as 'job timeout (s)') SINCE 2 days ago TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"job timeout rate by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*latest(minionJobsTimedout)/latest(minionJobsReceived) as 'job timeout rate' FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES AUTO SINCE 2 days ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } Copy Steps to import: Copy the Dashboard JSON and paste into a text editor. Replace \"accountId\": 1, with your New Relic account ID for each occurrence in the JSON code. Copy the Dashboard JSON from your text editor and import using one of the methods described above. Edit any charts that you'd like to use facet filtering with. Tip If your private locations exist in a parent account and Synthetics monitors in a sub account, insert the parent account ID for NRQL queries that use SyntheticPrivateLocationStatus and SyntheticsPrivateMinion, and the sub account ID for queries that use SyntheticCheck and SyntheticRequest. Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.49362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms": [
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.88763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " sites behind your firewall by adding the <em>synthetic</em> <em>monitoring</em> static IP addresses to your allow list. Use <em>private</em> <em>locations</em> to <em>monitor</em> internal sites or to expand your coverage to new <em>locations</em>. Compatibility with popular analytics platforms <em>Synthetic</em> <em>monitoring</em> specifically excludes scripts"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Tip",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-12-31T01:07:51Z",
      "updated_at": "2021-12-15T12:32:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The following Private Minion dashboard example JSON can be imported to your account using: the Import a dashboard button the Dashboard API Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Details on events from SyntheticPrivateLocationStatus, SyntheticsPrivateMinion, SyntheticCheck, SyntheticRequest, NrAuditEvent, plus a page for Performance Analysis.\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"SyntheticPrivateLocationStatus\", \"description\": \"Details on the private location queue.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 8, \"width\": 3 }, \"title\": \"pending checks by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(checksPending) FROM SyntheticsPrivateLocationStatus FACET name\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 4, \"width\": 9 }, \"title\": \"private location queue\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES max SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 5, \"height\": 4, \"width\": 9 }, \"title\": \"rate of queue growth\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(checksPending,1 minute),0) as 'queue growth rate' FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 9, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'PRIVATE_LOCATION' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticsPrivateMinion\", \"description\": \"Details on the minion instances.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 3 }, \"title\": \"private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(timestamp),uniqueCount(minionId) - 1 as 'restarts' from SyntheticsPrivateMinion since 2 days ago FACET minionLocation\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 3, \"width\": 7 }, \"title\": \"minion details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionId),latest(timestamp) as 'last seen',latest(minionStartTimestamp) as 'started',uniqueCount(minionId) - 1 as 'restarts',latest(minionIpv4),latest(minionJobsQueued),latest(minionJobsFinished),100*latest(minionJobsFailed)/latest(minionJobsQueued) as 'job failure rate',latest(minionJobsRunning),latest(minionJobsTimedout),latest(minionJobsSkipped),latest(minionJobsInternalEngineError),latest(minionWorkers),latest(minionProcessors),latest(minionPhysicalMemoryUsedBytes/(1024*1024*1024)) as 'used memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024)) as 'total memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024))/latest(minionWorkers) as 'memory (GiB) per heavy worker' FROM SyntheticsPrivateMinion FACET minionBuildNumber,minionLocation,minionOsVersion,minionContainerSystemVersion,minionHostname LIMIT 100 SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"minion instances over time\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' from SyntheticsPrivateMinion since 2 days ago TIMESERIES MAX \" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) AS 'CPU load %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"memory utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) AS 'used memory %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"free memory (GiB)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / (1024*1024*1024)) AS 'free (GiB)' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(minionJobsFinished,1 minute),0) FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"skipped jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsSkipped) as 'skipped jobs' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 2 weeks ago TIMESERIES MAX\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"count of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsInternalEngineError) as 'IEE',average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.stacked-bar\" }, \"layout\": { \"column\": 9, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"rate of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*average(minionJobsInternalEngineError)/average(minionJobsFailed) as 'IEE',100*(average(minionJobsFailed)-average(minionJobsInternalEngineError))/average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES AUTO SINCE 2 weeks ago\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticCheck\", \"description\": \"Details on job results.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 non-ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type != 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type = 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type = 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 6, \"width\": 6 }, \"title\": \"monitor details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(id) as 'results',uniqueCount(location)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET monitorName,monitorId,type LIMIT MAX\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 7, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 errors by monitor type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE error IS NOT NULL AND location NOT LIKE 'AWS%' FACET error,type TIMESERIES AUTO SINCE 2 weeks ago LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 10, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping duration with monitor count\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)',uniqueCount(monitorId) as 'monitor count' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job results\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET type TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type = 'SIMPLE' as 'ping',WHERE type != 'SIMPLE' as 'non-ping') TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 11, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type, result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type != 'SIMPLE' as 'non-ping',WHERE type = 'SIMPLE' as 'ping'),result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticRequest\", \"description\": \"Details on responses.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 6, \"width\": 5 }, \"title\": \"jobs per minion\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(jobId) as 'jobs' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' FACET location,minion,minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 6, \"row\": 1, \"height\": 6, \"width\": 4 }, \"title\": \"top 5 error response codes\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(responseCode) as 'responses' FROM SyntheticRequest WHERE responseCode NOT IN (200,201,202,203,204,300,301,302,303,304) AND responseCode IS NOT NULL AND location NOT LIKE 'AWS%' FACET responseCode,responseStatus TIMESERIES AUTO LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 10, \"row\": 1, \"height\": 6, \"width\": 3 }, \"title\": \"job rate\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(jobId), 1 minute) as 'job rate' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'MONITOR' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"Performance Analysis\", \"description\": \"Determine if there are enough heavy worker threads.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"minions (hosts) by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"count of heavy worker threads and cpu cores\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionWorkers),latest(minionProcessors) FROM SyntheticsPrivateMinion FACET minionHostname,minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.markdown\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"\", \"rawConfiguration\": { \"text\": \"See [this Google sheet](https://docs.google.com/spreadsheets/d/1k2Aw11r6-S8pIpXQUINQZ0T5qlxS8iSwSo9t9GKDvzc/edit?usp=sharing) to assist in calculating how many workers will be needed based on the values on this page. This will help you to assess the required size of each host (scaling up) and how many hosts you need (scaling out).\\n\\nFor more info: \\nhttps://discuss.newrelic.com/t/relic-solution-scaling-and-rightsizing-for-the-cpm/123999\" }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'non-ping monitors' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping avg job duration and timeout\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average((nr.internalQueueDuration+nr.executionDuration)/1e3) FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location,cases(WHERE error NOT LIKE '%timeout%' as 'job duration (s)', WHERE error LIKE '%timeout%' as 'job timeout (s)') SINCE 2 days ago TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"job timeout rate by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*latest(minionJobsTimedout)/latest(minionJobsReceived) as 'job timeout rate' FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES AUTO SINCE 2 days ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } Copy Steps to import: Copy the Dashboard JSON and paste into a text editor. Replace \"accountId\": 1, with your New Relic account ID for each occurrence in the JSON code. Copy the Dashboard JSON from your text editor and import using one of the methods described above. Edit any charts that you'd like to use facet filtering with. Tip If your private locations exist in a parent account and Synthetics monitors in a sub account, insert the parent account ID for NRQL queries that use SyntheticPrivateLocationStatus and SyntheticsPrivateMinion, and the sub account ID for queries that use SyntheticCheck and SyntheticRequest. Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.49359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-12-31T01:07:08Z",
      "updated_at": "2021-11-15T07:14:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (for example, counter) and an npm hosted modules (for example, async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED if synthetics.privateLocationKeySecretName is not set. UUID/Private location key of the private location, as found on the private location web page. synthetics.privateLocationKeySecretName REQUIRED if synthetics.privateLocationKey is not set. Name of the Kubernetes secret that contains the key privateLocationKey, which contains the authentication key associated with your Synthetics private location. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. imagePullSecrets The name of the secret object used to pull an image from a specified container registry. fullnameOverride Name override used for your StatefulSet installation, replacing the default. appVersionOverride Release version of CPM to use instead of the version specified in chart.yml. synthetics.minionLogLevel If contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers, where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1,250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionVsePassphrase If set, it enables verified script execution, and uses this value as a passphrase. synthetics.minionVsePassphraseSecretName If set, enables verified script execution and uses this value to retrieve the passphrase from a Kubernetes secret with a key called minionVsePassphrase. synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user-defined key value pairs. synthetics.minionJVMOpts Passes command line options to the internal JVM. Default: -server -XX:-UsePerfData synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. image.repository The container to pull. Default: quay.io/newrelic/synthetics-minion image.pullPolicy The pull policy. Default: IfNotPresent persistence.claimName The name of the PVC to use. If undefined or not set, Statefulset will dynamically create a PVC for each replica. persistence.storageClass Overrides StorageClass for VolumeClaimTemplates, relevant only if claimName is undefined or empty. For more details see persistent volumes. persistence.accessMode Access mode to be defined for the PVC, relevant only if claimName is undefined or empty. Default: ReadWriteOnce. persistence.annotations Annotations to add to the PVC, relevant only if claimName is undefined or empty. persistence.size Size to be defined for the PVC, relevant only if claimName is undefined or empty. Default: 10Gi. persistence.permanentData Path on the volume to the permanent data storage directory. For more details, see permanent data storage. persistence.customModules Path on the volume to the custom modules directory. For more details, see custom modules. persistence.userDefinedVariables Path on the volume to the user-defined-variable.json file. For more details, see user defined variables. serviceAccount.create If true, a service account is created and assigned to the deployment. Default: false. serviceAccount.name The service account to assign to the deployment. If serviceAccount.create is true, then this name is used when creating the service account. serviceAccount.annotations The annotations to add to the service account if serviceAccount.create is set to true. removeJobsLog Default Kubernetes doesn't include a jobs/log resource. Set this to true to remove it from the role if needed. Default: false. headlessService.serviceName The name of the headless service to associate to the StatefulSet. If not set a name is generated using the fullname template. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.82556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " * <em>synthetics</em>.heavyWorkers, where <em>synthetics</em>.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1,250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionApiEndpoint For US-based accounts, the endpoint"
      },
      "id": "603ea540196a67e50da83d95"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.27567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.88763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " sites behind your firewall by adding the <em>synthetic</em> <em>monitoring</em> static IP addresses to your allow list. Use <em>private</em> <em>locations</em> to <em>monitor</em> internal sites or to expand your coverage to new <em>locations</em>. Compatibility with popular analytics platforms <em>Synthetic</em> <em>monitoring</em> specifically excludes scripts"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-12-31T01:07:08Z",
      "updated_at": "2021-11-15T07:14:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (for example, counter) and an npm hosted modules (for example, async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED if synthetics.privateLocationKeySecretName is not set. UUID/Private location key of the private location, as found on the private location web page. synthetics.privateLocationKeySecretName REQUIRED if synthetics.privateLocationKey is not set. Name of the Kubernetes secret that contains the key privateLocationKey, which contains the authentication key associated with your Synthetics private location. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. imagePullSecrets The name of the secret object used to pull an image from a specified container registry. fullnameOverride Name override used for your StatefulSet installation, replacing the default. appVersionOverride Release version of CPM to use instead of the version specified in chart.yml. synthetics.minionLogLevel If contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers, where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1,250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionVsePassphrase If set, it enables verified script execution, and uses this value as a passphrase. synthetics.minionVsePassphraseSecretName If set, enables verified script execution and uses this value to retrieve the passphrase from a Kubernetes secret with a key called minionVsePassphrase. synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user-defined key value pairs. synthetics.minionJVMOpts Passes command line options to the internal JVM. Default: -server -XX:-UsePerfData synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. image.repository The container to pull. Default: quay.io/newrelic/synthetics-minion image.pullPolicy The pull policy. Default: IfNotPresent persistence.claimName The name of the PVC to use. If undefined or not set, Statefulset will dynamically create a PVC for each replica. persistence.storageClass Overrides StorageClass for VolumeClaimTemplates, relevant only if claimName is undefined or empty. For more details see persistent volumes. persistence.accessMode Access mode to be defined for the PVC, relevant only if claimName is undefined or empty. Default: ReadWriteOnce. persistence.annotations Annotations to add to the PVC, relevant only if claimName is undefined or empty. persistence.size Size to be defined for the PVC, relevant only if claimName is undefined or empty. Default: 10Gi. persistence.permanentData Path on the volume to the permanent data storage directory. For more details, see permanent data storage. persistence.customModules Path on the volume to the custom modules directory. For more details, see custom modules. persistence.userDefinedVariables Path on the volume to the user-defined-variable.json file. For more details, see user defined variables. serviceAccount.create If true, a service account is created and assigned to the deployment. Default: false. serviceAccount.name The service account to assign to the deployment. If serviceAccount.create is true, then this name is used when creating the service account. serviceAccount.annotations The annotations to add to the service account if serviceAccount.create is set to true. removeJobsLog Default Kubernetes doesn't include a jobs/log resource. Set this to true to remove it from the role if needed. Default: false. headlessService.serviceName The name of the headless service to associate to the StatefulSet. If not set a name is generated using the fullname template. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.82556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " * <em>synthetics</em>.heavyWorkers, where <em>synthetics</em>.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1,250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionApiEndpoint For US-based accounts, the endpoint"
      },
      "id": "603ea540196a67e50da83d95"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.27548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.8875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " sites behind your firewall by adding the <em>synthetic</em> <em>monitoring</em> static IP addresses to your allow list. Use <em>private</em> <em>locations</em> to <em>monitor</em> internal sites or to expand your coverage to new <em>locations</em>. Compatibility with popular analytics platforms <em>Synthetic</em> <em>monitoring</em> specifically excludes scripts"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Tip",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-12-31T01:07:51Z",
      "updated_at": "2021-12-15T12:32:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The following Private Minion dashboard example JSON can be imported to your account using: the Import a dashboard button the Dashboard API Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Details on events from SyntheticPrivateLocationStatus, SyntheticsPrivateMinion, SyntheticCheck, SyntheticRequest, NrAuditEvent, plus a page for Performance Analysis.\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"SyntheticPrivateLocationStatus\", \"description\": \"Details on the private location queue.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 8, \"width\": 3 }, \"title\": \"pending checks by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(checksPending) FROM SyntheticsPrivateLocationStatus FACET name\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 4, \"width\": 9 }, \"title\": \"private location queue\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES max SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 5, \"height\": 4, \"width\": 9 }, \"title\": \"rate of queue growth\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(checksPending,1 minute),0) as 'queue growth rate' FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 9, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'PRIVATE_LOCATION' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticsPrivateMinion\", \"description\": \"Details on the minion instances.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 3 }, \"title\": \"private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(timestamp),uniqueCount(minionId) - 1 as 'restarts' from SyntheticsPrivateMinion since 2 days ago FACET minionLocation\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 3, \"width\": 7 }, \"title\": \"minion details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionId),latest(timestamp) as 'last seen',latest(minionStartTimestamp) as 'started',uniqueCount(minionId) - 1 as 'restarts',latest(minionIpv4),latest(minionJobsQueued),latest(minionJobsFinished),100*latest(minionJobsFailed)/latest(minionJobsQueued) as 'job failure rate',latest(minionJobsRunning),latest(minionJobsTimedout),latest(minionJobsSkipped),latest(minionJobsInternalEngineError),latest(minionWorkers),latest(minionProcessors),latest(minionPhysicalMemoryUsedBytes/(1024*1024*1024)) as 'used memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024)) as 'total memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024))/latest(minionWorkers) as 'memory (GiB) per heavy worker' FROM SyntheticsPrivateMinion FACET minionBuildNumber,minionLocation,minionOsVersion,minionContainerSystemVersion,minionHostname LIMIT 100 SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"minion instances over time\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' from SyntheticsPrivateMinion since 2 days ago TIMESERIES MAX \" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) AS 'CPU load %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"memory utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) AS 'used memory %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"free memory (GiB)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / (1024*1024*1024)) AS 'free (GiB)' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(minionJobsFinished,1 minute),0) FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"skipped jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsSkipped) as 'skipped jobs' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 2 weeks ago TIMESERIES MAX\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"count of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsInternalEngineError) as 'IEE',average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.stacked-bar\" }, \"layout\": { \"column\": 9, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"rate of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*average(minionJobsInternalEngineError)/average(minionJobsFailed) as 'IEE',100*(average(minionJobsFailed)-average(minionJobsInternalEngineError))/average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES AUTO SINCE 2 weeks ago\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticCheck\", \"description\": \"Details on job results.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 non-ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type != 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type = 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type = 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 6, \"width\": 6 }, \"title\": \"monitor details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(id) as 'results',uniqueCount(location)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET monitorName,monitorId,type LIMIT MAX\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 7, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 errors by monitor type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE error IS NOT NULL AND location NOT LIKE 'AWS%' FACET error,type TIMESERIES AUTO SINCE 2 weeks ago LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 10, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping duration with monitor count\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)',uniqueCount(monitorId) as 'monitor count' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job results\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET type TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type = 'SIMPLE' as 'ping',WHERE type != 'SIMPLE' as 'non-ping') TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 11, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type, result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type != 'SIMPLE' as 'non-ping',WHERE type = 'SIMPLE' as 'ping'),result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticRequest\", \"description\": \"Details on responses.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 6, \"width\": 5 }, \"title\": \"jobs per minion\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(jobId) as 'jobs' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' FACET location,minion,minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 6, \"row\": 1, \"height\": 6, \"width\": 4 }, \"title\": \"top 5 error response codes\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(responseCode) as 'responses' FROM SyntheticRequest WHERE responseCode NOT IN (200,201,202,203,204,300,301,302,303,304) AND responseCode IS NOT NULL AND location NOT LIKE 'AWS%' FACET responseCode,responseStatus TIMESERIES AUTO LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 10, \"row\": 1, \"height\": 6, \"width\": 3 }, \"title\": \"job rate\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(jobId), 1 minute) as 'job rate' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'MONITOR' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"Performance Analysis\", \"description\": \"Determine if there are enough heavy worker threads.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"minions (hosts) by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"count of heavy worker threads and cpu cores\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionWorkers),latest(minionProcessors) FROM SyntheticsPrivateMinion FACET minionHostname,minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.markdown\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"\", \"rawConfiguration\": { \"text\": \"See [this Google sheet](https://docs.google.com/spreadsheets/d/1k2Aw11r6-S8pIpXQUINQZ0T5qlxS8iSwSo9t9GKDvzc/edit?usp=sharing) to assist in calculating how many workers will be needed based on the values on this page. This will help you to assess the required size of each host (scaling up) and how many hosts you need (scaling out).\\n\\nFor more info: \\nhttps://discuss.newrelic.com/t/relic-solution-scaling-and-rightsizing-for-the-cpm/123999\" }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'non-ping monitors' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping avg job duration and timeout\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average((nr.internalQueueDuration+nr.executionDuration)/1e3) FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location,cases(WHERE error NOT LIKE '%timeout%' as 'job duration (s)', WHERE error LIKE '%timeout%' as 'job timeout (s)') SINCE 2 days ago TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"job timeout rate by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*latest(minionJobsTimedout)/latest(minionJobsReceived) as 'job timeout rate' FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES AUTO SINCE 2 days ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } Copy Steps to import: Copy the Dashboard JSON and paste into a text editor. Replace \"accountId\": 1, with your New Relic account ID for each occurrence in the JSON code. Copy the Dashboard JSON from your text editor and import using one of the methods described above. Edit any charts that you'd like to use facet filtering with. Tip If your private locations exist in a parent account and Synthetics monitors in a sub account, insert the parent account ID for NRQL queries that use SyntheticPrivateLocationStatus and SyntheticsPrivateMinion, and the sub account ID for queries that use SyntheticCheck and SyntheticRequest. Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.49356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/troubleshoot-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.27548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.8875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " sites behind your firewall by adding the <em>synthetic</em> <em>monitoring</em> static IP addresses to your allow list. Use <em>private</em> <em>locations</em> to <em>monitor</em> internal sites or to expand your coverage to new <em>locations</em>. Compatibility with popular analytics platforms <em>Synthetic</em> <em>monitoring</em> specifically excludes scripts"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Tip",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-12-31T01:07:51Z",
      "updated_at": "2021-12-15T12:32:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The following Private Minion dashboard example JSON can be imported to your account using: the Import a dashboard button the Dashboard API Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Details on events from SyntheticPrivateLocationStatus, SyntheticsPrivateMinion, SyntheticCheck, SyntheticRequest, NrAuditEvent, plus a page for Performance Analysis.\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"SyntheticPrivateLocationStatus\", \"description\": \"Details on the private location queue.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 8, \"width\": 3 }, \"title\": \"pending checks by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(checksPending) FROM SyntheticsPrivateLocationStatus FACET name\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 4, \"width\": 9 }, \"title\": \"private location queue\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES max SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 5, \"height\": 4, \"width\": 9 }, \"title\": \"rate of queue growth\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(checksPending,1 minute),0) as 'queue growth rate' FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 9, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'PRIVATE_LOCATION' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticsPrivateMinion\", \"description\": \"Details on the minion instances.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 3 }, \"title\": \"private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(timestamp),uniqueCount(minionId) - 1 as 'restarts' from SyntheticsPrivateMinion since 2 days ago FACET minionLocation\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 3, \"width\": 7 }, \"title\": \"minion details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionId),latest(timestamp) as 'last seen',latest(minionStartTimestamp) as 'started',uniqueCount(minionId) - 1 as 'restarts',latest(minionIpv4),latest(minionJobsQueued),latest(minionJobsFinished),100*latest(minionJobsFailed)/latest(minionJobsQueued) as 'job failure rate',latest(minionJobsRunning),latest(minionJobsTimedout),latest(minionJobsSkipped),latest(minionJobsInternalEngineError),latest(minionWorkers),latest(minionProcessors),latest(minionPhysicalMemoryUsedBytes/(1024*1024*1024)) as 'used memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024)) as 'total memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024))/latest(minionWorkers) as 'memory (GiB) per heavy worker' FROM SyntheticsPrivateMinion FACET minionBuildNumber,minionLocation,minionOsVersion,minionContainerSystemVersion,minionHostname LIMIT 100 SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"minion instances over time\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' from SyntheticsPrivateMinion since 2 days ago TIMESERIES MAX \" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) AS 'CPU load %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"memory utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) AS 'used memory %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"free memory (GiB)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / (1024*1024*1024)) AS 'free (GiB)' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(minionJobsFinished,1 minute),0) FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"skipped jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsSkipped) as 'skipped jobs' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 2 weeks ago TIMESERIES MAX\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"count of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsInternalEngineError) as 'IEE',average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.stacked-bar\" }, \"layout\": { \"column\": 9, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"rate of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*average(minionJobsInternalEngineError)/average(minionJobsFailed) as 'IEE',100*(average(minionJobsFailed)-average(minionJobsInternalEngineError))/average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES AUTO SINCE 2 weeks ago\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticCheck\", \"description\": \"Details on job results.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 non-ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type != 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type = 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type = 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 6, \"width\": 6 }, \"title\": \"monitor details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(id) as 'results',uniqueCount(location)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET monitorName,monitorId,type LIMIT MAX\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 7, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 errors by monitor type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE error IS NOT NULL AND location NOT LIKE 'AWS%' FACET error,type TIMESERIES AUTO SINCE 2 weeks ago LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 10, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping duration with monitor count\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)',uniqueCount(monitorId) as 'monitor count' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job results\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET type TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type = 'SIMPLE' as 'ping',WHERE type != 'SIMPLE' as 'non-ping') TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 11, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type, result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type != 'SIMPLE' as 'non-ping',WHERE type = 'SIMPLE' as 'ping'),result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticRequest\", \"description\": \"Details on responses.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 6, \"width\": 5 }, \"title\": \"jobs per minion\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(jobId) as 'jobs' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' FACET location,minion,minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 6, \"row\": 1, \"height\": 6, \"width\": 4 }, \"title\": \"top 5 error response codes\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(responseCode) as 'responses' FROM SyntheticRequest WHERE responseCode NOT IN (200,201,202,203,204,300,301,302,303,304) AND responseCode IS NOT NULL AND location NOT LIKE 'AWS%' FACET responseCode,responseStatus TIMESERIES AUTO LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 10, \"row\": 1, \"height\": 6, \"width\": 3 }, \"title\": \"job rate\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(jobId), 1 minute) as 'job rate' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'MONITOR' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"Performance Analysis\", \"description\": \"Determine if there are enough heavy worker threads.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"minions (hosts) by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"count of heavy worker threads and cpu cores\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionWorkers),latest(minionProcessors) FROM SyntheticsPrivateMinion FACET minionHostname,minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.markdown\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"\", \"rawConfiguration\": { \"text\": \"See [this Google sheet](https://docs.google.com/spreadsheets/d/1k2Aw11r6-S8pIpXQUINQZ0T5qlxS8iSwSo9t9GKDvzc/edit?usp=sharing) to assist in calculating how many workers will be needed based on the values on this page. This will help you to assess the required size of each host (scaling up) and how many hosts you need (scaling out).\\n\\nFor more info: \\nhttps://discuss.newrelic.com/t/relic-solution-scaling-and-rightsizing-for-the-cpm/123999\" }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'non-ping monitors' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping avg job duration and timeout\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average((nr.internalQueueDuration+nr.executionDuration)/1e3) FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location,cases(WHERE error NOT LIKE '%timeout%' as 'job duration (s)', WHERE error LIKE '%timeout%' as 'job timeout (s)') SINCE 2 days ago TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"job timeout rate by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*latest(minionJobsTimedout)/latest(minionJobsReceived) as 'job timeout rate' FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES AUTO SINCE 2 days ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } Copy Steps to import: Copy the Dashboard JSON and paste into a text editor. Replace \"accountId\": 1, with your New Relic account ID for each occurrence in the JSON code. Copy the Dashboard JSON from your text editor and import using one of the methods described above. Edit any charts that you'd like to use facet filtering with. Tip If your private locations exist in a parent account and Synthetics monitors in a sub account, insert the parent account ID for NRQL queries that use SyntheticPrivateLocationStatus and SyntheticsPrivateMinion, and the sub account ID for queries that use SyntheticCheck and SyntheticRequest. Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.49356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.2753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.88737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " sites behind your firewall by adding the <em>synthetic</em> <em>monitoring</em> static IP addresses to your allow list. Use <em>private</em> <em>locations</em> to <em>monitor</em> internal sites or to expand your coverage to new <em>locations</em>. Compatibility with popular analytics platforms <em>Synthetic</em> <em>monitoring</em> specifically excludes scripts"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Tip",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-12-31T01:07:51Z",
      "updated_at": "2021-12-15T12:32:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The following Private Minion dashboard example JSON can be imported to your account using: the Import a dashboard button the Dashboard API Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Details on events from SyntheticPrivateLocationStatus, SyntheticsPrivateMinion, SyntheticCheck, SyntheticRequest, NrAuditEvent, plus a page for Performance Analysis.\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"SyntheticPrivateLocationStatus\", \"description\": \"Details on the private location queue.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 8, \"width\": 3 }, \"title\": \"pending checks by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(checksPending) FROM SyntheticsPrivateLocationStatus FACET name\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 4, \"width\": 9 }, \"title\": \"private location queue\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES max SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 4, \"row\": 5, \"height\": 4, \"width\": 9 }, \"title\": \"rate of queue growth\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(checksPending,1 minute),0) as 'queue growth rate' FROM SyntheticsPrivateLocationStatus FACET name TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 9, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'PRIVATE_LOCATION' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticsPrivateMinion\", \"description\": \"Details on the minion instances.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 3 }, \"title\": \"private locations\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(timestamp),uniqueCount(minionId) - 1 as 'restarts' from SyntheticsPrivateMinion since 2 days ago FACET minionLocation\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 4, \"row\": 1, \"height\": 3, \"width\": 7 }, \"title\": \"minion details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionId),latest(timestamp) as 'last seen',latest(minionStartTimestamp) as 'started',uniqueCount(minionId) - 1 as 'restarts',latest(minionIpv4),latest(minionJobsQueued),latest(minionJobsFinished),100*latest(minionJobsFailed)/latest(minionJobsQueued) as 'job failure rate',latest(minionJobsRunning),latest(minionJobsTimedout),latest(minionJobsSkipped),latest(minionJobsInternalEngineError),latest(minionWorkers),latest(minionProcessors),latest(minionPhysicalMemoryUsedBytes/(1024*1024*1024)) as 'used memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024)) as 'total memory (GiB)',latest(minionPhysicalMemoryTotalBytes/(1024*1024*1024))/latest(minionWorkers) as 'memory (GiB) per heavy worker' FROM SyntheticsPrivateMinion FACET minionBuildNumber,minionLocation,minionOsVersion,minionContainerSystemVersion,minionHostname LIMIT 100 SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"minion instances over time\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' from SyntheticsPrivateMinion since 2 days ago TIMESERIES MAX \" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) AS 'CPU load %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"memory utilization (%)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) AS 'used memory %' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"free memory (GiB)\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / (1024*1024*1024)) AS 'free (GiB)' FROM SyntheticsPrivateMinion TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT clamp_min(derivative(minionJobsFinished,1 minute),0) FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 7, \"height\": 3, \"width\": 2 }, \"title\": \"skipped jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsSkipped) as 'skipped jobs' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 2 weeks ago TIMESERIES MAX\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"count of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(minionJobsInternalEngineError) as 'IEE',average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES MAX SINCE 2 weeks ago\" } ], \"yAxisLeft\": { \"zero\": false } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.stacked-bar\" }, \"layout\": { \"column\": 9, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"rate of Internal Engine Errors (IEE) vs failed jobs\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*average(minionJobsInternalEngineError)/average(minionJobsFailed) as 'IEE',100*(average(minionJobsFailed)-average(minionJobsInternalEngineError))/average(minionJobsFailed) as 'failed jobs' FROM SyntheticsPrivateMinion TIMESERIES AUTO SINCE 2 weeks ago\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticCheck\", \"description\": \"Details on job results.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 non-ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type != 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"ping monitor details by location\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'monitors with results',uniqueCount(monitorId)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE type = 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location \" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 7, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 ping errors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(error) as 'count',latest(monitorName),average((nr.internalQueueDuration+nr.executionDuration)/1e3) as 'avg job duration (s)',max(timestamp) as 'last occurrence' FROM SyntheticCheck WHERE type = 'SIMPLE' AND result = 'FAILED' AND location NOT LIKE 'AWS%' FACET error LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 6, \"width\": 6 }, \"title\": \"monitor details\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(id) as 'results',uniqueCount(location)/rate(uniqueCount(id), 1 minute) as 'avg job frequency (m)',average(nr.internalQueueDuration+nr.executionDuration)/1e3 as 'avg duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET monitorName,monitorId,type LIMIT MAX\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 7, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"top 5 errors by monitor type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE error IS NOT NULL AND location NOT LIKE 'AWS%' FACET error,type TIMESERIES AUTO SINCE 2 weeks ago LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 10, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping duration with monitor count\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)',uniqueCount(monitorId) as 'monitor count' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job results\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(*) FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 3, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 7, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET type TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"job rate by type\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type = 'SIMPLE' as 'ping',WHERE type != 'SIMPLE' as 'non-ping') TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 11, \"row\": 13, \"height\": 3, \"width\": 2 }, \"title\": \"duration by type, result\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average(nr.internalQueueDuration+nr.executionDuration/1e3) as 'avg job duration (s)' FROM SyntheticCheck WHERE location NOT LIKE 'AWS%' FACET cases(WHERE type != 'SIMPLE' as 'non-ping',WHERE type = 'SIMPLE' as 'ping'),result TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] }, { \"name\": \"SyntheticRequest\", \"description\": \"Details on responses.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 6, \"width\": 5 }, \"title\": \"jobs per minion\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(jobId) as 'jobs' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' FACET location,minion,minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.area\" }, \"layout\": { \"column\": 6, \"row\": 1, \"height\": 6, \"width\": 4 }, \"title\": \"top 5 error response codes\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT count(responseCode) as 'responses' FROM SyntheticRequest WHERE responseCode NOT IN (200,201,202,203,204,300,301,302,303,304) AND responseCode IS NOT NULL AND location NOT LIKE 'AWS%' FACET responseCode,responseStatus TIMESERIES AUTO LIMIT 5\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 10, \"row\": 1, \"height\": 6, \"width\": 3 }, \"title\": \"job rate\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(jobId), 1 minute) as 'job rate' FROM SyntheticRequest WHERE location NOT LIKE 'AWS%' TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 4, \"width\": 12 }, \"title\": \"audit events for monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT * from NrAuditEvent WHERE targetType = 'MONITOR' SINCE 2 days ago LIMIT MAX\" } ] }, \"linkedEntityGuids\": null } ] }, { \"name\": \"Performance Analysis\", \"description\": \"Determine if there are enough heavy worker threads.\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"minions (hosts) by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(minionId) as 'minions' FROM SyntheticsPrivateMinion FACET minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 6 }, \"title\": \"count of heavy worker threads and cpu cores\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionWorkers),latest(minionProcessors) FROM SyntheticsPrivateMinion FACET minionHostname,minionLocation SINCE 5 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.markdown\" }, \"layout\": { \"column\": 11, \"row\": 1, \"height\": 3, \"width\": 2 }, \"title\": \"\", \"rawConfiguration\": { \"text\": \"See [this Google sheet](https://docs.google.com/spreadsheets/d/1k2Aw11r6-S8pIpXQUINQZ0T5qlxS8iSwSo9t9GKDvzc/edit?usp=sharing) to assist in calculating how many workers will be needed based on the values on this page. This will help you to assess the required size of each host (scaling up) and how many hosts you need (scaling out).\\n\\nFor more info: \\nhttps://discuss.newrelic.com/t/relic-solution-scaling-and-rightsizing-for-the-cpm/123999\" }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping monitors\", \"rawConfiguration\": { \"dataFormatters\": [], \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniqueCount(monitorId) as 'non-ping monitors' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 6 }, \"title\": \"non-ping avg job duration and timeout\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT average((nr.internalQueueDuration+nr.executionDuration)/1e3) FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location,cases(WHERE error NOT LIKE '%timeout%' as 'job duration (s)', WHERE error LIKE '%timeout%' as 'job timeout (s)') SINCE 2 days ago TIMESERIES AUTO\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.bar\" }, \"layout\": { \"column\": 1, \"row\": 7, \"height\": 3, \"width\": 4 }, \"title\": \"non-ping jobs per minute\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT rate(uniqueCount(id), 1 minute) as 'job rate' FROM SyntheticCheck WHERE type != 'SIMPLE' AND location NOT LIKE 'AWS%' FACET location SINCE 2 days ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 7, \"height\": 3, \"width\": 6 }, \"title\": \"job timeout rate by location\", \"rawConfiguration\": { \"facet\": { \"showOtherSeries\": false }, \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT 100*latest(minionJobsTimedout)/latest(minionJobsReceived) as 'job timeout rate' FROM SyntheticsPrivateMinion FACET minionLocation TIMESERIES AUTO SINCE 2 days ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } Copy Steps to import: Copy the Dashboard JSON and paste into a text editor. Replace \"accountId\": 1, with your New Relic account ID for each occurrence in the JSON code. Copy the Dashboard JSON from your text editor and import using one of the methods described above. Edit any charts that you'd like to use facet filtering with. Tip If your private locations exist in a parent account and Synthetics monitors in a sub account, insert the parent account ID for NRQL queries that use SyntheticPrivateLocationStatus and SyntheticsPrivateMinion, and the sub account ID for queries that use SyntheticCheck and SyntheticRequest. Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.49353,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "sections": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the <em>script</em> When using the <em>Synthetics</em> UI editor to create scripted browsers or API test <em>monitors</em>, follow these guidelines: <em>Script</em> Guidelines Format Anywhere in the <em>script</em> where"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-12-31T01:10:47Z",
      "updated_at": "2021-11-15T07:23:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy Here's an example of setting up a proxied network via proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, 'anotherExample.com': {username: 'authUsername', password: 'authPassword'}, } $network.setProxyPAC(\"https://www.example.com/pacScript\", authCredentialsMap) Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/import-nodejs-modules": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "sections": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the <em>script</em> When using the <em>Synthetics</em> UI editor to create scripted browsers or API test <em>monitors</em>, follow these guidelines: <em>Script</em> Guidelines Format Anywhere in the <em>script</em> where"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-12-31T01:10:47Z",
      "updated_at": "2021-11-15T07:23:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy Here's an example of setting up a proxied network via proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, 'anotherExample.com': {username: 'authUsername', password: 'authPassword'}, } $network.setProxyPAC(\"https://www.example.com/pacScript\", authCredentialsMap) Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/introduction-scripted-browser-monitors": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "sections": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the <em>script</em> When using the <em>Synthetics</em> UI editor to create scripted browsers or API test <em>monitors</em>, follow these guidelines: <em>Script</em> Guidelines Format Anywhere in the <em>script</em> where"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-12-31T01:10:47Z",
      "updated_at": "2021-11-15T07:23:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy Here's an example of setting up a proxied network via proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, 'anotherExample.com': {username: 'authUsername', password: 'authPassword'}, } $network.setProxyPAC(\"https://www.example.com/pacScript\", authCredentialsMap) Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "sections": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the <em>script</em> When using the <em>Synthetics</em> UI editor to create scripted browsers or API test <em>monitors</em>, follow these guidelines: <em>Script</em> Guidelines Format Anywhere in the <em>script</em> where"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-12-31T01:10:47Z",
      "updated_at": "2021-11-15T07:23:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy Here's an example of setting up a proxied network via proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, 'anotherExample.com': {username: 'authUsername', password: 'authPassword'}, } $network.setProxyPAC(\"https://www.example.com/pacScript\", authCredentialsMap) Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.70598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "sections": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the <em>script</em> When using the <em>Synthetics</em> UI editor to create scripted browsers or API test <em>monitors</em>, follow these guidelines: <em>Script</em> Guidelines Format Anywhere in the <em>script</em> where"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-11-07T09:33:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. (Note that Request is deprecated, but these options still apply.) Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. We recommend using SSL to avoid exposing plain text credentials in your headers. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(duration)%20FROM%20Transaction', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.60841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ". If any assert functions fail, the entire <em>monitor</em> will be considered a failed check. This may trigger alert notifications and affect your metrics. Important <em>Synthetic</em> <em>monitoring</em> does not allow thrown exceptions. Thrown exceptions result in <em>script</em> failure. Use the assert module to validate your results"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetic-scripted-browser-reference-monitor-versions-04x-or-lower": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30475,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "sections": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the <em>script</em> When using the <em>Synthetics</em> UI editor to create scripted browsers or API test <em>monitors</em>, follow these guidelines: <em>Script</em> Guidelines Format Anywhere in the <em>script</em> where"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-12-31T01:10:47Z",
      "updated_at": "2021-11-15T07:23:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy Here's an example of setting up a proxied network via proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, 'anotherExample.com': {username: 'authUsername', password: 'authPassword'}, } $network.setProxyPAC(\"https://www.example.com/pacScript\", authCredentialsMap) Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.70598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetics-scripted-browser-reference-monitor-versions-050": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30475,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "sections": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the <em>script</em> When using the <em>Synthetics</em> UI editor to create scripted browsers or API test <em>monitors</em>, follow these guidelines: <em>Script</em> Guidelines Format Anywhere in the <em>script</em> where"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-12-31T01:10:47Z",
      "updated_at": "2021-11-15T07:23:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy Here's an example of setting up a proxied network via proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, 'anotherExample.com': {username: 'authUsername', password: 'authPassword'}, } $network.setProxyPAC(\"https://www.example.com/pacScript\", authCredentialsMap) Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.70598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "sections": "Store secure credentials for <em>scripted</em> browsers and API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the <em>script</em> When using the <em>Synthetics</em> UI editor to create scripted browsers or API test <em>monitors</em>, follow these guidelines: <em>Script</em> Guidelines Format Anywhere in the <em>script</em> where"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-12-31T01:10:47Z",
      "updated_at": "2021-11-15T07:23:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy Here's an example of setting up a proxied network via proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, 'anotherExample.com': {username: 'authUsername', password: 'authPassword'}, } $network.setProxyPAC(\"https://www.example.com/pacScript\", authCredentialsMap) Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.70596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/monitor-produces-no-traffic": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> is a suite of automated, scriptable tools to <em>monitor</em> your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> is a suite of automated, scriptable tools to <em>monitor</em> your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/private-location-hmac-errors": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> is a suite of automated, scriptable tools to <em>monitor</em> your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> is a suite of automated, scriptable tools to <em>monitor</em> your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/troubleshoot-isolated-monitor-failures": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.30447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.4616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> is a suite of automated, scriptable tools to <em>monitor</em> your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.4616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/alerts-synthetic-monitoring": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/collect-synthetic-transaction-traces": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/handle-sites-authentication": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/manage-monitor-runtimes": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/recheck-failed-monitors": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60062,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-12-31T01:13:01Z",
      "updated_at": "2021-11-25T11:34:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also: Capture aggregate numbers, including an overview or summary for ping monitors. Provide detailed statistics for each page resource, and downtime incidents. Collect custom response codes for more detail on your monitor runs. You'll be able to add and configure synthetic monitors to suit your environnment after you create a New Relic account. (It's free, forever!) Add a monitor You can add several types of synthetic monitors: Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. The default timeout for a new monitor is 180 seconds. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL (may be any valid HTTP or HTTPS URL). Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Generate some traffic and wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Generate some traffic and wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Generate some traffic and wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Generate some traffic and wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor (may be any valid HTTP or HTTPS URL). Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Generate some traffic and wait a few minutes, then check your monitor from the Monitors index. Tip You can also add monitors with the Synthetics REST API. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor You cannot change a monitor's type after the monitor is created, but you can edit other monitor settings. From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also delete a monitor with the Synthetics REST API. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.18852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", select Settings &gt; Script to edit your <em>monitor</em> script. For <em>synthetic</em> <em>monitoring</em> alerts, click Manage alerts. Select Save changes to confirm. Delete a <em>monitor</em> To delete a <em>monitor</em>: From the <em>Monitors</em> tab in one.newrelic.com &gt; <em>Synthetics</em>, select the <em>monitor</em> you want to edit. From the selected <em>monitor</em>"
      },
      "id": "604526d064441f3ecc378f03"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.4613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.4613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-simple-scripted-monitor-results": [
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-12-31T01:15:18Z",
      "updated_at": "2021-12-31T01:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure credentials in New Relic One or with the API. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). To learn how to secure sensitive information in your synthetic monitoring workflows, watch this short video (3:15 minutes): Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. To add a new secure credential, look for the Create secure credential + button. If you have credentials already added, this button is at the top right. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. To edit an existing credential, click the ellipsis icon for options. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials UI shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.60034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> secure credentials with <em>synthetic</em> <em>monitoring</em> to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted <em>monitor</em> users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. You can set secure"
      },
      "id": "60452772196a67195c960f3b"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-12-31T01:07:09Z",
      "updated_at": "2021-12-31T01:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher. macOS: 10.11 or higher. Windows: Windows 10 64-bit or higher. You must also configure Docker to run Linux containers in order for CPMs to work on Windows systems. Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Unless hosting the images in a local image repository, connections to either quay.io or docker.io will need to be allowed through your firewall in order for Docker to pull the synthetics-minion and synthetics-minion-runner images. The \"runner\" image is pulled automatically on startup of the synthetics-minion container. See Docker environment configuration and Kubernetes environment configuration for details on how to set a local repository and the runner registry endpoint. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com/charts Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.26038,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2022-01-02T01:47:27Z",
      "updated_at": "2021-12-30T01:54:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests. Ready to get started? If you don't already have one, sign up for a New Relic account. It's free, forever! Synthetic monitoring has countless use cases, and knowing the right monitor type for yours is important. To learn about our different types of synthetic monitors and the differences between each, watch this short video (5:10 minutes). Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.46123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "sections": "Get started with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " critical business transactions. <em>Monitor</em> your API endpoints with API tests. Ready to get started? If you don&#x27;t already have one, sign up for a New Relic account. It&#x27;s free, forever! <em>Synthetic</em> <em>monitoring</em> has countless <em>use</em> cases, and knowing the right <em>monitor</em> type for yours is important. To learn about"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/using-new-relic/data/understand-data/new-relic-event-limits-sampling": [
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2021-12-31T01:40:19Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 77.34125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Install <em>APM</em>",
        "body": " to install New Relic monitoring services: <em>APM</em> Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install <em>APM</em> C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    },
    {
      "sections": [
        "View slow query details",
        "Slow query data samples",
        "View slow query data",
        "Tip",
        "Configuration",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Slow queries metrics",
        "Troubleshooting: No slow query data"
      ],
      "title": "View slow query details",
      "type": "docs",
      "tags": [
        "APM",
        "APM UI pages",
        "Monitoring"
      ],
      "external_id": "877f2ba64963875fce3cc4b656f5a66f43563cdd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/apm-ui-pages/monitoring/view-slow-query-details/",
      "published_at": "2021-12-31T01:39:27Z",
      "updated_at": "2021-12-30T02:57:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In APM, when transaction traces are collected, there may be additional Slow query data available on the Databases page. Let's look at what slow query data is, where to find it, and how to configure it. You can also use histograms and heatmaps to visualize the distribution of values for different metrics. This is useful to understand slow page performance. To learn how, watch this short video (4:18 minutes). Slow query data samples When transaction traces are reported, the slow queries feature samples the slowest database queries in those traces and reports data about them on the Databases page. Slow query data can include: Duration of query segments Query/explain plans (if recognized) Host and instance level details (if supported by agent) View slow query data Tip To get a high-level overview of all your applications and services, use the New Relic Explorer. To see your slow query data: Do one of the following: New Relic Explorer: Go to one.newrelic.com > Explorer > (select an app) > Monitor > Databases. APM: Go to one.newrelic.com > APM > (select an app) > Monitor > Databases. Select a database transaction. If available, select any available slow queries listed on the page. If you do not see expected slow query data, follow the troubleshooting tips. Configuration In general, you can configure your slow query settings either of these ways: Agent configuration Server-side configuration (if available for your agent) Agent configuration gives you more options than server-side configuration does. How you choose to configure slow queries will depend on your own setup and preferences. For more information, see the documentation for the specific agent: C SDK You can report slow query traces for SQL databases only. For more information, see Instrument your application with the C SDK. Go Agent configuration options: Enable/disable: SlowQuery.Enabled Slow query threshold: SlowQuery.Threshold For other datastore config options, see Datastore tracer configuration. Java Agent configuration: Slow query threshold: explain_threshold. For other settings related to slow transactions and queries, see the Transaction tracer config options. You can also edit basic slow query settings via server-side configuration. .NET Agent configuration: Enable/disable: slowSql enabled Slow query threshold: explainThreshold For other settings related to slow transactions and queries, see the Transaction tracer config options and the Datastore tracer options. You can also edit basic slow query settings via server-side configuration. Node.js Agent configuration: Enable/disable: enabled Threshold: explain_threshold Maximum slow query samples: max_samples For other settings related to slow transactions and queries, see the Transaction tracer config options. Server-side configuration of slow query data is not possible for the Node.js agent. PHP Agent configuration: Enable/disable: slow_sql Threshold: explain_threshold For other settings related to slow transactions and queries, see the Transaction tracer config options. Server-side configuration is not possible for the PHP agent. Python Agent configuration: Slow query threshold: explain_threshold For other settings related to slow transactions and queries, see the Transaction tracer config options and the Datastore tracer options. You can also edit basic slow query settings via server-side configuration. Ruby Agent configuration: Enable/disable: slow_sql.enabled Slow query threshold: slow_sql.explain_threshold For other settings related to slow transactions and queries, see the Transaction tracer config options and the Slow SQL config options. If applicable for your application's agent language, you can also edit basic slow query settings by using server-side configuration. Slow queries metrics The slow queries list contains the following metrics: Metric Description Response time The average response time for the statements sampled. Sample count The number of slow queries identified in the sample. To view additional details, select an individual slow query: Metric Description Start time When the stack trace began collecting the data shown. Max time The maximum time for all similar query statements in the sample. Action The action or process invoking the query. Query The query that is being reported as slow. Depending on your configuration, some parts of the query may be obfuscated. Stack trace Where in the code the statement was called. For MySQL, we provide a query analysis, which explains what happened in your query and what you might do to speed it up. Other databases display an explain plan whenever possible. Troubleshooting: No slow query data If you do not see slow query data, it may be for any of these reasons: The slow query feature has been disabled. The threshold is set to too high a duration and no slow queries are being reported. The query obfuscation setting (usually record_sql or similar) may be set to Off. To solve the problem, try adjusting the configuration options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 76.24568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>: No slow query data",
        "tags": "<em>APM</em>",
        "body": "In <em>APM</em>, when transaction traces are collected, there may be additional Slow query data available on the Databases page. Let&#x27;s look at what slow query data is, where to find it, and how to configure it. You can also use histograms and heatmaps to visualize the distribution of values for different"
      },
      "id": "604407dae7b9d26489579a05"
    },
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2021-12-30T14:51:07Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 61.090652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>APM</em> agents",
        "tags": "<em>Troubleshooting</em>",
        "body": " common issues. For additional <em>troubleshooting</em> tips, see the agent-specific docs.  <em>APM</em> agents Follow the <em>troubleshooting</em> procedures for your <em>APM</em> agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these <em>troubleshooting</em> steps that apply to all <em>APM</em> agents: Deleted or renamed"
      },
      "id": "603e8f2928ccbccc87eba750"
    }
  ],
  "/docs/using-new-relic/user-interface-functions/view-your-data/supported-browsers-new-relics-ui": [
    {
      "sections": [
        "Use workloads",
        "Health",
        "Activity",
        "Owner",
        "Header",
        "Create a workload",
        "Use tags to define the workload content",
        "How the dynamic query logic works",
        "Add dashboards to workloads",
        "Use the API"
      ],
      "title": "Use workloads",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "c39090bde9b797940e7f5ba0c9610ba39879677b",
      "image": "https://docs.newrelic.com/static/14c811e218cfc8793bb4d2bd4b2aad0b/c1b63/new-relic-workloads-add-dashboards.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/use-workloads/",
      "published_at": "2021-12-30T18:57:47Z",
      "updated_at": "2021-12-30T18:57:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view workloads, go to one.newrelic.com and find them on the Explorer. There are three main tabs (Health, Activity, and Owner) plus the header. Health The Health tab in a workload provides relevant status data that helps you operate the workload: It shows the global status of the workload, as well as the individual status of all the entities that make up the workload at each point in time. It looks like this: It comprises the following: The navigator view shows the entities that make up the workload, and provides controls to group and sort them. If you’ve used queries to dynamically select entities, the workload entities will change over time. The workload status informs about how your workload is performing, based on the individual alerting status of the entities in your workload. With health over time you’ll see whether and how the workload status has changed in the past three hours. If one or more entities are alerting, you’ll get a count of criticals and warnings and a summary of the open conditions, which will make it easier to identify and troubleshoot the most important issues. Activity The Activity tab shows performance data related to the entities in the workload, along with the events that could explain any changes in those time series. It looks like this: Here are the most important sections: Linked dashboards. You can add links to dashboards from your workload, and create pre-filtered, workload-relevant links to dashboards. Golden metrics. These are charts with the most relevant metrics for each entity type, such as number of requests, response time, and error rate for an application. Explore the charts to detect correlations among different entities (for example, two applications) and different stack layers (for example, applications and hosts). The golden metrics that you see for each entity type on a workload can be customized either at the account or the workload level through the NerdGraph API. Events timeline. This includes the start and end time of incidents and anomalies that refer to the workload entities. It also shows other event types that can explain a change in the status or performance of the workload, such as deployments and configuration changes. You can control which golden metrics are used to visualize your workload entities by using the golden metrics API. To learn more, watch this short video (approx. 4 minutes). Owner The Owner tab gives you information about the team responsible for the workload. It looks like this: It contains: The team responsible for the workload. You can include more than one team. The workload description. Share the mission of the workload, and the business logic it represents: Is it a web application? An API? A backend process? Fill in any details that are relevant to your team, or to other teams in your organization. Contact information. From the drop-down menu, choose how your team prefers to be contacted. Links to the most relevant resources to operate the workload. Here you can add links to runbooks, code repositories, productivity tools, or anything else related to the workload that you need at hand. Header The header contains the filter bar and the edition controls: Filter bar. Use the advanced filtering options when you need to focus only on certain entities within the workload. Edit workload. Define the entities that are part of the workload, and the accounts they’ll be fetched from. Setup status. Configure how the global workload status will be determined, based on the workload entities health. Summary page. See all the tags that have been added to the workload, as well as metadata such as the workload's identifier (GUID) and account. You can create workloads that update dynamically by leveraging tags. To learn how, watch this short video (approx. 3 minutes). Create a workload A workload should contain the entities you and your team want to see. Your choice of entities depends on your organization structure and goals. one.newrelic.com > Explorer > Workloads > Create a workload: When you create a workload, you choose the associated accounts and monitored entities. You can use New Relic One or the NerdGraph API to create a workload. Follow these steps to create a workload using the UI: Go to one.newrelic.com and click on the Explorer, and then click + Create a workload. Give the workload a name that will be meaningful for you and your team later. From the Select an account dropdown, select the workload account you'd like to use. Click Choose the scope accounts to check all of the accounts related to this workload. Find and choose the entities that make up the workload. When you have the results you're looking for, you can add specific entities or add the query to dynamically update the entities in the workload. You can search by entity type, tags, or attributes (like entity name, account ID, and AWS region). Click + Add this query to create a list of dynamically updated entities for your workload. We recommend this if you want your workload to update its entities as your system changes. Click + Add next to an entity to add it to your workload. This is a good choice if you know that the entities will stay useful even as your system changes. You can add a combination of queries and specific entities to the workload, which combine according to the query logic. Click Create a workload to save the workload. Once you've created the workload, you can edit it at any time If your workload contains one or more dashboards, you can set filters on those dashboard links. Below are more details about some aspects of how to define workloads: Use tags to define the workload content You can query and select workload entities using both tags and attributes. Therefore, to optimize your use of workloads, it helps to have a good entity-tagging strategy. We recommend reading the tagging documentation. How the dynamic query logic works You can add several individual entities and queries to define a workload. Queries can include multiple search terms. These are combined with an AND operator. Separate queries within a workload are combined with an OR operator. You can wrap strings between percent signs (%) to match exact substrings within a query. If you use substrings in entity names to categorize those entities (for example, <team>-<env>-<appName>), consider using tags complementarily, which are more powerful for filtering and grouping (for example, team:awesome, env:production). We recommend not to use percent signs (%) in dynamic queries that might return over 500 entities. This way, you get a more consistent experience in the user interface. Add dashboards to workloads If you have custom dashboards and you already know which data is relevant to your team for observing and operating their workloads, you can link those dashboards from your workload. You can also set filters on dashboards to scope them to a workload-specific context. When a user selects that dashboard from the workload, it opens with the filter already applied. one.newrelic.com > Apps > Workloads: You can add dashboards to a workload. To add dashboards to a workload: When creating or editing a workload, type Dashboard in the workload search bar to filter to dashboard entities. Add other search terms to filter to specific dashboards. Click Add. one.newrelic.com > Apps > Workloads: You can set filters on the dashboards you've linked to a workload. To filter a workload’s dashboard: From a workload’s Overview page, select a dashboard. Add search terms to filter the dashboard to a view that’s relevant for that workload. Select Save filter for this workload. Use the API You can query, create, and update workloads with our NerdGraph API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.85522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> workloads",
        "sections": "<em>Use</em> workloads",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of entities depends on your organization structure and goals. <em>one</em>.newrelic.com &gt; Explorer &gt; Workloads &gt; Create a workload: When you create a workload, you choose the associated accounts and monitored entities. You can <em>use</em> <em>New</em> <em>Relic</em> <em>One</em> or the NerdGraph API to create a workload. Follow these steps"
      },
      "id": "603e81e8196a67c972a83db1"
    },
    {
      "sections": [
        "Metric normalization rules",
        "Metric normalization rules management"
      ],
      "title": "Metric normalization rules",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "3c55e4717f145ac7ae0d88e860878f4e8d18cd6b",
      "image": "https://docs.newrelic.com/static/83edfb6f5b1b68712cac34d138bb8cb8/3996e/create-new-rule-window.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/metric-normalization-rules/",
      "published_at": "2021-12-30T02:16:02Z",
      "updated_at": "2021-12-04T18:10:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There may be cases where an application sends many individual metrics that could be better managed in groups. Most of these occur with web transactions metrics named from URLs. For more information on this issue, see Metric grouping issues (MGIs). To reduce high cardinality and prevent metric grouping issues, New Relic supports rules for grouping or filtering out metrics (normalization). In some cases, when MGIs with a significant high number of metrics are detected, a rule is created automatically to protect the platform from performance degradation. Metric normalization rules management You can create and manage new rules that deal with the noise produced from high cardinality metrics by using the metric normalization tool, which is accessible from each service dashboard in the New Relic Explorer. Once there, select Metric Normalization in the left sidebar. There you can see the existing rules or create new ones. Click a rule to modify it, or click Create a new rule to create a new one. A new pane to configure the rule will be displayed. Available fields are: Match expression: enter the regular expression to group all the metrics you want to include in the rule. Matches: here you will see a preview of the metrics matched by the regular expression above. Action: the action you want to perform on the metrics. Replace: replace the matched metrics by the regular expression with the value described in the Replacement field. Ignore: ignore any metric that matches the regular expression. Deny new metrics: only write metrics that have already been reported, and ignore those that match the regular expression. Replacement: only active when Replace is enabled. Matched metrics are replaced with the field's value. If the regular expression is capturing groups, you can use placeholders for them with \\1 or \\2 for the groups 1 and 2 respectively. Active: rules can’t be deleted, but can be deactivated. Click the toggle to enable or disable the rule. If you want the rule to be removed, reach out to New Relic's support. Terminate: When enabled, the rules waterfall is exited when the associated pattern is matched. Notes: internal notes on the rule. Has no effect on the rule. Once you have set up the fields, click Create (or Edit in case you are editing an existing rule), and the rule will be applied immediately as long as it's Active.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.99162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " grouping issues, <em>New</em> <em>Relic</em> supports rules for grouping or filtering out metrics (normalization). In some cases, when MGIs with a significant high number of metrics are detected, a rule is created automatically to protect the platform from performance degradation. Metric normalization rules management You"
      },
      "id": "603e810b64441ff3a74e8862"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-12-30T06:11:17Z",
      "updated_at": "2021-12-25T14:30:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters Allowed characters: Characters must be UTF-8. When using NerdGraph to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. And check out this short video on querying APM tags (3:20 minutes). Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.81107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize <em>and</em> find your <em>data</em>",
        "sections": "<em>Use</em> tags to help organize <em>and</em> find your <em>data</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " solution. Tip Tags were previously called labels in the <em>New</em> <em>Relic</em> <em>UI</em>. You may sometimes see labelin our code; for example, some of our APM agent config files <em>use</em> a label config option for tags. Tag format and limits Format requirements and limits for tags: The <em>UI</em> has limits on the total number of tags"
      },
      "id": "603ebd1228ccbc6278eba754"
    }
  ],
  "/docs/using-new-relic/welcome-new-relic/get-started/cloud-services-integrations": [
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "97b0a696cf7f831d225ecc76fb79b81599d1fc83",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-12-30T10:34:07Z",
      "updated_at": "2021-10-30T16:11:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations and quickstarts for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 65.63122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Instrument</em> <em>everything</em>",
        "body": " functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of <em>services</em>. It comes bundled with our infrastructure agent. You can <em>instrument</em> any app that exposes metrics over a standard protocol (HTTP, file, shell"
      },
      "id": "617d6ec5196a673341f7cebc"
    },
    {
      "image": "https://docs.newrelic.com/static/d2a9c929c7541b67b6fe4c87844fc01b/ae694/prometheus_grafana_dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2020/08/create-grafana-dashboards-prometheus-data-stored-new-relic/",
      "sections": [
        "Create Grafana dashboards with Prometheus data stored in New Relic",
        "Step 1: Get data flowing into New Relic with the Prometheus remote write integration",
        "Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic"
      ],
      "published_at": "2021-12-30T22:01:15Z",
      "title": "Create Grafana dashboards with Prometheus data stored in New Relic",
      "updated_at": "2021-10-19T05:58:32Z",
      "type": "docs",
      "external_id": "da09ab47a2ac806ad3ed1fa67e3a02dd54394383",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’ve teamed up with Grafana Labs so you can use our platform as a data source for Prometheus metrics and see them in your existing dashboards, seamlessly tapping into the reliability, scale, and security provided by New Relic. Follow the steps below or use this more detailed walkthrough to send Prometheus data to New Relic, so that Grafana can populate your existing Prometheus-specific dashboards with that data. This process requires Prometheus version 2.15.0 or higher and Grafana version 6.7.0 or higher. You’ll also need to sign up for New Relic. Here's an example of how these Grafana dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to Instrument Everything – US or Instrument Everything – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get your remote_write URL. For more information on how to set up the Prometheus remote write integration, check out our docs. Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic For more information on how to configure New Relic as a Prometheus data source for Grafana, check out our docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 57.428844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to <em>Instrument</em> <em>Everything</em> – US or <em>Instrument</em> <em>Everything</em> – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get"
      },
      "id": "60445821e7b9d23b585799e4"
    },
    {
      "image": "",
      "url": "https://opensource.newrelic.com/",
      "sections": [
        "Open standards. Open instrumentation. Open collaboration.",
        "Instrumentation projects",
        "Projects that we support",
        "Explore our projects",
        "Projects we sponsor"
      ],
      "published_at": "2022-01-02T01:38:28Z",
      "title": "Home",
      "updated_at": "2021-11-13T01:38:17Z",
      "type": "opensource",
      "external_id": "b7edd20013fd77e66b76c01dd31fb2d8150d1b6e",
      "document_type": "page",
      "popularity": 1,
      "info": "",
      "body": "External Projects Highlighted Projects New Relic Projects Standards Menu External Projects Highlighted Projects New Relic Projects Standards Open standards. Open instrumentation. Open collaboration. We built this site to make it easy for you to explore the open source projects we maintain and the open standards projects we participate in. Learn more. Instrumentation projects Instrument everything with our open source agents, tools, and sdk's or see other highlighted collections. Explore open source instrumentation Projects that we support New Relic contributes resources to the development of these projects. Explore our projects Check out some of the products that we’re developing in open source or view all projects. Projects we sponsor New Relic supports 50+ organizations and developers. Find out more here.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 51.99054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Open standards. Open <em>instrumentation</em>. Open collaboration.",
        "body": " and the open standards projects we participate in. Learn more. Instrumentation projects <em>Instrument</em> <em>everything</em> with our open source agents, tools, and sdk&#x27;s or see other highlighted collections. Explore open source instrumentation Projects that we support New Relic contributes resources to the development"
      },
      "id": "5f3180f7196a6739fffbd71c"
    }
  ],
  "/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability": [
    {
      "sections": [
        "New Relic guided install overview",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "78c43fb865811c44f388f0601e0fb5f7da82fe87",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/new-relic-guided-install-overview/",
      "published_at": "2021-12-30T20:03:34Z",
      "updated_at": "2021-12-14T03:50:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you haven't already, sign up for a free New Relic account so you can instrument your systems and send telemetry data to New Relic. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. Or, if your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.92072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Observe</em> <em>everything</em>",
        "body": "If you haven&#x27;t already, sign up for a free New Relic account so you can instrument your systems and send telemetry data to New Relic. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em>"
      },
      "id": "61b8148c64441fb9d3d703b5"
    },
    {
      "sections": [
        "Service Levels Management: Questions and next steps",
        "BETA FEATURE",
        "What permissions do I need to use New Relic's Service Levels?",
        "How do I get support from New Relic during the public beta?",
        "Why don’t I see any data right after I create an SLI?",
        "Can I configure an SLI on any entity type?",
        "Can I get alerts on SLI data?",
        "How does New Relic calculate the remaining error budget?",
        "How can I view the queries that define an SLI from the UI?",
        "How can I view the queries that define an SLI through the API?",
        "Can I chart the SLI attainment on a dashboard?"
      ],
      "title": "Service Levels Management: Questions and next steps",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Service Level Management"
      ],
      "external_id": "262058f4dc430fbaee0382261f79de147e348f53",
      "image": "https://docs.newrelic.com/static/763695119ceaa7668fdb3fb858c83c75/c1b63/slm_edit_menu_2.png",
      "url": "https://docs.newrelic.com/docs/service-level-management/faqs-slm/",
      "published_at": "2021-12-30T03:43:10Z",
      "updated_at": "2021-12-25T02:33:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. What permissions do I need to use New Relic's Service Levels? To use New Relic's Service Levels and see SLO results, you need a full platform user. However, in order to create new SLIs and SLOs, you need the specific capability in your role to modify events to metric rules. If you get the following errors, check your user permissions: The UI has disabled the option to save an SLI/SLO. The API returns the error message “Cannot query field \\\"eventExportRegisterRule\\\" on type \\\"RootMutationType\\\".”. How do I get support from New Relic during the public beta? Service Levels Management is in public beta, and no official support is offered yet through the Support portal. If you have general questions and feedback, please post them on the Explorers Hub. New Relic’s community and the product team will be glad to help you there. If you have suggestions about documentation, please suggest an improvement or send your contribution using the Create issue or Edit page buttons on the top right corner in the docs UI. Why don’t I see any data right after I create an SLI? New Relic starts generating new SLI metrics from the moment that you create an SLI. This is why we need a few minutes before we can start showing the first meaningful SLI attainment results. The benefit of the new data is that it has 13 month retention by default, and it’s more efficient to query for long periods of time. Can I configure an SLI on any entity type? Yes, you can configure an SLI on any entity type, such as an APM service, a browser application, or a Lambda function. SLI queries support NRDB events. Support for dimensional metrics on SLI queries is on our roadmap. Can I get alerts on SLI data? Alerts on New Relic's Service Levels are on our roadmap. How does New Relic calculate the remaining error budget? The remaining error budget indicates what percentage of requests could still have a bad response over the SLO period without compromising the objective. Therefore, the total amount of tolerated bad responses will vary with the throughput of requests. Time-based error budgets are on our roadmap. How can I view the queries that define an SLI from the UI? To view the queries that define an SLI, you can click on the ... menu on the SLI summary card, then select the Edit option. The queries will show at the top-right corner. How can I view the queries that define an SLI through the API? To view the queries that define an SLI through the API, use Nerdgraph. In order to view the SLI configuration, you'll need to know the GUID of the entity the SLI is attached to, and replace it in the following query: { actor { entity(guid: \"{entityGuid}\") { serviceLevel { indicators { events { badEvents { where from } goodEvents { from where } validEvents { from where } } name } } } } } Copy As a response you are going to receive all the SLIs attached to the entity, the SLI name, and the queries. Keep in mind that either goodEvents or badEvents is going to have content, depending on the configuration of the SLI. Can I chart the SLI attainment on a dashboard? You can chart SLI attainment time series on your custom dashboards using the following query: FROM Metric SELECT clamp_max((count(newrelic.sli.valid) - count(newrelic.sli.bad)) / count(newrelic.sli.valid) * 100, 100) as 'SLI attainment' WHERE sli.id = '<sli.id>' UNTIL 2 MINUTES AGO TIMESERIES AUTO Copy Where sli.id is the SLI identifier. The easiest way to add a chart like this to your dashboard is by using the Add to dashboard option, available on the Details view. Alternatively, you can find the SLI id and SLI attainment query through the Nerdgraph API with the following query: { actor { entity(guid: \"{entityGuid}\") { serviceLevel { indicators { name id resultQueries { indicator { nrql } } } } } } } Copy Use the entityGuid of the entity that's associated with the SLI. On the query results, you’ll get the SLI id in the serviceLevel.indicators.id field.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.82178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "How do I <em>get</em> support from New Relic during the public beta?",
        "tags": "<em>Observe</em> <em>everything</em>",
        "body": " events to metric rules. If you <em>get</em> the following errors, check your user permissions: The UI has disabled the option to save an SLI&#x2F;SLO. The API returns the error message “Cannot query field \\&quot;eventExportRegisterRule\\&quot; on type \\&quot;RootMutationType\\&quot;.”. How do I <em>get</em> support from New Relic during"
      },
      "id": "61ab3a9d28ccbc492ac23ee2"
    },
    {
      "sections": [
        "Get started with New Relic's Service Levels Management",
        "BETA FEATURE",
        "What are SLIs and SLOs?",
        "Service Levels and APM SLA reports",
        "What's next?"
      ],
      "title": "Get started with New Relic's Service Levels Management",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Service Level Management"
      ],
      "external_id": "c3da65667ad9557562bd537c738309d80d3f31ee",
      "image": "https://docs.newrelic.com/static/a0a3554edde9777dc70c4ee8281fddd6/01e7c/slm1_1.png",
      "url": "https://docs.newrelic.com/docs/service-level-management/intro-slm/",
      "published_at": "2022-01-02T01:45:43Z",
      "updated_at": "2021-12-02T01:44:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With New Relic you can define and consume service level indicators and service level objectives for your applications. What are SLIs and SLOs? Service Levels are used to measure the performance of a service from the end user (or client application) point of view. For instance, a Service Level can represent whether a video loaded quickly enough, or whether a directions service returned at least one possible route between two points. Service level indicators (SLIs) are accurate quantitative measures of the user experience as described by a service level. They represent a proportion of successful outputs, and therefore they’re expressed as a percentage (%). For example, an SLI can measure the proportion of requests that were faster than some threshold, or the proportion of records coming into a pipeline that resulted in the correct value coming out. And while users understand that a video might take a few additional seconds to load, or that an application might return an error from time to time, this shouldn’t happen often if you don’t want to lose their trust. Therefore, once you’ve defined SLIs for the performance aspects that are most relevant for the end users of your services, you need to set SLOs to track that the service is meeting their expectations. Service level objectives (SLOs) are defined as a target value that an SLI must meet over a period of time. For example, videos must start playing in less than 2 seconds 99% of the time over a week period. Please refer to the Service Level management use case implementation guide to learn more about identifying service boundaries and deploying the instrumentation that your service levels will be based on. Service Levels and APM SLA reports New Relic has provided automatic SLA Reports for APM Services for a long time. The Apdex-based reports, which you can get on your email inbox on Mondays, are automatically generated for services that produce web transactions, and are useful to see trends over time. On top of the SLAs, our new SLM level capability is better aligned with modern service level best practices, such as those promoted by the Google SRE Handbook, and provides new, improved functionality: SLIs can be defined on any NRDB event that is reported to New Relic, not just APM transactions. Therefore you can also base SLIs on your own custom events. You can decide which service boundaries and which metrics are relevant for your service levels, and you can set your own objectives. You can view SLO results across your accounts, and within your workloads. What's next? Ready to get started? If you don't already have one, sign up for a free New Relic account. You can find Service Levels in several places in New Relic One: At the top nav bar, under the More menu (which you can customize). At the previews of those entities that have an SLI defined. In APM services, at the reports section. Within a workload, at the Service Levels tab. Carry on and read our docs on how to create and consume SLIs and SLOs. You can also check out how to manage SLMs with our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.94371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic&#x27;s Service Levels Management",
        "sections": "<em>Get</em> <em>started</em> with New Relic&#x27;s Service Levels Management",
        "tags": "<em>Observe</em> <em>everything</em>",
        "body": " decide which service boundaries and which metrics are relevant for your service levels, and you can set your own objectives. You can view SLO results across your accounts, and within your workloads. What&#x27;s next? Ready to <em>get</em> <em>started</em>? If you don&#x27;t already have one, sign up for a free New Relic"
      },
      "id": "61a824fe28ccbcc5e3c22dc5"
    }
  ],
  "/docs/using-new-relic/welcome-new-relic/get-started/intro-new-relic": [
    {
      "sections": [
        "Glossary of New Relic terms",
        "account dropdown",
        "account switcher",
        "administrator",
        "agent",
        "agent API",
        "aggregated metrics",
        "aggregation delay",
        "aggregation function",
        "aggregation method",
        "aggregation timer",
        "aggregation window",
        "alert",
        "alert condition",
        "alert evaluation",
        "alert policy",
        "apdex",
        "apdex_f",
        "apdex_t",
        "API (application programming interface)",
        "APM",
        "application",
        "application ID",
        "application name",
        "Applied Intelligence (AI)",
        "attribute",
        "availability monitoring",
        "browser",
        "Browser monitoring",
        "background external",
        "child account",
        "cloud-based integration",
        "collector",
        "Command line interface (CLI)",
        "compute unit (CU)",
        "condition_id",
        "CPM (calls per minute)",
        "CPU burn",
        "custom attribute",
        "custom dashboard",
        "custom event",
        "custom instrumentation",
        "custom metric",
        "data collector",
        "data explorer",
        "degradation period",
        "dimensional metric",
        "Docker",
        "downtime",
        "entity",
        "event",
        "expected error",
        "exporter",
        "Flex",
        "framework",
        "harvest cycle",
        "health status indicator",
        "host",
        "host ID",
        "ignored error",
        "incident",
        "Infrastructure monitoring",
        "Insights",
        "instance ID",
        "instrumentation",
        "integration",
        "interaction",
        "interaction trace",
        "inventory data",
        "key transaction",
        "launcher",
        "log",
        "Log monitoring",
        "Logs",
        "Logs in context",
        "master account",
        "metric",
        "metric timeslice",
        "metric grouping issue",
        "minion",
        "Mobile monitoring",
        "monitor",
        "NerdGraph",
        "Nerdlet",
        "Nerdpack",
        "New Relic Edge with Infinite Tracing",
        "New Relic One",
        "New Relic One catalog",
        "NRQL (New Relic query language)",
        "non-web transaction",
        "notification",
        "notification channel",
        "on-host integration",
        "owner",
        "page load timing",
        "parameter",
        "parent account",
        "permalink",
        "pinger",
        "polling interval (AWS)",
        "PPM (pages per minute)",
        "private location",
        "recovery period",
        "response time",
        "restricted user",
        "rollup",
        "root span",
        "RPM",
        "RUM (real user monitoring)",
        "runbook",
        "SAML (Security Assertion Markup Language)",
        "Selenium",
        "service",
        "signal",
        "signal filter",
        "span",
        "SSL certificate",
        "SSO (single sign on)",
        "streaming algorithm",
        "sub-accounts",
        "Synthetic monitoring",
        "target",
        "tag",
        "thresholds",
        "throughput",
        "tier",
        "time picker",
        "time range",
        "timeslice data",
        "trace",
        "traffic light",
        "transaction",
        "transaction trace",
        "UI",
        "user",
        "UTC",
        "value function (metrics)",
        "violation",
        "web external",
        "web transaction",
        "WebDriverJS",
        "workload"
      ],
      "title": "Glossary of New Relic terms",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "8f8fc1ec9f41e6a4d6b4e986e9b0589bc2ca1f86",
      "image": "https://docs.newrelic.com/static/44172b3e07c1f24191825360676b9d99/c1b63/account-dropdown.png",
      "url": "https://docs.newrelic.com/docs/glossary/glossary/",
      "published_at": "2022-01-02T01:50:10Z",
      "updated_at": "2021-12-18T01:39:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you're considering New Relic One or you're already using our capabilities, this glossary of common terminology can help. And if you don't already have a New Relic account, don't hesitate to sign up at newrelic.com/signup. It's free, forever! account dropdown In the upper right of the New Relic UI, the account dropdown gives you access to your account settings. If you're trying to switch between accounts, use the account switcher. account switcher If you have access to more than one account in a multi-account organization, you can use the account switcher to switch between accounts. This is located in the top right of most New Relic UI pages. For more on factors that affect access to accounts, see Factors affecting access. To find account settings, use the account dropdown. administrator A type of user role on a New Relic account. For more information, see Users. agent At New Relic, an agent is a piece of monitoring software that provides integrations with various technologies (for example, web frameworks, host operating systems, or database types). The agents send that data to New Relic, usually on a specific cadence. For more information, see: New Relic Instant Observability Install agents agent API Some New Relic agents have agent APIs that allow you to extend the functionality of an agent. You can use the API to control, customize and extend the functionality of the agent. Here are some agent API docs: APM agents: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Ruby agent API Python agent API Browser agent: Browser agent API Mobile agents: iOS SDK API Android SDK API aggregated metrics Aggregated metric data summarizes calls to specific methods in your application, including how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on the New Relic tool and your subscription level. For more information, see the documentation about data retention. aggregation delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. aggregation function You can use NRQL query functions, such as sum(), average(), or latest() to choose how the data points in an aggregation window should be processed into a single data point. The single aggregated data point is what's passed through the alert evaluation process. aggregation method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics) CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer setting. The Timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. aggregation timer The length of time in seconds to wait after each data point received, to ensure the entire batch is processed. Required when using EVENT_TIMER aggregation_method type. aggregation window Streaming alerts gathers data together into specific amounts of time. These windows of time are customizable. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. alert An alert communicates an event or incident that designated personnel can track through Alerts. For an explanation of how basic alerts concepts are related, see Concepts and workflow. alert condition An alert condition (or condition), identified by its unique numeric condition_id, contains the criteria for creating a violation. The condition includes the threshold that is set for a metric timeslice or a custom metric over time on a chosen target. For an explanation of how a condition relates to other basic alerts concepts, see Concepts and workflow. alert evaluation Streaming data is assessed on a set of aggregation windows to determine if an alert condition is violating or recovering. The aggregation window time is how long we'll collect data before running the NRQL query condition. The offset evaluation time is how long you want us to wait for late data before assessing it. If a window doesn't have any data points, it's treated as a gap for loss of signal. alert policy A collection of one or more conditions, one or more notification channels, and an Incident preference setting. If a condition contained within the policy opens a violation, an incident may be opened depending on the Incident preference setting. Notifications will then be sent to all channels attached to the policy. For an explanation of how a policy relates to other basic alerts concepts, see Concepts and workflow. apdex Apdex is an industry-standard way to measure users' satisfaction with the response time of an application or service. New Relic rates each response as Satisfied, Tolerated, or Frustrated, and uses these ratings to calculate an overall user satisfaction score. For more information, see Apdex: Measure user satisfaction. apdex_f The response time above which a transaction are rated frustrating. Defaults to four times apdex_t. Requests that complete in less than apdex_t are rated satisfied. Requests that take longer than apdex_t, but less than four times apdex_t (apdex_f), are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. apdex_t The response time above which a transaction is considered tolerable. The default value is 0.5 seconds, but you can change this in your Apdex settings. Requests that complete in less than apdex_t are rated satisfied. Requests that take more than apdex_t, but less than apdex_f, are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. API (application programming interface) New Relic offers a variety of APIs and SDKs. For more information, see the introduction to New Relic's APIs. APM New Relic's APM (application performance monitoring) provides monitoring of your web or non-web application's performance. APM supports apps using several programming languages. application For New Relic purposes, any program instrumented by New Relic. application ID Some New Relic solutions assign a monitored application a unique application ID, often shortened to app ID. When present, this ID is available in the UI. It is also reported as an attribute and can be queried. For how to determine this, see Find app ID. application name The name that New Relic combines with your license key to uniquely identify a particular app. For more information, see Name your application. Applied Intelligence (AI) Applied Intelligence (AI) helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. Applied Intelligence includes Alerts, Incident Intelligence, and Proactive Detection. attribute Attributes are key-value pairs attached to data objects reported to New Relic. Attributes add detail, and they're similar to tags or labels in other SaaS software. You can explore this data by querying or searching via the UI or by using the data dictionary. Examples: APM reports a Transaction event. This includes timing data for the transaction in a duration attribute, which might have a value of .002. Our Infrastructure Monitoring reports a ProcessSample event. This includes a variety of CPU usage attributes, including a cpuSystemPercent attribute, which might have a value of .01. Our Telemetry SDK reports a Metric data type for storing metrics, with attached attributes like metricName and newrelic.source. Some New Relic tools allow you to report custom attributes to enhance your monitoring. For more information about attributes in APM, see Agent attributes. availability monitoring See Types of Synthetics monitors. browser The New Relic UI supports most browsers. For more information, see Supported browsers. For our end-user browser monitoring tool, see Browser Monitoring. Browser monitoring A Real User Monitoring (RUM) solution that measures the speed and performance of your end users as they navigate to your site from different web browsers, devices, operating systems, and networks. background external See web external. child account See parent account. cloud-based integration New Relic offers cloud-based integrations with providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. collector The component that collects data from New Relic agents running on an app server, mobile device, or end-user browser. While the agent is installed on a user's app server, the collectors are centrally located in New Relic's data center. In order to contact the collector, the agent must be able to reach New Relic's domains and IP addresses. (The exact domain or IP depends on the New Relic monitoring tool.) The collector receives and interprets this data, and stores it in a database. The data is then retrieved and presented in the New Relic UI and by our various REST APIs. Command line interface (CLI) Our command line interface (CLI) is a tool you can use to build a New Relic application. This is the same tool our own engineers use. Go here for quick start instructions. Go to our Developer site for sample apps and guides. compute unit (CU) A unit of measurement that determines your pricing for some New Relic products governed by our original product-based pricing model. For more information, see Compute unit pricing. condition_id See alert condition. CPM (calls per minute) The number of calls your application receives each minute. This usually corresponds to the number of page views or external connections, and is usually the same as RPM (requests per minute). CPU burn The time consumed by code minus the wait time for a transaction. This is the time actually spent processing the transaction. It appears in the New Relic UI at the top of the transaction view for the agents that provide it (Ruby and PHP only). custom attribute A key-value pair added to a transaction or event in order to gain additional information about it. For more information, see custom attributes. custom dashboard A customizable dashboard with charts and tables that includes data from multiple New Relic data sources. For more information, see dashboards. custom event An event, in New Relic terms, is a data object with attached attributes. New Relic reports default event types, like Transaction and TransactionError. You can also create your own events. Events can be queried, and are used in some other features. You can generate custom events with APM agents, the browser monitoring agent, the mobile monitoring agents, and via the Event API. Alternatively, you can add custom attributes to some existing default New Relic events. custom instrumentation Custom instrumentation allows you to extend New Relic's monitoring to instrument code elements New Relic doesn't automatically instrument. Custom instrumentation is useful when your framework is not supported by New Relic, or when New Relic fails to pick up some element of your program. You can also use custom instrumentation to block a transaction from being reported entirely. For more information, see Custom instrumentation. custom metric Metric timeslice data that is manually recorded via an API call. Custom metrics allow you to record arbitrary metrics; for example, timing or computer resource data. All custom metric names must be prefixed with Custom/. For more information, see Custom metrics. Not to be confused with custom instrumentation data. data collector See collector. data explorer Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. For more on using the data explorer, see Introduction to the data explorer. degradation period When a data source enters a violating state, a degradation period of time begins. The degradation period is set in the condition's threshold. A violation will open if the source stays in a violating state for the entire degradation period. In addition: If the data source enters a non-violating state before the entire time has elapsed, the degradation period countdown is reset, and a violation does not open. If your alert condition threshold is configured as at least once in, the degradation period always lasts a single minute. dimensional metric A dimensional metric is a metric that has multiple attributes, also known as dimensions. At New Relic, we report dimensional metrics using the Metric data type. For more on other metric data types, see Metric data. Docker An open platform for distributed applications, which allows you to assemble multi-container portable apps. Infrastructure Monitoring includes integrated Docker monitoring. For more information about Docker, see the Docker website. downtime The period of time when customers cannot access your site and your app is not reporting to New Relic. For more information, see Synthetic Monitoring and Types of synthetic monitors. entity In New Relic, an entity is anything we can identify that has data you can monitor. An entity can be something you monitor directly, like applications and microservices, or indirectly, like data centers. You can identify one or more entities to be targets for alert conditions. In the Alerts API, the entity being monitored is identified with an entity_id. For more on this, see What are entities? event The word event is a general term that can have many meanings. At New Relic, event can have several meanings: At New Relic, event data is one of our core data types. Event data represents a record of a single event at a particular moment in time. Events can vary by type (for example, Transaction or Mobile, and will have associated attributes (for example, timestamp or transactionName). For more details, see Event data. For our infrastructure monitoring, the word event can be used to refer to important system and host activity. For example, a configuration change for a monitored host would be registered on Infrastructure's Events UI page. For alerts, the Events UI page displays a list of alerts-related incidents for your monitored entities. Events are reported for a violation opening and for closing. In some contexts, event can refer to any NRQL-queryable data type. For example, when you run a NRQL query, you will see a count of inspected events: this refers to a count of all data types queried. expected error An expected error is a common error that you don't want to affect your Apdex score or error rate. For more information, see Manage errors in APM. exporter At New Relic, an exporter is a type of integration that reports telemetry data to New Relic from a third-party (non-New Relic) telemetry tool. For examples, see Exporters, or search our integration quickstarts in New Relic I/O. Flex New Relic Flex is an application-agnostic, all-in-one infrastructure integration. With it, you can build your own integration that collects metric data from a wide variety of services, and that can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text) to the terminal. It's a recommended way to create a custom integration, because it doesn't require coding skills. framework A framework is a structured collection of pre-defined functions, into which an application builder inserts their own code to build their application. A framework is not the same as a library. While a library is a collection of functions you can call as needed, a framework is a skeleton for your application. The functions in that framework then call your functions. For more about the distinction between a framework and a library, see What is the difference between a framework and a library?. New Relic automatically instruments many common frameworks. For more about the frameworks New Relic supports, see the agent-specific documentation: C SDK supported frameworks Go supported frameworks Java supported frameworks .NET supported frameworks Node.js supported frameworks PHP supported frameworks Python supported frameworks Ruby supported frameworks harvest cycle The period of time between each connection from a New Relic agent to the collector. Between harvest cycles, an agent collects and caches data. At the end of the cycle an agent reports those data to the collector, then begins a new harvest cycle. health status indicator Some New Relic UI pages have a health status indicator appearing next to an index of monitored entities. This is a colored bar (generally green, yellow, red, or gray) indicating the status of your app or other entity monitored by New Relic. It also indicates whether the entity has any alert policies assigned to it and whether there are any policy violations. In general, the colored bar will be green, yellow, red, or gray to indicate the health status. Exceptions: Our REST API (v2) uses orange instead of yellow for the application's health and reporting status. Service maps use different criteria for reporting the health of a connection between an app and an external service not monitored by New Relic (for example, a third party API). host At New Relic, a host means one of the following: A physical machine is a hardware-based device with dedicated physical resources, including memory, processing, and storage. Each machine has its own OS which applications run on. A virtual machine (VM) is the software implementation of a physical machine that executes programs like a physical machine. One or more virtual machines can run on a physical machine. Each virtual machine has its own OS and allocated virtual machine resources such as RAM and CPU. A cloud instance is a type of virtual machine that is run in the public cloud. In this context, virtual machines and cloud instances are different from Java Virtual Machines (JVMs) and containers. host ID Each host identified by APM is assigned a host ID. This ID is used to uniquely identify it, and to retrieve data about that host via the REST API. For more information, see List host ID. ignored error An error that you have told the APM agent not to report to the collector. For more information, see Manage errors in APM. incident An incident is a collection of one or more violations of the conditions defined in an alert policy. An incident record includes all of the open and close time stamps for each violation, as well as chart snapshots of the data being evaluated around the time of each violation. You can view detailed information from the Incidents pages in the user interface. You can also select your preference for how we roll up violations into the incident. For an explanation of how an incident relates to other basic alerts concepts, see Concepts and workflow. Infrastructure monitoring By connecting changes in host performance to changes in your configuration, infrastructure monitoring provides real-time metrics and powerful analytics that reduce your mean-time-to-resolution (MTTR). Infrastructure is specifically designed for complex environments that need flexible, dynamic server monitoring, from a physical datacenter to thousands of Amazon Elastic Compute Cloud (Amazon EC2) instances and other types of integrations. Insights Insights was the name for the New Relic product that previously governed the reporting of custom events, as well as the ability to query and chart your New Relic data. These features are now a fundamental part of the New Relic One platform and are no longer governed by the Insights product or name. To learn more about these features: Event API for reporting custom events Query and chart data For historical reasons, the word \"Insights\" is still used in some places. For example: Some APM agents still have Insights language in their codebase. For example, the Java agent custom_insights_events configuration. For New Relic organizations on our original pricing model, Insights Pro is still the product name governing custom event data ingest and retention. There is an API key called the Insights insert key. instance ID Each instance identified by New Relic is assigned a unique instance ID. Instance IDs are most commonly found for JVMs (Java Virtual Machines), but can exist for each agent. This ID is used to uniquely identify it, and to retrieve data about that instance via the REST API. For more information, see List instance IDs. instrumentation The collection of data from an application or host. When New Relic instruments a framework, it detects the methods and calls used by that framework, and intelligently groups them together. integration At New Relic, an integration refers to a solution that integrates with a specific technology (like a web framework or a type of database). All our integrations can be found as quickstarts in New Relic Instant Observability. interaction In our mobile monitoring, an interaction is a specific code path initiated by a user interaction (usually a button press). An interaction is the mobile equivalent of a transaction, and like a transaction an interaction can be traced and monitored. You can see much of the data included in an interaction in the BrowserInteraction event. interaction trace An interaction trace is a complete picture of a single interaction. With interaction traces, New Relic gives you much deeper visibility into a single slow interaction, which can help you understand a broader problem. Interaction traces are the mobile equivalent of a transaction trace. For more information, see Creating interactions (iOS) and Creating interactions (Android). inventory data Inventory data is information about the status or configuration of a service or host. Examples of inventory data include: Configuration settings Name of the host the service is on Amazon AWS region Port being used For more information, see Understand and use data. key transaction A web transaction that the user has marked as particularly important; for example, key business events (such as signups or purchase confirmations), or transactions with a high performance impact (such as searches). Key transactions have their own pages in the UI and other customized values. For more information, see Key transactions. launcher A launcher is a specific piece of code you can include when you create a New Relic One app. It creates the tile on the homepage that you click to launch the app. For more information, see the documentation about core UI components. log A log is a message about a system used to understand the activity of the system and to diagnose problems. For more information on how we use log data, see Log management. Log monitoring Our log management and monitoring features give you the tools to collect, process, explore, visualize, and alert on your log data using your existing log forwarder. With all of your log data in one place, you'll be able to make better decisions, detect and resolve problems more quickly, and see your logs in context to troubleshoot faster. Logs Our Logs feature is a scalable log management platform that allows you to connect your log data with the rest of your telemetry data. Pre-built plugins with some of the most common open-source logging tools make it simple to send your data from anywhere to New Relic. Logs in context Logs in context makes it easy to link to your log data with related data across the rest of our platform. Bringing all of this data together in a single tool allows you to quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. master account See parent account. metric A metric is a numeric measurement. Metric data is a broad category because there are several ways to make and report measurements. For more about how metrics are reported at New Relic, see New Relic data types. metric timeslice New Relic reports metrics in several ways. One variety of metric data is called metric timeslice data; this is the type of data used to generate many of the charts in APM, mobile monitoring, and browser monitoring (for more details, see metric timeslice data). Over time, metric timeslice data is aggregated into longer timeslice data records for more efficient storage. For more about how we aggregate this type of data, see Data aggregation. For how to query this type of data, see Query metric timeslice data. metric grouping issue A metric grouping issue occurs when an account sends too many differently named metric timeslice data points to New Relic, and those individual web transactions are not properly aggregated. For example, rather than a single /user/controlpanel/ metric name, you might see /user/controlpanel/alice, /user/controlpanel/bob, and /user/controlpanel/carol. For more information, see Metric grouping issues. minion The software that accepts monitor jobs from a private location. A minion is a packaged virtual appliance that runs in your hypervisor. For more information, see Private locations overview and install and configure private minions. Mobile monitoring Mobile monitoring allows you to monitor and manage the performance of your mobile apps on Android, iOS, tvOS, and other systems. Mobile monitoring provides end-to-end details, including crashes, throughput, HTTP requests, error traces, and more. Not to be confused with New Relic's own mobile apps for Android, iPhone, and iPad. monitor For our Synthetic Monitoring, a monitor ensures your website or API endpoint is available. For more information, see Adding and editing monitors. NerdGraph NerdGraph is our GraphQL API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph calls get all the data you need in a single request. NerdGraph also makes it easier to evolve APIs over time and enables powerful developer tools. You can use our NerdGraph GraphiQL explorer to explore the schema and find definitions. With valid New Relic API key, you can try it out yourself at api.newrelic.com/graphiql. Nerdlet A Nerdlet is a component of a New Relic One application. It's a specific UI view, represented by a React JavaScript package. For more information, see Nerdpack file structure. Nerdpack A Nerdpack is a component of a New Relic One application. It's the package containing all the files needed by that application. For more information, see Nerdpack file structure. New Relic Edge with Infinite Tracing New Relic Edge with Infinite Tracing is a fully managed, distributed tracing service that observes 100% of your application traces, then provides actionable data so you can solve issues faster. For more information, see /docs/understand-dependencies/distributed-tracing/get-started/how-new-relic-distributed-tracing-works. New Relic One For more information, see Introduction to New Relic One. New Relic One catalog Our catalog is a collection of applications built on the New Relic One platform. The catalog includes custom apps we've built, public open source apps, and any apps that you buid. You can browse the catalog on New Relic One. NRQL (New Relic query language) NRQL is a query language, similar in form to SQL, that allows you to query the data stored in your New Relic account. non-web transaction APM identifies transactions as either web or non-web. When New Relic does not detect a transaction was initiated by a web request, this is called a non-web transaction. For more information, see Background processes and other non-web transactions. notification The message sent when an incident opens, is acknowledged, or closes. The type of notification is defined by the alert policy's notification channel. For an explanation of how notifications relate to other basic alerts concepts, see Concepts and workflow. notification channel Where we send a notification when an incident opens, is acknowledged, or closes. Available channels include email, mobile push notifications, webhooks, and more. on-host integration On-host integrations refer to integrations that reside on your own servers or hosts and that communicate with our infrastructure agent. For more information, see Introduction to on-host integrations. owner For accounts on our original pricing model, this is a type of user role: the user who initially created the account. For more information, see Users. page load timing With page load timing, New Relic monitors the full load time for end-user browsers. New Relic's application agents dynamically inject JavaScript into the page, then capture the following key load points: Navigation start: The user initiates the transaction. First byte: The browser receives the requested page. DOM ready: The browser has finished parsing DOM. Page ready: Page loading is complete. Page load timing is sometimes referred to as RUM, or real user monitoring. Unlike standard RUM, page load timing also captures JavaScript errors and AJAX requests. For more information, see Page load timing process. parameter Deprecated term; see attribute. parent account New Relic organizations can have a parent/child account structure. This structure was much more important for organizations on our original user model, but is still used for some features for organizations on the New Relic One user model. Learn more about account structure. Parent accounts were previously referred to as \"master accounts\", and child accounts were previously referred to as \"sub-accounts\". permalink A unique URL that links to a view of your application at a specific point in time. Permalinks are useful for troubleshooting and for sharing interesting time windows with colleagues. pinger The component of New Relic that connects to your website to verify your website is accessible. New Relic has pingers in Europe, Asia, and the United States. Each pinger attempts to contact your website at least once every two minutes. If enough pingers are unable to reach your website, your application will be considered down. For in-depth scriptable testing, including real browser tests and tests of API endpoints, see Synthetic Monitoring. Synthetic Monitoring includes free ping monitoring, which allows you to monitor your website from locations around the world. For more information, see Types of Synthetic monitors. polling interval (AWS) Our Amazon integrations query your AWS services according to a polling interval, which varies depending on the integration. Each polling interval occurs for every AWS entity. For example, if you have thirteen Elastic Load Balancers (ELB), each one will be polled every five minutes. Depending on the AWS integration, there may be delays in the timing between the API request and the metric data returned. If you notice unusual delays, follow the integration troubleshooting procedures. PPM (pages per minute) The number of pages per minute your application serves. private location A Synthetic monitor feature that allows you to run Synthetic monitors from within your own systems by creating private minions. Private locations allow you to extend your Synthetic coverage to new geographical locations, and to monitor websites behind your firewall such as an intranet site. For more information, see Private locations overview. recovery period A recovery period of time begins when a data source enters a non-violating state after being in a violating state. The recovery period is set in the condition's threshold. A violation will close when a source remains in a non-violating state and the recovery period time has elapsed. If the data source enters a violating state before the time has elapsed, the recovery period clock will reset and the violation won't close. response time The duration of time between a request for service and a response. For more information, see Response time. restricted user A type of user role on a New Relic account. For more information, see Users. rollup Using the same application name for multiple applications. This allows you to combine data in APM, either from multiple applications, or from multiple instances of an application. For more information, see Rolling up app data. root span For distributed tracing, the root span is the first span in a trace. In many cases, the root span duration will represent the duration of the entire trace, or be very close to it. However, for more complex, modern systems that use a lot of asynchronous, non-blocking processes, this will not be true. For those systems, the root span’s duration may be significantly less than the duration of the trace. RPM The term RPM usually refers to the number of requests per minute your application receives from users. This is usually the same as CPM (calls per minute). Historically, some New Relic monitoring solutions, like APM and Browser Monitoring, used to contain RPM in the URL; for example, https://rpm.newrelic.com. This language use originally referred to Rails performance management because the first iteration of our product monitored Ruby on Rails applications. We monitor many more languages and systems than Ruby now. RUM (real user monitoring) See page load timing. runbook A runbook contains standard procedures and operations typically used by system administrators, network operations staff, and other personnel to handle outages, alert incidents, and other situations. If your organization stores runbook instructions as URLs, you can link this information to an alerts policy so your personnel has easy access to this information when an incident violates the defined policy thresholds. SAML (Security Assertion Markup Language) SAML is an XML-based data format for sharing authentication data between two parties. New Relic accounts must obtain a SAML certificate in order to enable Single Sign On for their users. For more information, see SAML service providers. Selenium Selenium is an open-source browser testing suite. Synthetics uses Selenium to test monitored websites with real browsers. For more information, see monitor types. service A service is a cluster of runtime server processes that accomplish a particular task, usually service requests. Unlike an application, a service is not usually invoked by a human. New Relic offers a variety of integrations that allow you to report data from your services. signal The stream of telemetry data that's watched and alerted on. You use NRQL queries to define a signal. signal filter When we receive data and it's routed to the streaming alerts platform, your NRQL WHERE clause will filter the data coming in. The filtered streaming data is what's evaluated for loss of signal violations, for example. span In a distributed trace, a span is a \"named, timed operation representing a contiguous segment of work in that trace\" (from OpenTracing.io definition). For distributed tracing, spans are displayed in the distributed tracing UI, and the data type Span is available to be queried. See also root span. SSL certificate SSL certificates encrypt data that is being transmitted. While New Relic refers to security certificates as SSL because it is a more commonly used term, all certificates adhere to industry standards for secure encryption in transit. SSO (single sign on) SSO (single sign on) allows you to manage user authentication in New Relic using an external SSO provider. For more information, see Setting up SSO. streaming algorithm This is what determines when the data in an aggregation window is processed. The streaming algorithm uses your server's clock time and the aggregation window size to trigger the alert evaluation process. sub-accounts See master account. Synthetic monitoring Synthetic monitoring allows you to monitor your website or API endpoint via automated, scriptable tools. Use free ping monitor to ensure your website is accessible, or expand your monitoring with browser monitors, which test your website with real browsers. Go further with scripting, to script browsers or API monitors for sophisticated testing. target A target is a resource or component monitored by a New Relic monitoring tool that has been identified in an alert condition. When the data source for that target crosses the defined critical threshold, we will open a violation. Depending on your policy's Incident preference setting, Alerts may create an incident record and send notifications through the defined channels. See also entity. tag Tags are key:value metadata added to monitored apps, hosts, dashboards, and other entities to help you organize your data at a high level. For details, see Tags. thresholds Thresholds are alert condition settings that define a violation. Threshold values include the value a data source must pass to trigger a violation and the time-related settings that define a violation; for example: Passing a certain value for at least x minutes Passing a certain value only once in x minutes While the data source passes a certain value, a degradation period starts. Likewise, when that data source stops passing a certain value, a recovery period starts. The durations of these two time periods are defined in the alert condition threshold settings. Thresholds have a required critical (red) threshold and an optional warning (yellow) threshold. In the UI, the entity's health status indicator will change to yellow or red when a threshold has been crossed and a violation will open. For more information, see Define thresholds. For an explanation of how thresholds relate to other basic Alerts concepts, see Concepts and workflow. throughput Throughput is a measurement of user activity for a monitored application. APM throughput and Browser Monitoring throughput are measured in different ways: APM: requests per minute (RPM) Browser: page views per minute (PPM) tier A tier can refer to how New Relic categorizes or visualizes the various agent language ecosystems that we support. For example: In APM, the color-coded categories that appear on your app's main Overview chart show response time spent in various functions, processes, or agents as tiers; for example, request queuing, garbage collection, Middleware, JVMs, etc. In New Relic labels, TIER can be used to define or classify the client-server architecture; for example, front-end and back-end tiers. \"Tier\" may sometimes be used to refer to our pricing editions. time picker By default the New Relic UI shows data for the past 30 minutes, ending now. To change the time window, use the time picker. time range A time range can refer to a length of time selected in the New Relic UI. New Relic displays a time range depending on the range you select using the time picker. timeslice data See metric timeslice data. trace A trace is a description of how a request travels through a system. Trace data helps you understand the performance of your system and diagnose problems. For more information on how we use trace data, see New Relic data types. traffic light See health status. transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. For more information, see documentation about web transactions and non-web transactions. The term transaction is also sometimes used in Browser Monitoring. In that case, it primarily refers to activity beginning with a browser-side web request and ending with a complete page load. transaction trace A transaction trace is a complete picture of a single transaction, down to the database queries and exact invocation patterns. With transaction traces, New Relic gives you much deeper visibility into a single slow transaction, which can help you understand a broader problem. For more information, see Transaction traces. UI The New Relic user interface. For more information, see Standard page functions. user A user can refer to a specific user role in a New Relic account. For more information, see Users. UTC Universal Time Coordinated (UTC), or Coordinated Universal Time, is a standard timestamp for synchronizing time around the world. value function (metrics) The numeric value obtained from metric timeslice data; for example, an average, minimum, maximum, total, sample size, etc. violation A violation occurs when the entity monitored by an alert condition reports a value that crosses the thresholds defined in that condition. For an explanation of how violations relate to other basic alerts concepts, see Concepts and workflow. You can view a summary of the violations for a selected incident's page. You can also view the violations for a specific entity from the product's UI. web external Web external is the term applied to the portion of time spent in transactions to external applications from within the code of the application you are monitoring. That time can be a call to a third party company (a payment provider, for example) or it could be a call to another microservice within your own company. Web external demonstrates how performance is impacted by your code executing outside the application you are measuring. web transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. Web transactions are initiated with an HTTP request. For most organizations, these represent customer-centric interactions and thus are the most important transactions to monitor. For more information, see Web transactions and Non-web transactions. WebDriverJS WebDriver is a Selenium component, used to control Synthetics scripted browsers. Specifically, Synthetics uses WebDriverJS, a Node.js-based flavor of Selenium. For more information, see Writing scripted browsers and Scripted browser examples. workload A workload represents a group of entities that work together to provide a digital service. For more information, see Workloads.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.93416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Glossary of <em>New</em> <em>Relic</em> terms",
        "sections": "Glossary of <em>New</em> <em>Relic</em> terms",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " line interface (CLI) is a tool you can <em>use</em> to build a <em>New</em> <em>Relic</em> application. This is the same tool our own engineers <em>use</em>. Go here for quick <em>start</em> instructions. Go to our Developer site for sample apps and guides. compute unit (CU) A unit of measurement that determines your pricing for some <em>New</em> <em>Relic</em>"
      },
      "id": "61b40189196a672dd0a5aa8c"
    },
    {
      "sections": [
        "Choose your data center (US or EU)",
        "Requirements",
        "Regions and availability",
        "Regions and account hierarchy",
        "Hierarchy example for partnership accounts",
        "Create an EU region account",
        "API endpoints for EU region accounts",
        "Access New Relic One",
        "Billing and pricing",
        "Operational access and processing",
        "Verify your account is based in EU region"
      ],
      "title": "Choose your data center (US or EU)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "58aede83cf1625a8a52aaeed540cebfbaa024d61",
      "image": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/images/Eu_account_hierarchy.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/",
      "published_at": "2021-12-30T08:15:40Z",
      "updated_at": "2021-12-14T04:22:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's global data hosting structure consists of two regions: the European Union (EU) region and the United States (US) region. Selecting your preferred region during the account setup process allows you to specify the region where your performance monitoring data will be hosted. You can also create accounts in each region. Requirements Access to the New Relic EU region requires the latest agent version. For new customers: Install the most recent agent version. For existing customers: Update to the most recent agent version. Minimum agent version required: C SDK 1.0.0 or higher Go 2.0.0 or higher Java 4.0.0 or higher .NET 8.0.0 or higher Node.js 3.0.0 or higher PHP 8.0.0.204 or higher Python 3.0.0.89 or higher Ruby 5.0.0.342 or higher Regions and availability Your choice of data center is not limited by your geographic location. You can choose to create an account with data hosted in either the EU or US region, regardless of where you or your systems reside. You can also create accounts in each region. New Relic offers almost all the same active products, features, support offerings, and performance levels in the EU region as what is offered in the US region. Exceptions: The following are not supported with an EU region account: Infinite Tracing is not available. APM's weekly performance reports are not available. Errors inbox is not available. Log patterns Deprecated products and features are not available. New Relic's Incident Intelligence service operates solely in the US whether you store your data in New Relic’s US region data center or New Relic’s EU region data center, by using New Relic Incident Intelligence, you consent that New Relic may move and store your data in the US region. New Relic CodeStream operates solely in the US. Whether you have selected New Relic's US or EU region data center during setup of your New Relic account, when using New Relic CodeStream, you consent that your New Relic CodeStream data will get stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted in the US region, you must create a new account to store data in the EU region. You cannot view EU data from a US account, or US data from an EU account. The data collected remains separate. The data cannot be aggregated or migrated between accounts. For organizations that have a parent/child account structure, you can only have one parent account. For more, see Manage apps or users with child accounts. For partnership accounts, no changes to the partnership owner account are required. However, data cannot be shared across regions, so a partnership requires a parent account for each region. Hierarchy example for partnership accounts With partnership accounts, a new parent account must be created for any data to be host in the EU region. This hierarchy illustrates how global accounts are structured with partnership owner accounts. Data is not aggregated beyond the parent account. Example hierarchy for partnership organizations. Because data cannot be shared across regions, a partnership will require a parent account for each region. Create an EU region account To create a New Relic account in the EU region: Go to the New Relic signup page. OR If you have a specific offer from a New Relic partner, follow that link directly. Follow the online steps to create your account. From the Select your region dropdown, select European Union. Agree to the Terms of Service. When you receive an email confirmation message, select the link to confirm your account and sign in to New Relic. Then install or update to the most recent agent version. API endpoints for EU region accounts If you have an EU region account, use the appropriate endpoints to access the following New Relic APIs: API EU endpoint Browser source maps API sourcemaps.service. eu .newrelic.com Copy Infrastructure Alert API infra-api. eu .newrelic.com Copy Dashboard API rpm. eu .newrelic.com/api/explore/dashboards/list Copy Insert API insights-collector. eu01 .nr-data.net Copy Insights Query API insights-api. eu .newrelic.com Copy Mobile apps rpm. eu .newrelic.com/mobile Copy NerdGraph GraphiQL API api. eu .newrelic.com/graphiql Copy Partner API The partner API is a global API with no regional data differences. Use this endpoint for both EU and US accounts: rpm.newrelic.com/api/v2/partners/ Copy REST API api. eu .newrelic.com Copy Synthetics API synthetics. eu .newrelic.com/synthetics/api Copy Trace API trace-api. eu .newrelic.com/trace/v1 Copy Metric API metric-api. eu .newrelic.com/metric/v1 Copy Log API log-api. eu .newrelic.com/log/v1 Copy Access New Relic One If your accounts report data to the EU data center, use the following link to go to New Relic One: one.eu.newrelic.com. Billing and pricing New Relic's account billing process and pricing options are the same for both the EU and US regions. Operational access and processing Customer Data is hosted in the region selected during account creation. Systems Operations Data is stored in the US region. All other information, including account information (such as license subscription information, billing, and internal monitoring) is hosted in the US region and replicated in the EU region. New Relic may access and process Customer Data in the United States and such other jurisdictions where New Relic has affiliates and subsidiaries, including as may be necessary to maintain, secure, or perform the services, to provide technical support, or as necessary to comply with law or a binding order of a government body. Customer Data from existing New Relic accounts cannot be transferred or shared across regions, and new data generated cannot be shared with existing accounts, even in partnership accounts. Verify your account is based in EU region Use either of these options to verify whether your account data is hosted in the EU region's data center: In APM, mouse over the application name to view the URL. If it begins with rpm.eu.newrelic.com/, it is an EU-based account. Check your New Relic license key. If it begins with EU, it is an EU-based account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.83618,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Access <em>New</em> <em>Relic</em> One",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>New</em> <em>Relic</em>&#x27;s US or EU region data center during setup of your <em>New</em> <em>Relic</em> account, when <em>using</em> <em>New</em> <em>Relic</em> CodeStream, you consent that your <em>New</em> <em>Relic</em> CodeStream data will <em>get</em> stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted"
      },
      "id": "61b81bf6e7b9d2a96fef4e3a"
    },
    {
      "sections": [
        "Find help and use the Support portal",
        "Ask in New Relic's Explorers Hub, our free forum",
        "Run the New Relic Diagnostics tool",
        "Find answers in New Relic Docs and New Relic University",
        "Contribute to our documentation",
        "Don't find what you need? File a documentation issue",
        "File a ticket in the support portal",
        "Important",
        "Check the status of our systems",
        "Licenses and security information"
      ],
      "title": "Find help and use the Support portal",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "ce14a732f0aae92aa495e61aac701f6880378a3d",
      "image": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/find-help-use-support-portal/images/new-relic-explorers-hub.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/find-help-use-support-portal/",
      "published_at": "2021-12-30T03:16:22Z",
      "updated_at": "2021-12-14T04:10:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of support options, including online help, a troubleshooting tool, open source documentation with detailed procedures and troubleshooting tips, and support assistance. Ask in New Relic's Explorers Hub. Run the New Relic Diagnostics tool. Find answers in New Relic Docs and New Relic University. Contribute to our documentation. Don't find what you need? File a documentation issue. File a ticket in the support portal. Check the status of our systems. Read about our licenses, data security, and compliance information. Ask in New Relic's Explorers Hub, our free forum New Relic's Explorer Hub is our forum that's free for all users. New Relic users and employees engage every day in conversations to troubleshoot and solve issues, find workarounds, and discuss new features. discuss.newrelic.com: The Explorer Hub is our public forum. Use it to ask questions and find answers. Join our community of users to learn more about New Relic and get some inspiration. Run the New Relic Diagnostics tool New Relic Diagnostics is our automated diagnostic tool for Linux, Windows, and Mac. If it detects a problem with any of our agents, it suggests solutions and saves troubleshooting logs that you can attach to tickets. Find answers in New Relic Docs and New Relic University New Relic's docs site contains helpful installation, configuration, and troubleshooting tips. From the main page, select from frequently-used categories and topics, like release notes. Or, search from any page. For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. Contribute to our documentation Our documentation is open source and available in GitHub, and we encourage you to contribute! We really care about ensuring our docs are helpful, complete, and accurate. To edit a page, click the Edit page button in any document to create a pull request with the edit you think is needed. We don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. docs.newrelic.com: At the right-hand side of each page you'll find a feedback widget. Use it to tell us whether a page is helpful, create an issue, or edit the page. Don't find what you need? File a documentation issue If you can't find an answer in the documentation, you can file an issue to ask us for help. When you find places the docs could be better, let us know too! To do it, click the Create issue button in any document and we'll look into your problem to find a solution. docs.newrelic.com: At the right-hand side of each page you'll find a feedback widget. Use it to tell us whether a page is helpful, create an issue, or edit the page. File a ticket in the support portal If none of the above methods worked, go to support.newrelic.com. The Support portal gives you access to unified search across all of New Relic's help resources. If you can't find what you are looking for and your subscription level includes technical support, you can file a support ticket. Important Support for beta or limited release features may not be available. To file a new ticket: Go to support.newrelic.com > Login. From the Support portal, select the area of New Relic where you need help. Select your account. Provide as many details as possible. Include the URL, if applicable, or select Attach file to include a log file, a New Relic Diagnostics file, screenshots, or other useful attachments. Click Submit. Check the status of our systems It's always a good idea to visit status.newrelic.com to check the status of our systems. If there are open incidents, you'll be able to find more information. Licenses and security information Review New Relic's licenses, attributions, and other notices. Read about our data security, privacy, and compliance policies.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.81837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find help and <em>use</em> the Support portal",
        "sections": "Ask in <em>New</em> <em>Relic&#x27;s</em> Explorers Hub, our free forum",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>Relic</em>&#x27;s Explorer Hub is our forum that&#x27;s free for all users. <em>New</em> <em>Relic</em> users and employees engage every day in conversations to troubleshoot and solve issues, find workarounds, and discuss <em>new</em> features. discuss.newrelic.com: The Explorer Hub is our public forum. <em>Use</em> it to ask questions and find"
      },
      "id": "603eb6b5e7b9d299072a07e5"
    }
  ],
  "/docs/using-new-relic/welcome-new-relic/get-started/networks": [
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2021-12-31T01:40:19Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.98337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> <em>New</em> <em>Relic</em> ",
        "sections": "<em>Install</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "After you sign up for a <em>New</em> <em>Relic</em> account (it&#x27;s free, forever!) and <em>install</em> any of our monitoring services, you can start working with your data. Get started quickly with our <em>New</em> <em>Relic</em> Instant Observability quickstarts. Alternatively, <em>use</em> our guided <em>install</em>. Here are links to instructions on how"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    },
    {
      "sections": [
        "Notification of changes to New Relic SaaS features and distributed software",
        "What we communicate",
        "Lead time for notifications",
        "EOL lead times: impact on distributed software",
        "Subject to EOL lead times:",
        "EOL lead times not applicable:",
        "Questions about EOL notifications?"
      ],
      "title": "Notification of changes to New Relic SaaS features and distributed software",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "9a6b696d32c2863811e2df52d736ed2428228a93",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/end-of-life/notification-changes-new-relic-saas-features-distributed-software/",
      "published_at": "2021-12-30T02:53:29Z",
      "updated_at": "2021-12-14T04:01:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we support our customers by continually improving our Software as a Service (SaaS) features and distributed software. Sometimes that means we introduce changes that can include moving away from existing software components and features, called end-of-life (EOL). As we make these decisions, we strive to balance the need to introduce improvements with our customer’s tolerance for change. We do our best to anticipate the impact of these changes for our customers. What we communicate We're committed to communicating about the changes that impact user experience, especially when these changes have a significant effect on workflow. In assessing impact we evaluate: Potential impact to customer workflow Feature usage information Customer feedback In communicating changes, we strive to: Give as much lead time as possible Minimize interruption Provide a documented alternative Lead time for notifications EOL changes are classified into the following categories: Transition impact Description Notification lead time Low Limited changes to customer processes or procedures are anticipated. None to 90 days Moderate Changes to functionality are limited in scope. Actions such as upgrading retired agents to supported versions may be required. Minimum of 90 days High Changes are highly impactful to customers and will require significant investment from customers to adapt. Minimum of 180 days Critical A third party dependency, security issue, or other critical risk causes an urgent need to change or remove functionality on an accelerated timeline. Notified as soon as reasonably practical EOL lead times: impact on distributed software Subject to EOL lead times: Our lead time notifications also apply to distributed software, which is software developed by New Relic that is installed on customer-owned systems. Distributed software is not cloud-based, and has a lifespan from the date of each released version. After that date, it may cease to function or stop reporting data to New Relic. We have fully open sourced many of our distributed software projects as community projects. We also participate in many community-led software development projects. If we have not open sourced our software projects, or if we have designated them as Community Plus projects, the following timeframes apply to them: Released on or after October 1, 2020: These projects will be compatible with our SaaS offering for at least two years after the date of publishing the release. Released prior to October 1, 2020: These projects will be compatible for at least three years after the date of publishing the release. All fixes and security updates are provided in the latest released version of distributed software, and we encourage our customers to keep installed software up to date. In the event a released version of software will cease normal function sooner than two (or three) years, New Relic will follow the EOL process. EOL lead times not applicable: Some of our distributed software have been open sourced, are designated as such, and are available at github.com/newrelic, including: Community projects New Relic One catalog Example code New Relic experimental Archived Our EOL policy does not apply to these projects, which is why we do not provide advance EOL notification for them. However, you can still find information and support for selected projects through: New Relic's documentation at docs.newrelic.com Project repos at github.com/newrelic Questions about EOL notifications? Share any questions or comments with us in New Relic’s Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.02713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of changes to <em>New</em> <em>Relic</em> SaaS features <em>and</em> distributed software",
        "sections": "Notification of changes to <em>New</em> <em>Relic</em> SaaS features <em>and</em> distributed software",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": " that is installed on customer-owned systems. Distributed software is not cloud-based, and has a lifespan from the date of each released version. After that date, it may cease to <em>function</em> or stop reporting data to <em>New</em> <em>Relic</em>. We have fully open sourced many of our distributed software projects as community"
      },
      "id": "604454f4e7b9d261f3579a03"
    },
    {
      "sections": [
        "Uninstall New Relic agents",
        "Before you uninstall",
        "Important",
        "Uninstall APM",
        "Remove apps from UI",
        "Uninstall browser agent",
        "Uninstall infrastructure agent",
        "Delete account",
        "Uninstall other tools"
      ],
      "title": "Uninstall New Relic agents",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "15ae05c4370739bb72086bc5bd3ac2e00c438f09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/uninstall-agent/",
      "published_at": "2021-12-30T20:03:34Z",
      "updated_at": "2021-12-14T03:51:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require installation of an agent. You can uninstall the agent if you want it to stop reporting data. If you need to uninstall New Relic completely, follow the procedures for your agent. If you encounter problems, see support.newrelic.com. Before you uninstall Important For paying New Relic accounts, note that an alternative option to uninstalling is to downgrade your account to a less expensive or free tier. Uninstall APM After uninstalling APM agents or making a change to your startup script, you must restart your app (or the app server or web server where it is located). You must do this because New Relic agents typically run in the memory of the process running the app. Simply removing those files will not stop the applications that are currently running from sending data to New Relic. C SDK Go Java .NET Node.js PHP Python Ruby Remove apps from UI See Remove apps from UI. Uninstall browser agent Choose a procedure: Disable browser agent on specific pages Uninstall browser agent Uninstall infrastructure agent Choose a procedure: Uninstall infrastructure agent Uninstall a cloud or on-host integration Delete account See Downgrade/cancel your account. Uninstall other tools For uninstall instructions for solutions not listed here, see the docs for a specific New Relic solution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.01126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall <em>New</em> <em>Relic</em> agents",
        "sections": "Uninstall <em>New</em> <em>Relic</em> agents",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require installation of an agent. You can uninstall the agent if you want it to stop reporting data. If you need to uninstall <em>New</em> <em>Relic</em> completely, follow the procedures for your agent. If you encounter problems, see support.newrelic.com. Before you uninstall Important"
      },
      "id": "61c087d064441fd18799eba6"
    }
  ],
  "/docs/using-new-relic/welcome-new-relic/optimize-your-cloud-native-environment/establish-objectives-baselines-define-team-slos": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/3a9f13f0b98dead811d9f7f56cc2a594/1f083/catalyst-establish-objectives-1_4.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2021-12-30T06:23:52Z",
      "updated_at": "2021-12-30T06:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. rpm.newrelic.com > Service maps: To explore detailed granularity for any area, use the service map's nodes. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 3304.245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Establish</em> <em>objectives</em> <em>and</em> <em>baselines</em>: <em>define</em> <em>team</em> <em>SLOs</em>",
        "sections": "<em>Establish</em> <em>objectives</em> <em>and</em> <em>baselines</em>: <em>define</em> <em>team</em> <em>SLOs</em>",
        "body": " <em>objectives</em> (<em>SLOs</em>) provide a powerful mechanism to codify the goals of a DevOps <em>team</em> in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Set proactive alerting: understand and respond to performance issues",
        "Prerequisites",
        "1. Define required alerting policies based on Service Level Objectives",
        "2. Set specific alerts for performance, correctness, throughput, availability, and dependencies",
        "3. Identify groups to alert, and set broadcasting methods",
        "4. Leverage AI to fine-tune alerts and seek anomalies",
        "5. Create an alerts dashboard",
        "Conclusion"
      ],
      "title": "Set proactive alerting: understand and respond to performance issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "3036c581a382835ed21eedf4f73eca196a2f9162",
      "image": "https://docs.newrelic.com/static/49cfe6b2c2181499588c35b9720a1e4f/c1b63/new-relic-recent-anomalies-view.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/set-proactive-alerting-understand-respond-performance-issues/",
      "published_at": "2021-12-31T13:36:45Z",
      "updated_at": "2021-12-30T03:15:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term \"alerting\" often carries some negative connotations; for too many developers, alerting correlates too closely with errors, mistakes, and ongoing issues. However, for developers who are proactive about alerting, they know they don’t have to stare at their dashboards all day, because effective alerts will tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Alerts can become overwhelming, so tune alerts and leverage AI so you get alerted on what matters. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the tutorial Establish objectives and baselines before you begin this one. Optional: added custom attributes and events. 1. Define required alerting policies based on Service Level Objectives A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, “95% of requests completed within 250 ms AND availability is 99.99%”), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it’s meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than .20%. However, not every SLO needs to become an alert. A strong alert strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature DevOps customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic DevOps customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alert strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use Synthetic monitoring pings to determine if the site is up and scripted checks to determine that the most important capabilities (such as a checkout cart) are working. How's our underlying infrastructure? Set KPIs for key hardware, virtual hosts, containers, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie that to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site’s availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don’t yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (select an alert policy) > (select an alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we’ve set both a warning and a violation for throughput: alerts.newrelic.com > (select an alert policy) > (select an alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier -- this can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic approximately evenly across five different servers. You can set an alert based on a NRQL query, and notification to be sent if any server starts getting significantly more or less traffic than the other servers. Here’s the graph: alerts.newrelic.com > (select an alert policy) > (select an alert condition) > Define thresholds And here’s a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups to alert, and set broadcasting methods Alerting without the proper broadcasting methods leaves you vulnerable. Your alerts strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the the types of alerts that warrant waking someone up. 4. Leverage AI to fine-tune alerts and seek anomalies To ensure you aren't training your teams to turn off or ignore notifications, keep your alerts valid and fresh. As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. To keep alerts to a minimum, leverage New Relic Applied Intelligence features, such as Incident Intelligence, which correlates related alerts into one actionable issue combining machine learning and manual input. Check to make sure alerts are correlated correctly and train your system to obtain the most accurate incident correlation. An additional way to reduce alert noise is by flapping detection and suppression. When an issue is \"flapping,\" it is cycling between an open and resolved state, creating a new alert every time it cycles. Effectively handling these can reduce the number of total alerts sent to your team. Finally, when you have maintenance scheduled, take advantage of alert muting rules to suppress those alerts you don't need. Now that you have tuned your alerts to valid notifications, you can proactively go after anomalies so you can fix issues before they become incidents. Enable Proactive Detection of anomalies and set some level of notification for them. 5. Create an alerts dashboard Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use NRQL to create your dashboards. For example, the dashboard above was created using the following NRQL queries: Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you’re using. For a more extensive discussion on notification channels, refer to the incident orchestration tutorial. Conclusion Establishing a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or infrastructure. With proactive alerting, you will decrease user-reported incidents, and allow your teams to spend less time firefighting and more time deploying significant changes to your product.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.37842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proactive alerting: understand <em>and</em> respond to performance issues",
        "sections": "1. <em>Define</em> required alerting policies based on Service Level <em>Objectives</em>",
        "body": ". Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the tutorial <em>Establish</em> <em>objectives</em> and <em>baselines</em> before you begin this one. Optional: added custom attributes and events. 1. <em>Define</em> required alerting policies based on Service Level <em>Objectives</em> A service level"
      },
      "id": "60445b8764441fe7fd378ee5"
    },
    {
      "sections": [
        "Customer experience improvement: track experience indicators",
        "Prerequisites",
        "1. Use custom attributes to associate performance data",
        "Tip",
        "2. Create dashboards with performance and business metrics",
        "3. Share dashboards across departments",
        "4. Utilize data to separate performance by cohort and debug issues at the customer level"
      ],
      "title": "Customer experience improvement: track experience indicators",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "78b347edcf28e1492126b1df1a82fb78ba147483",
      "image": "https://docs.newrelic.com/static/65dadbef1fe9c07817f7ead13e12e05e/302a4/Insights-catalyst-dashbaord-1.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/customer-experience-improvement-track-experience-indicators/",
      "published_at": "2021-12-31T13:46:56Z",
      "updated_at": "2021-12-30T03:14:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This tutorial covers methods to identify and track the key indicators of customer experience and clarifies the effect of application performance on your business. A clear understanding of what creates successful customer experience helps DevOps teams drive greater efficiencies in work efforts and deliver greater productivity. An efficient, well-functioning DevOps culture enables organizations to make rapid, frequent releases and product changes. A strong DevOps culture also democratizes data beyond the typical backend users, and makes it available to groups like customer service, support, sales, and marketing. However, this data information enablement is only useful if its purpose is to improve and optimize customer experience. Prerequisites This tutorial assumes you’ve reviewed the Establish team dashboards tutorial. 1. Use custom attributes to associate performance data In order to relate performance data to user experience, you need to capture information that ties a particular user or customer to the front- and back-end transactions that are responsible for their interactions with your application. In New Relic, you collect this data with custom attributes. Tip If you plan to collect this information in both frontend and backend, be sure to forward custom attributes from APM to browser. Here are some common attributes to collect: User ID Organization or customer ID A/B testing cohort value High-value customer indicator Purchase value or product IDs (for e-commerce) If you’ve completed the Iterate and measure impact or Establish objectives and baselines tutorials, consider what service level objectives (SLOs) or key metrics you defined in those stages. New Relic recommends including attributes like the above to measure the impact of your changes and optimizations at a customer level—not only a performance level. 2. Create dashboards with performance and business metrics Using the attributes collected in Step 1, build dashboards to examine the impact of performance issues on your users. Additionally, to drive visibility across your teams, add dedicated widgets to the team dashboards you built in the Establish team dashboards . insights.newrelic.com > Dashboards For example, if you were collecting a custom username attribute, you could use NRQL queries like these to create your widgets for your New Relic Insights dashboard: Number of errors by username: SELECT count(*) FROM TransactionError FACET username Copy Median response time by username: SELECT percentile(duration,50) FROM Transaction FACET username Copy Total purchase value in transactions with errors: SELECT sum(purchaseTotal) FROM TransactionError FACET username Copy Tip If you include a FACET clause in your queries, you’ll be able to click into metric results to see corresponding change in the performance data. For more information on faceting, see Linking Between Dashboards to Drill Into Your Data. 3. Share dashboards across departments Dashboards, data, and metrics that nobody looks at or knows about might as well not exist. When considering how, or with whom, to share your dashboards, consider the following questions: Which teams are responsible for applications that have high levels of end-user interaction? What non-engineering teams could benefit from this information? Customer support: Could customer issues be resolved faster? Product/engineering: Could product make more informed roadmap decisions? Customer success: Can this data be used to make our customers more successful? Are there other teams that can benefit from cohort analysis that includes performance metrics? 4. Utilize data to separate performance by cohort and debug issues at the customer level After you create your dashboards, use them to scope issues affecting particular customers or sets of customers. For example, the following widget shows which apps have errors for a particular user: insights.newrelic.com > Dashboards Use attributes that track user and performance to set alerts on high priority users or customers. For example, you could include a WHERE clause in your NRQL queries to scope the results to a set of user IDs or customer IDs. Set alerts on any performance or business metric that is tied to these attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.62347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Create dashboards with performance <em>and</em> business metrics",
        "body": ") If you’ve completed the Iterate and measure impact or <em>Establish</em> <em>objectives</em> and <em>baselines</em> tutorials, consider what service level <em>objectives</em> (<em>SLOs</em>) or key metrics you defined in those stages. New Relic recommends including attributes like the above to measure the impact of your changes and optimizations"
      },
      "id": "60440f5f28ccbcf7dc2c60b2"
    }
  ]
}